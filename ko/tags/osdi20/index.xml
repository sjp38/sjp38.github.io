<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>osdi20 | hacklog</title>
    <link>/ko/tags/osdi20/</link>
      <atom:link href="/ko/tags/osdi20/index.xml" rel="self" type="application/rss+xml" />
    <description>osdi20</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>ko-kr</language><lastBuildDate>Sat, 19 Dec 2020 22:35:27 +0100</lastBuildDate>
    <image>
      <url>/img/tux.png</url>
      <title>osdi20</title>
      <link>/ko/tags/osdi20/</link>
    </image>
    
    <item>
      <title>OSDI 2020 발표 영상 감상</title>
      <link>/ko/post/osdi2020_videos_review/</link>
      <pubDate>Sat, 19 Dec 2020 22:35:27 +0100</pubDate>
      <guid>/ko/post/osdi2020_videos_review/</guid>
      <description>&lt;p&gt;차일 피일 미루고 있던 OSDI&#39;20 발표 영상 비디오를 휴가 기간동안 하루 한편이라도
보기로 했습니다.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;a-large-scale-analysis-of-hundreds-of-in-memory-cache-clusters-at-twitter&#34;&gt;A large scale analysis of hundreds of in-memory cache clusters at Twitter&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=OQtMM5vdhlI&amp;amp;feature=emb_title&#34;&gt;https://www.youtube.com/watch?v=OQtMM5vdhlI&amp;amp;feature=emb_title&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;트위터의 in-memory 캐시 시스템의 워크로드를 트레이스하고 그 특성을 분석한
논문입니다.  개인적으로 아래 내용이 흥미로웠습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;쓰기 리퀘스트가 많음.&lt;/li&gt;
&lt;li&gt;각 오브젝트의 크기는 작아서 (중간값이 200 바이트), 오브젝트별 메타데이터 (64
바이트) 가 공간을 많이 차지함.&lt;/li&gt;
&lt;li&gt;키의 크기가 밸류의 크기보다 그렇게 작지 않음.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;트레이스 데이터는 github[1] 통해 받을 수 있습니다.  압축해도 2.8TB, 압출 풀면
14TB 군요.&lt;/p&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://github.com/twitter/cache-trace&#34;&gt;https://github.com/twitter/cache-trace&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;aifm-high-performance-application-integrated-far-memory&#34;&gt;AIFM: High-Performance, Application-Integrated Far Memory&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=xHhaniGXTUg&amp;amp;feature=emb_title&#34;&gt;https://www.youtube.com/watch?v=xHhaniGXTUg&amp;amp;feature=emb_title&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;OS 수준에서의 fast network 기반 far memory 접근법은 어플리케이션의 수정이
필요없다는 장점을 갖지만 고정된 크기의 페이지 abstraction 에 따른 semantic
차이와 어플리케이션에 대한 지식이 없는 커널에서의 주요 오퍼레이션 수행으로 인해
성능이 떨어집니다.  AIFM 은 새로운 데이터 구조 abstraction 을 사용해 semantic
차이를 해결하고 user space 런타임 시스템을 사용해 kernel space 에서의 시간
낭비를 제거했습니다.  결과적으로 어플리케이션은 수정이 필요하지만 저자들은
약간의 수정일 뿐이라 주자합니다.  또다른 state-of-the-art (FastSwap,
EuroSys&#39;20) 대비 13배 성능 향상을 이뤘다는군요.&lt;/p&gt;
&lt;h2 id=&#34;linnos-predictability-on-unpredictable-flash-storage-with-a-light-neural-network&#34;&gt;LinnOS: Predictability on Unpredictable Flash Storage with a Light Neural Network&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=yzv9lcjxhAg&amp;amp;feature=emb_title&#34;&gt;https://www.youtube.com/watch?v=yzv9lcjxhAg&amp;amp;feature=emb_title&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;최신 고속 저장장치는 캐싱, 웨어레벨링, 가비지 콜렉션 등의 복잡한 내부 구조를
가지고 있어서, 각 I/O 에 대한 응답시간을 예측하기가 어렵습니다.  이에 대한 잘
알려진 해결책은 Hedging 입니다.  여러 SSD 를 준비해 두고, I/O 요청을 그 중
하나의 SSD 에 일단 던지고, 그 응답이 미리 지정된 한계치를 넘도록 돌아오지
않으면 해당 요청을 취소하고 다른 SSD 를 쓰는 것이죠.  한계치 만큼은 기다려야
한다는 게 약점입니다.  LinnOS 는 Hedging 과 유사하지만 각 SSD 로의 각 I/O 가
빠르게 처리될지 예측하는 신경망을 이용합니다.  이를 위해, 해당 신경망은 현재
I/O queue depth, 최근의 몇개 I/O 시 queue depth 와 latency 를 입력으로 받고 그
결과 레이턴시가 빠를지 느릴지만 예측합니다.  잘못된 예측으로 인한 문제를
처리하기 위해선 biased learning 과 예측 정확도에 따른 adaptive hedging 을
사용합니다.  신경망의 학습은 오프라인으로 이루어집니다.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
