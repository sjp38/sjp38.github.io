<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>projects | hacklog</title>
    <link>https://sjp38.github.io/categories/projects/</link>
      <atom:link href="https://sjp38.github.io/categories/projects/index.xml" rel="self" type="application/rss+xml" />
    <description>projects</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sun, 11 Feb 2024 10:05:34 -0800</lastBuildDate>
    <image>
      <url>https://sjp38.github.io/img/tux.png</url>
      <title>projects</title>
      <link>https://sjp38.github.io/categories/projects/</link>
    </image>
    
    <item>
      <title>Perfbook 2nd edition translation is complete</title>
      <link>https://sjp38.github.io/post/perfbook_2nd_edition_translation_complete/</link>
      <pubDate>Sun, 11 Feb 2024 10:05:34 -0800</pubDate>
      <guid>https://sjp38.github.io/post/perfbook_2nd_edition_translation_complete/</guid>
      <description>&lt;p&gt;After about 8 years of progress on my little hobby project[1], the Korean
translation of Paul E. McKenney &amp;lsquo;s book, I&amp;rsquo;m marking it as completed a humble
milestone[2].  It was a very fun and informative journey.&lt;/p&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://git.kernel.org/pub/scm/linux/kernel/git/paulmck/perfbook.git/commit/?id=edbfcdee0460&#34;&gt;https://git.kernel.org/pub/scm/linux/kernel/git/paulmck/perfbook.git/commit/?id=edbfcdee0460&lt;/a&gt;
[2] &lt;a href=&#34;https://lore.kernel.org/perfbook/20240211175355.4986-1-sj38.park@gmail.com/&#34;&gt;https://lore.kernel.org/perfbook/20240211175355.4986-1-sj38.park@gmail.com/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Starting perfbook translation again</title>
      <link>https://sjp38.github.io/post/perfbook_translate_restart/</link>
      <pubDate>Sat, 27 Mar 2021 13:01:07 +0100</pubDate>
      <guid>https://sjp38.github.io/post/perfbook_translate_restart/</guid>
      <description>&lt;p&gt;I stopped translation of perfbook since 2019-09-27.  Because the 2nd edition of
perfbook is released[0], I&amp;rsquo;m starting the translation again[1], from the
scratch.  The old versions are still available, of course[2].&lt;/p&gt;
&lt;p&gt;[0] &lt;a href=&#34;https://mirrors.edge.kernel.org/.../perfbook/perfbook.html&#34;&gt;https://mirrors.edge.kernel.org/.../perfbook/perfbook.html&lt;/a&gt;&lt;br&gt;
[1] &lt;a href=&#34;https://github.com/sjp38/perfbook-ko_KR/commit/1c44ef30179b&#34;&gt;https://github.com/sjp38/perfbook-ko_KR/commit/1c44ef30179b&lt;/a&gt;&lt;br&gt;
[2] &lt;a href=&#34;https://github.com/sjp38/perfbook-ko_KR-pdf&#34;&gt;https://github.com/sjp38/perfbook-ko_KR-pdf&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RCX: Read-Copy Transact</title>
      <link>https://sjp38.github.io/post/rcx/</link>
      <pubDate>Sat, 15 Feb 2020 09:11:55 +0100</pubDate>
      <guid>https://sjp38.github.io/post/rcx/</guid>
      <description>&lt;p&gt;Read-copy update (RCU) can provide ideal scalability for read-mostly workloads,
but some believe that it provides only poor performance for updates. This
belief is due to the lack of RCU-centric update synchronization mechanisms. RCU
instead works with a range of update-side mechanisms, such as locking. In fact,
many developers embrace simplicity by using global locking. Logging, hardware
transactional memory, or fine-grained locking can provide better scalability,
but each of these approaches has limitations, such as imposing overhead on
readers or poor scalability on non-uniform memory access (NUMA) systems, mainly
due to their lack of NUMA-aware design principles.&lt;/p&gt;
&lt;p&gt;This project introduces an RCU extension (RCX) that provides highly scalable
RCU updates on NUMA systems while retaining RCU’s read-side benefits. RCX
combines hardware transactional memory (HTM) and traditional locking based on
our NUMA-aware design principles for RCU. Micro-benchmarks on a NUMA system
having 144 hardware threads show RCX has up to 22.61 times better performance
and up to 145.00 times lower HTM abort rates compared to a state-of-the-art
RCU/HTM combination. To demonstrate the effectiveness and applicability of RCX,
we have applied RCX to parallelize some of the Linux kernel memory management
system and an in-memory database system. The optimized kernel and the database
show up to 24 and 17 times better performance compared to the original version,
respectively.&lt;/p&gt;
&lt;h2 id=&#34;source-code&#34;&gt;Source Code&lt;/h2&gt;
&lt;p&gt;The source code of RCX is available at: &lt;a href=&#34;https://github.com/rcx-sync&#34;&gt;https://github.com/rcx-sync&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;publications-and-presentations&#34;&gt;Publications and Presentations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;SeongJae Park, Paul E. McKenney, Laurent Dufour, Heon Y. Yeom, &lt;strong&gt;An HTM-Based
Update-side Synchronization for RCU on NUMA systems.&lt;/strong&gt; In &lt;em&gt;15th ACM European
Conference on Computer Systems (EuroSys)&lt;/em&gt;, April 2020.
&lt;a href=&#34;https://dl.acm.org/doi/abs/10.1145/3342195.3387527&#34;&gt;Paper&lt;/a&gt;,
&lt;a href=&#34;https://www.youtube.com/watch?v=QydRe1z5uYk&amp;amp;feature=youtu.be&#34;&gt;Video (Short)&lt;/a&gt;,
&lt;a href=&#34;https://www.youtube.com/watch?v=h7RzyhR_lPQ&amp;amp;feature=youtu.be&#34;&gt;Video (Long)&lt;/a&gt;,
&lt;a href=&#34;https://www.eurosys2020.org/wp-content/uploads/2020/04/slides/166_seongjae_slides.pdf&#34;&gt;Slides&lt;/a&gt;,
&lt;a href=&#34;https://www.eurosys2020.org/program/&#34;&gt;Link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;news&#34;&gt;News&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;2020-04-19&lt;/em&gt;: The EuroSys&#39;20 paper is uploaded at
&lt;a href=&#34;https://dl.acm.org/doi/abs/10.1145/3342195.3387527&#34;&gt;ACM DL&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;2020-04-04&lt;/em&gt;: The accepted papers list of EuroSys&#39;20 has
&lt;a href=&#34;https://www.eurosys2020.org/program/accepted-papers/&#34;&gt;uploaded&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;2020-02-14&lt;/em&gt;: The paper introducing RCX has accepted to be presented by
&lt;a href=&#34;https://www.eurosys2020.org/&#34;&gt;EuroSys&#39;20&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Linux Development History Visualization Youtube Channel</title>
      <link>https://sjp38.github.io/post/linux_develop_visualization_youtube/</link>
      <pubDate>Tue, 04 Jun 2019 10:44:33 +0900</pubDate>
      <guid>https://sjp38.github.io/post/linux_develop_visualization_youtube/</guid>
      <description>&lt;p&gt;I created a Youtube channel[1]. I will upload videos for the git history
between each release of the Linux kernel, just for jun. I use gource[2] for the
visualization for now. The scripts I use for these videos are available[3]
under GPL v3. If you want, you may use the scripts for your own video
generation.&lt;/p&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://www.youtube.com/channel/UCI7qoGt1hOfCsI8hFqriYCg&#34;&gt;https://www.youtube.com/channel/UCI7qoGt1hOfCsI8hFqriYCg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href=&#34;https://gource.io/&#34;&gt;https://gource.io/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[3] &lt;a href=&#34;https://github.com/sjp38/linux_development_visualization&#34;&gt;https://github.com/sjp38/linux_development_visualization&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DAPHICX: Data Access Pattern Hint Injecting Compiler Extension</title>
      <link>https://sjp38.github.io/post/daphicx/</link>
      <pubDate>Thu, 30 May 2019 18:59:53 +0900</pubDate>
      <guid>https://sjp38.github.io/post/daphicx/</guid>
      <description>&lt;p&gt;Memory pressure is inevitable as the size of working sets is rapidly growing
while the capacity of dynamic random access memory (DRAM) is not. Meanwhile,
storage devices have evolved so that their speed is comparable to the speed of
DRAM while their capacity scales are comparable to that of hard disk drives
(HDD). Thus, hierarchial memory systems configuring DRAM as the main memory and
high-end storages as swap devices will be common.&lt;/p&gt;
&lt;p&gt;Due to the unique characteristics of these modern storage devices, the swap
target decision should be optimal. It is essential to know the exact data
access patterns of workloads for such an optimal decision, although underlying
systems cannot accurately estimate such complex and dynamic patterns. For this
reason, memory systems allow programs to voluntarily hint their data access
pattern. Nevertheless, it is exhausting for a human to manually figure out the
patterns and embed optimal hints if the workloads are huge and complex.&lt;/p&gt;
&lt;p&gt;This project introduces a compiler extension that automatically optimizes a
program to voluntarily hint its dynamic data access patterns to the underlying
swap system using a static/dynamic analysis based profiling result. To our best
knowledge, this is the first profile-guided optimization (PGO) for modern swap
devices. Our empirical evaluation of the scheme using realistic workloads shows
consistent improvement in performance and swap device lifetime up to 2.65 times
and 2.98 times, respectively.&lt;/p&gt;
&lt;h1 id=&#34;publications-and-presentations&#34;&gt;Publications And Presentations&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;SeongJae Park, Yunjae Lee, Moonsub Kim Heon Y. Yeom, &lt;strong&gt;Automating Context
Based Access Pattern Hint Injection for System Performance and Swap Storage
Durability.&lt;/strong&gt; In 11th USENIX Workshop on Hot Topics in Storage and File
Systems (HotStorage), July 2019.
&lt;a href=&#34;https://www.usenix.org/system/files/hotstorage19-paper-park.pdf&#34;&gt;Paper&lt;/a&gt;,
&lt;a href=&#34;https://www.usenix.org/sites/default/files/conference/protected-files/hotstorage19_slides_park.pdf&#34;&gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SeongJae Park, Yunjae Lee, Moonsub Kim, Heon Y. Yeom, &lt;strong&gt;Automated Data Access
Pattern Hint Instrumentation for System Performance and Durability of Swap
Storages.&lt;/strong&gt; (WiP) In 17th USENIX Conference on File and Storage Technologies
(FAST), February 2019.
&lt;a href=&#34;https://www.usenix.org/conference/fast19/wips&#34;&gt;Link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Idle Page Tracking Tools</title>
      <link>https://sjp38.github.io/post/idle_page_tracking/</link>
      <pubDate>Wed, 13 Sep 2017 13:46:00 +0900</pubDate>
      <guid>https://sjp38.github.io/post/idle_page_tracking/</guid>
      <description>&lt;p&gt;&lt;code&gt;idle_page_tracking&lt;/code&gt;[1] is a simple, stupid toolbox for idle pages tracking.
It can be used to get real working set size of a process.&lt;/p&gt;
&lt;h1 id=&#34;tools&#34;&gt;Tools&lt;/h1&gt;
&lt;p&gt;This section describes two tools in the box though more tools exists.  You can
get more description about each tool from the README in the repository[1].&lt;/p&gt;
&lt;h2 id=&#34;userprog&#34;&gt;userprog&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;userprog&lt;/code&gt; is a sample synthetic workload for test of other tools.  It
interactively allocates and access specified pages in the allocated pages.
After execution, it first asks how many pages to allocates.  Once you type in
how many pages to allocate, the program will repeatedly asks how many pages in
the allocated pages you want to do access.&lt;/p&gt;
&lt;h2 id=&#34;wspagessh&#34;&gt;wspages.sh&lt;/h2&gt;
&lt;p&gt;Now you can calculate working set size of a process using the tools.  To
simplify the life even more, &lt;code&gt;wspages.sh&lt;/code&gt; helps the complicated works.  It
requires pid, time interval, and target memory mapped regions as argument.  The
third argument can be ignored.  In the case, it uses heap, stack, and anonymous
pages as target memory region by default.  If you give the arguments well, this
tool will prints out number of pages accessed between the time interval.
Simple example of usage and output is as below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo ./wspages.sh `pidof userprog` 1 [heap]
3
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;wspgstatsh&#34;&gt;wspgstat.sh&lt;/h2&gt;
&lt;p&gt;Like &lt;code&gt;*stat&lt;/code&gt; programs (such as vmstat, iostat, &amp;hellip;), wspgstat.sh monitors and
print out number of pages in working set of specific process repeatedly.  It
requires pid of target program, delay between idleness check, and target memory
mapped regions as arguments.  The third argument is optional and has default
value as same as wspages.sh&amp;rsquo;s same argument.  Simple example usage is as below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./wspgstat.sh `pidof mysqld` 5
1 17448
9 21536
18 21659
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;limitations&#34;&gt;Limitations&lt;/h1&gt;
&lt;p&gt;The tools use idle page tracking feature of the Linux kernel[2] internally.  It
means that the tools work on Linux systems that idle page tracking feature is
turned on.  You can check whether your system turned on or off the feature by
simply running the command below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ if [ -d /sys/kernel/mm/page_idle ]; \
        then echo &amp;quot;ON&amp;quot;; else echo &amp;quot;OFF&amp;quot;; fi
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It also shares limitation of idle page tracking feature of the Linux kernel.
It tracks only userspace pages on LRU list of the kernel.&lt;/p&gt;
&lt;h1 id=&#34;license&#34;&gt;License&lt;/h1&gt;
&lt;p&gt;GPL v3&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://github.com/sjp38/idle_page_tracking&#34;&gt;https://github.com/sjp38/idle_page_tracking&lt;/a&gt;&lt;br&gt;
[2] &lt;a href=&#34;https://www.kernel.org/doc/Documentation/vm/idle_page_tracking.txt&#34;&gt;https://www.kernel.org/doc/Documentation/vm/idle_page_tracking.txt&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>lkml livestream</title>
      <link>https://sjp38.github.io/post/lkml_go/</link>
      <pubDate>Sun, 28 May 2017 17:51:43 +0900</pubDate>
      <guid>https://sjp38.github.io/post/lkml_go/</guid>
      <description>&lt;p&gt;I wrote a simple, stupid program[1] that showing LKML[2] mails in terminal
briefly like twitter livestream in Go language.  It is just an early version
and so many things to be complemented exists, though.  Nevertheless, now it
just works as I wanted at first.&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://github.com/sjp38/lkml&#34;&gt;https://github.com/sjp38/lkml&lt;/a&gt;&lt;br&gt;
[2] &lt;a href=&#34;https://en.wikipedia.org/wiki/Linux_kernel_mailing_list&#34;&gt;https://en.wikipedia.org/wiki/Linux_kernel_mailing_list&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GCMA: Guaranteed Contiguous Memory Allocator</title>
      <link>https://sjp38.github.io/post/gcma/</link>
      <pubDate>Sat, 14 Jan 2017 23:11:23 +0900</pubDate>
      <guid>https://sjp38.github.io/post/gcma/</guid>
      <description>&lt;p&gt;The importance of physically contiguous memory has increased in modern
computing environments, including both low- and high-end systems. Existing
physically contiguous memory allocators generally have critical limitations.
For example, the most commonly adopted solution, the memory reservation
technique, wastes a significant amount of memory space. Scatter/Gather direct
memory access (DMA) and input-output memory management units (IOMMUs) avoid
this problem by utilizing additional hardware for address space virtualization.
However, additional hardware means an increase in costs and power consumption,
which is especially disadvantageous for small systems and they do not provide
real contiguous memory. Linux Contiguous Memory Allocator (CMA) aims to provide
both contiguous memory allocation and to maximize memory utilization based on
page migration, but they suffer from unpredictably long latency and a high
probability of allocation failure. Therefore, we introduce a new solution to
this problem, the guaranteed contiguous memory allocator (GCMA). This
guarantees efficient memory space utilization, short latency, and successful
allocation. The GCMA uses a reservation scheme and increases memory utilization
by sharing the memory with immediately discardable data. Our evaluation of a
GCMA on a Raspberry Pi 2 finds a latency that is 15-130 times lower compared to
a CMA, and a latency that is up to 10 times lower when taking a photo. Using a
large working set in a memory-fragmented high-end system, the GCMA is able to
produce a 2.27× speedup.&lt;/p&gt;
&lt;h1 id=&#34;source-code&#34;&gt;Source Code&lt;/h1&gt;
&lt;p&gt;The source code for this version has been submitted to &lt;a href=&#34;https://lkml.org/lkml/2015/2/23/480&#34;&gt;LKML&lt;/a&gt; for discussion.
A complete git tree is also available at &lt;a href=&#34;https://github.com/gcma-mm/linux&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&#34;publications-and-presentations&#34;&gt;Publications and Presentations&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;SeongJae Park, Minchan Kim, Heon Y. Yeom, &lt;strong&gt;GCMA: Guaranteed Contiguous
Memory Allocator.&lt;/strong&gt; In &lt;em&gt;Transactions on Computers&lt;/em&gt;, March 2019.
&lt;a href=&#34;https://ieeexplore.ieee.org/document/8456561&#34;&gt;Link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SeongJae Park, &lt;strong&gt;GCMA: Guaranteed Contiguous Memory Allocator.&lt;/strong&gt; In &lt;em&gt;The
Linux Kernel Summit&lt;/em&gt;, November 2018.
&lt;a href=&#34;https://linuxplumbersconf.org/event/2/contributions/247/attachments/74/85/gcma_ksummit2018.pdf&#34;&gt;Slides&lt;/a&gt;,
&lt;a href=&#34;https://www.youtube.com/watch?v=ARrelFfdVkw&#34;&gt;Video&lt;/a&gt;,
&lt;a href=&#34;https://linuxplumbersconf.org/event/2/contributions/247/&#34;&gt;Link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SeongJae Park, Minchan Kim, Heon Y. Yeom, &lt;strong&gt;GCMA: Guaranteed Contiguous
Memory Allocator.&lt;/strong&gt; In &lt;em&gt;45th issue of ACM SIGBED Review&lt;/em&gt;, January 2016.
&lt;a href=&#34;http://sigbed.seas.upenn.edu/archives/2016-01/EWiLi15_4.pdf&#34;&gt;Paper&lt;/a&gt;,
&lt;a href=&#34;http://sigbed.seas.upenn.edu/vol13_num1.html#issue&#34;&gt;Link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SeongJae Park, Minchan Kim, Heon Y. Yeom, &lt;strong&gt;GCMA: Guaranteed Contiguous
Memory Allocator.&lt;/strong&gt; In &lt;em&gt;Embedded Operating Systems Workshop (EWiLi)&lt;/em&gt;, October
2015.
&lt;a href=&#34;http://ceur-ws.org/Vol-1464/ewili15_12.pdf&#34;&gt;Paper&lt;/a&gt;,
&lt;a href=&#34;https://www.slideshare.net/SeongJaePark1/gcma-guaranteed-contiguous-memory-allocator&#34;&gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SeongJae Park, Minchan Kim, &lt;strong&gt;GCMA: Guaranteed Contiguous Memory Allocator.&lt;/strong&gt;
In &lt;em&gt;Linux Foundation Korea Linux Forum (LFKLF)&lt;/em&gt;, October 2014.
&lt;a href=&#34;http://events.linuxfoundation.org/sites/events/files/slides/gcma-guaranteed_contiguous_memory_allocator-lfklf2014_0.pdf&#34;&gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>&#34;Is Parallel Programming Hard, And, If So, What Can You Do About It?&#34; Translation</title>
      <link>https://sjp38.github.io/post/perfbook-kokr/</link>
      <pubDate>Tue, 10 Jan 2017 13:46:00 +0900</pubDate>
      <guid>https://sjp38.github.io/post/perfbook-kokr/</guid>
      <description>&lt;p&gt;&amp;ldquo;Is Parallel Programming is Hard, And, If So, What Can You Do About It?&amp;quot;[1] 은
parallel programming 분야에서 대가라 불릴만한 분으로, 이쪽 분야에서 매우 중요한
동기화 메커니즘인 RCU[2] 를 개발했으며 리눅스 커널의 RCU 메인테이너로 활동하고
있는 Paul E. McKenney[3] 가 오픈소스 방식으로 저술하고 있는, parallel
programming 에 대한 책입니다.&lt;/p&gt;
&lt;p&gt;개인적으로 이 책의 한국어 번역을 오픈소스[4]로 진행하고 있습니다.  이
프로젝트는 원저작자인 Paul 에게 공식 한국어 번역으로 인증받았습니다[5].&lt;/p&gt;
&lt;p&gt;컨트리뷰션에 대해서도 열려 있으니, 이에 관심 있는 분은 repository 내의 README
문서의 Contribution 섹션[6] 을 참고 바랍니다.&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://www.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html&#34;&gt;https://www.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html&lt;/a&gt;&lt;br&gt;
[2] &lt;a href=&#34;https://en.wikipedia.org/wiki/Read-copy-update&#34;&gt;https://en.wikipedia.org/wiki/Read-copy-update&lt;/a&gt;&lt;br&gt;
[3] &lt;a href=&#34;http://www.rdrop.com/~paulmck/&#34;&gt;http://www.rdrop.com/~paulmck/&lt;/a&gt;&lt;br&gt;
[4] &lt;a href=&#34;https://github.com/sjp38/perfbook-ko_KR&#34;&gt;https://github.com/sjp38/perfbook-ko_KR&lt;/a&gt;&lt;br&gt;
[5] &lt;a href=&#34;https://git.kernel.org/pub/scm/linux/kernel/git/paulmck/perfbook.git/commit/?id=edbfcdee046026d3f98592c411a20219b96c8e50&#34;&gt;https://git.kernel.org/pub/scm/linux/kernel/git/paulmck/perfbook.git/commit/?id=edbfcdee046026d3f98592c411a20219b96c8e50&lt;/a&gt;&lt;br&gt;
[6] &lt;a href=&#34;https://github.com/sjp38/perfbook-ko_KR#contribution&#34;&gt;https://github.com/sjp38/perfbook-ko_KR#contribution&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
