<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>projects | hacklog</title>
    <link>/categories/projects/</link>
      <atom:link href="/categories/projects/index.xml" rel="self" type="application/rss+xml" />
    <description>projects</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 04 Jun 2019 10:44:33 +0900</lastBuildDate>
    <image>
      <url>/img/tux.png</url>
      <title>projects</title>
      <link>/categories/projects/</link>
    </image>
    
    <item>
      <title>Linux Development History Visualization Youtube Channel</title>
      <link>/post/linux_develop_visualization_youtube/</link>
      <pubDate>Tue, 04 Jun 2019 10:44:33 +0900</pubDate>
      <guid>/post/linux_develop_visualization_youtube/</guid>
      <description>&lt;p&gt;재미 삼아 리눅스 커널 릴리즈 때마다 git history 를 visualize 해서 올리는 유투브
채널[1]을 개설해 봤습니다. 지금은 visualization 에는 gource[2] 를 사용하고
있습니다. 이 비디오를 만드는데 사용되는 스크립트도 GPL v3 로 공개[3]했으니
필요한 분은 사용해 보셔도 좋을 것 같습니다.&lt;/p&gt;
&lt;p&gt;I created a Youtube channel[1]. I will upload videos for the git history
between each release of the Linux kernel, just for jun. I use gource[2] for the
visualization for now. The scripts I use for these videos are available[3]
under GPL v3. If you want, you may use the scripts for your own video
generation.&lt;/p&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://www.youtube.com/channel/UCI7qoGt1hOfCsI8hFqriYCg&#34;&gt;https://www.youtube.com/channel/UCI7qoGt1hOfCsI8hFqriYCg&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href=&#34;https://gource.io/&#34;&gt;https://gource.io/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[3] &lt;a href=&#34;https://github.com/sjp38/linux_development_visualization&#34;&gt;https://github.com/sjp38/linux_development_visualization&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DAPHICX: Data Access Pattern Hint Injecting Compiler Extension</title>
      <link>/post/daphicx/</link>
      <pubDate>Thu, 30 May 2019 18:59:53 +0900</pubDate>
      <guid>/post/daphicx/</guid>
      <description>&lt;p&gt;Memory pressure is inevitable as the size of working sets is rapidly growing
while the capacity of dynamic random access memory (DRAM) is not. Meanwhile,
storage devices have evolved so that their speed is comparable to the speed of
DRAM while their capacity scales are comparable to that of hard disk drives
(HDD). Thus, hierarchial memory systems configuring DRAM as the main memory and
high-end storages as swap devices will be common.&lt;/p&gt;
&lt;p&gt;Due to the unique characteristics of these modern storage devices, the swap
target decision should be optimal. It is essential to know the exact data
access patterns of workloads for such an optimal decision, although underlying
systems cannot accurately estimate such complex and dynamic patterns. For this
reason, memory systems allow programs to voluntarily hint their data access
pattern. Nevertheless, it is exhausting for a human to manually figure out the
patterns and embed optimal hints if the workloads are huge and complex.&lt;/p&gt;
&lt;p&gt;This project introduces a compiler extension that automatically optimizes a
program to voluntarily hint its dynamic data access patterns to the underlying
swap system using a static/dynamic analysis based profiling result. To our best
knowledge, this is the first profile-guided optimization (PGO) for modern swap
devices. Our empirical evaluation of the scheme using realistic workloads shows
consistent improvement in performance and swap device lifetime up to 2.65 times
and 2.98 times, respectively.&lt;/p&gt;
&lt;p&gt;DAPHICX has introduced by the [FAST&#39;19 WiP]
(&lt;a href=&#34;https://www.usenix.org/conference/fast19/wips&#34;&gt;https://www.usenix.org/conference/fast19/wips&lt;/a&gt;) and the [HotStorage&#39;19]
(&lt;a href=&#34;https://www.usenix.org/conference/hotstorage19/presentation/park)&#34;&gt;https://www.usenix.org/conference/hotstorage19/presentation/park)&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Idle Page Tracking Tools</title>
      <link>/post/idle_page_tracking/</link>
      <pubDate>Wed, 13 Sep 2017 13:46:00 +0900</pubDate>
      <guid>/post/idle_page_tracking/</guid>
      <description>&lt;p&gt;&lt;code&gt;idle_page_tracking&lt;/code&gt;[1] is a simple, stupid toolbox for idle pages tracking.
It can be used to get real working set size of a process.&lt;/p&gt;
&lt;h1 id=&#34;tools&#34;&gt;Tools&lt;/h1&gt;
&lt;p&gt;This section describes two tools in the box though more tools exists.  You can
get more description about each tool from the README in the repository[1].&lt;/p&gt;
&lt;h2 id=&#34;userprog&#34;&gt;userprog&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;userprog&lt;/code&gt; is a sample synthetic workload for test of other tools.  It
interactively allocates and access specified pages in the allocated pages.
After execution, it first asks how many pages to allocates.  Once you type in
how many pages to allocate, the program will repeatedly asks how many pages in
the allocated pages you want to do access.&lt;/p&gt;
&lt;h2 id=&#34;wspagessh&#34;&gt;wspages.sh&lt;/h2&gt;
&lt;p&gt;Now you can calculate working set size of a process using the tools.  To
simplify the life even more, &lt;code&gt;wspages.sh&lt;/code&gt; helps the complicated works.  It
requires pid, time interval, and target memory mapped regions as argument.  The
third argument can be ignored.  In the case, it uses heap, stack, and anonymous
pages as target memory region by default.  If you give the arguments well, this
tool will prints out number of pages accessed between the time interval.
Simple example of usage and output is as below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo ./wspages.sh `pidof userprog` 1 [heap]
3
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;wspgstatsh&#34;&gt;wspgstat.sh&lt;/h2&gt;
&lt;p&gt;Like &lt;code&gt;*stat&lt;/code&gt; programs (such as vmstat, iostat, &amp;hellip;), wspgstat.sh monitors and
print out number of pages in working set of specific process repeatedly.  It
requires pid of target program, delay between idleness check, and target memory
mapped regions as arguments.  The third argument is optional and has default
value as same as wspages.sh&#39;s same argument.  Simple example usage is as below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./wspgstat.sh `pidof mysqld` 5
1 17448
9 21536
18 21659
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;limitations&#34;&gt;Limitations&lt;/h1&gt;
&lt;p&gt;The tools use idle page tracking feature of the Linux kernel[2] internally.  It
means that the tools work on Linux systems that idle page tracking feature is
turned on.  You can check whether your system turned on or off the feature by
simply running the command below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ if [ -d /sys/kernel/mm/page_idle ]; \
        then echo &amp;quot;ON&amp;quot;; else echo &amp;quot;OFF&amp;quot;; fi
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It also shares limitation of idle page tracking feature of the Linux kernel.
It tracks only userspace pages on LRU list of the kernel.&lt;/p&gt;
&lt;h1 id=&#34;license&#34;&gt;License&lt;/h1&gt;
&lt;p&gt;GPL v3&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://github.com/sjp38/idle_page_tracking&#34;&gt;https://github.com/sjp38/idle_page_tracking&lt;/a&gt;&lt;br&gt;
[2] &lt;a href=&#34;https://www.kernel.org/doc/Documentation/vm/idle_page_tracking.txt&#34;&gt;https://www.kernel.org/doc/Documentation/vm/idle_page_tracking.txt&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>lkml livestream</title>
      <link>/post/lkml_go/</link>
      <pubDate>Sun, 28 May 2017 17:51:43 +0900</pubDate>
      <guid>/post/lkml_go/</guid>
      <description>&lt;p&gt;I wrote a simple, stupid program[1] that showing LKML[2] mails in terminal
briefly like twitter livestream in Go language.  It is just an early version
and so many things to be complemented exists, though.  Nevertheless, now it
just works as I wanted at first.&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://github.com/sjp38/lkml&#34;&gt;https://github.com/sjp38/lkml&lt;/a&gt;&lt;br&gt;
[2] &lt;a href=&#34;https://en.wikipedia.org/wiki/Linux_kernel_mailing_list&#34;&gt;https://en.wikipedia.org/wiki/Linux_kernel_mailing_list&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GCMA: Guaranteed Contiguous Memory Allocator</title>
      <link>/post/gcma/</link>
      <pubDate>Sat, 14 Jan 2017 23:11:23 +0900</pubDate>
      <guid>/post/gcma/</guid>
      <description>&lt;p&gt;GCMA (Guaranteed Contiguous Memory Allocator) is a contiguous memory allocator
for Linux kernel that guarantees fast latency, success of allocation, and
reasonable system memory utilization.  Our evaluation on Raspberry Pi 2 shows
&lt;strong&gt;15 to 130 times faster&lt;/strong&gt; and more predictable allocation latency without
system performance degradation compared to Linux v3.18 default CMA.&lt;/p&gt;
&lt;p&gt;The project has been introduced by Linux Foundation Korea Forum 2014[1] and
Embedded Operating Systems Workshop 2015[2].  A paper about the project has
been published by proceeding of Embedded Operating Systems Workshop 2015 and
45th issue of ACM SIGBED Review[3].  The source code has been submitted to
LKML[4] for discussion.  It is also available at Github[5].&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://korealinuxforum2014.sched.com/event/1qZcBAO/gcma-guaranteed-contiguous-memory-allocator-seongjae-park-seoul-national-university-minchan-kim-lg&#34;&gt;https://korealinuxforum2014.sched.com/event/1qZcBAO/gcma-guaranteed-contiguous-memory-allocator-seongjae-park-seoul-national-university-minchan-kim-lg&lt;/a&gt;&lt;br&gt;
[2] &lt;a href=&#34;http://ceur-ws.org/Vol-1464/&#34;&gt;http://ceur-ws.org/Vol-1464/&lt;/a&gt;&lt;br&gt;
[3] &lt;a href=&#34;http://sigbed.seas.upenn.edu/vol13_num1.html#issue&#34;&gt;http://sigbed.seas.upenn.edu/vol13_num1.html#issue&lt;/a&gt;&lt;br&gt;
[4] &lt;a href=&#34;https://lkml.org/lkml/2015/2/23/480&#34;&gt;https://lkml.org/lkml/2015/2/23/480&lt;/a&gt;&lt;br&gt;
[5] &lt;a href=&#34;https://github.com/sjp38/linux.gcma&#34;&gt;https://github.com/sjp38/linux.gcma&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>&#34;Is Parallel Programming Hard, And, If So, What Can You Do About It?&#34; Translation</title>
      <link>/post/perfbook-kokr/</link>
      <pubDate>Tue, 10 Jan 2017 13:46:00 +0900</pubDate>
      <guid>/post/perfbook-kokr/</guid>
      <description>&lt;p&gt;&amp;ldquo;Is Parallel Programming is Hard, And, If So, What Can You Do About It?&amp;quot;[1] 은
parallel programming 분야에서 대가라 불릴만한 분으로, 이쪽 분야에서 매우 중요한
동기화 메커니즘인 RCU[2] 를 개발했으며 리눅스 커널의 RCU 메인테이너로 활동하고
있는 Paul E. McKenney[3] 가 오픈소스 방식으로 저술하고 있는, parallel
programming 에 대한 책입니다.&lt;/p&gt;
&lt;p&gt;개인적으로 이 책의 한국어 번역을 오픈소스[4]로 진행하고 있습니다.  이
프로젝트는 원저작자인 Paul 에게 공식 한국어 번역으로 인증받았습니다[5].&lt;/p&gt;
&lt;p&gt;컨트리뷰션에 대해서도 열려 있으니, 이에 관심 있는 분은 repository 내의 README
문서의 Contribution 섹션[6] 을 참고 바랍니다.&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://www.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html&#34;&gt;https://www.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html&lt;/a&gt;&lt;br&gt;
[2] &lt;a href=&#34;https://en.wikipedia.org/wiki/Read-copy-update&#34;&gt;https://en.wikipedia.org/wiki/Read-copy-update&lt;/a&gt;&lt;br&gt;
[3] &lt;a href=&#34;http://www.rdrop.com/~paulmck/&#34;&gt;http://www.rdrop.com/~paulmck/&lt;/a&gt;&lt;br&gt;
[4] &lt;a href=&#34;https://github.com/sjp38/perfbook-ko_KR&#34;&gt;https://github.com/sjp38/perfbook-ko_KR&lt;/a&gt;&lt;br&gt;
[5] &lt;a href=&#34;https://git.kernel.org/pub/scm/linux/kernel/git/paulmck/perfbook.git/commit/?id=edbfcdee046026d3f98592c411a20219b96c8e50&#34;&gt;https://git.kernel.org/pub/scm/linux/kernel/git/paulmck/perfbook.git/commit/?id=edbfcdee046026d3f98592c411a20219b96c8e50&lt;/a&gt;&lt;br&gt;
[6] &lt;a href=&#34;https://github.com/sjp38/perfbook-ko_KR#contribution&#34;&gt;https://github.com/sjp38/perfbook-ko_KR#contribution&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
