<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>tip | hacklog</title>
    <link>/categories/tip/</link>
      <atom:link href="/categories/tip/index.xml" rel="self" type="application/rss+xml" />
    <description>tip</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 27 Jun 2019 17:02:49 +0900</lastBuildDate>
    <image>
      <url>/img/tux.png</url>
      <title>tip</title>
      <link>/categories/tip/</link>
    </image>
    
    <item>
      <title>Integrate external git repository with its history</title>
      <link>/post/integrate_external_git_repository_with_history/</link>
      <pubDate>Thu, 27 Jun 2019 17:02:49 +0900</pubDate>
      <guid>/post/integrate_external_git_repository_with_history/</guid>
      <description>&lt;p&gt;프로젝트 a 와 프로젝트 b 를 병렬로 진행하고 있었는데, 두개의 리포지토리를
합치고 싶어지는 경우가 있습니다.  예컨대 프로젝트 a 의 성격이 보다 범용이
되었고 프로젝트 b 는 프로젝트 a 를 위한 도구적 성격이 되는 경우가 있겠죠.
a 프로젝트에 &amp;lsquo;b&amp;rsquo; 디렉토리를 만들고 그 아래 기존 프로젝트 b 의 파일들을 위치하고
싶습니다.
하지만 기존 b 프로젝트의 git 히스토리들도 유지하고 싶습니다.
비슷한 사례로 리눅스 커널 메모리 모델 프로젝트는 별도의 리포지토리[1] 로
개발되었지만 리눅스 업스트림 리포지토리의 tools/ 디렉토리 아래로 머지[2]
되었는데, 이 때 기존 개발 히스토리를 유지했죠.&lt;/p&gt;
&lt;p&gt;이 포스트는 이렇게 특정 git 리포지토리를 그 히스토리를 유지한 채 다른 git
리포지토리의 하위 디렉토리로 옮기는 법을 설명합니다.&lt;/p&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://github.com/aparri/memory-model&#34;&gt;https://github.com/aparri/memory-model&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href=&#34;https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/tools/memory-model&#34;&gt;https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/tools/memory-model&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;--&#34;&gt;초기 상황과 목표&lt;/h2&gt;
&lt;p&gt;먼저 현재 디렉토리 아래에 a 리포지토리와 b 리포지토리가 있다고 가정합니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ls
a   b
$
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;우리는 a 리포지토리 아래 b/ 디렉토리를 만들고 그 아래 b 리포지토리를 넣고
싶습니다.&lt;/p&gt;
&lt;h2 id=&#34;heading&#34;&gt;전략&lt;/h2&gt;
&lt;p&gt;b 리포지토리가 b/ 디렉토리 아래 모든 파일을 위치하도록 변경한 후, 이
리포지토리를 a 리포지토리에서 &lt;code&gt;--allow-unrelated-histories&lt;/code&gt; 옵션을 사용해
머지하도록 하겠습니다.&lt;/p&gt;
&lt;h2 id=&#34;----&#34;&gt;합쳐질 리포지토리 파일 구조 변경&lt;/h2&gt;
&lt;p&gt;먼저 b 리포지토리의 파일들이 b/ 디렉토리 아래 위치하도록 만듭니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd b
$ mkdir b
$ git mv !(b) b
$ git commit -a -m &amp;quot;Relocate files for inclusion&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;-&#34;&gt;리포지토리 병합&lt;/h2&gt;
&lt;p&gt;이제 b 리포지토리를 임시 remote 리포지토리로 등록하고 머지합니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd ../a
$ git remote add temp ../b
$ git fetch temp
$ git merge --allow-unrelated-histories temp/master
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;--allow-unrelated-histories&lt;/code&gt; 는 경로가 다른 파일에 대한 커밋들도 머지가 될 수
있게 해줍니다.&lt;/p&gt;
&lt;p&gt;임시로 등록한 remote 리포지토리는 지워줍시다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ git remote rm temp
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;heading1&#34;&gt;정리&lt;/h2&gt;
&lt;p&gt;이상과 같이 기존의 개발 히스토리를 유지하면서 특정 git 리포지토리를 다른 git
리포지토리의 하위 디렉토리로 병합하는 방법을 알아보았습니다.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>spec cpu2006 벤치마크 수정하기</title>
      <link>/post/spec_cpu2006_modification/</link>
      <pubDate>Sun, 24 Dec 2017 17:30:12 +0900</pubDate>
      <guid>/post/spec_cpu2006_modification/</guid>
      <description>&lt;p&gt;경우에 따라서 SPEC CPU2006 의 벤치마크 중 일부의 소스코드를 수정하고 싶을 수
있습니다.  예를 들어 특정 벤치마크가 구체적으로 어떻게 동작하는지 알아보기 위해
디버깅 메세지를 추가하고자 할수도 있고, 코드 변경을 통해 성능을 높인다거나 해볼
수도 있겠죠.  그러나, SPEC CPU2006 은 엄정한 벤치마크 수트이기 때문에
소스코드는 물론, 소스코드를 사용하는 도구가 변경된 경우 에러 메세지를 내고
수행을 거부합니다.  수정된 소스코드로 얻어진 결과는 벤치마크 결과로 적합하지
않기 때문이죠.&lt;/p&gt;
&lt;p&gt;때문에, 어쩔 수 없이 수정이 필요하면서도 기존의 수행 방법을 따르려면 이 에러를
내는 곳을 없애는 게 한가지 방법이 될 수 있습니다.  다음의 패치를 적용하면
이 검증 코드가 사라져서 수정된 코드로도 벤치마크를 돌릴 수 있게 됩니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;diff --git a/bin/formatter/setup_common.pl b/bin/formatter/setup_common.pl
index 36170cda1649..b21890972dbd 100755
--- a/bin/formatter/setup_common.pl
+++ b/bin/formatter/setup_common.pl
@@ -278,13 +278,13 @@ sub check_important_files {
     return if (   $::suite_version &amp;gt; 4
                &amp;amp;&amp;amp; !$ENV{&#39;SPEC_CHECK&#39;});
     $::check_integrity = 1;
-    foreach my $important_file (jp(&#39;bin&#39;, basename($0)),
-                                grep { m/$re/ } keys %::file_md5) {
-        if (!check_files(\%::file_md5, $important_file)) {
-            print STDERR &amp;quot;\n\nPart of the tools ($important_file) is corrupt!\nAborting...\n\n&amp;quot;;
-            exit 1;
-        }
-    }
+#    foreach my $important_file (jp(&#39;bin&#39;, basename($0)),
+#                                grep { m/$re/ } keys %::file_md5) {
+#        if (!check_files(\%::file_md5, $important_file)) {
+#            print STDERR &amp;quot;\n\n Part of the tools ($important_file) is corrupt!\nAborting...\n\n&amp;quot;;
+#            exit 1;
+#        }
+#    }
 }
 
 1;
diff --git a/bin/setup_common.pl b/bin/setup_common.pl
index 36170cda1649..d9dbe214d498 100755
--- a/bin/setup_common.pl
+++ b/bin/setup_common.pl
@@ -219,9 +219,9 @@ sub md5filedigest {
 sub load_module {
     my ($module, $quiet) = @_;
 
-    if ($::check_integrity &amp;amp;&amp;amp; !check_files(\%::file_md5, jp(&#39;bin&#39;, $module))) {
-	die &amp;quot;\n\nPart of the tools ($module) is corrupt!  Aborting...\n\n&amp;quot;;
-    }
+#    if ($::check_integrity &amp;amp;&amp;amp; !check_files(\%::file_md5, jp(&#39;bin&#39;, $module))) {
+#	die &amp;quot;\n\nPart of the tools ($module) is corrupt!  Aborting...\n\n&amp;quot;;
+#    }
     eval &amp;quot;require \&amp;quot;$module\&amp;quot;;&amp;quot;;
     print &#39;.&#39; unless ($quiet);
     if ($@) {
@@ -278,13 +278,13 @@ sub check_important_files {
     return if (   $::suite_version &amp;gt; 4
                &amp;amp;&amp;amp; !$ENV{&#39;SPEC_CHECK&#39;});
     $::check_integrity = 1;
-    foreach my $important_file (jp(&#39;bin&#39;, basename($0)),
-                                grep { m/$re/ } keys %::file_md5) {
-        if (!check_files(\%::file_md5, $important_file)) {
-            print STDERR &amp;quot;\n\nPart of the tools ($important_file) is corrupt!\nAborting...\n\n&amp;quot;;
-            exit 1;
-        }
-    }
+#    foreach my $important_file (jp(&#39;bin&#39;, basename($0)),
+#                                grep { m/$re/ } keys %::file_md5) {
+#        if (!check_files(\%::file_md5, $important_file)) {
+#            print STDERR &amp;quot;\n\nPart of the tools ($important_file) is corrupt!\nAborting...\n\n&amp;quot;;
+#            exit 1;
+#        }
+#    }
 }
 
 1;
diff --git a/bin/util.pl b/bin/util.pl
index ccf4a72477c0..c8c0cd786522 100755
--- a/bin/util.pl
+++ b/bin/util.pl
@@ -211,11 +211,11 @@ sub copy_tree {
                     offer_verify_advice();
 		    return 0;
 		}
-		if ($sumhash-&amp;gt;{$sf} ne md5filedigest($sf)) {
-		    Log(0, &amp;quot;\n$sf is corrupt!\n&amp;quot;);
-                    offer_verify_advice();
-		    return 0;
-		}
+#		if ($sumhash-&amp;gt;{$sf} ne md5filedigest($sf)) {
+#		    Log(0, &amp;quot;\n$sf is corrupt!\n&amp;quot;);
+#                    offer_verify_advice();
+#		    return 0;
+#		}
 	    }
             if ($sf =~ /\.bz2$/) {
               copy_bz2_file($sf, $file, [$target], 0);
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>TPC-H on MariaDB (MySQL)</title>
      <link>/post/tpch-on-mariadb/</link>
      <pubDate>Sun, 10 Sep 2017 10:54:24 +0900</pubDate>
      <guid>/post/tpch-on-mariadb/</guid>
      <description>&lt;p&gt;Benchmarks for Database can be roughly divided into two kinds, OLTP and
OLAP[1].
One of the most popular OLTP benchamrks is TPC-C, while that of OLAP is
TPC-H[2].
This post describes how you can run TPC-H against MariaDB.&lt;/p&gt;
&lt;h1 id=&#34;environment-setup&#34;&gt;Environment Setup&lt;/h1&gt;
&lt;p&gt;The versions of the OS and programs I used for writeup of this post are as
below.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ubuntu 16.04.2 Server&lt;/li&gt;
&lt;li&gt;MariaDB 10.2.8&lt;/li&gt;
&lt;li&gt;TPC-H toolkit 2.17.2&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;automated-scripts&#34;&gt;Automated Scripts&lt;/h1&gt;
&lt;p&gt;I automated whole things I will describe below using scripts and uploaded the
scripts to the Github:
&lt;a href=&#34;https://github.com/sjp38/tpch-mariadb&#34;&gt;https://github.com/sjp38/tpch-mariadb&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you hano no time, just go to the link and use the script.&lt;/p&gt;
&lt;h1 id=&#34;tpch-spec&#34;&gt;TPC-H Spec&lt;/h1&gt;
&lt;p&gt;You can ge TPC-H benchmark specification from TPC website[3].
Refer to it if you need strict specification of the benchmark.
Nonetheless, I give you a rough description of the benchmark here, though.
TPC-H stores a huge data into 8 tables and run 22 queries analysing this data.
To measure the performance, we can measure the time to store/load the data,
runtime of each of the 22 queries, and the throughput (number of processed
queries per second) of multiple sessions.&lt;/p&gt;
&lt;h1 id=&#34;get-tpch-toolkit&#34;&gt;Get TPC-H Toolkit&lt;/h1&gt;
&lt;p&gt;TPC provides the specification says how the tables should be constructed, what
data should be stored in the tables, and what kind of queries should be issued.
So, anyone can implement their TPC-H based on this specification.
Nonetheless, as manual read of the specification and manual implementation can
be boring and exhaustive to someone.
For the reason, TPC officially provides a tool, namely &lt;code&gt;TPC-H Toolkit&lt;/code&gt;, that
helps creation of the tables, the data, and the queries.
If you go to the site[4], enter your personal information, and agree to the
license, they will send you a link to download the TPC-H Toolkit by mail.&lt;/p&gt;
&lt;p&gt;The file is in zip format.
After extracting the file, you can get the directory named by the version of
the toolkit.
The source code and license file is under the directory.
We will use &lt;code&gt;dbgen/&lt;/code&gt; directory here.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ tree 2.17.2 -L 1
2.17.2
├── dbgen
├── dev-tools
├── EULA.txt
└── ref_data
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;build-source-code&#34;&gt;Build Source Code&lt;/h1&gt;
&lt;p&gt;Under the &lt;code&gt;dbgen/&lt;/code&gt;, there are source code of the programs that we will use,
&lt;code&gt;dbgen&lt;/code&gt; and &lt;code&gt;qgen&lt;/code&gt;.
Copy &lt;code&gt;makefile.suite&lt;/code&gt; to &lt;code&gt;makefile&lt;/code&gt; and edit the content as below.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ diff -u makefile.suite makefile
--- makefile.suite      2017-04-21 06:01:08.000000000 +0900
+++ makefile    2017-09-10 11:10:12.563384756 +0900
@@ -100,15 +100,15 @@
 ################
 ## CHANGE NAME OF ANSI COMPILER HERE
 ################
-CC      =
+CC      = gcc
 # Current values for DATABASE are: INFORMIX, DB2, TDAT (Teradata)
 #                                  SQLSERVER, SYBASE, ORACLE, VECTORWISE
 # Current values for MACHINE are:  ATT, DOS, HP, IBM, ICL, MVS,
 #                                  SGI, SUN, U2200, VMS, LINUX, WIN32
 # Current values for WORKLOAD are:  TPCH
-DATABASE=
-MACHINE =
-WORKLOAD =
+DATABASE= SQLSERVER
+MACHINE = LINUX
+WORKLOAD = TPCH
 #
 CFLAGS = -g -DDBNAME=\&amp;quot;dss\&amp;quot; -D$(MACHINE) -D$(DATABASE) -D$(WORKLOAD) -DRNG_TEST -D_FILE_OFFSET_BITS=64
 LDFLAGS = -O
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, &lt;code&gt;$ make&lt;/code&gt; command will build &lt;code&gt;dbgen&lt;/code&gt; and &lt;code&gt;qgen&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ make

...

 bm_utils.o qgen.o rnd.o varsub.o text.o bcd2.o permute.o speed_seed.o rng64.o -lm
$ file dbgen
dbgen: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.32, BuildID[sha1]=d0bca1a18c33947d85f5943c8325837faec7c95d, not stripped
$ file qgen
qgen: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.32, BuildID[sha1]=79a6216e04c446715b0e55f9c804586887b698c8, not stripped
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;tpch-toolkit-usage&#34;&gt;TPC-H Toolkit Usage&lt;/h1&gt;
&lt;p&gt;To run TPC-H on MariaDB, we need several more modification.
Before that, let&#39;s see how we run TPC-H using the files under &lt;code&gt;dbgen/&lt;/code&gt;
directory.&lt;/p&gt;
&lt;h2 id=&#34;data-preparation&#34;&gt;Data Preparation&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;dss.ddl&lt;/code&gt; file has the sql statements be used for the creation of the 8 tables.
If you command your DB to execute the sql statements in this file, the 8 tables
will be created.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;dbgen&lt;/code&gt; creates the sql statements that stores the data to the table.
If you run the &lt;code&gt;dbgen&lt;/code&gt; with optional arguments including scale factor, 8 files
having &lt;code&gt;.tbl&lt;/code&gt; suffix will be created.
Each of these files has query statements inserting the data to the table having
same name with the file.
You can store the data to the tables by making your DB to run the sql
statements.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;dss.ri&lt;/code&gt; has a sql statement creating the table index.
Once your DB runs these sql statements, the table index will be generated and
you will be ready to run the TPC-H queries.&lt;/p&gt;
&lt;h2 id=&#34;query-creation-and-execution&#34;&gt;Query Creation and Execution&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;qgen&lt;/code&gt; creates the queries doing the TPC-H&#39;s analysis tasks.
We simply said 22 queries, but it would be better to say 22 kinds of queries.
If a query is repeatedly issued with same arguments, DB server can cache the
results and simply return it to the client.
As this can distort the results, TPC-H Toolkit has the template of the 22
queries under &lt;code&gt;dbgen/queries/&lt;/code&gt; directory and let &lt;code&gt;qgen&lt;/code&gt; to create query
statements using random arguments, based on this templates.
The seed for the random number generation is created based on &lt;code&gt;dists.dss&lt;/code&gt; file.&lt;/p&gt;
&lt;h1 id=&#34;modify-tpch-toolkit-for-mariadb&#34;&gt;Modify TPC-H Toolkit for MariaDB&lt;/h1&gt;
&lt;p&gt;Each DBMS has a little bit different query syntax.
Thus, TPC-H Toolkit is made to support multiple DBMSes, but the MariaDB is not
in the supported DBMSes.
Therefore, you should modify a part of the TPC-H Toolkit to run TPC-H on the
MariaDB.&lt;/p&gt;
&lt;p&gt;The files need modifications are &lt;code&gt;dss.ddl&lt;/code&gt;, &lt;code&gt;dss.ri&lt;/code&gt;, and the templates under
the &lt;code&gt;queries/&lt;/code&gt; directory.
As the description of the each of the modifications will be too long, I simply
made patches for the modifications and uploaded on Github[5].
You can apply the patch files to your TPC-H Toolkit as below.
You should be on the TPC-H Toolkit source code directory while running below
command.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ wget https://raw.githubusercontent.com/sjp38/tpch-mariadb/07fdcbfa9ba1be26f437ff130338a223d0dbfecd/0001-Modify-for-MariaDB.patch
$ patch -p1 &amp;lt; 0001-Modify-for-MariaDB.patch
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The changes above includes the modification of the makefile.
After applying, build &lt;code&gt;dbgen&lt;/code&gt; and &lt;code&gt;qgen&lt;/code&gt;.&lt;/p&gt;
&lt;h1 id=&#34;data-creation&#34;&gt;Data Creation&lt;/h1&gt;
&lt;p&gt;Now, move to &lt;code&gt;dbgen/&lt;/code&gt; directory and run &lt;code&gt;dbgen&lt;/code&gt;.
You can give scale factor using its argument.
Refer to the usage of dbgen using &lt;code&gt;-h&lt;/code&gt; option.
After its execution, you can see below 8 &lt;code&gt;.tbl&lt;/code&gt; files.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dbgen$ ls -ahl *.tbl
-rw-rw-r-- 1 sjpark sjpark 187M Sep  9 10:48 customer.tbl
-rw-rw-r-- 1 sjpark sjpark 5.8G Sep  9 10:48 lineitem.tbl
-rw-rw-r-- 1 sjpark sjpark 2.2K Sep  9 10:48 nation.tbl
-rw-rw-r-- 1 sjpark sjpark 1.4G Sep  9 10:48 orders.tbl
-rw-rw-r-- 1 sjpark sjpark 919M Sep  9 10:48 partsupp.tbl
-rw-rw-r-- 1 sjpark sjpark 186M Sep  9 10:48 part.tbl
-rw-rw-r-- 1 sjpark sjpark  389 Sep  9 10:48 region.tbl
-rw-rw-r-- 1 sjpark sjpark  11M Sep  9 10:48 supplier.tbl
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The above results used scale factor value as 8.&lt;/p&gt;
&lt;h1 id=&#34;load-data&#34;&gt;Load Data&lt;/h1&gt;
&lt;p&gt;Now, with your MariaDB, create a database named tpch (line 1), create tables
under the database (line 2), load the data to the tables (lines 3-5), and make
index for each of the tables (line 6).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ mysql -u root -p password -e &amp;quot;create database tpch;&amp;quot;
$ mysql -u root -p password &amp;lt; dss.ddl
$ for table in customer lineitem nation orders partsupp part region supplier \
	do mysql -u root -p -e \
		&amp;quot;LOAD DATA LOCAL INFILE &#39;$table.tbl&#39; FIELDS TERMINATED BY &#39;|&#39;;&amp;quot;
	done
$ mysql -u root -p password &amp;lt; ./dss.ri
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;create-queries&#34;&gt;Create Queries&lt;/h1&gt;
&lt;p&gt;Now, create the queries.
&lt;code&gt;qgen&lt;/code&gt; receives a number from 1 to 22 which means the type of the queries to
create, generate the query statement, and print on the screen.
You can save the queries with below commands.
This example assumes it is executed on the &lt;code&gt;dbgen/&lt;/code&gt; directory.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd queries/
$ for i in {1..22}; do ../qgen $i &amp;gt; query-$i.sql; done
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now, you have 22 &lt;code&gt;query-&lt;/code&gt; prefixed files containing each type of queries under
the &lt;code&gt;dbgen/queries/&lt;/code&gt; directory.&lt;/p&gt;
&lt;h1 id=&#34;execute-queries&#34;&gt;Execute Queries&lt;/h1&gt;
&lt;p&gt;As the query files have sql statement compatible with MariaDB, you can simply
run them as below.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ for i in {1..22}; do mysql -u root -p password &amp;lt; dbgen/queries/query-$i.sql
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Few queries will take few of tens of seconds to complete while another queries
take less than 1 second.&lt;/p&gt;
&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;This post summarised how TPC-H is constructed, how you can run it, and what
modifications are required to run it on MariaDB.
You can do this with only few lines of command based on the automated scripts
on my Github repo[6].&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;[1] &lt;a href=&#34;http://datawarehouse4u.info/OLTP-vs-OLAP.html&#34;&gt;http://datawarehouse4u.info/OLTP-vs-OLAP.html&lt;/a&gt;&lt;br&gt;
[2] &lt;a href=&#34;http://www.tpc.org/tpch/&#34;&gt;http://www.tpc.org/tpch/&lt;/a&gt;&lt;br&gt;
[3] &lt;a href=&#34;http://www.tpc.org/tpc_documents_current_versions/pdf/tpc-h_v2.17.2.pdf&#34;&gt;http://www.tpc.org/tpc_documents_current_versions/pdf/tpc-h_v2.17.2.pdf&lt;/a&gt;&lt;br&gt;
[4] &lt;a href=&#34;http://www.tpc.org/tpc_documents_current_versions/download_programs/tools-download-request.asp?bm_type=TPC-H&amp;amp;bm_vers=2.17.2&amp;amp;mode=CURRENT-ONLY&#34;&gt;http://www.tpc.org/tpc_documents_current_versions/download_programs/tools-download-request.asp?bm_type=TPC-H&amp;amp;bm_vers=2.17.2&amp;amp;mode=CURRENT-ONLY&lt;/a&gt;&lt;br&gt;
[5] &lt;a href=&#34;https://raw.githubusercontent.com/sjp38/tpch-mariadb/07fdcbfa9ba1be26f437ff130338a223d0dbfecd/0001-Modify-for-MariaDB.patch&#34;&gt;https://raw.githubusercontent.com/sjp38/tpch-mariadb/07fdcbfa9ba1be26f437ff130338a223d0dbfecd/0001-Modify-for-MariaDB.patch&lt;/a&gt;&lt;br&gt;
[6] &lt;a href=&#34;https://github.com/sjp38/tpch-mariadb&#34;&gt;https://github.com/sjp38/tpch-mariadb&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ubuntu 16.04 Server 위에 MariaDB 설치/사용하기</title>
      <link>/post/mariadb_setup/</link>
      <pubDate>Thu, 31 Aug 2017 14:37:07 +0900</pubDate>
      <guid>/post/mariadb_setup/</guid>
      <description>&lt;p&gt;악의 조직 Oracle 에서 Sun 을 인수한 후 이어진 반 open source 적 행보에 MySQL
개발자는 MySQL 을 fork 해서 MariaDB 를 개발하고 있습니다.  저작권을 악용해
중요한 기능은 천천히 릴리즈 하거나 유료 라이센스로만 공개하기도 하는 Oracle 의
MySQL 과 달리 MariaDB 는 예전 MySQL 처럼 공개적으로 개발되고 있어 새롭고
진보적인 기능도 많이 있는 편인 것 같습니다.&lt;/p&gt;
&lt;p&gt;이 글에서는 Ubuntu 16.04 서버에 MariaDB 를 소스코드부터 가져와서 설치하고
사용하는 간단한 사용법을 정리해 봅니다.&lt;/p&gt;
&lt;h1 id=&#34;environment&#34;&gt;Environment&lt;/h1&gt;
&lt;p&gt;이 글에서는 Ubuntu 16.04.2 server 버전을 사용합니다.&lt;/p&gt;
&lt;h1 id=&#34;build-and-install&#34;&gt;Build and Install&lt;/h1&gt;
&lt;p&gt;MariaDB 는 대부분의 리눅스 배포본을 위한 패키징이 잘 되어 있어서 각 배포본의
패키징 시스템을 사용하면 한두줄의 커맨드로 쉽게 설치할 수 있습니다.  하지만
여기선 문서[1] 를 참고해 가며 소스 코드부터 가져와서 바닥부터 가장 최신 버전을
설치해 보기로 합시다.&lt;/p&gt;
&lt;p&gt;소스코드는 github 에 git repository 의 형태로 공개되어 있습니다.  아래의
명령어로 코드를 &lt;code&gt;mariadb/&lt;/code&gt; 디렉토리 아래에 가져올 수 있습니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/MariaDB/server.git mariadb
$ cd mariadb
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;git repository 인만큼 버전은 git 을 통해 tag 로 관리되고 있습니다.  이 글을
작성 중인 시점에서 가장 최신 stable 릴리즈는 10.2.8[2] 로, 2017년 8월 18일
자로 릴리즈 되었습니다.  다음 커맨드로 해당 버전의 코드를 checkout 할 수
있습니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ git checkout mariadb-10.2.8
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;이제 소스코드는 준비되었고, 빌드할 차례입니다.  &lt;code&gt;cmake&lt;/code&gt; 를 사용해 어떻게
빌드할지 등을 설정할 수 있는데, 여기선 release 할때 사용하는 설정을 사용해
보겠습니다.  &lt;code&gt;cmake&lt;/code&gt; 가 실패하는 경우는 대부분 필요 패키지가 설치되지 않은
경우입니다.  &lt;code&gt;libaio-dev&lt;/code&gt;, &lt;code&gt;libjemalloc-dev&lt;/code&gt;, &lt;code&gt;libgnutls-dev&lt;/code&gt; 등의 패키지가
설치되어 있어야 합니다.&lt;/p&gt;
&lt;p&gt;해당 패키지 설치 후에도 같은 에러 메세지가 나올 수 있는데, cmake 의 기존 결과가
캐싱되어 재사용되기 때문입니다.  &lt;code&gt;CMakeCache.txt&lt;/code&gt; 와 &lt;code&gt;CMakeFiles/&lt;/code&gt; 디렉토리를
제거해주면 캐싱된 내용은 사라집니다.&lt;/p&gt;
&lt;p&gt;이어서 간단히 &lt;code&gt;make&lt;/code&gt; 를 사용해 빌드하고 설치를 할 수 있습니다.
설치는 super user 권한이 필요하기 때문에 &lt;code&gt;sudo&lt;/code&gt; 를 사용해야 합니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cmake . -DBUILD_CONFIG=mysql_release
$ make
$ sudo make install
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;어떤 사양의 머신에서 빌드하느냐에 따라 다르겠지만 빌드하는데 꽤 긴 시간이
걸립니다.  이 글을 작성하며 사용한 72 코어 / 144 쓰레드 머신에서는 &lt;code&gt;-j144&lt;/code&gt;
옵션을 줘서 빌드할 경우 1분 5초 걸렸습니다.  별다른 에러 메세지가 없다면 빌드에
성공한 것입니다.&lt;/p&gt;
&lt;h1 id=&#34;initialize-mariadb-server&#34;&gt;Initialize MariaDB Server&lt;/h1&gt;
&lt;p&gt;이제 MariaDB 의 기본 설치는 마무리 되었지만, 아직 MariaDB 구동을 위한 준비가
모두 끝나진 않았습니다.  MariaDB 가 제대로 동작하기 위해서는 test database,
default user 등등의 최소 데이터를 생성하는 초기화 작업을 진행해야 합니다.  앞의
설치는 MariaDB 실행파일을 만들어 시스템에 설치한 것이고, 이 초기화 작업은
MariaDB 서비스의 설치라고 생각하면 이해가 조금 편할 수도 있겠습니다.&lt;/p&gt;
&lt;p&gt;super user 권한의 남용은 보안적으로 위험할 수 있으므로, MariaDB 는 기본적으로
별개의 사용자 계정을 사용할 것을 권장합니다.  다음 예에서는 mysql 이라는 이름의
user 를 생성하고 이 사용자 계정을 사용하도록 해서 초기화를 진행합니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo adduser mysql
$ sudo chown -R mysql /usr/local/mysql/
$ cd /usr/local/mysql/
$ sudo -u mysql ./scripts/mysql_install_db --user=mysql
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;순조롭게 진행되었다면 다음과 같은 메세지를 볼 수 있을 겁니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Installing MariaDB/MySQL system tables in &#39;./data&#39; ...
OK

To start mysqld at boot time you have to copy
support-files/mysql.server to the right place for your system

PLEASE REMEMBER TO SET A PASSWORD FOR THE MariaDB root USER !
To do so, start the server, then issue the following commands:

&#39;./bin/mysqladmin&#39; -u root password &#39;new-password&#39;
&#39;./bin/mysqladmin&#39; -u root -h hydra password &#39;new-password&#39;

Alternatively you can run:
&#39;./bin/mysql_secure_installation&#39;

which will also give you the option of removing the test
databases and anonymous user created by default.  This is
strongly recommended for production servers.

See the MariaDB Knowledgebase at http://mariadb.com/kb or the
MySQL manual for more instructions.

You can start the MariaDB daemon with:
cd &#39;.&#39; ; ./bin/mysqld_safe --datadir=&#39;./data&#39;

You can test the MariaDB daemon with mysql-test-run.pl
cd &#39;./mysql-test&#39; ; perl mysql-test-run.pl

Please report any problems at http://mariadb.org/jira

The latest information about MariaDB is available at http://mariadb.org/.
You can find additional information about the MySQL part at:
http://dev.mysql.com
Consider joining MariaDB&#39;s strong and vibrant community:
https://mariadb.org/get-involved/
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;starting-mariadb&#34;&gt;Starting MariaDB&lt;/h1&gt;
&lt;p&gt;이제 준비가 끝났습니다.  앞의 초기화 과정 이후 나온 메세지에서도 알 수 있듯이,
다음 커맨드로 MariaDB 서버를 시작할 수 있습니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo -u mysql /usr/local/mysql/bin/mysqld_safe --datadir=&#39;./data&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;connect-to-local-mariadb-server&#34;&gt;Connect to Local MariaDB Server&lt;/h1&gt;
&lt;p&gt;MariaDB 는 여러가지 방법으로 접근해 사용할 수 있는데, 관리 목적 등으로는 local
shell 을 사용하는게 가장 간단합니다.  다음 커맨드로 local shell 을 열 수
있습니다.  이 커맨드는 같은 기계 위에 띄워져 있는 MariaDB 서버 프로세스에
접속해 해당 서버에 sql 쿼리를 날릴 수 있는 프롬프트를 띄워 줍니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ /usr/local/mysql/bin/mysql
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;위 커맨드에 &amp;ndash;version 인자를 주면 현재 mariadb 의 버전도 볼 수 있습니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ /usr/local/mysql/bin/mysql --version
/usr/local/mysql/bin/mysql  Ver 15.1 Distrib 10.2.8-MariaDB, for Linux (x86_64) using readline 5.1
s
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;kill-mariadb-server&#34;&gt;Kill MariaDB Server&lt;/h1&gt;
&lt;p&gt;서버를 끝낼 수도 있어야겠죠.  다음의 커맨드로 mysql 서버 프로세스에게 SIGTERM
시그널을 날려서 서버 프로세스를 종료시킬 수 있습니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo -u mysql kill -SIGTERM `pidof mysqld`
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;basical-usage&#34;&gt;Basical Usage&lt;/h1&gt;
&lt;p&gt;프롬프트에서 다음과 같이 기본적인 sql 쿼리를 날릴 수 있습니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo /usr/local/mysql/bin/mysql
&amp;gt; create database sj_db;
&amp;gt; create table sjtable ( id INT PRIMARY KEY, name VARCHAR(20) );
&amp;gt; insert into sjtable values ( 1, &#39;Will&#39; );
&amp;gt; select * from sjtable;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;그 외의 MariaDB sql 문법을 위해서는 MariaDB basic sql statement 문서[3] 를
참고합시다.&lt;/p&gt;
&lt;h1 id=&#34;mycnf-configuration&#34;&gt;my.cnf configuration&lt;/h1&gt;
&lt;p&gt;mysql 과 마찬가지로 MariaDB 역시 my.cnf 파일을 사용해[1] 대부분의 설정을
구성합니다.  기본적으로 /etc/my.cnf, /etc/mysql/my.cnf &amp;hellip; 순으로 설정 파일을
찾게 되며, mysqld_safe 실행파일 실행 시에 &amp;ndash;defaults-file 인자로 파일 경로를
줄수도 있습니다.  소스 코드 디렉토리의 support-files/ 디렉토리 아래에
my-huge.cnf, my-large.cnf, my-medium.cnf 등의 예제 설정도 있습니다.&lt;/p&gt;
&lt;p&gt;앞의 과정을 따라서 설치하면 /etc/ 아래에 my.cnf 파일이 없을 겁니다.  이 때의
기본 설정은 어떻게 되는지는 다음 커맨드를 통해 알 수 있습니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ /usr/local/mysql/bin/mysql -NBe &#39;SHOW VARIABLES&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;askapache.com 에서는[5] 이를 이용해 기본 my.cnf 를 추출하는 커맨드도 소개하고
있으니 필요하면 참고하시기 바랍니다.&lt;/p&gt;
&lt;h1 id=&#34;data-directory-specification&#34;&gt;Data Directory Specification&lt;/h1&gt;
&lt;p&gt;실험용으로 MariaDB 를 사용하는 경우라면 MariaDB 데이터를 최초 상태로 백업해
두거나 서로 다른 설정의 데이터를 유지해야 할 수도 있습니다.&lt;/p&gt;
&lt;p&gt;MariaDB 의 default data directory 는 /usr/local/mysql/data/ 로, 프롬프트에서&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; select @@datadir;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;명령으로 현재 띄워진 MariaDB 서버 프로세스가 사용중인 data directory 의 경로를
볼 수 있습니다.  이 경로는 my.cnf 상에서 수정할 수도 있고, mysqld_safe 실행 시
&amp;ndash;datadir 옵션으로 지정할 수도 있습니다.  주의할 점은, 이때 &amp;ndash;datadir 인자로
주는 데이터 디렉토리는 한번은 scripts/mysql_install_db 를 실행해준 디렉토리여야
한다는 것입니다.  mysql_install_db 명령에도 &amp;ndash;datadir 인자를 줄수 있습니다.&lt;/p&gt;
&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;MariaDB 최신 버전의 소스코드를 가져와 빌드하고 설치해서 사용하는 방법을
알아봤습니다.  하나의 예제로 정리해 보자면 다음과 같습니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/MariaDB/server.git mariadb
$ cd mariadb
$ git checkout mariadb-10.2.8
$ cmake . -DBUILD_CONFIG=mysql_release
$ make
$ sudo make install
$ sudo adduser mysql
$ sudo chown -R mysql /usr/local/mysql/
$ cd /usr/local/mysql/
$ sudo -u mysql ./scripts/mysql_install_db --datadirr=&#39;./data&#39; &amp;amp;
$ /usr/local/mysql/bin/mysql
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://mariadb.com/kb/en/mariadb/generic-build-instructions/&#34;&gt;https://mariadb.com/kb/en/mariadb/generic-build-instructions/&lt;/a&gt;&lt;br&gt;
[2] &lt;a href=&#34;https://downloads.mariadb.org/mariadb/+releases/&#34;&gt;https://downloads.mariadb.org/mariadb/+releases/&lt;/a&gt;&lt;br&gt;
[3] &lt;a href=&#34;https://mariadb.com/kb/en/mariadb/basic-sql-statements/&#34;&gt;https://mariadb.com/kb/en/mariadb/basic-sql-statements/&lt;/a&gt;&lt;br&gt;
[4] &lt;a href=&#34;https://mariadb.com/kb/en/mariadb/configuring-mariadb-with-mycnf/&#34;&gt;https://mariadb.com/kb/en/mariadb/configuring-mariadb-with-mycnf/&lt;/a&gt;&lt;br&gt;
[5] &lt;a href=&#34;https://www.askapache.com/mysql/view-mysql-variables-my-cnf/&#34;&gt;https://www.askapache.com/mysql/view-mysql-variables-my-cnf/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Golang 1.9 install on Fedora 26</title>
      <link>/post/golang1.9_fedora26/</link>
      <pubDate>Sat, 26 Aug 2017 10:54:24 +0900</pubDate>
      <guid>/post/golang1.9_fedora26/</guid>
      <description>&lt;p&gt;현재 사용중인 랩탑에 설치한 OS 는 Fedora 24 였는데, 너무 오래되었고 지원도
얼마전 끝났기에[0] 이번에 Fedora 26 으로 새로 설치했습니다.  마침 go 언어도 1.9 가
최근에 릴리즈 되었기에 개인적으로 go 언어를 설치하는 방법을 기록해 둡니다.&lt;/p&gt;
&lt;p&gt;여기선 소스 코드만 가지고 빌드, 설치하는 방법을 기록합니다.&lt;/p&gt;
&lt;h1 id=&#34;get-source-code&#34;&gt;Get Source Code&lt;/h1&gt;
&lt;p&gt;go 언어는 오픈소스입니다.  다음 커맨드를 통해 구글로부터 소스코드를 받아올 수
있습니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ git clone https://go.googlesource.com/go
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;기다리면 &lt;code&gt;go/&lt;/code&gt; 디렉토리에 소스코드가 딸려옵니다.&lt;/p&gt;
&lt;h1 id=&#34;golang-14-build--install&#34;&gt;golang 1.4 Build &amp;amp; Install&lt;/h1&gt;
&lt;p&gt;go 언어를 빌드한다는 건 go 언어 컴파일러와 기본 라이브러리 등과 같은, go 언어로
짠 프로그램을 빌드하고 수행하는데 필요한 도구들을 빌드한다는 이야기입니다.
이런 기본 도구는 go 언어로 짜여져 있기 때문에 go 언어를 소스코드로부터
빌드하려면 go 언어가 미리 설치되어 있어야 합니다.  따라서 1.4 버전의 go 언어를
먼저 빌드, 설치합니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cp -R go go1.4
$ cd go1.4/src
$ git checkout go1.4.3
$ CGO_ENABLED=0 ./all.bash
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;앞서 받아온 소스코드를 &lt;code&gt;go1.4/&lt;/code&gt; 디렉토리로 복사하고 (line 1) 그리로 이동해서
(line 2) git 을 사용해 1.4 버전들 중 가장 마지막 버전인 1.4.3 버전의 코드를
꺼낸 후 (line 3) 마지막 줄에서 빌드를 하는 명령들입니다.&lt;/p&gt;
&lt;p&gt;참고로 CGO_ENABLED=0 를 빼먹으면 빌드에 실패합니다[1].  go 개발팀에선 그냥
바이너리로 최신 go 를 짜기 위한 go 를 설치하길 권장하지만[2], 전 소스
코드만으로 설치를 하고 싶으므로 이렇게 합니다.&lt;/p&gt;
&lt;h1 id=&#34;golang-19-build--install&#34;&gt;golang 1.9 Build &amp;amp; Install&lt;/h1&gt;
&lt;p&gt;역시 간단합니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cd ../go/src
git checkout go1.9
./all.bash
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;앞서 받아둔 go 소스 코드로 돌아가서 (line 1), 1.9 버전의 소스코드를 꺼내고
(line 2), 마지막으로 빌드 / 설치를 진행합니다 (line 3).&lt;/p&gt;
&lt;p&gt;다음과 같은 메세지를 보게 되면 빌드 / 설치에 성공한 겁니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
ALL TESTS PASSED

---
Installed Go for linux/amd64 in /home/sjpark/go
Installed commands in /home/sjpark/go/bin
*** You need to add /home/sjpark/go/bin to your PATH.
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;test-installation&#34;&gt;Test Installation&lt;/h2&gt;
&lt;p&gt;설치가 잘 되었는지 마지막으로 테스트 해봅시다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ go version
go version devel +bad6b6fa91 Fri Aug 25 23:29:55 2017 +0000 linux/amd64
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;위와 같이 결과가 나오면 잘 설치된 것입니다.&lt;/p&gt;
&lt;h1 id=&#34;additional-configuration&#34;&gt;Additional Configuration&lt;/h1&gt;
&lt;p&gt;추가적으로 go 바이너리의 위치를 PATH 에 넣어주고, 사용할 GOPATH 를 지정해
줍니다.  golang 은 개발 코드의 위치와 go 언어로 짜여진 프로그램의 설치 위치
규칙을 기본적으로 권장하는 규칙이 있는데, 이를 위해 사용되는 디렉토리의
꼭대기가 GOPATH 입니다.  나만의 방식으로 go 언어를 다루겠다면 굳이 지정할 필요
없지만, 전 그정도 규칙은 따르는 편이므로 다음 내용을 홈 디렉토리의 .bashrc 에
추가해 이를 지정해 줍니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export GOPATH=$HOME/gopath
export PATH=$PATH:$HOME/go/bin
export PATH=$PATH:$GOPATH/bin
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;GOPATH 아래 &lt;code&gt;bin/&lt;/code&gt; 디렉토리는 일반적으로 설치한 go 언어 프로그램의 실행파일을
위치시키는 곳이므로 역시 PATH 에 추가해줬습니다 (line 3).&lt;/p&gt;
&lt;p&gt;이 규칙을 이해하기 쉽게 다음과 같이 제가 만든 &lt;code&gt;hn&lt;/code&gt; 이라는 프로그램을 설치해
보고, 이 명령이 GOPATH 를 어떻게 사용하는지 보면 다음과 같습니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ go get github.com/sjp38/hn
$ tree gopath/
gopath/
├── bin
│   └── hn
└── src
    └── github.com
        └── sjp38
            └── hn
                ├── hn.go
                ├── LICENSE
                └── README.md

5 directories, 4 files
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;[0] &lt;a href=&#34;https://fedoramagazine.org/fedora-24-eol/&#34;&gt;https://fedoramagazine.org/fedora-24-eol/&lt;/a&gt;&lt;br&gt;
[1] &lt;a href=&#34;https://github.com/golang/go/issues/18156#issuecomment-264389887&#34;&gt;https://github.com/golang/go/issues/18156#issuecomment-264389887&lt;/a&gt;&lt;br&gt;
[2] &lt;a href=&#34;https://github.com/golang/go/issues/18156#issuecomment-264492152&#34;&gt;https://github.com/golang/go/issues/18156#issuecomment-264492152&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Parsec 3.0 설치 / 사용법</title>
      <link>/post/parsec_3_howto/</link>
      <pubDate>Fri, 19 May 2017 06:23:15 +0900</pubDate>
      <guid>/post/parsec_3_howto/</guid>
      <description>&lt;p&gt;PARSEC 은 멀티쓰레드 프로그램들로 구성된 benchmark suite 입니다.  멀티쓰레드로
구성되어 있기 때문에 멀티코어 시스템에서의 multi core scalability 를 테스트
하기에도 적합합니다.  이 글에선 현재 최신 버전인 3.0 버전의 PARSEC 을 Ubuntu
16.04 server 에 설치하면서 겪는 문제의 해결법과 간단한 사용법을 정리해 봅니다.&lt;/p&gt;
&lt;h1 id=&#34;toolbox-for-parsec-30-on-ubuntu-xenial&#34;&gt;Toolbox for PARSEC 3.0 on Ubuntu Xenial&lt;/h1&gt;
&lt;p&gt;아래의 내용을 하나하나 읽어가면서 따라하는 것도 귀찮은 일입니다.  그래서
아래에서 설명하는, Ubuntu Xenial 에서 PARSEC 3.0 을 돌리기 위해 필요한 작업을
대부분 자동으로 해주는 도구들을 만들어 두었습니다.  오픈소스로 공개되어
있으니[1], 아래의 머리 아픈 내용을 읽기 귀찮다면 해당 도구들을 사용하시기
바랍니다.  해당 도구들의 사용법은 README 에 간략히 설명되어 있습니다.&lt;/p&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://github.com/sjp38/parsec_on_ubuntu_xenial&#34;&gt;https://github.com/sjp38/parsec_on_ubuntu_xenial&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;parsec-30-download&#34;&gt;PARSEC 3.0 Download&lt;/h1&gt;
&lt;p&gt;공식 홈페이지[1] 에 들어가면 PARSEC 3.0 다운로드 링크가 첫페이지부터 있습니다.
해당 링크를 사용하면 &lt;code&gt;tar.gz&lt;/code&gt; 포맷의 tarball 로 정리된 PARSEC 3.0 을 다운받을
수 있습니다.  웹브라우저로 들어가서 다운로드를 받는 방법도 있겠고, &lt;code&gt;curl&lt;/code&gt; 이나
&lt;code&gt;wget&lt;/code&gt; 등의 command line tool 을 사용해 다운받을 수도 있겠습니다.  다음
커맨드는 PARSEC 3.0 을 다운받아 &lt;code&gt;parsec-3.0/&lt;/code&gt; 디렉토리 아래 압축을 풀고 압축을
푼 디렉토리로 이동합니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ wget http://parsec.cs.princeton.edu/download/3.0/parsec-3.0.tar.gz
$ tar zxvf parsec-3.0.tar.gz
$ cd parsec-3.0
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;build&#34;&gt;Build&lt;/h1&gt;
&lt;p&gt;이제 PARSEC 3.0 을 빌드해야 합니다.  PARSEC 은 여러 벤치마크를 포함하고
있으므로 개별적 벤치마크를 하나하나 직접적으로 다루기보다는 suite 내의 각
벤치마크를 통합적으로 관리할 수 있는 &lt;code&gt;parsecmgmt&lt;/code&gt; 라는 관리 프로그램을
사용하도록 되어 있습니다.  빌드 역시 마찬가지입니다.  참고로, &lt;code&gt;parsecmgmt&lt;/code&gt; 는
bash script 입니다.&lt;/p&gt;
&lt;p&gt;기본적인 PARSEC 3.0 빌드 방법은 다음과 같이 간단합니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ source ./env.sh
$ parsecmgmt -a build
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;첫번째 커맨드는 parsecmgmt 의 경로를 PATH 에 추가하는 등, 환경 변수 설정 등의
일을 처리해 주며, 두번째의 간단한 커맨드가 전체 PARSEC 3.0 빌드 프로세스를
수행하게 됩니다.&lt;/p&gt;
&lt;h2 id=&#34;perl-version-problem&#34;&gt;Perl Version Problem&lt;/h2&gt;
&lt;p&gt;하지만 Ubuntu 16.04 server 에서는 다음과 같은 에러 메세지를 내뱉으며 빌드에
실패합니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;smime.pod around line 272: Expected text after =item, not a number
smime.pod around line 276: Expected text after =item, not a number
smime.pod around line 280: Expected text after =item, not a number
smime.pod around line 285: Expected text after =item, not a number
smime.pod around line 289: Expected text after =item, not a number
POD document had syntax errors at /usr/bin/pod2man line 68.
make: *** [install_docs] Error 1
Makefile:680: recipe for target &#39;install_docs&#39; failed
[PARSEC] Error: &#39;env PATH=/usr/local/sbin:...&#39; failed.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;에러 메세지에서 유추할 수 있듯 PARSEC 3.0 의 소스 코드 중 smime.pod 파일이
문법에 맞지 않아 생긴 문제입니다.  참고로 pod 는 perl 프로그램 문서화에
사용되는 간단한 markup language 입니다[2].  Ubuntu 16.04 는 perl 5.22.1 버전을
기본으로 사용하고 있는데, PARSEC 3.0 에 있는 코드는 perl 5.14.2 버전에 맞춰져
있으며 최신 버전으로 오는 사이 문법이 바뀐 것으로 인한 문제로 보입니다.
해결책은 두가지가 있습니다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;방법 1: perl 5.14.2 설치&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Google groups 의 관련 쓰레드[3] 를 참고한 방법입니다.
5.14.2 버전의 perl 소스코드를 받아와 이를 설치하고 PARSEC 빌드에 이 버전의 perl
을 사용하는 방법입니다.  다음의 커맨드로 &lt;code&gt;~/localperl/&lt;/code&gt; 디렉토리 아래 5.14.2
버전 perl 을 설치하고 사용할 수 있습니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wget http://www.cpan.org/src/5.0/perl-5.14.2.tar.gz
$ tar zxvf perl-5.14.2.tar.gz
$ cd perl-5.14.2/
$ mkdir ~/localperl
$ ./Configure -des -Dprefix=$HOME/localperl
$ time make -j
$ make test
$ make install
$ ~/localperl/bin/perl -v
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;방법 2: pod 파일 문법 오류 수정&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;좀 더 정공법에 가까운 방법으로, 다음 글을 참고한 해결책입니다:
&lt;a href=&#34;https://yulistic.gitlab.io/2016/05/parsec-3.0-installation-issues/&#34;&gt;https://yulistic.gitlab.io/2016/05/parsec-3.0-installation-issues/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;최신 버전의 문법에 맞게 pod 파일의 문제시 되는 부분들을 고쳐주는 것으로,
문제되는 모든 pod 파일의 &lt;code&gt;=item [0-9]&lt;/code&gt; 을 &lt;code&gt;=item C&amp;lt;[0-9]&amp;gt;&lt;/code&gt; 으로 바꿔줍니다.
&lt;code&gt;diff&lt;/code&gt; 로 표현하면 다음과 같은 수정을 가하게 되겠습니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--- a/pkgs/libs/ssl/src/doc/apps/smime.pod
+++ b/pkgs/libs/ssl/src/doc/apps/smime.pod
@@ -265,28 +265,28 @@ encrypted data is used for other purposes.

 =over 4

-=item 0
+=item C&amp;lt;0&amp;gt;

 the operation was completely successfully.

-=item 1
+=item C&amp;lt;1&amp;gt;

 an error occurred parsing the command options.

-=item 2
+=item C&amp;lt;2&amp;gt;

 one of the input files could not be read.

-=item 3
+=item C&amp;lt;3&amp;gt;

 an error occurred creating the PKCS#7 file or when reading the MIME
 message.

-=item 4
+=item C&amp;lt;4&amp;gt;

 an error occurred decrypting or verifying the message.

-=item 5
+=item C&amp;lt;5&amp;gt;

 the message was verified correctly but an error occurred writing out
 the signers certificates.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;이렇게 파일 하나하나 수정하면 이 에러 메세지는 사라집니다.  참고한 링크에서는
하나하나 손으로 수정하기보다는 다음과 같이 간단한 bash shell script 를 짜서
일괄적으로 수정하는 걸 추천합니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#! /bin/bash
for i in 0 1 2 3 4 5 6 7 8 9 
do
    echo &amp;quot;Replacing &#39;=item $i&#39; to &#39;=item C&amp;lt;$i&amp;gt;&#39;&amp;quot;
    grep -rl &amp;quot;=item $i&amp;quot; * | xargs sed -i &amp;quot;s/=item $i/=item C&amp;lt;$i&amp;gt;/g&amp;quot;
done
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;이어서 설명할 문제들과 해결책도 해당 링크를 참고한 것임을 밝혀둡니다.&lt;/p&gt;
&lt;h2 id=&#34;mbstatet-conflict&#34;&gt;&lt;code&gt;__mbstate_t&lt;/code&gt; Conflict&lt;/h2&gt;
&lt;p&gt;앞의 에러 메세지는 사라지지만 이제 다음과 같은 에러 메세지가 나올 겁니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/usr/include/wchar.h:94:3: error: conflicting types for ‘__mbstate_t’
 } __mbstate_t;
   ^
In file included from ../include/machine/bsd_endian.h:37:0,
                 from ../include/sys/bsd_types.h:44,
                 from ../include/sys/bsd_param.h:64,
                 from if_host.c:48:
../include/sys/bsd__types.h:105:3: note: previous declaration of ‘__mbstate_t’ was here
 } __mbstate_t;
   ^
In file included from ../include/net/bsd_if_var.h:82:0,
                 from ../include/net/bsd_if.h:459,
                 from if_host.c:57:
../include/sys/bsd_buf_ring.h: In function ‘buf_ring_dequeue_sc’:
../include/sys/bsd_buf_ring.h:200:33: warning: variable ‘cons_next_next’ set but not used [-Wunused-but-set-variable]
  uint32_t cons_head, cons_next, cons_next_next;
                                 ^
make[1]: *** [if_host.o] Error 1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;basd__types.h&lt;/code&gt; 파일에 &lt;code&gt;__mbstate_t&lt;/code&gt; 타입을 중복 정의했기 때문에 발생한
문제입니다.  해당 파일에서 해당 정의 부분을 다음과 같이 주석 처리하면 이 문제는
사라집니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;diff --git a/pkgs/libs/uptcpip/src/include/sys/bsd__types.h b/pkgs/libs/uptcpip/src/include/sys/bsd__types.h
index fa1b0f0f26d9..bd7e6a97f4c8 100644
--- a/pkgs/libs/uptcpip/src/include/sys/bsd__types.h
+++ b/pkgs/libs/uptcpip/src/include/sys/bsd__types.h
@@ -93,6 +93,7 @@ typedef       __ct_rune_t     __wint_t;       /* wint_t (see above) */

 typedef        __uint32_t      __fixpt_t;      /* fixed point number */

+#if 0  /* Skip conflicting __mbstate_t definition */
 /*
  * mbstate_t is an opaque object to keep conversion state during multibyte
  * stream conversions.
@@ -104,5 +105,6 @@ typedef union {
        __int64_t       _mbstateL;      /* for alignment */
 } __mbstate_t;
 #endif
+#endif /* Skip conflicting __mbstate_t definition */

 #endif /* !_BSD_SYS__TYPES_H_ */
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;pkgconfig-package-not-found&#34;&gt;pkg-config Package Not Found&lt;/h2&gt;
&lt;p&gt;성공적인 빌드를 위해선 당연하지만 PARSEC 3.0 이 의존성을 가진 패키지가 모두
설치되어 있어야 합니다.  이를 주의 깊게 미리 설치해 두지 않았다면 다음과 같은
에러 메세지를 만날 수도 있습니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;configure: error: *** pkg-config not found. See http://www.freedesktop.org/software/pkgconfig/
[PARSEC] Error: ...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;위 메세지는 &lt;code&gt;pkg-config&lt;/code&gt; 프로그램이 설치되어 있지 않아서 발생한 문제임을 알 수
있습니다.  간단히 Ubuntu 의 package 시스템인 apt 를 사용해 다음과 같이 해당
프로그램을 설치해 주면 문제는 사라집니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo apt install pkg-config
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;build-success&#34;&gt;Build Success&lt;/h2&gt;
&lt;p&gt;이 정도까지가 나타날 수 있는 대부분의 문제입니다.  위 해결책들을 모두
적용했다면 아마 빌드에 성공할 겁니다.  빌드에 성공하면 다음과 같이 성공했다는
메세지를 볼 수 있을 겁니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[PARSEC]
[PARSEC] BIBLIOGRAPHY
[PARSEC]
[PARSEC] [1] Bienia. Benchmarking Modern Multiprocessors. Ph.D. Thesis, 2011.
[PARSEC] [2] Woo et al. The SPLASH-2 Programs: Characterization and Methodological Considerations. ISCA, 1995.
[PARSEC]
[PARSEC] Done.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;참고로 빌드에 꽤 긴 시간이 소모됩니다.  제가 사용한 72 코어 / 144 쓰레드
머신에서도 약 10분이 걸렸습니다.&lt;/p&gt;
&lt;h1 id=&#34;simple-usage&#34;&gt;Simple Usage&lt;/h1&gt;
&lt;p&gt;이제 빌드가 잘 되었는지 돌려봐야 할 차례입니다.  다음 커맨드는 각 벤치마크를
가장 작은 크기의 데이터셋을 가지고 실행해 보기 때문에 각 벤치마크가 돌아가긴
하는지만 보는데 적격입니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;parsecmgmt -a run
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;가장 작은 크기의 데이터셋을 사용하기 때문에 모든 벤치마크를 수행하지만 빠르게
종료됩니다.&lt;/p&gt;
&lt;h2 id=&#34;parsecmgmt-options&#34;&gt;&lt;code&gt;parsecmgmt&lt;/code&gt; Options&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;-a&lt;/code&gt; 옵션은 action 을 의미합니다.  앞의 섹션에서는 빌드를 위해 여기에 &lt;code&gt;build&lt;/code&gt;
값을 주었고, 여기선 벤치마크 수행을 위해 &lt;code&gt;run&lt;/code&gt; 값을 준 것입니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;-i&lt;/code&gt; 옵션을 통해 벤치마크들은 워크로드에서 사용할 데이터 크기를 지정할 수
있습니다.  이 인자의 값으로 test, simdev, simsmall, simmedium, simlarge, native
를 줄 수 있습니다.  Test 는 정확성 테스트만을 위한, 빨리 끝나는 데이터로 이
인자를 주지 않으면 default 로 이 값이 취해집니다.  native 는 가장 realworld
workload 에 가까운 벤치마크를 위한 데이터라 볼 수 있습니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;-p&lt;/code&gt; 옵션을 통해 어떤 sub benchmark 를 돌릴지 정할 수 있습니다.  이 옵션을
별도로 주지 않으면 모든 benchmark 를 돌리게 됩니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;-n&lt;/code&gt; 옵션은 number of threads to use 입니다.&lt;/p&gt;
&lt;p&gt;예를 들어 &lt;code&gt;parsecmgmt -p canneal -a run -i native -n 1&lt;/code&gt; 은 &lt;code&gt;canneal&lt;/code&gt; sub
benchmark 하나만을 쓰레드 한개 써서 &lt;code&gt;native&lt;/code&gt; 데이터셋으로 실행합니다.&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;[1] &lt;a href=&#34;http://parsec.cs.princeton.edu&#34;&gt;http://parsec.cs.princeton.edu&lt;/a&gt;&lt;br&gt;
[2] &lt;a href=&#34;https://en.wikipedia.org/wiki/Plain_Old_Documentation&#34;&gt;https://en.wikipedia.org/wiki/Plain_Old_Documentation&lt;/a&gt;&lt;br&gt;
[3] &lt;a href=&#34;https://groups.google.com/forum/#&#34;&gt;https://groups.google.com/forum/#&lt;/a&gt;!topic/snipersim/_1qpbmpPRtg&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>원격 데스크탑의 clipboard 를 ssh 와 xclip 으로 복사해오기</title>
      <link>/post/xclip_copy_remote_clipboard/</link>
      <pubDate>Fri, 31 Mar 2017 13:53:54 +0900</pubDate>
      <guid>/post/xclip_copy_remote_clipboard/</guid>
      <description>&lt;p&gt;여러개의 리눅스 데스크탑 PC 를 한 책상 위에서 사용하는 경우가 있다.  이 때, 한
PC 에서 Ctrl-C 해서 clipboard 에 복사한 내용을 다른쪽 PC 에서 Ctrl-V 로
붙여넣고 싶은 경우가 있다.  여러가지 해결책이 있겠으나, 다음과 같이 ssh 와
xclip 을 사용해서 해결할 수도 있다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ssh &amp;lt;username&amp;gt;@&amp;lt;remote host&amp;gt; &#39;DISPLAY=:0 xclip -o -selection clipboard&#39; | \
	xclip -i -selection clipboard
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;참고: &lt;a href=&#34;http://askubuntu.com/questions/513442/can-two-pcs-with-ubuntu-share-the-clipboard-buffer&#34;&gt;http://askubuntu.com/questions/513442/can-two-pcs-with-ubuntu-share-the-clipboard-buffer&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Install / execute spec cpu2006 benchmark</title>
      <link>/post/spec_cpu2006_install/</link>
      <pubDate>Wed, 29 Mar 2017 05:10:55 +0900</pubDate>
      <guid>/post/spec_cpu2006_install/</guid>
      <description>&lt;p&gt;SPEC, which is a standard corporation for the benchmark[1], makes and shares
various benchmark suites.  SPEC CPU 2006[1] is one of those benchmark suites.
It has made to measure performance of computation intensive workload and widely
being used now.  It has released v1.0 in 2006, 1.1 in 2008, and 1.2 in 2011.
This post briefly describes the way to install and execute the SPEC CPU 2006
v1.1 on Ubuntu 16.04 servers.&lt;/p&gt;
&lt;h1 id=&#34;automated-toolbox&#34;&gt;Automated Toolbox&lt;/h1&gt;
&lt;p&gt;For those who might say &lt;code&gt;TL; DR&lt;/code&gt;, I wrote a script that can install and execute
the SPEC CPU 2006 with one command[1].  If you have no time to read further,
just use it, please.&lt;/p&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://github.com/sjp38/spec_on_ubuntu_xenial&#34;&gt;https://github.com/sjp38/spec_on_ubuntu_xenial&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;test-environment&#34;&gt;Test Environment&lt;/h1&gt;
&lt;p&gt;The test machine I used for this post has:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Intel Xeon E7-8870 v3&lt;/li&gt;
&lt;li&gt;Linux 4.10 kernel&lt;/li&gt;
&lt;li&gt;Ubuntu 16.04.1 Server version&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;get-the-source-code&#34;&gt;Get The Source Code&lt;/h1&gt;
&lt;p&gt;You should get the source code first.  You can buy SPEC CPU 2006 in DVD or
&lt;code&gt;.iso&lt;/code&gt; file format (As of March 2017, the cost of the SPEC CPU 2006 v1.2 is
$800).
There are source code of the benchmarks, source code of tool programs that
helps compile, execution, and verification of the benchmarks, pre-compiled tool
programs, rule files for the execution of the benchmarks, and documents.
This post is written basedon SPEC CPU 2006 v1.1.
If you got the &lt;code&gt;.iso&lt;/code&gt; file, you can access to the files in it by mounting it as
below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ mkdir tmnt
$ sudo mount -o loop SPEC_CPU2006v1.1.iso ./tmnt
$ ls tmnt
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It is ok to directly install and execute the benchmarks, but I prefer to first
copy the files outside of the mounted dir.
The &lt;code&gt;owner&lt;/code&gt; of the files is &lt;code&gt;root&lt;/code&gt;, as the above command mounted the file via
the &lt;code&gt;sudo&lt;/code&gt; command.
Change the owner to you as below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ mkdir SPEC_CPU2006v1.1
$ cp -R ./tmnt/* SPEC_CPU2006v1.1/
$ sudo umount ./tmnt &amp;amp;&amp;amp; rm -fr ./tmnt
$ sudo chown -R &amp;lt;username&amp;gt; SPEC_CPU2006v1.1
$ sudo chmod -R 755 SPEC_CPU2006v1.1
$ cd SPEC_CPU2006v1.1
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;build-the-tools&#34;&gt;Build The Tools&lt;/h1&gt;
&lt;p&gt;The &lt;code&gt;.iso&lt;/code&gt; file has executable binaries for the tools, which is built for
various platforms such as redhat and suse.
But, there is no binary for Ubuntu.
Therefore, you should build the tools from the source code as below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd tools/src
$ ./buildtools
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;buildtools&lt;/code&gt; is a shell script which builds tools under &lt;code&gt;tools/src&lt;/code&gt;.
But, you may encounter some errors.  Following sections describe the errors and
how you can solve it.&lt;/p&gt;
&lt;h2 id=&#34;conflicting-types-for-getline&#34;&gt;Conflicting types for &amp;lsquo;getline&amp;rsquo;&lt;/h2&gt;
&lt;p&gt;Build of &lt;code&gt;md5sum&lt;/code&gt; will show you following error message:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gcc -DHAVE_CONFIG_H    -I/home/sjpark/SPEC_CPU2006v1.1/tools/output/include   -I. -Ilib  -c -o md5sum.o md5sum.c
In file included from md5sum.c:38:0:
lib/getline.h:31:1: error: conflicting types for &#39;getline&#39;
 getline PARAMS ((char **_lineptr, size_t *_n, FILE *_stream));
 ^
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Type conflict is occurred because &lt;code&gt;getline()&lt;/code&gt; and &lt;code&gt;getdelim()&lt;/code&gt; functions are
declared in &lt;code&gt;stdio.h&lt;/code&gt;, but those are declared again in &lt;code&gt;getline.h&lt;/code&gt; file.
You can fix this as below, by checking &lt;code&gt;GLIBC&lt;/code&gt; version.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--- a/tools/src/specmd5sum/lib/getline.h
+++ b/tools/src/specmd5sum/lib/getline.h
@@ -27,10 +27,14 @@ Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.  */
 #  endif
 # endif

+# if __GLIBC__ &amp;lt; 2
+
 int
 getline PARAMS ((char **_lineptr, size_t *_n, FILE *_stream));

 int
 getdelim PARAMS ((char **_lineptr, size_t *_n, int _delimiter, FILE *_stream));

+#endif
+
 #endif /* not GETLINE_H_ */
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;undefined-reference-to-pow&#34;&gt;Undefined reference to &lt;code&gt;pow&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;I referenced an internet post[3] to solve this and following two problems.&lt;/p&gt;
&lt;p&gt;Now, you will see below error message while building &lt;code&gt;perl&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cc -L/home/sjpark/SPEC_CPU2006v1.1/tools/output/lib -L/usr/local/lib -o miniperl \
            miniperlmain.o opmini.o libperl.a
libperl.a(pp.o): In function `Perl_pp_pow&#39;:
pp.c:(.text+0x2a76): undefined reference to `pow&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It failed to find &lt;code&gt;pow&lt;/code&gt; functiona.  You should modify it to link &lt;code&gt;libm&lt;/code&gt;
library.
You can solve this problem by setting &lt;code&gt;PERLFLAGS&lt;/code&gt; env variable and executing
&lt;code&gt;buildtools&lt;/code&gt; again:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$ PERLFLAGS=&amp;quot;-A libs=-lm -A libs=-ldl&amp;quot; ./buildtools&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;you-havent-done-a-make-depend-yet&#34;&gt;You haven&#39;t done a &amp;ldquo;make depend&amp;rdquo; yet!&lt;/h2&gt;
&lt;p&gt;Now, you see below error message.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;You haven&#39;t done a &amp;quot;make depend&amp;quot; yet!
make[1]: *** [hash.o] Error 1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &lt;code&gt;bin/sh&lt;/code&gt; which is used while building &lt;code&gt;perl&lt;/code&gt; directs to &lt;code&gt;/bin/dash&lt;/code&gt;.
This problem made by &lt;code&gt;dash&lt;/code&gt;.
Simply modify the symbolic link so that it can use &lt;code&gt;bash&lt;/code&gt; instead.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo rm /bin/sh
$ sudo ln -s /bin/bash /bin/sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you want it to revert this change, simply restore the symbolic link again.&lt;/p&gt;
&lt;h2 id=&#34;asmpageh-file-not-found&#34;&gt;&lt;code&gt;asm/page.h&lt;/code&gt; file not found&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;tools/src/perl-5.8.8/ext/IPC/SysV/SysV.xs&lt;/code&gt; is including a kernel header file,
&lt;code&gt;asm/page.h&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cc -c   -I/home/sjpark/SPEC_CPU2006v1.1/tools/output/include -fno-strict-aliasing -pipe -Wdeclaration-after-statement -I/usr/local/include -D_LARGEFILE_SOURCE -D_FILE_OFFSET_BITS=64 -O2   -DVERSION=\&amp;quot;1.04\&amp;quot; -DXS_VERSION=\&amp;quot;1.04\&amp;quot; -fpic &amp;quot;-I../../..&amp;quot;   SysV.c
SysV.xs:7:25: fatal error: asm/page.h: No such file or directory
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Block the &lt;code&gt;include&lt;/code&gt; statement in the &lt;code&gt;SysV.xs&lt;/code&gt; file and define &lt;code&gt;PAGE_SIZE&lt;/code&gt; as
below.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--- a/tools/src/perl-5.8.8/ext/IPC/SysV/SysV.xs
+++ b/tools/src/perl-5.8.8/ext/IPC/SysV/SysV.xs
@@ -4,7 +4,7 @@

 #include &amp;lt;sys/types.h&amp;gt;
 #ifdef __linux__
-#   include &amp;lt;asm/page.h&amp;gt;
+#define PAGE_SIZE      4096
 #endif
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;perl-test-fail&#34;&gt;&lt;code&gt;perl&lt;/code&gt; test fail&lt;/h2&gt;
&lt;p&gt;If you apply every solution above and run &lt;code&gt;$ PERLFLAGS=&amp;quot;-A libs=-lm -A libs=-ldl&amp;quot; ./buildtools&lt;/code&gt;, about 9 of 900 tests for the perl fails.
Because those tests are ignorable, just answer to ignore (Simply enter &lt;code&gt;y&lt;/code&gt; as
the prompt explains).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Failed 9 test scripts out of 907, 99.01% okay.
### Since not all tests were successful, you may want to run some of
### them individually and examine any diagnostic messages they produce.
### See the INSTALL document&#39;s section on &amp;quot;make test&amp;quot;.
### You have a good chance to get more information by running
###   ./perl harness
### in the &#39;t&#39; directory since most (&amp;gt;=80%) of the tests succeeded.
### You may have to set your dynamic library search path,
### LD_LIBRARY_PATH, to point to the build directory:
###   setenv LD_LIBRARY_PATH `pwd`:$LD_LIBRARY_PATH; cd t; ./perl harness
###   LD_LIBRARY_PATH=`pwd`:$LD_LIBRARY_PATH; export LD_LIBRARY_PATH; cd t; ./perl harness
###   export LD_LIBRARY_PATH=`pwd`:$LD_LIBRARY_PATH; cd t; ./perl harness
### for csh-style shells, like tcsh; or for traditional/modern
### Bourne-style shells, like bash, ksh, and zsh, respectively.
u=0.92  s=0.69  cu=89.23  cs=5.47  scripts=907  tests=112394
make[2]: *** [_test_tty] Error 1
make[2]: Leaving directory `/home/sjpark/SPEC_CPU2006v1.1/tools/src/perl-5.8.8&#39;
make[1]: *** [_test] Error 2
make[1]: Leaving directory `/home/sjpark/SPEC_CPU2006v1.1/tools/src/perl-5.8.8&#39;
make: *** [test] Error 2
+ &#39;[&#39; 2 -ne 0 &#39;]&#39;
+ set +x


Hey!  Some of the Perl tests failed!  If you think this is okay, enter y now:
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;build-success&#34;&gt;Build success&lt;/h2&gt;
&lt;p&gt;Finally, the build step completes.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Tools built successfully.  Go to the top of the tree and
source the shrc file.  Then you should be ready.
$
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;execution&#34;&gt;Execution&lt;/h1&gt;
&lt;h2 id=&#34;configuration-file&#34;&gt;Configuration File&lt;/h2&gt;
&lt;p&gt;Now you can execute the benchmarks.
For this, you should configure the execution environemnts of the benchmarks.
There are example configuration files under &lt;code&gt;config/&lt;/code&gt; dir.&lt;br&gt;
&lt;code&gt;Example-linux64-amd64-gcc43.cfg&lt;/code&gt; would be appropriate for the test system I
use for this post.
You can modify this file as you want.
In my test, I just copied the file to &lt;code&gt;config/config.cfg&lt;/code&gt; file.&lt;/p&gt;
&lt;h2 id=&#34;environment-setup&#34;&gt;Environment Setup&lt;/h2&gt;
&lt;p&gt;For execution of SPEC CPU benchmarks, you should set various environemnt
variables.  Below simple one command do that for you.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ source ./shrc
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;running-workload&#34;&gt;Running Workload&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;runspec&lt;/code&gt; program is used for the execution of each benchmark.
This program is located under &lt;code&gt;bin/&lt;/code&gt; dir of the SPEC CPU source code, but you
can use it directly without entering path, as the above envrionment variables
setting has registered it as &lt;code&gt;$PATH&lt;/code&gt;.
For example, if you want to execute &lt;code&gt;mcf&lt;/code&gt; benchmark, you can use below command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ runspec --iterations 1 --size ref --action onlyrun --config config.cfg --noreportable mcf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This command executes &lt;code&gt;mcf&lt;/code&gt; benchmark and prints the path to the log file
describing the execution results.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;...

Run Complete

The log for this run is in /home/username/spec/spec_src/result/CPU2006.003.log

runspec finished at Sun Sep 24 13:55:14 2017; 290 total seconds elapsed
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To do some experiments for your particular use case, you should understand the
usage of &lt;code&gt;runspec&lt;/code&gt;.
Because it is an out of scope of this post, reference to other documents,
please.&lt;/p&gt;
&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;This post described the way to run SPEC CPU 2006 on an Ubuntu 16.04 system.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[0] &lt;a href=&#34;http://spec.org/&#34;&gt;http://spec.org/&lt;/a&gt;&lt;br&gt;
[1] &lt;a href=&#34;http://spec.org/benchmarks.html#cpu&#34;&gt;http://spec.org/benchmarks.html#cpu&lt;/a&gt;&lt;br&gt;
[2] &lt;a href=&#34;http://spec.org/order.html&#34;&gt;http://spec.org/order.html&lt;/a&gt;&lt;br&gt;
[3] &lt;a href=&#34;https://wiki.linaro.org/MichaelHope/Sandbox/BuildingSPECTools&#34;&gt;https://wiki.linaro.org/MichaelHope/Sandbox/BuildingSPECTools&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Updating Google Chrome on Fedora 23</title>
      <link>/post/fedora-chrome-update/</link>
      <pubDate>Mon, 20 Mar 2017 22:24:26 +0900</pubDate>
      <guid>/post/fedora-chrome-update/</guid>
      <description>&lt;p&gt;I am using Fedora 23 laptop and installed stable version Google Chrome from its
official website [0].  In this case, just using &lt;code&gt;Updates&lt;/code&gt; of Fedora &lt;code&gt;Software&lt;/code&gt;
program doesn&#39;t update Chrome automatically.  For the case, follow below
commands to update your Chrome:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo dnf update google-chrome-stable
...
$ sudo killall chrome
$ google-chrome-stable
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The second &lt;code&gt;killall&lt;/code&gt; command is necessary because Chrome doesn&#39;t kill its
process by just cliking &lt;code&gt;Close&lt;/code&gt; button.  Or, you may reboot your computer but
you wouldn&#39;t like that.&lt;/p&gt;
&lt;p&gt;[0] &lt;a href=&#34;https://www.google.com/chrome/browser/desktop/index.html?brand=CHBD&amp;amp;gclid=CKiMjdqX5dICFYcGKgodqZIM2Q&#34;&gt;https://www.google.com/chrome/browser/desktop/index.html?brand=CHBD&amp;amp;gclid=CKiMjdqX5dICFYcGKgodqZIM2Q&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using arping to know ip-MAC mapping</title>
      <link>/post/arping-howto/</link>
      <pubDate>Tue, 07 Mar 2017 19:41:16 +0900</pubDate>
      <guid>/post/arping-howto/</guid>
      <description>&lt;p&gt;You can use &lt;code&gt;arping&lt;/code&gt; to know IP address to MAC address mapping of your local
network.  Usage is simple:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;arping  [-AbDfhqUV]  [-c count] [-w deadline] [-s source] -I interface destination
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;For example, you may use the command as below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ arping -I eth0 10.0.0.1
ARPING 10.0.0.1 from 10.0.0.2 eth0
Unicast reply from 10.0.0.1 [11:22:33:44:55:66]  0.123ms
Unicast reply from 10.0.0.1 [11:22:33:44:55:66]  0.251ms
...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Secret of the tool is ARP protocol [1].  To know the MAC address of the machine
that has a specific IP address, IP protocol layer uses the protocol.  MAC
address that found in this way can be used to communicate with Ethernet
protocol layer.  &lt;code&gt;arping&lt;/code&gt; just sends the ARP REQUEST to local network
neighbour.&lt;/p&gt;
&lt;p&gt;It could be useful in case of internet connection problem if IP duplication is
suspicious.&lt;/p&gt;
&lt;p&gt;[1] &lt;a href=&#34;http://www.erg.abdn.ac.uk/users/gorry/course/inet-pages/arp.html&#34;&gt;http://www.erg.abdn.ac.uk/users/gorry/course/inet-pages/arp.html&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
