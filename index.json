[{"content":"A few weeks ago I heard modern normal computers can build kernel faster than I expected. My 10 years old personal laptop (Thinkpad X1) used to build a kernel per a couple of hours. The last time I built kernel on the laptop was about 8 years ago. Since then, I was always using only workstation or server level machines for building kernels.\nSo I wanted to know how good modern normal desktop-level machines are, by myself. Also I was about to lose access to my previous development environment, and expecting a few weeks for setting a new one.\nSo I bought a ~$320 mini PC from Amazon. On the machine, I installed Debian13 desktop and ran kcbench. The results are as below:\n$ bash kcbench -s 6.17 Processor: AMD Ryzen 7 6800H with Radeon Graphics [16 threads] Cpufreq; Memory: powersave [amd-pstate-epp]; 27841 MiB Linux running: 6.12.48+deb13-amd64 [x86_64] Compiler: gcc (Debian 14.2.0-19) 14.2.0 Linux compiled: 6.17.0 [/.../.cache/kcbench/linux-6.17] Config; Environment: defconfig; CCACHE_DISABLE=\u0026#34;1\u0026#34; Build command: make vmlinux Filling caches: This might take a while... Done Run 1 (-j 16): 161.38 seconds / 22.31 kernels/hour [P:1440%, 134 maj. pagefaults] Run 2 (-j 16): 162.53 seconds / 22.15 kernels/hour [P:1441%, 140 maj. pagefaults] Run 3 (-j 19): 172.87 seconds / 20.82 kernels/hour [P:1366%, 266 maj. pagefaults] Run 4 (-j 19): 164.76 seconds / 21.85 kernels/hour [P:1446%, 258 maj. pagefaults] Run 5 (-j 8): 190.83 seconds / 18.86 kernels/hour [P:742%, 49 maj. pagefaults] Run 6 (-j 8): 190.21 seconds / 18.93 kernels/hour [P:743%, 55 maj. pagefaults] Run 7 (-j 11): 178.62 seconds / 20.15 kernels/hour [P:1011%, 96 maj. pagefaults] Run 8 (-j 11): 185.62 seconds / 19.39 kernels/hour [P:975%, 126 maj. pagefaults] So, about three minutes per clean kernel build. I\u0026rsquo;d say this is not bad for small kernel hacking setup. While the build is ongoing, I can definitely hear the fan is running. But that\u0026rsquo;s not that bad. At least not worse than the fan for myself that I use in summer.\nI also setup a QEMU-based virtual machine, providing 8 cores and 16 GiB memory. Still, it works reasonably fast.\nProcessor: QEMU Virtual CPU version 2.5+ [8 threads] Cpufreq; Memory: Unknown; 6738 MiB Linux running: 6.18.0-rc1-mm-new-damon+ [x86_64] Compiler: gcc (Debian 14.2.0-19) 14.2.0 Linux compiled: 6.17.0 [/.../.cache/kcbench/linux-6.17/] Config; Environment: defconfig; CCACHE_DISABLE=\u0026#34;1\u0026#34; Build command: make vmlinux Filling caches: This might take a while... Done Run 1 (-j 8): 209.24 seconds / 17.21 kernels/hour [P:742%, 33 maj. pagefaults] Run 2 (-j 8): 209.67 seconds / 17.17 kernels/hour [P:742%, 40 maj. pagefaults] Run 3 (-j 10): 214.39 seconds / 16.79 kernels/hour [P:744%, 133 maj. pagefaults] Run 4 (-j 10): 214.73 seconds / 16.77 kernels/hour [P:744%, 134 maj. pagefaults] I have used this mini machine as my DAMON hacking environment for last three weeks, and quite satisfied so far. I even traveled with it. I brought bluetooth keyboard (having a trackpoint like Thinkpad laptops) and an HCMI cable together, and connected the machine with a tv in the hotel room. It was weird to code on the bad, but anyway it worked with no problem.\nSo my take on these results I got so far is that the world has been much more kind for hobbyist kernel hackers. And I can continue kernel hacking without serious build machine resource dependencies.\n","permalink":"https://sjp38.github.io/posts/mini_desktop_as_local_kernel_hacking_machine/","summary":"A few weeks ago I heard modern normal computers can build kernel faster than I expected. My 10 years old personal laptop (Thinkpad X1) used to build a kernel per a couple of hours. The last time I built kernel on the laptop was about 8 years ago. Since then, I was always using only workstation or server level machines for building kernels.\nSo I wanted to know how good modern normal desktop-level machines are, by myself.","title":"A mini desktop as a local kernel hacking machine"},{"content":"DAMON talk for Kernel Recipes 2025 has been scheduled. The title of the talk is \u0026ldquo;Overcoming Observer Effects in Memory Management with DAMON\u0026rdquo;. It will introduce DAMON at whole for wider audience.\n","permalink":"https://sjp38.github.io/posts/kernel_recipes_2025_talk/","summary":"DAMON talk for Kernel Recipes 2025 has been scheduled. The title of the talk is \u0026ldquo;Overcoming Observer Effects in Memory Management with DAMON\u0026rdquo;. It will introduce DAMON at whole for wider audience.","title":"I will have a talk at the Kernel Recipes 2025"},{"content":"DAMON talk for OSSummit North America 2025 has been accepted and scheduled. The title of the talk is \u0026ldquo;Self-Driving DAMON/S: Controlled and Automated Access-aware Efficient Systems\u0026rdquo;. It will present DAMON\u0026rsquo;s two auto-tuning features for access monitoring and access-aware system operations.\n","permalink":"https://sjp38.github.io/posts/ossummit_na_2025_talk/","summary":"DAMON talk for OSSummit North America 2025 has been accepted and scheduled. The title of the talk is \u0026ldquo;Self-Driving DAMON/S: Controlled and Automated Access-aware Efficient Systems\u0026rdquo;. It will present DAMON\u0026rsquo;s two auto-tuning features for access monitoring and access-aware system operations.","title":"I will have a talk at the Open Source Summit North America 2025"},{"content":"I will present and discuss about the current status and future plans of DAMON, and any requirements to DAMON for more access-aware memory management kernel subsystem of future in Linux Storage/File System/Memory Management/BPF (LSFMM+BPF) 2025. The title of the talks are \u0026ldquo;DAMON Updates and Plans: Monitoring Parameters Auot-tuning and Memory Tiering\u0026rdquo; and \u0026ldquo;DAMON Requirements for Access-aware MM of Future\u0026rdquo;, respectively.\nDetailed schedules can be found from the below Google doc spreadsheet.\nhttps://docs.google.com/spreadsheets/d/1PgjzaPOnIHgRIfqgwDNiftY5Xr6aU3NLWtDs7zFoIvc/edit?gid=1852749899#gid=1852749899\n","permalink":"https://sjp38.github.io/posts/lsfmmbpf_2025_talks/","summary":"I will present and discuss about the current status and future plans of DAMON, and any requirements to DAMON for more access-aware memory management kernel subsystem of future in Linux Storage/File System/Memory Management/BPF (LSFMM+BPF) 2025. The title of the talks are \u0026ldquo;DAMON Updates and Plans: Monitoring Parameters Auot-tuning and Memory Tiering\u0026rdquo; and \u0026ldquo;DAMON Requirements for Access-aware MM of Future\u0026rdquo;, respectively.\nDetailed schedules can be found from the below Google doc spreadsheet.","title":"I will have two sessions for DAMON at LSFMM+BPF 2025"},{"content":"As today is the last day of 2024, I checked my open source commits statistics using my simple and buggy scripts. Similar statistics for 2023 is available at another post.\nNote that the script may have bugs, and numbers don\u0026rsquo;t tell everything.\nIn short, I made 7th and 2nd biggest changes to Linux kernel memory management subsystem among the 340 people, in terms of lines of changes (2,347) and commits (102).\nFor the Linux kernel whole tree, the numbers become 235-th (3,754 lines) and 74th (150 commits) among 5,278 people.\nI also made around 45,000 lines of changes with around 2,500 commits for non-Linux open source projects.\nLinux kernel statistics I ran my buggy script[1] to show some 2024 statistics for memory management subsystem and whole tree of Linux kernel as below.\n$ date Tue Dec 31 10:23:57 AM PST 2024 $ $ # for memory management subsystem, number of changed lines $ ./authors.py ~/linux --commits linus/master \\ --linux_subsystems \u0026#34;MEMORY MANAGEMENT\u0026#34; \\ --since 2024-01-01 --until 2024-12-31 --skip_merge_commits \\ --sortby lines --max_nr_authors 9 [...] 7. SeongJae Park \u0026lt;sj@kernel.org\u0026gt;: 2347 lines [...] # 340 authors, 82650 lines in total $ $ # for memory management subsystem, number of commits $ ./authors.py ~/linux --commits linus/master --linux_subsystems \u0026#34;MEMORY MANAGEMENT\u0026#34; --since 2024-01-01 --until 2024-12-31 --skip_merge_commits --sortby commits --max_nr_authors 9 [...] 2. SeongJae Park \u0026lt;sj@kernel.org\u0026gt;: 102 commits [...] # 340 authors, 1938 commits in total $ $ # for linux whole tree, number of changed lines $ ./authors.py ~/linux --commits linus/master \\ --since 2024-01-01 --until 2024-12-31 --skip_merge_commits \\ --sortby lines --max_nr_authors 6000 [...] 235. SeongJae Park \u0026lt;sj@kernel.org\u0026gt;: 3754 lines [...] # 5278 authors, 4698294 lines in total $ $ # for linux whole tree, number of commits $ ./authors.py ~/linux --commits linus/master \\ --since 2024-01-01 --until 2024-12-31 --skip_merge_commits \\ --sortby commits --max_nr_authors 6000 [...] 74. SeongJae Park \u0026lt;sj@kernel.org\u0026gt;: 150 commits [...] # 5278 authors, 71163 commits in total Memory Management Subsystem In 2024, 340 people participated in Linux kernel memory management subsystem development by making 82,650 lines of changes with 1,938 commits.\nI made 7th and 2nd biggest changes among the 340 people, for lines of changes (2,347) and commits (102). Note that I counted only files under mm/ directory of the source tree, though.\nDistribution of the numbers can be plotted like below.\n$ ./authors.py ~/linux --commits linus/master \\ --linux_subsystems \u0026#34;MEMORY MANAGEMENT\u0026#34; \\ --since 2024-01-01 --until 2024-12-31 --skip_merge_commits \\ --sortby lines --max_nr_authors 400 --pr_for_plot | \\ ../gnuplot/plot.py --ylog --pointsize 0.3 mm-lines-per-author-2024.png The plot for the distribution of the number of changed lines per author for memory management subsystem in 2024 is like below. Note that y-axis is in logscale. My number on the graph is 2,347.\nThe plot for the distribution of the number of commits per author for memory management subsystem in 2024 is like below. Note that both x-axis and y-axis are in logscale. My number on the graph is 102.\nLinux kernel Whole Tree In 2024, 5,278 people participated in Linux kernel development by making 4,598.294 lines of changes with 71,163 commits.\nI made 235th and 74th biggest changes among the 5,278 people, for lines of changes (3,754) and commits (150).\nThe plot for the distribution of the number of changed lines per author for the whole Linux kernel source tree in 2024 is like below. Note that both x-axis and y-axis are in logscale. My number on this graph is 3,754.\nThe plot for the distribution of the number of commits per author for the whole Linux kernel source tree in 2024 is like below. Note that both x-axis and y-axis is in logscale. My number on this graph is 150.\nNon-Linux Kernel Contributions In 2024, I also I spend some of my time on projects other than Linux kernel including\nDAMON user-space tool (damo), an email tool for DAMON and Linux kernel contributors (hkml), my personal scripts toolbox (\u0026rsquo;lazybox\u0026rsquo;), and perfbook Korean translation (https://github.com/sjp38/perfbook-ko_KR). Let\u0026rsquo;s see simple record of my contributions on those.\n$ ./profile_author.py SeongJae --repo ~/damo --max_files 5 # below changes made by # - SeongJae Park \u0026lt;sj@kernel.org\u0026gt; # - SeongJae Park \u0026lt;sj38.park@gmail.com\u0026gt; # since 2024-01-01 11:29:53 -0800 until 2024-12-30 13:56:29 -0800 # \u0026lt;changed_lines\u0026gt; \u0026lt;file\u0026gt; 2846 _damon_sysfs.py 2660 USAGE.md 2079 src/damo_report_access.py 1330 src/damo_show.py 946 src/_damo_records.py # 19745 total lines # 113 total files # 1021 commits $ ./profile_author.py SeongJae --repo ~/hackermail/ --max_files 5 # below changes made by # - SeongJae Park \u0026lt;sj@kernel.org\u0026gt; # - SeongJae Park \u0026lt;sj38.park@gmail.com\u0026gt; # - SeongJae Park \u0026lt;sjpark@amazon.com\u0026gt; # since 2024-01-01 11:46:33 -0800 until 2024-12-28 15:02:12 -0800 # \u0026lt;changed_lines\u0026gt; \u0026lt;file\u0026gt; 3753 src/hkml_view.py 2832 src/hkml_view_mails.py 2471 hkml_list.py 2045 USAGE.md 1398 src/hkml_list.py # 22074 total lines # 57 total files # 1560 commits $ ./profile_author.py SeongJae --repo ~/lazybox/ --max_files 5 # below changes made by # - SeongJae Park \u0026lt;sj38.park@gmail.com\u0026gt; # since 2024-01-03 18:16:02 -0800 until 2024-07-26 17:18:56 -0700 # \u0026lt;changed_lines\u0026gt; \u0026lt;file\u0026gt; 513 git_helpers/relstat.py 329 git_helpers/profile_author.py 222 parallel_runs/README.md 219 README.md 208 parallel_runs/exp.py # 3525 total lines # 57 total files # 90 commits $ ./profile_author.py SeongJae --repo ~/perfbook-ko_KR/ --max_files 5 # below changes made by # - SeongJae Park \u0026lt;sj38.park@gmail.com\u0026gt; # since 2024-01-06 09:09:02 -0800 until 2024-02-11 09:09:47 -0800 # \u0026lt;changed_lines\u0026gt; \u0026lt;file\u0026gt; 1814 appendix/whymb/whymemorybarriers.tex 622 glossary.tex 427 appendix/toyrcu/toyrcu.tex # 2863 total lines # 3 total files # 42 commits Like other years, I made no small amount of changes for non-Linux projects in 2024. Around 2,500 commits of around 45,000 lines of change in total. I remind and find a few interesting points below from the numbers.\nThe last commit to perfbook Korean translation was February 2024, since I completed the translation of the second edition, which I started since 2021. I may do the translation from the scratch again, once the third edition is tagged. I highly recommend every programmer to read the book, since it is not only about performance and parallelism but general software engineering, in my opinion.\nMy last commit to lazybox was July 2024. It is a bit surprise to me, since most of my hobby programming time was spent on it for many years. I might became a boring man, or just became busy for other projects. Hopefully I will revisit it next year.\nThe number of changes to hkml is pretty impressive to me. I made changes for hkml even more than those for damo. I actually made an official support commitment this year, and looking forward to introduce it to more people in FOSDEM'25, to promote more DAMON contributors.\n","permalink":"https://sjp38.github.io/posts/my_opensource_commits_stat_2024/","summary":"As today is the last day of 2024, I checked my open source commits statistics using my simple and buggy scripts. Similar statistics for 2023 is available at another post.\nNote that the script may have bugs, and numbers don\u0026rsquo;t tell everything.\nIn short, I made 7th and 2nd biggest changes to Linux kernel memory management subsystem among the 340 people, in terms of lines of changes (2,347) and commits (102).","title":"My opensource commits statistics in 2024"},{"content":"I will present DAMON in FOSDEM'25. The title of the talk is \u0026ldquo;DAMON: Kernel Subsystem for Data Access Monitoring and Access-aware System Operations\u0026rdquo;.\n","permalink":"https://sjp38.github.io/posts/fosdem2025_talk/","summary":"I will present DAMON in FOSDEM'25. The title of the talk is \u0026ldquo;DAMON: Kernel Subsystem for Data Access Monitoring and Access-aware System Operations\u0026rdquo;.","title":"I will have a talk at the FOSDEM 2025"},{"content":"I just made a DAMON logo using DAMON, like below.\n$ git clone https://github.com/sjp38/masim \u0026amp;\u0026amp; cd masim $ cat damon_pixel_2 11111111 11 11 111111 11111111 11 11 11111111 11111111 1111 11111111 11111111 11 11 11111111 11111111 1111 11111111 $ ./pixels_to_access_config.py ./damon_pixel_2 $((100*1024*1024)) 300 damon.cfg $ sudo damo record \u0026#34;./masim ./configs/stairs.cfg\u0026#34; $ sudo damo report heatmap --output damon.png The output is below:\nThe cropped one:\n","permalink":"https://sjp38.github.io/posts/damon_heatmap_logo/","summary":"I just made a DAMON logo using DAMON, like below.\n$ git clone https://github.com/sjp38/masim \u0026amp;\u0026amp; cd masim $ cat damon_pixel_2 11111111 11 11 111111 11111111 11 11 11111111 11111111 1111 11111111 11111111 11 11 11111111 11111111 1111 11111111 $ ./pixels_to_access_config.py ./damon_pixel_2 $((100*1024*1024)) 300 damon.cfg $ sudo damo record \u0026#34;./masim ./configs/stairs.cfg\u0026#34; $ sudo damo report heatmap --output damon.png The output is below:\nThe cropped one:","title":"Creating DAMON logo using DAMON"},{"content":"DAMON talk for OSSummit EU 2024 has accepted and scheduled. The talk will focus on use cases of DAMON for saving memory including those for real world products.\nThe title of the talk is \u0026ldquo;DAMON Recipes: Ways to Save Memory Using a Linux Kernel Subsystem in the Real World\u0026rdquo;.\n","permalink":"https://sjp38.github.io/posts/ossummit_eu_2024_talk/","summary":"DAMON talk for OSSummit EU 2024 has accepted and scheduled. The talk will focus on use cases of DAMON for saving memory including those for real world products.\nThe title of the talk is \u0026ldquo;DAMON Recipes: Ways to Save Memory Using a Linux Kernel Subsystem in the Real World\u0026rdquo;.","title":"I will have a talk at the Open Source Summit Euroe 2024"},{"content":"I will present and discuss about the current status and future plans of DAMON in Linux Storage/File System/Memory Management/BPF (LSFMM+BPF) 2024. The title of the talks is \u0026ldquo;DAMON updates and Plans: Automation of DAMON tuning, tiering, and VM guest scaling\u0026rdquo;.\nhttps://docs.google.com/spreadsheets/d/176LXLys9Uh6A-Eal2flrzcbUSJMUXGkGwyihr9jAAaQ/edit#gid=0\n","permalink":"https://sjp38.github.io/posts/lsfmmbpf_2024_talk/","summary":"I will present and discuss about the current status and future plans of DAMON in Linux Storage/File System/Memory Management/BPF (LSFMM+BPF) 2024. The title of the talks is \u0026ldquo;DAMON updates and Plans: Automation of DAMON tuning, tiering, and VM guest scaling\u0026rdquo;.\nhttps://docs.google.com/spreadsheets/d/176LXLys9Uh6A-Eal2flrzcbUSJMUXGkGwyihr9jAAaQ/edit#gid=0","title":"I will have a session for DAMON at LSFMM 2024"},{"content":"I started subscribing linux kernel mailing list with my gmail account in 2013. Dealing with the large amount of mails was not that easy, probably due to my poor setup and being lazy at trying more tools.\nIn 2019, while returning from Linux Plumbers Conference, I read an LWN article saying Linus Torvalds is now considering unsubscribing the linux kernel mailing list, owing to the evolvement of the public-inbox and lore.kernel.org.\nlore.kernel.org was so nice but I wanted some more personalized mails management setup, and wanted to avoid the dependency on the web browser and the internet. I hence further looked into the internal of public-inbox a bit. The git-based mails management structure of public-inbox made me believe maybe I could hack my own mail client using it. I hence started the hackermail project. After about a few weeks of the hack, I replaced some parts of my mail workflow with the new tool, namely hkml, and it became much better than before. It looked like there were many more things that I could improve with it, but because it was already enough for my personal workflow, I stopped working on the project for a while. I only fixed some bugs and implemented features as required for myself.\nAfter I started using hackermail, I met a few kernel hackers who reached out to me asking how I manage mails. They were also finding a better way for the kernel mails management. I introduced them hackermail and my workflow. Because it was optimized for only my personal workflow, my answer was not that helpful for them. They gave me many helpful advice, though. I added some TODO items for them but didn\u0026rsquo;t prioritize and work for those.\nA few months ago, I learned that too many gmail accounts subscribing linux kernel mailing list can be a problem. I personally want every discussion to Cc linux-kernel@, but don\u0026rsquo;t want to make kernel.org have the problem. Hence I unsubscribed the mailing lists and decided to improve hkml to a level that I can migrate all my workflow on it. I also wanted it to be good enough for not only my workflow but also for general. At least the old TODO items should be removed.\nSo I hacked on it in personal time again. After a few months of such a hack, now I feel I made all the features I wanted to have. The old todo items are now removed. Some of the items were added for not myself but others, but some of those turned out to be very helpful for me, too. Now I think my workflow itself is much more improved.\nDue to my tiny source of ideas rather than the quality of the tool, now I show not many TODO items. Hence, I tagged the current version of the tool as v1.0.0. I hope it answers the questions on my mail management workflow, better than those of the past.\n","permalink":"https://sjp38.github.io/posts/hackermail_v1/","summary":"I started subscribing linux kernel mailing list with my gmail account in 2013. Dealing with the large amount of mails was not that easy, probably due to my poor setup and being lazy at trying more tools.\nIn 2019, while returning from Linux Plumbers Conference, I read an LWN article saying Linus Torvalds is now considering unsubscribing the linux kernel mailing list, owing to the evolvement of the public-inbox and lore.","title":"Hackermail v1 is released"},{"content":"DAMON talk for OSSummit North America 2024 has been accepted and scheduled. The talk will present DAMOS auto-tuning and hopefully, more new DAMO features. The features are still under development, but hopefully, the power of presentation-driven development will make it. ;) Looking forward to meeting you there!\n","permalink":"https://sjp38.github.io/posts/ossummit_na_2024_talk/","summary":"DAMON talk for OSSummit North America 2024 has been accepted and scheduled. The talk will present DAMOS auto-tuning and hopefully, more new DAMO features. The features are still under development, but hopefully, the power of presentation-driven development will make it. ;) Looking forward to meeting you there!","title":"I will have a talk at the Open Source Summit North America 2024"},{"content":"제 작은 취미 프로젝트[1]였던 Paul E. McKenney 의 책 한국어 번역이 약 8년 만에 소박한 이정표[2]를 완성했습니다. 매우 재미있고 유익한 여정이었습니다.\n[1] https://git.kernel.org/pub/scm/linux/kernel/git/paulmck/perfbook.git/commit/?id=edbfcdee0460 [2] https://lore.kernel.org/perfbook/20240211175355.4986-1-sj38.park@gmail.com/\n","permalink":"https://sjp38.github.io/posts/ko/perfbook_2nd_edition_translation_complete/","summary":"제 작은 취미 프로젝트[1]였던 Paul E. McKenney 의 책 한국어 번역이 약 8년 만에 소박한 이정표[2]를 완성했습니다. 매우 재미있고 유익한 여정이었습니다.\n[1] https://git.kernel.org/pub/scm/linux/kernel/git/paulmck/perfbook.git/commit/?id=edbfcdee0460 [2] https://lore.kernel.org/perfbook/20240211175355.4986-1-sj38.park@gmail.com/","title":"Perfbook 2nd edition translation is complete"},{"content":"After about 8 years of progress on my little hobby project[1], the Korean translation of Paul E. McKenney \u0026rsquo;s book, I\u0026rsquo;m marking it as completed a humble milestone[2]. It was a very fun and informative journey.\n[1] https://git.kernel.org/pub/scm/linux/kernel/git/paulmck/perfbook.git/commit/?id=edbfcdee0460 [2] https://lore.kernel.org/perfbook/20240211175355.4986-1-sj38.park@gmail.com/\n","permalink":"https://sjp38.github.io/posts/perfbook_2nd_edition_translation_complete/","summary":"After about 8 years of progress on my little hobby project[1], the Korean translation of Paul E. McKenney \u0026rsquo;s book, I\u0026rsquo;m marking it as completed a humble milestone[2]. It was a very fun and informative journey.\n[1] https://git.kernel.org/pub/scm/linux/kernel/git/paulmck/perfbook.git/commit/?id=edbfcdee0460 [2] https://lore.kernel.org/perfbook/20240211175355.4986-1-sj38.park@gmail.com/","title":"Perfbook 2nd edition translation is complete"},{"content":"As today is the last day of 2023, I checked some open source commits statistics using my simple and buggy script, and github. Similar statistics for 2022 is available at another post.\nIn short, I made 8th and 4th biggest changes to Linux kernel memory management subsystem among the 295 people, for lines of changes (1,910) and commits (66).\nFor the Linux kernel whole tree, the numbers become 264th (3,562 lines) and 80th (147 commits) among 5,006 people.\nLinux kernel statistics I ran my buggy script[1] to show some 2023 statistics for memory management subsystem and whole tree of Linux kernel as below.\n$ date Sun Dec 31 01:26:17 PM PST 2023 $ ./authors.py ~/linux --commits linus/master --file mm/ \\ \u0026gt; --since 2023-01-01 --skip_merge_commits \\ \u0026gt; --sortby lines --max_nr_authors 9 1. Mike Rapoport (IBM) \u0026lt;rppt@kernel.org\u0026gt;: 5686 lines 2. Hugh Dickins \u0026lt;hughd@google.com\u0026gt;: 3938 lines 3. Qi Zheng \u0026lt;zhengqi.arch@bytedance.com\u0026gt;: 2775 lines 4. Kefeng Wang \u0026lt;wangkefeng.wang@huawei.com\u0026gt;: 2382 lines 5. Matthew Wilcox (Oracle) \u0026lt;willy@infradead.org\u0026gt;: 2278 lines 6. Huang Ying \u0026lt;ying.huang@intel.com\u0026gt;: 2149 lines 7. Liam R. Howlett \u0026lt;Liam.Howlett@Oracle.com\u0026gt;: 1995 lines 8. SeongJae Park \u0026lt;sj@kernel.org\u0026gt;: 1910 lines 9. Lorenzo Stoakes \u0026lt;lstoakes@gmail.com\u0026gt;: 1779 lines # 272 authors, 57035 lines in total $ $ ./authors.py ~/linux --commits linus/master --file mm/ \\ \u0026gt; --since 2023-01-01 --skip_merge_commits \\ \u0026gt; --sortby commits --max_nr_authors 5 1. Matthew Wilcox (Oracle) \u0026lt;willy@infradead.org\u0026gt;: 111 commits 2. Hugh Dickins \u0026lt;hughd@google.com\u0026gt;: 77 commits 3. Kefeng Wang \u0026lt;wangkefeng.wang@huawei.com\u0026gt;: 71 commits 4. SeongJae Park \u0026lt;sj@kernel.org\u0026gt;: 66 commits 5. Lorenzo Stoakes \u0026lt;lstoakes@gmail.com\u0026gt;: 41 commits # 272 authors, 1690 commits in total $ $ ./authors.py ~/linux --commits linus/master \\ \u0026gt; --since 2023-01-01 --skip_merge_commits \\ \u0026gt; --sortby lines --max_nr_authors 7000 \u0026gt; 2023_by_lines $ tail -n 1 2023_by_lines # 5006 authors, 5253379 lines in total $ grep -A1 -B1 sj@kernel.org 2023_by_lines 263. Claudiu Beznea \u0026lt;claudiu.beznea@microchip.com\u0026gt;: 3581 lines 264. SeongJae Park \u0026lt;sj@kernel.org\u0026gt;: 3562 lines 265. Thomas Weißschuh \u0026lt;linux@weissschuh.net\u0026gt;: 3558 lines $ $ ./authors.py ~/linux --commits linus/master \\ \u0026gt; --since 2023-01-01 --skip_merge_commits \\ \u0026gt; --sortby commits --max_nr_authors 7000 \u0026gt; 2023_by_commits $ tail -n 1 2023_by_commits # 5006 authors, 74198 commits in total $ grep -A1 -B1 sj@kernel.org 2023_by_commits 79. Pavel Begunkov \u0026lt;asml.silence@gmail.com\u0026gt;: 150 commits 80. SeongJae Park \u0026lt;sj@kernel.org\u0026gt;: 147 commits 81. Andrii Nakryiko \u0026lt;andrii@kernel.org\u0026gt;: 146 commits Memory Management In 2023, 272 people participated in Linux kernel memory management subsystem development by making 57,035 lines of changes with 1,690 commits.\nI made 8th and 4th biggest changes among the 295 people, for lines of changes (1,910) and commits (66). Note that I counted only files under mm/ directory of the source tree, though.\nDistribution of the numbers can be plotted like below.\n$ ./authors.py ~/linux --commits linus/master --file mm/ --since 2023-01-01 \\ --skip_merge_commits --sortby lines --max_nr_authors 300 \\ --pr_for_plot | ../gnuplot/plot.py --ylog --pointsize 0.2 output.png The plot for the distribution of the number of changed lines per author for memory management subsystem in 2023 is like below. Note that y-axis is in logscale. My number on the graph is 1,910.\nThe plot for the distribution of the number of commits per author for memory management subsystem in 2023 is like below. Note that both x-axis and y-axis are in logscale. My number on the graph is 66.\nLinux kernel Whole Tree In 2023, 5,006 people participated in Linux kernel development by making 5,253,379 lines of changes with 74,198 commits.\nI made 264th and 80th biggest changes among the 5,006 people, for lines of changes (3,562) and commits (147).\nThe plot for the distribution of the number of changed lines per author for the whole Linux kernel source tree in 2023 is like below. Note that both x-axis and y-axis are in logscale. My number on this graph is 3,562.\nThe plot for the distribution of the number of commits per author for the whole Linux kernel source treein 2023 is like below. Note that both x-axis and y-axis is in logscale. My number on this graph is 147.\nGithub On github, I made 3,264 commits in 2023. It\u0026rsquo;s counting only the commits that I made with my github main account\u0026rsquo;s email address, so it doesn\u0026rsquo;t cover some of my commits for some projects including Linux kernel. I made commits everyday except three days in 2023.\nApparently 2023 was a busy year for me and the world. Hope I and the community to continue happy hacking in 2023.\n","permalink":"https://sjp38.github.io/posts/my_opensource_commits_stat_2023/","summary":"As today is the last day of 2023, I checked some open source commits statistics using my simple and buggy script, and github. Similar statistics for 2022 is available at another post.\nIn short, I made 8th and 4th biggest changes to Linux kernel memory management subsystem among the 295 people, for lines of changes (1,910) and commits (66).\nFor the Linux kernel whole tree, the numbers become 264th (3,562 lines) and 80th (147 commits) among 5,006 people.","title":"My opensource commits statistics in 2023"},{"content":"DAMON talk for OSSummit EU 2023 has accepted and scheduled. The talk will focus on its user-space tool, damo. It\u0026rsquo;s mainly for helping more audiences to digest the content easier, and also for accelerating the development of damo. By the time, hopefully the version of damo would reach to, or exceed 2.0.0, and newer interface and features will be introduced together.\nThe title of the talk is \u0026ldquo;Data Access Monitoring Operator (DAMO): User-Space Tool/Python Library for Access-Aware Profiling and Optimization of Your Linux Systems\u0026rdquo;.\nhttps://sched.co/1OGf9\n","permalink":"https://sjp38.github.io/posts/ossummit_eu_2023_talk/","summary":"DAMON talk for OSSummit EU 2023 has accepted and scheduled. The talk will focus on its user-space tool, damo. It\u0026rsquo;s mainly for helping more audiences to digest the content easier, and also for accelerating the development of damo. By the time, hopefully the version of damo would reach to, or exceed 2.0.0, and newer interface and features will be introduced together.\nThe title of the talk is \u0026ldquo;Data Access Monitoring Operator (DAMO): User-Space Tool/Python Library for Access-Aware Profiling and Optimization of Your Linux Systems\u0026rdquo;.","title":"I will have a talk at the Open Source Summit Europe 2023"},{"content":"!! NOTE !!\nThis post has migrated to https://damonitor.github.io/posts/damon_publications_talks. This out-dated post will be removed soon.\nBelow is a list of publications and presentations that cover DAMON project.\nThis list is not exhaustive and is compiled to the best of our ability, as some publications or presentations may have been made without the knowledge of the DAMON maintainers. If you find a publication or announcement that should be added to this list, please let us know at sj@kernel.org and/or damon@lists.linux.dev.\nWhat to read/cite?\nFor people who more familiar to academic papers, DAMON papers for Middleware'19 Industry and HPDC'22 are recommended to read and/or cite. The paper for Middleware'19 covers DAMON\u0026rsquo;s monitoring mechanisms and access pattern profiling-guided optimizations. The paper for HPDC'22 extends the coverage to DAMOS (automated access-aware system operations) and user-space driven auto-tuning.\nSeongJae Park, DAMON: Long-term Plans for Kernel That {Just Works,Extensible}. In Linux Kernel Memory Management Microconferenct at Linux Plumbers, Sep 2024. Slides, Video, Link SeongJae Park, DAMON Recipes: Ways to Save Memory Using a Linux Kernel Subsystem in the Real World. In Open Source Summit Europe, Sep 2024. Slides 1, Slides 2, Video, Link Jonathan Corbet, An update and future plans for DAMON. In Linux Weekly News, May 2024. Article SeongJae Park, DAMON Updates and Plans: Automation of DAMON tuning, tiering, and VM guest scaling. In Linux Storage | Filesystem | MM \u0026amp; BPF Summit, May 2024. Slides, Video, Link SeongJae Park, DAMO[N,S]?: Implementing Self-Driven Data Access-Aware Efficient Linux System. In Open Source Summit North America, Apr 2024. Slides, Video, Link SeongJae Park, DAMON: Current Status and Future Plans. In Kernel Summit, Nov 2023. Slides, Video, Link SeongJae Park, Data Access Monitoring Operator (DAMO): User-Space Tool/Python Library for Access-Aware Profiling and Optimization of Your Linux Systems. In Open Source Summit Europe, Sep 2023. Slides, Video, Link Jonathan Corbet, A 2023 DAMON update. In Linux Weekly News, May 2023. Article SeongJae Park, DAMON, DAMOS, and DAMO: Kernel Subsystems and User-Space Tools for Data Access-Aware System Analysis/Optimizations. In Open Source Summit North America, May 2023. Slides, Video, Link SeongJae Park, DAMON updates and future plans. In Linux Storage | Filesystem | MM \u0026amp; BPF Summit, May 2023. Slides, Video, Link SeongJae Park, Current Status and Future Plans of DAMON. In The Linux Kernel Summit, September 2022. Slides, Video, Link Jonathan Corbet, LRU-list manipulation with DAMON. In Linux Weekly News, August 2022. Article SeongJae Park, Current Status, Future Plans, and Possible Collaborations for DAMON. In The Linux Kernel Summit, September 2022. Link SeongJae Park, Madhuparna Bhowmik, Alexandru Uta, DAOS: Data Access-aware Operating System. In The 31st International ACM Symposium on High-Performance Parallel and Distributed Computing (HPDC'22), June 2022. Paper, Slides, Poster SeongJae Park, Writing a fine-grained access pattern oriented lightweight kernel module using DAMON/DAMOS in 10 minutes. In The Linux Kernel Summit, September 2021. Slides, Video, Link Jonathan Corbet, Using DAMON for proactive reclaim. In Linux Weekly News, July 2021. Article SeongJae Park, DAMON: Data Access Monitoring Framework for Fun and Memory Management Optimizations, In The Linux Kernel Summit, August 2020. Slides, Video, Link Yunjae Lee, Yunhee Kim, and Heon. Y. Yeom, Lightweight Memory Tracing for Hot Data Identification, In Cluster computing, 2020. Paper Jonathan Corbet, Memory-management optimization with DAMON. In Linux Weekly News, February 2020. Article SeongJae Park, Yunjae Lee, Heon Y. Yeom, Profiling Dynamic Data Access Patterns with Controlled Overhead and Quality. In 20th ACM/IFIP International Middleware Conference Industry, December 2019. Paper SeongJae Park, Tracing Data Access Pattern with Bounded Overhead and Best-effort Accuracy. In The Linux Kernel Summit, September 2019. Slides, Link SeongJae Park, Yunjae Lee, Yunhee Kim, Heon Y. Yeom, Profiling Dynamic Data Access Patterns with Bounded Overhead and Accuracy. In IEEE International Workshop on Foundations and Applications of Self-* Systems (FAS* 2019), June 2019. Paper ","permalink":"https://sjp38.github.io/posts/damon_publications_talks/","summary":"!! NOTE !!\nThis post has migrated to https://damonitor.github.io/posts/damon_publications_talks. This out-dated post will be removed soon.\nBelow is a list of publications and presentations that cover DAMON project.\nThis list is not exhaustive and is compiled to the best of our ability, as some publications or presentations may have been made without the knowledge of the DAMON maintainers. If you find a publication or announcement that should be added to this list, please let us know at sj@kernel.","title":"DAMON Publications and Presentations"},{"content":"!! NOTE !!\nThis post has migrated to https://damonitor.github.io/posts/damon_publications_talks. This out-dated post will be removed soon.\nBelow is a list of publications and presentations that cover DAMON project.\nThis list is not exhaustive and is compiled to the best of our ability, as some publications or presentations may have been made without the knowledge of the DAMON maintainers. If you find a publication or announcement that should be added to this list, please let us know at sj@kernel.org and/or damon@lists.linux.dev.\nWhat to read/cite?\nFor people who more familiar to academic papers, DAMON papers for Middleware'19 Industry and HPDC'22 are recommended to read and/or cite. The paper for Middleware'19 covers DAMON\u0026rsquo;s monitoring mechanisms and access pattern profiling-guided optimizations. The paper for HPDC'22 extends the coverage to DAMOS (automated access-aware system operations) and user-space driven auto-tuning.\nSeongJae Park, DAMON: Long-term Plans for Kernel That {Just Works,Extensible}. In Linux Kernel Memory Management Microconferenct at Linux Plumbers, Sep 2024. Slides, Video, Link SeongJae Park, DAMON Recipes: Ways to Save Memory Using a Linux Kernel Subsystem in the Real World. In Open Source Summit Europe, Sep 2024. Slides 1, Slides 2, Video, Link Jonathan Corbet, An update and future plans for DAMON. In Linux Weekly News, May 2024. Article SeongJae Park, DAMON Updates and Plans: Automation of DAMON tuning, tiering, and VM guest scaling. In Linux Storage | Filesystem | MM \u0026amp; BPF Summit, May 2024. Slides, Video, Link SeongJae Park, DAMO[N,S]?: Implementing Self-Driven Data Access-Aware Efficient Linux System. In Open Source Summit North America, Apr 2024. Slides, Video, Link SeongJae Park, DAMON: Current Status and Future Plans. In Kernel Summit, Nov 2023. Slides, Video, Link SeongJae Park, Data Access Monitoring Operator (DAMO): User-Space Tool/Python Library for Access-Aware Profiling and Optimization of Your Linux Systems. In Open Source Summit Europe, Sep 2023. Slides, Video, Link Jonathan Corbet, A 2023 DAMON update. In Linux Weekly News, May 2023. Article SeongJae Park, DAMON, DAMOS, and DAMO: Kernel Subsystems and User-Space Tools for Data Access-Aware System Analysis/Optimizations. In Open Source Summit North America, May 2023. Slides, Video, Link SeongJae Park, DAMON updates and future plans. In Linux Storage | Filesystem | MM \u0026amp; BPF Summit, May 2023. Slides, Video, Link SeongJae Park, Current Status and Future Plans of DAMON. In The Linux Kernel Summit, September 2022. Slides, Video, Link Jonathan Corbet, LRU-list manipulation with DAMON. In Linux Weekly News, August 2022. Article SeongJae Park, Current Status, Future Plans, and Possible Collaborations for DAMON. In The Linux Kernel Summit, September 2022. Link SeongJae Park, Madhuparna Bhowmik, Alexandru Uta, DAOS: Data Access-aware Operating System. In The 31st International ACM Symposium on High-Performance Parallel and Distributed Computing (HPDC'22), June 2022. Paper, Slides, Poster SeongJae Park, Writing a fine-grained access pattern oriented lightweight kernel module using DAMON/DAMOS in 10 minutes. In The Linux Kernel Summit, September 2021. Slides, Video, Link Jonathan Corbet, Using DAMON for proactive reclaim. In Linux Weekly News, July 2021. Article SeongJae Park, DAMON: Data Access Monitoring Framework for Fun and Memory Management Optimizations, In The Linux Kernel Summit, August 2020. Slides, Video, Link Yunjae Lee, Yunhee Kim, and Heon. Y. Yeom, Lightweight Memory Tracing for Hot Data Identification, In Cluster computing, 2020. Paper Jonathan Corbet, Memory-management optimization with DAMON. In Linux Weekly News, February 2020. Article SeongJae Park, Yunjae Lee, Heon Y. Yeom, Profiling Dynamic Data Access Patterns with Controlled Overhead and Quality. In 20th ACM/IFIP International Middleware Conference Industry, December 2019. Paper SeongJae Park, Tracing Data Access Pattern with Bounded Overhead and Best-effort Accuracy. In The Linux Kernel Summit, September 2019. Slides, Link SeongJae Park, Yunjae Lee, Yunhee Kim, Heon Y. Yeom, Profiling Dynamic Data Access Patterns with Bounded Overhead and Accuracy. In IEEE International Workshop on Foundations and Applications of Self-* Systems (FAS* 2019), June 2019. Paper ","permalink":"https://sjp38.github.io/posts/ko/damon_publications_talks/","summary":"!! NOTE !!\nThis post has migrated to https://damonitor.github.io/posts/damon_publications_talks. This out-dated post will be removed soon.\nBelow is a list of publications and presentations that cover DAMON project.\nThis list is not exhaustive and is compiled to the best of our ability, as some publications or presentations may have been made without the knowledge of the DAMON maintainers. If you find a publication or announcement that should be added to this list, please let us know at sj@kernel.","title":"DAMON Publications and Presentations"},{"content":"!! NOTE !!\nThis post has migrated to https://damonitor.github.io/posts/damon_news. This out-dated post will be removed soon.\nBelow is a list of news around DAMON project.\nThis list is not exhaustive but just a DAMON maintainer\u0026rsquo;s collection of news. If you find a news that should be added to this list, please let us know at sj@kernel.org and/or damon@lists.linux.dev.\n2024 2024-10-15: DAMON debugfs interface removal RFC patch has posted.\n2024-10-10: Monthly PyPI downloads of DAMON user-space too, DAMO, doubled again after ten days. !damo_9000_monthly_downloads !damo_rolling_monthly_downloads_2024-10-10\n2024-10-08: Videos for DAMON recipes at Open Source Summit EU'2024 and DAMON long-term plans at Kernel Memory Management Microconference'2024 are uploaded to YouTube.\n2024-10-01: 2024-Q3 DAMON news letter including news for new features, more users, repos reorganizations, and conference talks is posted.\n2024-09-30: DAMON User Space Tool, DAMO, surpasses 4,000 monthly PyPI downloads! 2024-09-20: Livestreamed video for DAMON talk at kernel memory management microconference 2024 is now available at Youtube.\n2024-09-19: An academic paper preprint that optimizing THP using DAMON and BPF, titled \u0026ldquo;eBPF-mm: Userspace-guided memory management in Linux with eBPF\u0026rdquo; is uploaded to ArXiv\n2024-09-16: CONFIG_DAMON is enabled on Debian kernel\n2024-08-14: GitHub repos for non-kernel parts of DAMON project including \u0026lsquo;damo\u0026rsquo;, \u0026lsquo;damon-tests\u0026rsquo; and \u0026lsquo;damoos\u0026rsquo; will be moved from \u0026lsquo;awslabs\u0026rsquo; to \u0026lsquo;damonitor\u0026rsquo;, by 2024-09-05\n2024-07-29: VLDB paper about Aurora Serverless V2, which reveals their usage of DAMON on the product, is now available.\n2024-07-21: Memory Management subsystem pull request for Linux v6.11-rc1 is posted with DAMON changes for CXL memory tiering, documentation of a mailing tool for newcomers, and minor fixups.\n2024-07-18: DAMON topic for Linux Kernel Memory Management Microconference at LPC'24 has accepted.\n2024-07-11: ATC'24 also published two DAMON-citing papers at the same time. The first one proposes a way to improve monitoring accuracy of DAMON, while the second one mentions DAMON can be useful for extensible memory management.\n2024-07-11: A couple of OSDI'24 papers (1, 2) for memory tiering that references and exploring DAMON as a part of them are available now.\n2024-07-01: DAMON Quaterly Newsletter for 2024-Q2 has posted.\n2024-06-21: HacKerMaiL (hkml) has announced as a mailing tool for DAMON community that the maintainer is committed to support.\n2024-06-14: DAMON talk for Kernel Summit 2024 is proposed.\n2024-06-14: SK hynix\u0026rsquo; patch series \u0026ldquo;DAMON based tiered memory management for CXL memory\u0026rdquo; has merged into -mm tree.\n2024-06-12: DAMON talk for OpenSource Summit Europe 2024 has been accepted and scheduled.\n2024-05-18: Memory management subsystem pull request for Linux 6.10-rc1 has been posted. This pull request includes DAMOS young page filter, a DAMOS functionality kselftest, and misc cleanups/fixups for code, documentation, and tests.\n2024-05-17: LWN published an article introducing DAMON session at LSFMM 2024.\n2024-05-02: LSFMMBPF schedule is uploaded. DAMON talk is scheduled for the Monday noon.\n2024-04-29: The video of the DAMON presentation at OSSummit NA'24 is uploaded.\n2024-04-28: Yet another academic paper exploring DAMON for serverless computing has published on ASPLOS 24.\n2024-04-17: The third in-person DAMON meetup has held as a unconference session of Open Source Summint North America 2024\n2024-04-03: Oracle released a tool that helps finding distros that enabled DAMON\n2024-04-01: DAMO v2.2.8 is out. This version supports recording memory footprint of monitoring target processes together with their access pattern. Users could know when how much memory is allocated and really accessed. Such visualization is one of the future works, though.\n2024-03-13: Memory management subsystem pull request for Linux 6.9-rc1 has been posted. To quote Andrew’s summary for DAMON part:\nMore DAMON work from SeongJae Park in the series \u0026ldquo;mm/damon: make DAMON debugfs interface deprecation unignorable\u0026rdquo; \u0026ldquo;selftests/damon: add more tests for core functionalities and corner cases\u0026rdquo; \u0026ldquo;Docs/mm/damon: misc readability improvements\u0026rdquo; \u0026ldquo;mm/damon: let DAMOS feeds and tame/auto-tune itself\u0026rdquo; 2024-03-06: LSF/MM/BPF 2024 DAMON discussion topic is accepted\n2024-03-04: DAMO v2.2.4 is released with a new feature for access pattern-based profiling. For example, users can know which code is making their program\u0026rsquo;s memory usage unexpectedly high, or which code is intensively accessing memory, and optimize.\n2024-02-27: DAMON user-space tool, DAMO, has downloaded from PyPI more than 2,000 times last month. 2024-02-21: Yet another academic paper exploring DAMON for tiered memory management will be presented at EuroSys 2024\n2023-02-20: DAMO v2.2.2 is released with a new command, replay. It will hopefully help reproducing the real-world memory access pattern for analysis and benchmarks.\n2024-02-14: DAMON talk for OSSummit NA 2024 has been accepted and scheduled\n2024-02-09: DAMON in Amazon Linux 5.10.y kernel has updated to that of v6.7 Linux kernel. Major updates on this change include\nDAMOS apply target regions tracing and Sampling interval granularity monitoring results generation and DAMOS. 2024-01-29: LSF/MM/BPF 2024 topic proposal for DAMON has posted\n2024-01-15: SK Hynix shared their DAMOS-based tiered memory management test results showing 4-17% performance slowdown reduction, with patches for that.\n2024-01-12: LWN introduced the feedback-driven DAMOS aggressiveness auto-tuning as one of interesting changes for Linux v6.8\n2024-01-08: Memory management subsystem pull request for Linux v6.8-rc1 has posted. To quote Andrew\u0026rsquo;s summary for DAMON part:\nDAMON/DAMOS feature and maintenance work from SeongJae Park in the series \u0026ldquo;mm/damon: let users feed and tame/auto-tune DAMOS\u0026rdquo; \u0026ldquo;selftests/damon: add Python-written DAMON functionality tests\u0026rdquo; \u0026ldquo;mm/damon: misc updates for 6.8\u0026rdquo; 2023 2023-12-31: A retrospect of DAMON development in 2023 for the upstream community has posted.\n2023-12-27: SK Hynix released Heterogeneous Memory Software Development Kit (HMSDK) v2.0 which utilizes DAMON for tiered memory management.\n2023-11-24: A paper exploring DAMON and finding grateful areas to improve has uploaded to arXiv.\n2023-11-17: Livestreamed video for DAMON talk at kernel summit 2023 is now available at YouTube.\n2023-11-12: RFC idea for DAMOS-based tiered memory management is sent.\n2023-11-12: RFC idea for Access/Contiguity-aware Memory Auto-scaling is sent.\n2023-11-12: RFC patchset for Aim-oriented Feedback-driven DAMOS Aggressiveness Auto Tuning is sent.\n2023-11-08: The second in-person DAMON community meetup at LPC has accepted and announced.\n2023-11-02: Memory management subsystem pull requests for Linux v6.7-rc1, which contains the changes for DAMON, has sent.\n2023-10-22: An SOSP paper for tiered memory management that referencing and exploring DAMON has found.\n2023-10-12: LPC BoF session proposal for DAMON community in-person meetup has submitted.\n2023-10-04: DAMON talk for Kernel Summit track of Linux Plumbers Conference 2023 has accepted.\n2023-09-07: Yet another academic paper preprint regarding serverless on CXL using/citing DAMON has uploaded. The title of the preprint is \u0026ldquo;Understanding and Optimizing Serverless Workloads in CXL-Enabled Tiered Memory\u0026rdquo;\n2023-08-09: DAMON community started running its CI test against all stable kernels and report the results.\n2023-08-08: DAMON user-space tool (damo) has reached 100 Github stars. 2023-08-07: DAMON user-space tool (damo) has released its 100th version. A mail for the news, release stats, and appreciation to the DAMON community has also posted.\n2023-08-03: DAMON continuous functionality testing started testing stable rc kernels and report back the results.\n2023-08-01: DAMON Beer/Coffee/Tea meeting will be postponed from mid of August to end of OSSummit Euro 2023.\n2023-07-26: The kernel summit talk proposal for DAMON status and future plans has posted\n2023-07-10: Hocus wrote an article introducing DAMON as a kernel feature that could be useful for memory efficient VM, with its limitations.\n2023-06-30: DAMON talk for OSSummit EU 2023 has accepted and scheduled\n2023-06-25: DAMON userspace tool, damo has packaged for Debian/Ubuntu in addition to Fedora. It also turned out it was already packaged for ArchLinux. Refer to repology for detail.\n2023-05-26: Open Source Summit North America DAMON talk video is now available at Youtube\n2023-05-26: LSF/MM+BPF DAMON discussion video is now available at Youtube\n2023-05-17: Now DAMON user space tool (DAMO) is available at Fedora Packages\n2023-05-16: Michel from Fedora community is gonna package DAMON user space tool (DAMO) for Fedora!\n2023-05-16: An LWN article for LSF/MM+BPF DAMON discussion has uploaded\n2023-05-04: The schedule for DAMON talk/discussion at LSFMM is available now.\n2023-03-14: The schedule for DAMON talk at OSSummit NA is available now.\n2023-03-10: A DAMON talk proposal for OSSummit NA has accepted.\n2023-03-06: DAMOS filters feature has introduced as one of the most significant changes for Linux v6.3 by an LWN article\n2023-02-24: A preprint of an academic paper that compares their approach against DAMON has uploaded to ArXiv.\n2023-02-13: LSF/MM/BPF topic proposal for DAMON has posted\n2023-02-09: DAMON debugfs deprecation patchset has posted\n2022 2022-12-29: DAMON development summary of 2022 has shared and featured by Phoronix.\n2022-12-16: The DAMOS filtering for anon pages and/or memory cgroups have merged in mm tree.\n2022-10-19: An RFC patchset for efficient query-like DAMON monitoring results have posted\n2022-09-15: The video for my kernel summit DAMON talk this year is now available at Youtube\n2022-09-09: The plan for the first in-person DAMON community meetup at LPC and the in-person office hour at OSSummit EU has announced\n2022-09-06: AL2 5.10 kernel\u0026rsquo;s DAMON code has updated to that of v5.19\n2022-08-30: AL2 5.10 kernel\u0026rsquo;s DAMON code has updated to that of v5.18\n2022-08-22: LWN introduced DAMON-based LRU-lists manipulation (DAMON_LRU_SORT) in detail\n2022-08-15: LWN introduced DAMON’s new features including \u0026lsquo;LRU_SORT\u0026rsquo; as significant changes for Linux 6.0\n2022-08-12: Bi-weekly DAMON Beer/Coffee/Tea Chat series for open, regular, and informal community syncups and discussions has announced.\n2022-07-29: Current status, future plans, and possible collaborations for DAMON will be presented at the Kernel Summit 2022.\n2022-06-26: The poster of the DAOS paper is available online.\n2022-06-13: DAMON-based LRU-lists sorting patchset has posted and immediately merged in the -mm tree\n2022-05-04: A paper introducing DAMON and related works have accepted by HPDC22\n2022-05-03: Now DAMON has its own open mailing list\n2022-04-29: Patches for DAMON online tuning have merged in -mm tree\n2022-04-27: Android has backported and enabled building DAMON and DAMON_RECLAIM for the common kernel.\n2022-04-27: Alibaba has shared thier own DAMON user space tool.\n2022-02-28: The DAMON sysfs interface patchset has merged in -mm tree.\n2022-02-17: An RFC patchset for sysfs-based DAMON\u0026rsquo;s new user interface has posted.\n2022-01-20: A roadmap of DAMON has shared.\n2022-01-09: Linux 5.16 is released. \u0026ldquo;DAMON-based proactive memory reclamation, operation schemes and physical memory monitoring\u0026rdquo; are marked as prominent features of the release by the Kernel newbies and LWN.\n2021 2021-12-23: A great blog post for DAMON-enabled kernel has uploaded\n2021-11-07: DAMON patches for automated memory management optimization, the physical address space monitoring support, and proactive reclamation have merged in the mainline.\n2021-11-01: DAMON has released with Linux v5.15.\n2021-10-14: DAMON_RECLAIM patchset is merged in the Amazon Linux 5.10.y kernel tree.\n2021-10-02: DAMOS patchset is merged in the -mm tree.\n2021-09-23: DAMON and DAMOS are presented in the kernel summit. Slides, Video, Link\n2021-09-16: DAMON development tree on kernel.org is created.\n2021-09-08: DAMON patchset is merged in the Linus Torvalds\u0026rsquo; tree, aka mainline\n2021-09-07: DAMON/DAMOS will be presented at the Kernel Summit 2021\n2021-08-31: DAMON user-space tool is uploaded to the official Python packages system, PyPi\n2021-08-06: DAMON patchset is merged in the -mm tree\n2021-07-27: LWN published a second article introducing DAMON patchset series\n2021-06-11: DAMON-based proactive reclamation RFC patchset has shared on the hackernews and introduced by a Phoronix article\n2021-05-31: DAMON-based proactive reclamation RFC patchset has posted\n2021-05-26: DAMON-enabled Amazon Linux 2 kernels have deployed to all users\n2021-05-07: DAMON has merged in the public source tree for Amazon Linux v5.4.y kernel\n2021-04-05: damo now supports heatmap visualization on the terminal\n2021-03-31: DAMON user-space tool (damo) is released as an individual open source project\n2021-03-19: DAMON has merged in the public source tree for Amazon Linux v5.10.y kernel\n2021-03-04: DAMON supports for two latest LTS kernels announced\n2021-03-03: DAMON is merged in v5.10 based public Amazon Linux kernel tree\n2021-02-25: An example usage of DAMON for profiling is shared\n2021-01-07: A runtime system for DAMON-based optimal operation scheme finding is released\n2020 2020-12-03: Further plans around DAMON is shared\n2020-11-17: A real-world user story of DAMON is shared\n2020-09-26: The tests package for DAMON is released under GPL v2 license\n2020-08-19: A demo video is available\n2020-08-05: DAMON will be presented at the Kernel Summit 2020\n2020-06-04: Physical Memory Monitoring is now available\n2020-05-18: DAMON showcase website is announced\n2020-05-13: DAMON official document is uploaded online\n2020-02-20: DAMON has introduced by an LWN article\n2020-02-10: The first RFC of Data Access Monitoring-based Operating Schemes (DAMOS) has posted to LKML\n2020-01-23: The RFC of DAMON has introduced by LWN\u0026rsquo;s \u0026lsquo;Kernel patches of interest\u0026rsquo;\n2020-01-20: The first RFC patchset of DAMON has posted to LKML\n","permalink":"https://sjp38.github.io/posts/damon_news/","summary":"!! NOTE !!\nThis post has migrated to https://damonitor.github.io/posts/damon_news. This out-dated post will be removed soon.\nBelow is a list of news around DAMON project.\nThis list is not exhaustive but just a DAMON maintainer\u0026rsquo;s collection of news. If you find a news that should be added to this list, please let us know at sj@kernel.org and/or damon@lists.linux.dev.\n2024 2024-10-15: DAMON debugfs interface removal RFC patch has posted.\n2024-10-10: Monthly PyPI downloads of DAMON user-space too, DAMO, doubled again after ten days.","title":"DAMON News List"},{"content":"!! NOTE !!\nThis post has migrated to https://damonitor.github.io/posts/damon_news. This out-dated post will be removed soon.\nBelow is a list of news around DAMON project.\nThis list is not exhaustive but just a DAMON maintainer\u0026rsquo;s collection of news. If you find a news that should be added to this list, please let us know at sj@kernel.org and/or damon@lists.linux.dev.\n2024 2024-10-15: DAMON debugfs interface removal RFC patch has posted.\n2024-10-10: Monthly PyPI downloads of DAMON user-space too, DAMO, doubled again after ten days. !damo_9000_monthly_downloads !damo_rolling_monthly_downloads_2024-10-10\n2024-10-08: Videos for DAMON recipes at Open Source Summit EU'2024 and DAMON long-term plans at Kernel Memory Management Microconference'2024 are uploaded to YouTube.\n2024-10-01: 2024-Q3 DAMON news letter including news for new features, more users, repos reorganizations, and conference talks is posted.\n2024-09-30: DAMON User Space Tool, DAMO, surpasses 4,000 monthly PyPI downloads! 2024-09-20: Livestreamed video for DAMON talk at kernel memory management microconference 2024 is now available at Youtube.\n2024-09-19: An academic paper preprint that optimizing THP using DAMON and BPF, titled \u0026ldquo;eBPF-mm: Userspace-guided memory management in Linux with eBPF\u0026rdquo; is uploaded to ArXiv\n2024-09-16: CONFIG_DAMON is enabled on Debian kernel\n2024-08-14: GitHub repos for non-kernel parts of DAMON project including \u0026lsquo;damo\u0026rsquo;, \u0026lsquo;damon-tests\u0026rsquo; and \u0026lsquo;damoos\u0026rsquo; will be moved from \u0026lsquo;awslabs\u0026rsquo; to \u0026lsquo;damonitor\u0026rsquo;, by 2024-09-05\n2024-07-29: VLDB paper about Aurora Serverless V2, which reveals their usage of DAMON on the product, is now available.\n2024-07-21: Memory Management subsystem pull request for Linux v6.11-rc1 is posted with DAMON changes for CXL memory tiering, documentation of a mailing tool for newcomers, and minor fixups.\n2024-07-18: DAMON topic for Linux Kernel Memory Management Microconference at LPC'24 has accepted.\n2024-07-11: ATC'24 also published two DAMON-citing papers at the same time. The first one proposes a way to improve monitoring accuracy of DAMON, while the second one mentions DAMON can be useful for extensible memory management.\n2024-07-11: A couple of OSDI'24 papers (1, 2) for memory tiering that references and exploring DAMON as a part of them are available now.\n2024-07-01: DAMON Quaterly Newsletter for 2024-Q2 has posted.\n2024-06-21: HacKerMaiL (hkml) has announced as a mailing tool for DAMON community that the maintainer is committed to support.\n2024-06-14: DAMON talk for Kernel Summit 2024 is proposed.\n2024-06-14: SK hynix\u0026rsquo; patch series \u0026ldquo;DAMON based tiered memory management for CXL memory\u0026rdquo; has merged into -mm tree.\n2024-06-12: DAMON talk for OpenSource Summit Europe 2024 has been accepted and scheduled.\n2024-05-18: Memory management subsystem pull request for Linux 6.10-rc1 has been posted. This pull request includes DAMOS young page filter, a DAMOS functionality kselftest, and misc cleanups/fixups for code, documentation, and tests.\n2024-05-17: LWN published an article introducing DAMON session at LSFMM 2024.\n2024-05-02: LSFMMBPF schedule is uploaded. DAMON talk is scheduled for the Monday noon.\n2024-04-29: The video of the DAMON presentation at OSSummit NA'24 is uploaded.\n2024-04-28: Yet another academic paper exploring DAMON for serverless computing has published on ASPLOS 24.\n2024-04-17: The third in-person DAMON meetup has held as a unconference session of Open Source Summint North America 2024\n2024-04-03: Oracle released a tool that helps finding distros that enabled DAMON\n2024-04-01: DAMO v2.2.8 is out. This version supports recording memory footprint of monitoring target processes together with their access pattern. Users could know when how much memory is allocated and really accessed. Such visualization is one of the future works, though.\n2024-03-13: Memory management subsystem pull request for Linux 6.9-rc1 has been posted. To quote Andrew’s summary for DAMON part:\nMore DAMON work from SeongJae Park in the series \u0026ldquo;mm/damon: make DAMON debugfs interface deprecation unignorable\u0026rdquo; \u0026ldquo;selftests/damon: add more tests for core functionalities and corner cases\u0026rdquo; \u0026ldquo;Docs/mm/damon: misc readability improvements\u0026rdquo; \u0026ldquo;mm/damon: let DAMOS feeds and tame/auto-tune itself\u0026rdquo; 2024-03-06: LSF/MM/BPF 2024 DAMON discussion topic is accepted\n2024-03-04: DAMO v2.2.4 is released with a new feature for access pattern-based profiling. For example, users can know which code is making their program\u0026rsquo;s memory usage unexpectedly high, or which code is intensively accessing memory, and optimize.\n2024-02-27: DAMON user-space tool, DAMO, has downloaded from PyPI more than 2,000 times last month. 2024-02-21: Yet another academic paper exploring DAMON for tiered memory management will be presented at EuroSys 2024\n2023-02-20: DAMO v2.2.2 is released with a new command, replay. It will hopefully help reproducing the real-world memory access pattern for analysis and benchmarks.\n2024-02-14: DAMON talk for OSSummit NA 2024 has been accepted and scheduled\n2024-02-09: DAMON in Amazon Linux 5.10.y kernel has updated to that of v6.7 Linux kernel. Major updates on this change include\nDAMOS apply target regions tracing and Sampling interval granularity monitoring results generation and DAMOS. 2024-01-29: LSF/MM/BPF 2024 topic proposal for DAMON has posted\n2024-01-15: SK Hynix shared their DAMOS-based tiered memory management test results showing 4-17% performance slowdown reduction, with patches for that.\n2024-01-12: LWN introduced the feedback-driven DAMOS aggressiveness auto-tuning as one of interesting changes for Linux v6.8\n2024-01-08: Memory management subsystem pull request for Linux v6.8-rc1 has posted. To quote Andrew\u0026rsquo;s summary for DAMON part:\nDAMON/DAMOS feature and maintenance work from SeongJae Park in the series \u0026ldquo;mm/damon: let users feed and tame/auto-tune DAMOS\u0026rdquo; \u0026ldquo;selftests/damon: add Python-written DAMON functionality tests\u0026rdquo; \u0026ldquo;mm/damon: misc updates for 6.8\u0026rdquo; 2023 2023-12-31: A retrospect of DAMON development in 2023 for the upstream community has posted.\n2023-12-27: SK Hynix released Heterogeneous Memory Software Development Kit (HMSDK) v2.0 which utilizes DAMON for tiered memory management.\n2023-11-24: A paper exploring DAMON and finding grateful areas to improve has uploaded to arXiv.\n2023-11-17: Livestreamed video for DAMON talk at kernel summit 2023 is now available at YouTube.\n2023-11-12: RFC idea for DAMOS-based tiered memory management is sent.\n2023-11-12: RFC idea for Access/Contiguity-aware Memory Auto-scaling is sent.\n2023-11-12: RFC patchset for Aim-oriented Feedback-driven DAMOS Aggressiveness Auto Tuning is sent.\n2023-11-08: The second in-person DAMON community meetup at LPC has accepted and announced.\n2023-11-02: Memory management subsystem pull requests for Linux v6.7-rc1, which contains the changes for DAMON, has sent.\n2023-10-22: An SOSP paper for tiered memory management that referencing and exploring DAMON has found.\n2023-10-12: LPC BoF session proposal for DAMON community in-person meetup has submitted.\n2023-10-04: DAMON talk for Kernel Summit track of Linux Plumbers Conference 2023 has accepted.\n2023-09-07: Yet another academic paper preprint regarding serverless on CXL using/citing DAMON has uploaded. The title of the preprint is \u0026ldquo;Understanding and Optimizing Serverless Workloads in CXL-Enabled Tiered Memory\u0026rdquo;\n2023-08-09: DAMON community started running its CI test against all stable kernels and report the results.\n2023-08-08: DAMON user-space tool (damo) has reached 100 Github stars. 2023-08-07: DAMON user-space tool (damo) has released its 100th version. A mail for the news, release stats, and appreciation to the DAMON community has also posted.\n2023-08-03: DAMON continuous functionality testing started testing stable rc kernels and report back the results.\n2023-08-01: DAMON Beer/Coffee/Tea meeting will be postponed from mid of August to end of OSSummit Euro 2023.\n2023-07-26: The kernel summit talk proposal for DAMON status and future plans has posted\n2023-07-10: Hocus wrote an article introducing DAMON as a kernel feature that could be useful for memory efficient VM, with its limitations.\n2023-06-30: DAMON talk for OSSummit EU 2023 has accepted and scheduled\n2023-06-25: DAMON userspace tool, damo has packaged for Debian/Ubuntu in addition to Fedora. It also turned out it was already packaged for ArchLinux. Refer to repology for detail.\n2023-05-26: Open Source Summit North America DAMON talk video is now available at Youtube\n2023-05-26: LSF/MM+BPF DAMON discussion video is now available at Youtube\n2023-05-17: Now DAMON user space tool (DAMO) is available at Fedora Packages\n2023-05-16: Michel from Fedora community is gonna package DAMON user space tool (DAMO) for Fedora!\n2023-05-16: An LWN article for LSF/MM+BPF DAMON discussion has uploaded\n2023-05-04: The schedule for DAMON talk/discussion at LSFMM is available now.\n2023-03-14: The schedule for DAMON talk at OSSummit NA is available now.\n2023-03-10: A DAMON talk proposal for OSSummit NA has accepted.\n2023-03-06: DAMOS filters feature has introduced as one of the most significant changes for Linux v6.3 by an LWN article\n2023-02-24: A preprint of an academic paper that compares their approach against DAMON has uploaded to ArXiv.\n2023-02-13: LSF/MM/BPF topic proposal for DAMON has posted\n2023-02-09: DAMON debugfs deprecation patchset has posted\n2022 2022-12-29: DAMON development summary of 2022 has shared and featured by Phoronix.\n2022-12-16: The DAMOS filtering for anon pages and/or memory cgroups have merged in mm tree.\n2022-10-19: An RFC patchset for efficient query-like DAMON monitoring results have posted\n2022-09-15: The video for my kernel summit DAMON talk this year is now available at Youtube\n2022-09-09: The plan for the first in-person DAMON community meetup at LPC and the in-person office hour at OSSummit EU has announced\n2022-09-06: AL2 5.10 kernel\u0026rsquo;s DAMON code has updated to that of v5.19\n2022-08-30: AL2 5.10 kernel\u0026rsquo;s DAMON code has updated to that of v5.18\n2022-08-22: LWN introduced DAMON-based LRU-lists manipulation (DAMON_LRU_SORT) in detail\n2022-08-15: LWN introduced DAMON’s new features including \u0026lsquo;LRU_SORT\u0026rsquo; as significant changes for Linux 6.0\n2022-08-12: Bi-weekly DAMON Beer/Coffee/Tea Chat series for open, regular, and informal community syncups and discussions has announced.\n2022-07-29: Current status, future plans, and possible collaborations for DAMON will be presented at the Kernel Summit 2022.\n2022-06-26: The poster of the DAOS paper is available online.\n2022-06-13: DAMON-based LRU-lists sorting patchset has posted and immediately merged in the -mm tree\n2022-05-04: A paper introducing DAMON and related works have accepted by HPDC22\n2022-05-03: Now DAMON has its own open mailing list\n2022-04-29: Patches for DAMON online tuning have merged in -mm tree\n2022-04-27: Android has backported and enabled building DAMON and DAMON_RECLAIM for the common kernel.\n2022-04-27: Alibaba has shared thier own DAMON user space tool.\n2022-02-28: The DAMON sysfs interface patchset has merged in -mm tree.\n2022-02-17: An RFC patchset for sysfs-based DAMON\u0026rsquo;s new user interface has posted.\n2022-01-20: A roadmap of DAMON has shared.\n2022-01-09: Linux 5.16 is released. \u0026ldquo;DAMON-based proactive memory reclamation, operation schemes and physical memory monitoring\u0026rdquo; are marked as prominent features of the release by the Kernel newbies and LWN.\n2021 2021-12-23: A great blog post for DAMON-enabled kernel has uploaded\n2021-11-07: DAMON patches for automated memory management optimization, the physical address space monitoring support, and proactive reclamation have merged in the mainline.\n2021-11-01: DAMON has released with Linux v5.15.\n2021-10-14: DAMON_RECLAIM patchset is merged in the Amazon Linux 5.10.y kernel tree.\n2021-10-02: DAMOS patchset is merged in the -mm tree.\n2021-09-23: DAMON and DAMOS are presented in the kernel summit. Slides, Video, Link\n2021-09-16: DAMON development tree on kernel.org is created.\n2021-09-08: DAMON patchset is merged in the Linus Torvalds\u0026rsquo; tree, aka mainline\n2021-09-07: DAMON/DAMOS will be presented at the Kernel Summit 2021\n2021-08-31: DAMON user-space tool is uploaded to the official Python packages system, PyPi\n2021-08-06: DAMON patchset is merged in the -mm tree\n2021-07-27: LWN published a second article introducing DAMON patchset series\n2021-06-11: DAMON-based proactive reclamation RFC patchset has shared on the hackernews and introduced by a Phoronix article\n2021-05-31: DAMON-based proactive reclamation RFC patchset has posted\n2021-05-26: DAMON-enabled Amazon Linux 2 kernels have deployed to all users\n2021-05-07: DAMON has merged in the public source tree for Amazon Linux v5.4.y kernel\n2021-04-05: damo now supports heatmap visualization on the terminal\n2021-03-31: DAMON user-space tool (damo) is released as an individual open source project\n2021-03-19: DAMON has merged in the public source tree for Amazon Linux v5.10.y kernel\n2021-03-04: DAMON supports for two latest LTS kernels announced\n2021-03-03: DAMON is merged in v5.10 based public Amazon Linux kernel tree\n2021-02-25: An example usage of DAMON for profiling is shared\n2021-01-07: A runtime system for DAMON-based optimal operation scheme finding is released\n2020 2020-12-03: Further plans around DAMON is shared\n2020-11-17: A real-world user story of DAMON is shared\n2020-09-26: The tests package for DAMON is released under GPL v2 license\n2020-08-19: A demo video is available\n2020-08-05: DAMON will be presented at the Kernel Summit 2020\n2020-06-04: Physical Memory Monitoring is now available\n2020-05-18: DAMON showcase website is announced\n2020-05-13: DAMON official document is uploaded online\n2020-02-20: DAMON has introduced by an LWN article\n2020-02-10: The first RFC of Data Access Monitoring-based Operating Schemes (DAMOS) has posted to LKML\n2020-01-23: The RFC of DAMON has introduced by LWN\u0026rsquo;s \u0026lsquo;Kernel patches of interest\u0026rsquo;\n2020-01-20: The first RFC patchset of DAMON has posted to LKML\n","permalink":"https://sjp38.github.io/posts/ko/damon_news/","summary":"!! NOTE !!\nThis post has migrated to https://damonitor.github.io/posts/damon_news. This out-dated post will be removed soon.\nBelow is a list of news around DAMON project.\nThis list is not exhaustive but just a DAMON maintainer\u0026rsquo;s collection of news. If you find a news that should be added to this list, please let us know at sj@kernel.org and/or damon@lists.linux.dev.\n2024 2024-10-15: DAMON debugfs interface removal RFC patch has posted.\n2024-10-10: Monthly PyPI downloads of DAMON user-space too, DAMO, doubled again after ten days.","title":"DAMON News List"},{"content":"I will present and discuss about the current status and future plans of DAMON in Linux Storage/File System/Memory Management/BPF (LSFMM+BPF) 2023. The title of the talks is \u0026ldquo;DAMON updates and future plans\u0026rdquo;.\nhttps://events.linuxfoundation.org/lsfmm/program/schedule-at-a-glance/\n","permalink":"https://sjp38.github.io/posts/lsfmmbpf_2023_talk/","summary":"I will present and discuss about the current status and future plans of DAMON in Linux Storage/File System/Memory Management/BPF (LSFMM+BPF) 2023. The title of the talks is \u0026ldquo;DAMON updates and future plans\u0026rdquo;.\nhttps://events.linuxfoundation.org/lsfmm/program/schedule-at-a-glance/","title":"I will have a session for DAMON at the LSFMM 2023"},{"content":"I will present DAMON, DAMOS, and DAMO in Open Source Summit North America 2023. The title of the talk is \u0026ldquo;DAMON, DAMOS, and DAMO: Kernel Subsystems and User-Space Tools for Data Access-Aware System Analysis/Optimizations\u0026rdquo;.\nhttps://sched.co/1K5HS\n","permalink":"https://sjp38.github.io/posts/ossummit_na_2023_talk/","summary":"I will present DAMON, DAMOS, and DAMO in Open Source Summit North America 2023. The title of the talk is \u0026ldquo;DAMON, DAMOS, and DAMO: Kernel Subsystems and User-Space Tools for Data Access-Aware System Analysis/Optimizations\u0026rdquo;.\nhttps://sched.co/1K5HS","title":"I will have a talk at the Open Source Summit North America 2023"},{"content":"This document helps you estimating the amount of benefit that you could get from DAMON-based system optimizations, and describes how you could achieve it.\nCheck The Signs No optimization can provide same extent of benefit to every case. Therefore you should first guess how much improvements you could get using DAMON. If some of below conditions match your situation, you could consider using DAMON.\nLow IPC and High Cache Miss Ratios. Low IPC means most of the CPU time is spent waiting for the completion of time-consuming operations such as memory access, while high cache miss ratios mean the caches don\u0026rsquo;t help it well. DAMON is not for cache level optimization, but DRAM level. However, improving DRAM management will also help this case by reducing the memory operation latency. Memory Over-commitment and Unknown Users. If you are doing memory overcommitment and you cannot control every user of your system, a memory bank run could happen at any time. You can estimate when it will happen based on DAMON\u0026rsquo;s monitoring results and act earlier to avoid or deal better with the crisis. Frequent Memory Pressure. Frequent memory pressure means your system has wrong configurations or memory hogs. DAMON will help you find the right configuration and/or the criminals. Heterogeneous Memory System. If your system is utilizing memory devices that placed between DRAM and traditional hard disks, such as non-volatile memory or fast SSDs, DAMON could help you utilizing the devices more efficiently. Profile If you found some positive signals, you could start by profiling your workloads using DAMON. Find major workloads on your systems and analyze their data access pattern to find something wrong or can be improved. The DAMON user space tool (damo) will be useful for this. You can get damo from https://github.com/damonitor/damo.\nWe recommend you to start from working set size distribution check using damo report wss. If the distribution is ununiform or quite different from what you estimated, you could consider Memory Configuration optimization.\nThen, review the overall access pattern in heatmap form using damo report heats. If it shows a simple pattern consists of a small number of memory regions having high contrast of access temperature, you could consider manual Program Modification.\nIf the access pattern is very frequently changing so that you cannot figure out what is the performance important region using your human eye, Automated DAMON-based Memory Operations might help the case owing to its machine-level microscope view.\nIf you still want to absorb more benefits, you should develop Personalized DAMON Application for your special case.\nYou don\u0026rsquo;t need to take only one approach among the above plans, but you could use multiple of the above approaches to maximize the benefit.\nOptimize If the profiling result also says it\u0026rsquo;s worth trying some optimization, you could consider below approaches. Note that some of the below approaches assume that your systems are configured with swap devices or other types of auxiliary memory so that you don\u0026rsquo;t strictly required to accommodate the whole working set in the main memory. Most of the detailed optimization should be made on your concrete understanding of your memory devices.\nMemory Configuration No more no less, DRAM should be large enough to accommodate only important working sets, because DRAM is highly performance critical but expensive and heavily consumes the power. However, knowing the size of the real important working sets is difficult. As a consequence, people usually equips unnecessarily large or too small DRAM. Many problems stem from such wrong configurations.\nUsing the working set size distribution report provided by damo report wss, you can know the appropriate DRAM size for you. For example, roughly speaking, if you worry about only 95 percentile latency, you don\u0026rsquo;t need to equip DRAM of a size larger than 95 percentile working set size.\nLet\u0026rsquo;s see a real example. This page \u0026lt;https://damonitor.github.io/doc/html/v17/admin-guide/mm/damon/guide.html#memory-configuration\u0026gt; shows the heatmap and the working set size distributions/changes of freqmine workload in PARSEC3 benchmark suite. The working set size spikes up to 180 MiB, but keeps smaller than 50 MiB for more than 95% of the time. Even though you give only 50 MiB of memory space to the workload, it will work well for 95% of the time. Meanwhile, you can save the 130 MiB of memory space.\nProgram Modification If the data access pattern heatmap plotted by damo report heats is quite simple so that you can understand how the things are going in the workload with your human eye, you could manually optimize the memory management.\nFor example, suppose that the workload has two big memory object but only one object is frequently accessed while the other one is only occasionally accessed. Then, you could modify the program source code to keep the hot object in the main memory by invoking mlock() or madvise() with MADV_WILLNEED. Or, you could proactively evict the cold object using madvise() with MADV_COLD or MADV_PAGEOUT. Using both together would be also worthy.\nA research work [1] using the mlock() achieved up to 2.55x performance speedup.\nLet\u0026rsquo;s see another realistic example access pattern for this kind of optimizations. This another page \u0026lt;https://damonitor.github.io/doc/html/v17/admin-guide/mm/damon/guide.html#program-modification\u0026gt; shows the visualized access patterns of streamcluster workload in PARSEC3 benchmark suite. We can easily identify the 100 MiB sized hot object.\nAutomated DAMON-based Memory Operations Though Manual Program Optimization works well in many cases and DAMON can help it, modifying the source code is not a good option in many cases. First of all, the source code could be too old or unavailable. And, many workloads will have complex data access patterns that even hard to distinguish hot memory objects and cold memory objects with the human eye. Finding the mapping from the visualized access pattern to the source code and injecting the hinting system calls inside the code will also be quite challenging.\nBy using DAMON-based operation schemes (DAMOS) via damo schemes, you will be able to easily optimize your workload in such a case. Our example schemes called \u0026rsquo;efficient THP\u0026rsquo; and \u0026lsquo;proactive reclamation\u0026rsquo; achieved significant speedup and memory space saves against 25 realistic workloads [2].\nThat said, note that you need careful tune of the schemes (e.g., target region size and age) and monitoring attributes for the successful use of this approach. Because the optimal values of the parameters will be dependent on each system and workload, misconfiguring the parameters could result in worse memory management.\nFor the tuning, you could measure the performance metrics such as IPC, TLB misses, and swap in/out events and adjusts the parameters based on their changes. The total number and the total size of the regions that each scheme is applied, which are provided via the debugfs interface and the programming interface can also be useful. Writing a program automating this optimal parameter could be an option.\nPersonalized DAMON Application Above approaches will work well for many general cases, but would not enough for some special cases.\nIf this is the case, it might be the time to forget the comfortable use of the user space tool and dive into the debugfs interface (refer to :doc:usage for the detail) of DAMON. Using the interface, you can control the DAMON more flexibly. Therefore, you can write your personalized DAMON application that controls the monitoring via the debugfs interface, analyzes the result, and applies complex optimizations itself. Using this, you can make more creative and wise optimizations.\nIf you are a kernel space programmer, writing kernel space DAMON applications using the API (refer to the :doc:/mm/damon/api for more detail) would be an option.\nReference Practices Referencing previously done successful practices could help you getting the sense for this kind of optimizations. There is an academic paper [1] reporting the visualized access pattern and manual Program Modification results for a number of realistic workloads. You can also get the visualized access patterns [3,4,5] and Automated DAMON-based Memory Operations results for other realistic workloads that collected with latest version of DAMON [2].\n[1] https://dl.acm.org/doi/10.1145/3366626.3368125\n[2] https://damonitor.github.io/test/result/perf/latest/html/\n[3] https://damonitor.github.io/test/result/visual/latest/rec.heatmap.1.png.html\n[4] https://damonitor.github.io/test/result/visual/latest/rec.wss_sz.png.html\n[5] https://damonitor.github.io/test/result/visual/latest/rec.wss_time.png.html\n","permalink":"https://sjp38.github.io/posts/damon_optimization_guide/","summary":"This document helps you estimating the amount of benefit that you could get from DAMON-based system optimizations, and describes how you could achieve it.\nCheck The Signs No optimization can provide same extent of benefit to every case. Therefore you should first guess how much improvements you could get using DAMON. If some of below conditions match your situation, you could consider using DAMON.\nLow IPC and High Cache Miss Ratios.","title":"DAMON-based System Optimization Guide"},{"content":"This document helps you estimating the amount of benefit that you could get from DAMON-based system optimizations, and describes how you could achieve it.\nCheck The Signs No optimization can provide same extent of benefit to every case. Therefore you should first guess how much improvements you could get using DAMON. If some of below conditions match your situation, you could consider using DAMON.\nLow IPC and High Cache Miss Ratios. Low IPC means most of the CPU time is spent waiting for the completion of time-consuming operations such as memory access, while high cache miss ratios mean the caches don\u0026rsquo;t help it well. DAMON is not for cache level optimization, but DRAM level. However, improving DRAM management will also help this case by reducing the memory operation latency. Memory Over-commitment and Unknown Users. If you are doing memory overcommitment and you cannot control every user of your system, a memory bank run could happen at any time. You can estimate when it will happen based on DAMON\u0026rsquo;s monitoring results and act earlier to avoid or deal better with the crisis. Frequent Memory Pressure. Frequent memory pressure means your system has wrong configurations or memory hogs. DAMON will help you find the right configuration and/or the criminals. Heterogeneous Memory System. If your system is utilizing memory devices that placed between DRAM and traditional hard disks, such as non-volatile memory or fast SSDs, DAMON could help you utilizing the devices more efficiently. Profile If you found some positive signals, you could start by profiling your workloads using DAMON. Find major workloads on your systems and analyze their data access pattern to find something wrong or can be improved. The DAMON user space tool (damo) will be useful for this. You can get damo from https://github.com/damonitor/damo.\nWe recommend you to start from working set size distribution check using damo report wss. If the distribution is ununiform or quite different from what you estimated, you could consider Memory Configuration optimization.\nThen, review the overall access pattern in heatmap form using damo report heats. If it shows a simple pattern consists of a small number of memory regions having high contrast of access temperature, you could consider manual Program Modification.\nIf the access pattern is very frequently changing so that you cannot figure out what is the performance important region using your human eye, Automated DAMON-based Memory Operations might help the case owing to its machine-level microscope view.\nIf you still want to absorb more benefits, you should develop Personalized DAMON Application for your special case.\nYou don\u0026rsquo;t need to take only one approach among the above plans, but you could use multiple of the above approaches to maximize the benefit.\nOptimize If the profiling result also says it\u0026rsquo;s worth trying some optimization, you could consider below approaches. Note that some of the below approaches assume that your systems are configured with swap devices or other types of auxiliary memory so that you don\u0026rsquo;t strictly required to accommodate the whole working set in the main memory. Most of the detailed optimization should be made on your concrete understanding of your memory devices.\nMemory Configuration No more no less, DRAM should be large enough to accommodate only important working sets, because DRAM is highly performance critical but expensive and heavily consumes the power. However, knowing the size of the real important working sets is difficult. As a consequence, people usually equips unnecessarily large or too small DRAM. Many problems stem from such wrong configurations.\nUsing the working set size distribution report provided by damo report wss, you can know the appropriate DRAM size for you. For example, roughly speaking, if you worry about only 95 percentile latency, you don\u0026rsquo;t need to equip DRAM of a size larger than 95 percentile working set size.\nLet\u0026rsquo;s see a real example. This page \u0026lt;https://damonitor.github.io/doc/html/v17/admin-guide/mm/damon/guide.html#memory-configuration\u0026gt; shows the heatmap and the working set size distributions/changes of freqmine workload in PARSEC3 benchmark suite. The working set size spikes up to 180 MiB, but keeps smaller than 50 MiB for more than 95% of the time. Even though you give only 50 MiB of memory space to the workload, it will work well for 95% of the time. Meanwhile, you can save the 130 MiB of memory space.\nProgram Modification If the data access pattern heatmap plotted by damo report heats is quite simple so that you can understand how the things are going in the workload with your human eye, you could manually optimize the memory management.\nFor example, suppose that the workload has two big memory object but only one object is frequently accessed while the other one is only occasionally accessed. Then, you could modify the program source code to keep the hot object in the main memory by invoking mlock() or madvise() with MADV_WILLNEED. Or, you could proactively evict the cold object using madvise() with MADV_COLD or MADV_PAGEOUT. Using both together would be also worthy.\nA research work [1] using the mlock() achieved up to 2.55x performance speedup.\nLet\u0026rsquo;s see another realistic example access pattern for this kind of optimizations. This another page \u0026lt;https://damonitor.github.io/doc/html/v17/admin-guide/mm/damon/guide.html#program-modification\u0026gt; shows the visualized access patterns of streamcluster workload in PARSEC3 benchmark suite. We can easily identify the 100 MiB sized hot object.\nAutomated DAMON-based Memory Operations Though Manual Program Optimization works well in many cases and DAMON can help it, modifying the source code is not a good option in many cases. First of all, the source code could be too old or unavailable. And, many workloads will have complex data access patterns that even hard to distinguish hot memory objects and cold memory objects with the human eye. Finding the mapping from the visualized access pattern to the source code and injecting the hinting system calls inside the code will also be quite challenging.\nBy using DAMON-based operation schemes (DAMOS) via damo schemes, you will be able to easily optimize your workload in such a case. Our example schemes called \u0026rsquo;efficient THP\u0026rsquo; and \u0026lsquo;proactive reclamation\u0026rsquo; achieved significant speedup and memory space saves against 25 realistic workloads [2].\nThat said, note that you need careful tune of the schemes (e.g., target region size and age) and monitoring attributes for the successful use of this approach. Because the optimal values of the parameters will be dependent on each system and workload, misconfiguring the parameters could result in worse memory management.\nFor the tuning, you could measure the performance metrics such as IPC, TLB misses, and swap in/out events and adjusts the parameters based on their changes. The total number and the total size of the regions that each scheme is applied, which are provided via the debugfs interface and the programming interface can also be useful. Writing a program automating this optimal parameter could be an option.\nPersonalized DAMON Application Above approaches will work well for many general cases, but would not enough for some special cases.\nIf this is the case, it might be the time to forget the comfortable use of the user space tool and dive into the debugfs interface (refer to :doc:usage for the detail) of DAMON. Using the interface, you can control the DAMON more flexibly. Therefore, you can write your personalized DAMON application that controls the monitoring via the debugfs interface, analyzes the result, and applies complex optimizations itself. Using this, you can make more creative and wise optimizations.\nIf you are a kernel space programmer, writing kernel space DAMON applications using the API (refer to the :doc:/mm/damon/api for more detail) would be an option.\nReference Practices Referencing previously done successful practices could help you getting the sense for this kind of optimizations. There is an academic paper [1] reporting the visualized access pattern and manual Program Modification results for a number of realistic workloads. You can also get the visualized access patterns [3,4,5] and Automated DAMON-based Memory Operations results for other realistic workloads that collected with latest version of DAMON [2].\n[1] https://dl.acm.org/doi/10.1145/3366626.3368125\n[2] https://damonitor.github.io/test/result/perf/latest/html/\n[3] https://damonitor.github.io/test/result/visual/latest/rec.heatmap.1.png.html\n[4] https://damonitor.github.io/test/result/visual/latest/rec.wss_sz.png.html\n[5] https://damonitor.github.io/test/result/visual/latest/rec.wss_time.png.html\n","permalink":"https://sjp38.github.io/posts/ko/damon_optimization_guide/","summary":"This document helps you estimating the amount of benefit that you could get from DAMON-based system optimizations, and describes how you could achieve it.\nCheck The Signs No optimization can provide same extent of benefit to every case. Therefore you should first guess how much improvements you could get using DAMON. If some of below conditions match your situation, you could consider using DAMON.\nLow IPC and High Cache Miss Ratios.","title":"DAMON-based System Optimization Guide"},{"content":"!! NOTE !!\nThis post has migrated to https://damonitor.github.io/posts/damon_evaluation. This out-dated post will be removed soon.\nDAMON is lightweight. It increases system memory usage by 0.39% and slows target workloads down by 1.16%.\nDAMON is accurate and useful for memory management optimizations. An experimental DAMON-based operation scheme for THP, namely \u0026rsquo;ethp\u0026rsquo;, removes 76.15% of THP memory overheads while preserving 51.25% of THP speedup. Another experimental DAMON-based \u0026lsquo;proactive reclamation\u0026rsquo; implementation, namely \u0026lsquo;prcl\u0026rsquo;, reduces 93.38% of residential sets and 23.63% of system memory footprint while incurring only 1.22% runtime overhead in the best case (parsec3/freqmine).\nSetup On QEMU/KVM based virtual machines utilizing 130GB of RAM and 36 vCPUs hosted by AWS EC2 i3.metal instances that running a Linux v5.10 based kernel that v24 DAMON patchset is applied, I measure runtime and consumed system memory while running various realistic workloads with several configurations. From each of PARSEC3 [3] and SPLASH-2X [4] benchmark suites I pick 12 workloads, so I use 24 workloads in total. I use another wrapper scripts [5] for convenient setup and run of the workloads.\nMeasurement For the measurement of the amount of consumed memory in system global scope, I drop caches before starting each of the workloads and monitor \u0026lsquo;MemFree\u0026rsquo; in the \u0026lsquo;/proc/meminfo\u0026rsquo; file. To make results more stable, I repeat the runs 5 times and average results.\nConfigurations The configurations I use are as below.\norig: Linux v5.10 with \u0026lsquo;madvise\u0026rsquo; THP policy rec: \u0026lsquo;orig\u0026rsquo; plus DAMON running with virtual memory access recording prec: \u0026lsquo;orig\u0026rsquo; plus DAMON running with physical memory access recording thp: same with \u0026lsquo;orig\u0026rsquo;, but use \u0026lsquo;always\u0026rsquo; THP policy ethp: \u0026lsquo;orig\u0026rsquo; plus a DAMON operation scheme, \u0026rsquo;efficient THP\u0026rsquo; prcl: \u0026lsquo;orig\u0026rsquo; plus a DAMON operation scheme, \u0026lsquo;proactive reclaim [6]\u0026rsquo; I use \u0026lsquo;rec\u0026rsquo; for measurement of DAMON overheads to target workloads and system memory. \u0026lsquo;prec\u0026rsquo; is for physical memory monitroing and recording. It monitors 17GB sized \u0026lsquo;System RAM\u0026rsquo; region. The remaining configs including \u0026rsquo;thp\u0026rsquo;, \u0026rsquo;ethp\u0026rsquo;, and \u0026lsquo;prcl\u0026rsquo; are for measurement of DAMON monitoring accuracy.\n\u0026rsquo;ethp\u0026rsquo; and \u0026lsquo;prcl\u0026rsquo; are simple DAMON-based operation schemes developed for proof of concepts of DAMON. \u0026rsquo;ethp\u0026rsquo; reduces memory space waste of THP [1,2], by using DAMON for the decision of promotions and demotion for huge pages, while \u0026lsquo;prcl\u0026rsquo; is as similar as the original work. For example, those can be implemented as below::\n# format: \u0026lt;min/max size\u0026gt; \u0026lt;min/max frequency (0-100)\u0026gt; \u0026lt;min/max age\u0026gt; \u0026lt;action\u0026gt; # ethp: Use huge pages if a region shows \u0026gt;=5% access rate, use regular # pages if a region \u0026gt;=2MB shows 0 access rate for \u0026gt;=7 seconds min max 5 max min max hugepage 2M max min min 7s max nohugepage # prcl: If a region \u0026gt;=4KB shows 0 access rate for \u0026gt;=5 seconds, page out. 4K max 0 0 5s max pageout Note that these examples are designed with my only straightforward intuition because those are for only proof of concepts and monitoring accuracy of DAMON. In other words, those are not for production. For production use, those should be more tuned. For automation of such tuning, you can use a user space tool called DAMOOS [8]. For the evaluation, we use \u0026rsquo;ethp\u0026rsquo; as same to above example, but we use DAMOOS-tuned \u0026lsquo;prcl\u0026rsquo; for each workload.\nThe evaluation is done using the tests package for DAMON, damon-tests [7]. Using it, you can do the evaluation and generate a report on your own.\n[1] \u0026ldquo;Redis latency problems troubleshooting\u0026rdquo;, https://redis.io/topics/latency\n[2] \u0026ldquo;Disable Transparent Huge Pages (THP)\u0026rdquo;, https://docs.mongodb.com/manual/tutorial/transparent-huge-pages/\n[3] \u0026ldquo;The PARSEC Becnhmark Suite\u0026rdquo;, https://parsec.cs.princeton.edu/index.htm\n[4] \u0026ldquo;SPLASH-2x\u0026rdquo;, https://parsec.cs.princeton.edu/parsec3-doc.htm#splash2x\n[5] \u0026ldquo;parsec3_on_ubuntu\u0026rdquo;, https://github.com/sjp38/parsec3_on_ubuntu\n[6] \u0026ldquo;Proactively reclaiming idle memory\u0026rdquo;, https://lwn.net/Articles/787611/\n[7] \u0026ldquo;damon-tests\u0026rdquo;, https://github.com/damonitor/damon-tests\n[8] \u0026ldquo;DAMOOS\u0026rdquo;, https://github.com/damonitor/damoos\nResults Below two tables show the measurement results. The runtimes are in seconds while the memory usages are in KiB. Each configuration except \u0026lsquo;orig\u0026rsquo; shows its overhead relative to \u0026lsquo;orig\u0026rsquo; in percent within parenthesizes.::\nruntime orig rec (overhead) prec (overhead) thp (overhead) ethp (overhead) prcl (overhead) parsec3/blackscholes 139.658 140.168 (0.37) 139.385 (-0.20) 138.367 (-0.92) 139.279 (-0.27) 147.024 (5.27) parsec3/bodytrack 123.788 124.622 (0.67) 123.636 (-0.12) 125.115 (1.07) 123.840 (0.04) 141.928 (14.65) parsec3/canneal 207.491 210.318 (1.36) 217.927 (5.03) 174.287 (-16.00) 202.609 (-2.35) 225.483 (8.67) parsec3/dedup 18.292 18.301 (0.05) 18.378 (0.47) 18.264 (-0.15) 18.298 (0.03) 20.541 (12.30) parsec3/facesim 343.893 340.286 (-1.05) 338.217 (-1.65) 332.953 (-3.18) 333.840 (-2.92) 365.650 (6.33) parsec3/fluidanimate 339.959 326.886 (-3.85) 330.286 (-2.85) 331.239 (-2.57) 326.011 (-4.10) 341.684 (0.51) parsec3/freqmine 445.987 436.332 (-2.16) 435.946 (-2.25) 435.704 (-2.31) 437.595 (-1.88) 451.414 (1.22) parsec3/raytrace 184.106 182.158 (-1.06) 182.056 (-1.11) 183.180 (-0.50) 183.545 (-0.30) 202.197 (9.83) parsec3/streamcluster 599.990 674.091 (12.35) 617.314 (2.89) 521.864 (-13.02) 551.971 (-8.00) 696.127 (16.02) parsec3/swaptions 220.462 222.637 (0.99) 220.449 (-0.01) 219.921 (-0.25) 221.607 (0.52) 223.956 (1.59) parsec3/vips 87.767 88.700 (1.06) 87.461 (-0.35) 87.466 (-0.34) 87.875 (0.12) 91.768 (4.56) parsec3/x264 110.843 117.856 (6.33) 113.023 (1.97) 108.665 (-1.97) 115.434 (4.14) 117.811 (6.29) splash2x/barnes 131.441 129.275 (-1.65) 128.341 (-2.36) 119.317 (-9.22) 126.199 (-3.99) 147.602 (12.30) splash2x/fft 59.705 58.382 (-2.22) 58.858 (-1.42) 45.949 (-23.04) 59.939 (0.39) 64.548 (8.11) splash2x/lu_cb 132.552 131.604 (-0.72) 131.846 (-0.53) 132.320 (-0.18) 132.100 (-0.34) 140.289 (5.84) splash2x/lu_ncb 150.215 149.670 (-0.36) 149.646 (-0.38) 148.823 (-0.93) 149.416 (-0.53) 152.338 (1.41) splash2x/ocean_cp 84.033 76.405 (-9.08) 75.104 (-10.63) 73.487 (-12.55) 77.789 (-7.43) 77.380 (-7.92) splash2x/ocean_ncp 153.833 154.247 (0.27) 156.227 (1.56) 106.619 (-30.69) 139.299 (-9.45) 165.030 (7.28) splash2x/radiosity 143.566 143.654 (0.06) 142.426 (-0.79) 141.193 (-1.65) 141.740 (-1.27) 157.817 (9.93) splash2x/radix 49.984 49.996 (0.02) 50.519 (1.07) 46.573 (-6.82) 50.724 (1.48) 50.695 (1.42) splash2x/raytrace 133.238 134.337 (0.83) 134.389 (0.86) 134.833 (1.20) 131.073 (-1.62) 145.541 (9.23) splash2x/volrend 121.700 120.652 (-0.86) 120.560 (-0.94) 120.629 (-0.88) 119.581 (-1.74) 129.422 (6.35) splash2x/water_nsquared 370.771 375.236 (1.20) 376.829 (1.63) 355.592 (-4.09) 354.087 (-4.50) 419.606 (13.17) splash2x/water_spatial 133.295 132.931 (-0.27) 132.762 (-0.40) 133.090 (-0.15) 133.809 (0.39) 153.647 (15.27) total 4486.580 4538.750 (1.16) 4481.600 (-0.11) 4235.430 (-5.60) 4357.660 (-2.87) 4829.510 (7.64) memused.avg orig rec (overhead) prec (overhead) thp (overhead) ethp (overhead) prcl (overhead) parsec3/blackscholes 1828693.600 1834084.000 (0.29) 1823839.800 (-0.27) 1819296.600 (-0.51) 1830281.800 (0.09) 1603975.800 (-12.29) parsec3/bodytrack 1424963.400 1440085.800 (1.06) 1438384.200 (0.94) 1421718.400 (-0.23) 1432834.600 (0.55) 1439283.000 (1.00) parsec3/canneal 1036782.600 1052828.800 (1.55) 1050148.600 (1.29) 1035104.400 (-0.16) 1051145.400 (1.39) 1050019.400 (1.28) parsec3/dedup 2511841.400 2507374.000 (-0.18) 2472450.600 (-1.57) 2523557.600 (0.47) 2508912.000 (-0.12) 2493347.200 (-0.74) parsec3/facesim 537769.800 550740.800 (2.41) 548683.600 (2.03) 543547.800 (1.07) 560556.600 (4.24) 482782.600 (-10.23) parsec3/fluidanimate 570268.600 585598.000 (2.69) 579837.800 (1.68) 571433.000 (0.20) 582112.800 (2.08) 470073.400 (-17.57) parsec3/freqmine 982941.400 996253.200 (1.35) 993919.800 (1.12) 990531.800 (0.77) 1000994.400 (1.84) 750685.800 (-23.63) parsec3/raytrace 1737446.000 1749908.800 (0.72) 1741183.800 (0.22) 1726674.800 (-0.62) 1748530.200 (0.64) 1552275.600 (-10.66) parsec3/streamcluster 115857.000 155194.400 (33.95) 158272.800 (36.61) 122125.200 (5.41) 134545.600 (16.13) 133448.600 (15.18) parsec3/swaptions 13694.200 28451.800 (107.76) 28464.600 (107.86) 12797.800 (-6.55) 25328.200 (84.96) 28138.400 (105.48) parsec3/vips 2976126.400 3002408.600 (0.88) 3008218.800 (1.08) 2978258.600 (0.07) 2995428.600 (0.65) 2936338.600 (-1.34) parsec3/x264 3233886.200 3258790.200 (0.77) 3248355.000 (0.45) 3232070.000 (-0.06) 3256360.200 (0.69) 3254707.400 (0.64) splash2x/barnes 1210470.600 1211918.600 (0.12) 1204507.000 (-0.49) 1210892.800 (0.03) 1217414.800 (0.57) 944053.400 (-22.01) splash2x/fft 9697440.000 9604535.600 (-0.96) 9210571.800 (-5.02) 9867368.000 (1.75) 9637571.800 (-0.62) 9804092.000 (1.10) splash2x/lu_cb 510680.400 521792.600 (2.18) 517724.600 (1.38) 513500.800 (0.55) 519980.600 (1.82) 351787.000 (-31.11) splash2x/lu_ncb 512896.200 529353.600 (3.21) 521248.600 (1.63) 513493.200 (0.12) 523793.400 (2.12) 418701.600 (-18.37) splash2x/ocean_cp 3320800.200 3313688.400 (-0.21) 3225585.000 (-2.87) 3359032.200 (1.15) 3316591.800 (-0.13) 3304702.200 (-0.48) splash2x/ocean_ncp 3915132.400 3917401.000 (0.06) 3884086.400 (-0.79) 7050398.600 (80.08) 4532528.600 (15.77) 3920395.800 (0.13) splash2x/radiosity 1456908.200 1467611.800 (0.73) 1453612.600 (-0.23) 1466695.400 (0.67) 1467495.600 (0.73) 421197.600 (-71.09) splash2x/radix 2345874.600 2318202.200 (-1.18) 2261499.200 (-3.60) 2438228.400 (3.94) 2373697.800 (1.19) 2336605.600 (-0.40) splash2x/raytrace 43258.800 57624.200 (33.21) 55164.600 (27.52) 46204.400 (6.81) 60475.000 (39.80) 48865.400 (12.96) splash2x/volrend 149615.000 163809.400 (9.49) 162115.400 (8.36) 149119.600 (-0.33) 162747.800 (8.78) 157734.600 (5.43) splash2x/water_nsquared 40384.400 54848.600 (35.82) 53796.600 (33.21) 41455.800 (2.65) 53226.400 (31.80) 58260.600 (44.27) splash2x/water_spatial 670580.200 680444.200 (1.47) 670020.400 (-0.08) 668262.400 (-0.35) 678552.000 (1.19) 372931.000 (-44.39) total 40844300.000 41002900.000 (0.39) 40311600.000 (-1.30) 44301900.000 (8.47) 41671052.000 (2.02) 38334431.000 (-6.14) DAMON Overheads In total, DAMON virtual memory access recording feature (\u0026lsquo;rec\u0026rsquo;) incurs 1.16% runtime overhead and 0.39% memory space overhead. Even though the size of the monitoring target region becomes much larger with the physical memory access recording (\u0026lsquo;prec\u0026rsquo;), it still shows only modest amount of overhead (-0.11% for runtime and -1.30% for memory footprint).\nFor a convenient test run of \u0026lsquo;rec\u0026rsquo; and \u0026lsquo;prec\u0026rsquo;, I use a Python wrapper. The wrapper constantly consumes about 10-15MB of memory. This becomes a high memory overhead if the target workload has a small memory footprint. Nonetheless, the overheads are not from DAMON, but from the wrapper, and thus should be ignored. This fake memory overhead continues in \u0026rsquo;ethp\u0026rsquo; and \u0026lsquo;prcl\u0026rsquo;, as those configurations are also using the Python wrapper.\nEfficient THP THP \u0026lsquo;always\u0026rsquo; enabled policy achieves 5.60% speedup but incurs 8.47% memory overhead. It achieves 30.69% speedup in the best case, but 80.08% memory overhead in the worst case. Interestingly, both the best and worst-case are with \u0026lsquo;splash2x/ocean_ncp\u0026rsquo;).\nThe 2-lines implementation of data access monitoring based THP version (\u0026rsquo;ethp\u0026rsquo;) shows 2.87% speedup and 2.02% memory overhead. In other words, \u0026rsquo;ethp\u0026rsquo; removes 76.15% of THP memory waste while preserving 51.25% of THP speedup in total. In the case of the \u0026lsquo;splash2x/ocean_ncp\u0026rsquo;, \u0026rsquo;ethp\u0026rsquo; removes 80.30% of THP memory waste while preserving 30.79% of THP speedup.\nProactive Reclamation As similar to the original work, I use 4G \u0026lsquo;zram\u0026rsquo; swap device for this configuration. Also note that we use DAMOOS-tuned ethp schemes for each workload.\nIn total, our 1 line implementation of Proactive Reclamation, \u0026lsquo;prcl\u0026rsquo;, incurred 7.64% runtime overhead in total while achieving 6.14% system memory footprint reduction. Even in the worst case, the runtime overhead was only 16.02%.\nNonetheless, as the memory usage is calculated with \u0026lsquo;MemFree\u0026rsquo; in \u0026lsquo;/proc/meminfo\u0026rsquo;, it contains the SwapCached pages. As the swapcached pages can be easily evicted, I also measured the residential set size of the workloads::\nrss.avg orig rec (overhead) prec (overhead) thp (overhead) ethp (overhead) prcl (overhead) parsec3/blackscholes 587536.800 585720.000 (-0.31) 586233.400 (-0.22) 587045.400 (-0.08) 586753.400 (-0.13) 252207.400 (-57.07) parsec3/bodytrack 32302.200 32290.600 (-0.04) 32261.800 (-0.13) 32215.800 (-0.27) 32173.000 (-0.40) 6798.800 (-78.95) parsec3/canneal 842370.600 841443.400 (-0.11) 844012.400 (0.19) 838074.400 (-0.51) 841700.800 (-0.08) 840804.000 (-0.19) parsec3/dedup 1180414.800 1164634.600 (-1.34) 1188886.200 (0.72) 1207821.000 (2.32) 1193896.200 (1.14) 572359.200 (-51.51) parsec3/facesim 311848.400 311709.800 (-0.04) 311790.800 (-0.02) 317345.800 (1.76) 315443.400 (1.15) 188488.000 (-39.56) parsec3/fluidanimate 531868.000 531885.600 (0.00) 531828.800 (-0.01) 532988.000 (0.21) 532959.600 (0.21) 415153.200 (-21.94) parsec3/freqmine 552491.000 552718.600 (0.04) 552807.200 (0.06) 556574.200 (0.74) 554374.600 (0.34) 36573.400 (-93.38) parsec3/raytrace 879683.400 880752.200 (0.12) 879907.000 (0.03) 870631.000 (-1.03) 880952.200 (0.14) 293119.200 (-66.68) parsec3/streamcluster 110991.800 110937.200 (-0.05) 110964.600 (-0.02) 115606.800 (4.16) 116199.000 (4.69) 110108.200 (-0.80) parsec3/swaptions 5665.000 5718.400 (0.94) 5720.600 (0.98) 5682.200 (0.30) 5628.600 (-0.64) 3613.800 (-36.21) parsec3/vips 32143.600 31823.200 (-1.00) 31912.200 (-0.72) 33164.200 (3.18) 33925.800 (5.54) 27813.600 (-13.47) parsec3/x264 81534.000 81811.000 (0.34) 81708.400 (0.21) 83052.400 (1.86) 83758.800 (2.73) 81691.800 (0.19) splash2x/barnes 1220515.200 1218291.200 (-0.18) 1217699.600 (-0.23) 1228551.600 (0.66) 1220669.800 (0.01) 681096.000 (-44.20) splash2x/fft 9915850.400 10036461.000 (1.22) 9881242.800 (-0.35) 10334603.600 (4.22) 10006993.200 (0.92) 8975181.200 (-9.49) splash2x/lu_cb 511327.200 511679.000 (0.07) 511761.600 (0.08) 511971.600 (0.13) 511711.200 (0.08) 338005.000 (-33.90) splash2x/lu_ncb 511505.000 506816.800 (-0.92) 511392.800 (-0.02) 496623.000 (-2.91) 511410.200 (-0.02) 404734.000 (-20.87) splash2x/ocean_cp 3398834.000 3405017.800 (0.18) 3415287.800 (0.48) 3443604.600 (1.32) 3416264.200 (0.51) 3387134.000 (-0.34) splash2x/ocean_ncp 3947092.800 3939805.400 (-0.18) 3952311.600 (0.13) 7165858.800 (81.55) 4610075.000 (16.80) 3944753.400 (-0.06) splash2x/radiosity 1475024.000 1474053.200 (-0.07) 1475032.400 (0.00) 1483718.800 (0.59) 1475919.600 (0.06) 99637.200 (-93.25) splash2x/radix 2431302.200 2416928.600 (-0.59) 2455596.800 (1.00) 2568526.400 (5.64) 2479966.800 (2.00) 2437406.600 (0.25) splash2x/raytrace 23274.400 23278.400 (0.02) 23287.200 (0.05) 28828.000 (23.86) 27800.200 (19.45) 5667.000 (-75.65) splash2x/volrend 44106.800 44151.400 (0.10) 44186.000 (0.18) 45200.400 (2.48) 44751.200 (1.46) 16912.000 (-61.66) splash2x/water_nsquared 29427.200 29425.600 (-0.01) 29402.400 (-0.08) 28055.400 (-4.66) 28572.400 (-2.90) 13207.800 (-55.12) splash2x/water_spatial 664312.200 664095.600 (-0.03) 663025.200 (-0.19) 664100.600 (-0.03) 663597.400 (-0.11) 261214.200 (-60.68) total 29321300.000 29401500.000 (0.27) 29338300.000 (0.06) 33179900.000 (13.16) 30175600.000 (2.91) 23393600.000 (-20.22) In total, 20.22% of residential sets were reduced.\nWith parsec3/freqmine, \u0026lsquo;prcl\u0026rsquo; reduced 93.38% of residential sets and 23.63% of system memory usage while incurring only 1.22% runtime overhead.\n","permalink":"https://sjp38.github.io/posts/damon_evaluation/","summary":"!! NOTE !!\nThis post has migrated to https://damonitor.github.io/posts/damon_evaluation. This out-dated post will be removed soon.\nDAMON is lightweight. It increases system memory usage by 0.39% and slows target workloads down by 1.16%.\nDAMON is accurate and useful for memory management optimizations. An experimental DAMON-based operation scheme for THP, namely \u0026rsquo;ethp\u0026rsquo;, removes 76.15% of THP memory overheads while preserving 51.25% of THP speedup. Another experimental DAMON-based \u0026lsquo;proactive reclamation\u0026rsquo; implementation, namely \u0026lsquo;prcl\u0026rsquo;, reduces 93.","title":"DAMON Evaluation"},{"content":"DAMON is lightweight. It increases system memory usage by 0.39% and slows target workloads down by 1.16%.\nDAMON is accurate and useful for memory management optimizations. An experimental DAMON-based operation scheme for THP, namely \u0026rsquo;ethp\u0026rsquo;, removes 76.15% of THP memory overheads while preserving 51.25% of THP speedup. Another experimental DAMON-based \u0026lsquo;proactive reclamation\u0026rsquo; implementation, namely \u0026lsquo;prcl\u0026rsquo;, reduces 93.38% of residential sets and 23.63% of system memory footprint while incurring only 1.22% runtime overhead in the best case (parsec3/freqmine).\nSetup On QEMU/KVM based virtual machines utilizing 130GB of RAM and 36 vCPUs hosted by AWS EC2 i3.metal instances that running a kernel that v24 DAMON patchset is applied, I measure runtime and consumed system memory while running various realistic workloads with several configurations. From each of PARSEC3 [3] and SPLASH-2X [4] benchmark suites I pick 12 workloads, so I use 24 workloads in total. I use another wrapper scripts [5] for convenient setup and run of the workloads.\nMeasurement For the measurement of the amount of consumed memory in system global scope, I drop caches before starting each of the workloads and monitor \u0026lsquo;MemFree\u0026rsquo; in the \u0026lsquo;/proc/meminfo\u0026rsquo; file. To make results more stable, I repeat the runs 5 times and average results.\nConfigurations The configurations I use are as below.\norig: Linux v5.10 with \u0026lsquo;madvise\u0026rsquo; THP policy rec: \u0026lsquo;orig\u0026rsquo; plus DAMON running with virtual memory access recording prec: \u0026lsquo;orig\u0026rsquo; plus DAMON running with physical memory access recording thp: same with \u0026lsquo;orig\u0026rsquo;, but use \u0026lsquo;always\u0026rsquo; THP policy ethp: \u0026lsquo;orig\u0026rsquo; plus a DAMON operation scheme, \u0026rsquo;efficient THP\u0026rsquo; prcl: \u0026lsquo;orig\u0026rsquo; plus a DAMON operation scheme, \u0026lsquo;proactive reclaim [6]\u0026rsquo; I use \u0026lsquo;rec\u0026rsquo; for measurement of DAMON overheads to target workloads and system memory. \u0026lsquo;prec\u0026rsquo; is for physical memory monitroing and recording. It monitors 17GB sized \u0026lsquo;System RAM\u0026rsquo; region. The remaining configs including \u0026rsquo;thp\u0026rsquo;, \u0026rsquo;ethp\u0026rsquo;, and \u0026lsquo;prcl\u0026rsquo; are for measurement of DAMON monitoring accuracy.\n\u0026rsquo;ethp\u0026rsquo; and \u0026lsquo;prcl\u0026rsquo; are simple DAMON-based operation schemes developed for proof of concepts of DAMON. \u0026rsquo;ethp\u0026rsquo; reduces memory space waste of THP [1,2], by using DAMON for the decision of promotions and demotion for huge pages, while \u0026lsquo;prcl\u0026rsquo; is as similar as the original work. For example, those can be implemented as below::\n# format: \u0026lt;min/max size\u0026gt; \u0026lt;min/max frequency (0-100)\u0026gt; \u0026lt;min/max age\u0026gt; \u0026lt;action\u0026gt; # ethp: Use huge pages if a region shows \u0026gt;=5% access rate, use regular # pages if a region \u0026gt;=2MB shows 0 access rate for \u0026gt;=7 seconds min max 5 max min max hugepage 2M max min min 7s max nohugepage # prcl: If a region \u0026gt;=4KB shows 0 access rate for \u0026gt;=5 seconds, page out. 4K max 0 0 5s max pageout Note that these examples are designed with my only straightforward intuition because those are for only proof of concepts and monitoring accuracy of DAMON. In other words, those are not for production. For production use, those should be more tuned. For automation of such tuning, you can use a user space tool called DAMOOS [8]. For the evaluation, we use \u0026rsquo;ethp\u0026rsquo; as same to above example, but we use DAMOOS-tuned \u0026lsquo;prcl\u0026rsquo; for each workload.\nThe evaluation is done using the tests package for DAMON, damon-tests [7]. Using it, you can do the evaluation and generate a report on your own.\n[1] \u0026ldquo;Redis latency problems troubleshooting\u0026rdquo;, https://redis.io/topics/latency\n[2] \u0026ldquo;Disable Transparent Huge Pages (THP)\u0026rdquo;, https://docs.mongodb.com/manual/tutorial/transparent-huge-pages/\n[3] \u0026ldquo;The PARSEC Becnhmark Suite\u0026rdquo;, https://parsec.cs.princeton.edu/index.htm\n[4] \u0026ldquo;SPLASH-2x\u0026rdquo;, https://parsec.cs.princeton.edu/parsec3-doc.htm#splash2x\n[5] \u0026ldquo;parsec3_on_ubuntu\u0026rdquo;, https://github.com/sjp38/parsec3_on_ubuntu\n[6] \u0026ldquo;Proactively reclaiming idle memory\u0026rdquo;, https://lwn.net/Articles/787611/\n[7] \u0026ldquo;damon-tests\u0026rdquo;, https://github.com/awslabs/damon-tests\n[8] \u0026ldquo;DAMOOS\u0026rdquo;, https://github.com/awslabs/damoos\nResults Below two tables show the measurement results. The runtimes are in seconds while the memory usages are in KiB. Each configuration except \u0026lsquo;orig\u0026rsquo; shows its overhead relative to \u0026lsquo;orig\u0026rsquo; in percent within parenthesizes.::\nruntime orig rec (overhead) prec (overhead) thp (overhead) ethp (overhead) prcl (overhead) parsec3/blackscholes 139.658 140.168 (0.37) 139.385 (-0.20) 138.367 (-0.92) 139.279 (-0.27) 147.024 (5.27) parsec3/bodytrack 123.788 124.622 (0.67) 123.636 (-0.12) 125.115 (1.07) 123.840 (0.04) 141.928 (14.65) parsec3/canneal 207.491 210.318 (1.36) 217.927 (5.03) 174.287 (-16.00) 202.609 (-2.35) 225.483 (8.67) parsec3/dedup 18.292 18.301 (0.05) 18.378 (0.47) 18.264 (-0.15) 18.298 (0.03) 20.541 (12.30) parsec3/facesim 343.893 340.286 (-1.05) 338.217 (-1.65) 332.953 (-3.18) 333.840 (-2.92) 365.650 (6.33) parsec3/fluidanimate 339.959 326.886 (-3.85) 330.286 (-2.85) 331.239 (-2.57) 326.011 (-4.10) 341.684 (0.51) parsec3/freqmine 445.987 436.332 (-2.16) 435.946 (-2.25) 435.704 (-2.31) 437.595 (-1.88) 451.414 (1.22) parsec3/raytrace 184.106 182.158 (-1.06) 182.056 (-1.11) 183.180 (-0.50) 183.545 (-0.30) 202.197 (9.83) parsec3/streamcluster 599.990 674.091 (12.35) 617.314 (2.89) 521.864 (-13.02) 551.971 (-8.00) 696.127 (16.02) parsec3/swaptions 220.462 222.637 (0.99) 220.449 (-0.01) 219.921 (-0.25) 221.607 (0.52) 223.956 (1.59) parsec3/vips 87.767 88.700 (1.06) 87.461 (-0.35) 87.466 (-0.34) 87.875 (0.12) 91.768 (4.56) parsec3/x264 110.843 117.856 (6.33) 113.023 (1.97) 108.665 (-1.97) 115.434 (4.14) 117.811 (6.29) splash2x/barnes 131.441 129.275 (-1.65) 128.341 (-2.36) 119.317 (-9.22) 126.199 (-3.99) 147.602 (12.30) splash2x/fft 59.705 58.382 (-2.22) 58.858 (-1.42) 45.949 (-23.04) 59.939 (0.39) 64.548 (8.11) splash2x/lu_cb 132.552 131.604 (-0.72) 131.846 (-0.53) 132.320 (-0.18) 132.100 (-0.34) 140.289 (5.84) splash2x/lu_ncb 150.215 149.670 (-0.36) 149.646 (-0.38) 148.823 (-0.93) 149.416 (-0.53) 152.338 (1.41) splash2x/ocean_cp 84.033 76.405 (-9.08) 75.104 (-10.63) 73.487 (-12.55) 77.789 (-7.43) 77.380 (-7.92) splash2x/ocean_ncp 153.833 154.247 (0.27) 156.227 (1.56) 106.619 (-30.69) 139.299 (-9.45) 165.030 (7.28) splash2x/radiosity 143.566 143.654 (0.06) 142.426 (-0.79) 141.193 (-1.65) 141.740 (-1.27) 157.817 (9.93) splash2x/radix 49.984 49.996 (0.02) 50.519 (1.07) 46.573 (-6.82) 50.724 (1.48) 50.695 (1.42) splash2x/raytrace 133.238 134.337 (0.83) 134.389 (0.86) 134.833 (1.20) 131.073 (-1.62) 145.541 (9.23) splash2x/volrend 121.700 120.652 (-0.86) 120.560 (-0.94) 120.629 (-0.88) 119.581 (-1.74) 129.422 (6.35) splash2x/water_nsquared 370.771 375.236 (1.20) 376.829 (1.63) 355.592 (-4.09) 354.087 (-4.50) 419.606 (13.17) splash2x/water_spatial 133.295 132.931 (-0.27) 132.762 (-0.40) 133.090 (-0.15) 133.809 (0.39) 153.647 (15.27) total 4486.580 4538.750 (1.16) 4481.600 (-0.11) 4235.430 (-5.60) 4357.660 (-2.87) 4829.510 (7.64) memused.avg orig rec (overhead) prec (overhead) thp (overhead) ethp (overhead) prcl (overhead) parsec3/blackscholes 1828693.600 1834084.000 (0.29) 1823839.800 (-0.27) 1819296.600 (-0.51) 1830281.800 (0.09) 1603975.800 (-12.29) parsec3/bodytrack 1424963.400 1440085.800 (1.06) 1438384.200 (0.94) 1421718.400 (-0.23) 1432834.600 (0.55) 1439283.000 (1.00) parsec3/canneal 1036782.600 1052828.800 (1.55) 1050148.600 (1.29) 1035104.400 (-0.16) 1051145.400 (1.39) 1050019.400 (1.28) parsec3/dedup 2511841.400 2507374.000 (-0.18) 2472450.600 (-1.57) 2523557.600 (0.47) 2508912.000 (-0.12) 2493347.200 (-0.74) parsec3/facesim 537769.800 550740.800 (2.41) 548683.600 (2.03) 543547.800 (1.07) 560556.600 (4.24) 482782.600 (-10.23) parsec3/fluidanimate 570268.600 585598.000 (2.69) 579837.800 (1.68) 571433.000 (0.20) 582112.800 (2.08) 470073.400 (-17.57) parsec3/freqmine 982941.400 996253.200 (1.35) 993919.800 (1.12) 990531.800 (0.77) 1000994.400 (1.84) 750685.800 (-23.63) parsec3/raytrace 1737446.000 1749908.800 (0.72) 1741183.800 (0.22) 1726674.800 (-0.62) 1748530.200 (0.64) 1552275.600 (-10.66) parsec3/streamcluster 115857.000 155194.400 (33.95) 158272.800 (36.61) 122125.200 (5.41) 134545.600 (16.13) 133448.600 (15.18) parsec3/swaptions 13694.200 28451.800 (107.76) 28464.600 (107.86) 12797.800 (-6.55) 25328.200 (84.96) 28138.400 (105.48) parsec3/vips 2976126.400 3002408.600 (0.88) 3008218.800 (1.08) 2978258.600 (0.07) 2995428.600 (0.65) 2936338.600 (-1.34) parsec3/x264 3233886.200 3258790.200 (0.77) 3248355.000 (0.45) 3232070.000 (-0.06) 3256360.200 (0.69) 3254707.400 (0.64) splash2x/barnes 1210470.600 1211918.600 (0.12) 1204507.000 (-0.49) 1210892.800 (0.03) 1217414.800 (0.57) 944053.400 (-22.01) splash2x/fft 9697440.000 9604535.600 (-0.96) 9210571.800 (-5.02) 9867368.000 (1.75) 9637571.800 (-0.62) 9804092.000 (1.10) splash2x/lu_cb 510680.400 521792.600 (2.18) 517724.600 (1.38) 513500.800 (0.55) 519980.600 (1.82) 351787.000 (-31.11) splash2x/lu_ncb 512896.200 529353.600 (3.21) 521248.600 (1.63) 513493.200 (0.12) 523793.400 (2.12) 418701.600 (-18.37) splash2x/ocean_cp 3320800.200 3313688.400 (-0.21) 3225585.000 (-2.87) 3359032.200 (1.15) 3316591.800 (-0.13) 3304702.200 (-0.48) splash2x/ocean_ncp 3915132.400 3917401.000 (0.06) 3884086.400 (-0.79) 7050398.600 (80.08) 4532528.600 (15.77) 3920395.800 (0.13) splash2x/radiosity 1456908.200 1467611.800 (0.73) 1453612.600 (-0.23) 1466695.400 (0.67) 1467495.600 (0.73) 421197.600 (-71.09) splash2x/radix 2345874.600 2318202.200 (-1.18) 2261499.200 (-3.60) 2438228.400 (3.94) 2373697.800 (1.19) 2336605.600 (-0.40) splash2x/raytrace 43258.800 57624.200 (33.21) 55164.600 (27.52) 46204.400 (6.81) 60475.000 (39.80) 48865.400 (12.96) splash2x/volrend 149615.000 163809.400 (9.49) 162115.400 (8.36) 149119.600 (-0.33) 162747.800 (8.78) 157734.600 (5.43) splash2x/water_nsquared 40384.400 54848.600 (35.82) 53796.600 (33.21) 41455.800 (2.65) 53226.400 (31.80) 58260.600 (44.27) splash2x/water_spatial 670580.200 680444.200 (1.47) 670020.400 (-0.08) 668262.400 (-0.35) 678552.000 (1.19) 372931.000 (-44.39) total 40844300.000 41002900.000 (0.39) 40311600.000 (-1.30) 44301900.000 (8.47) 41671052.000 (2.02) 38334431.000 (-6.14) DAMON Overheads In total, DAMON virtual memory access recording feature (\u0026lsquo;rec\u0026rsquo;) incurs 1.16% runtime overhead and 0.39% memory space overhead. Even though the size of the monitoring target region becomes much larger with the physical memory access recording (\u0026lsquo;prec\u0026rsquo;), it still shows only modest amount of overhead (-0.11% for runtime and -1.30% for memory footprint).\nFor a convenient test run of \u0026lsquo;rec\u0026rsquo; and \u0026lsquo;prec\u0026rsquo;, I use a Python wrapper. The wrapper constantly consumes about 10-15MB of memory. This becomes a high memory overhead if the target workload has a small memory footprint. Nonetheless, the overheads are not from DAMON, but from the wrapper, and thus should be ignored. This fake memory overhead continues in \u0026rsquo;ethp\u0026rsquo; and \u0026lsquo;prcl\u0026rsquo;, as those configurations are also using the Python wrapper.\nEfficient THP THP \u0026lsquo;always\u0026rsquo; enabled policy achieves 5.60% speedup but incurs 8.47% memory overhead. It achieves 30.69% speedup in the best case, but 80.08% memory overhead in the worst case. Interestingly, both the best and worst-case are with \u0026lsquo;splash2x/ocean_ncp\u0026rsquo;).\nThe 2-lines implementation of data access monitoring based THP version (\u0026rsquo;ethp\u0026rsquo;) shows 2.87% speedup and 2.02% memory overhead. In other words, \u0026rsquo;ethp\u0026rsquo; removes 76.15% of THP memory waste while preserving 51.25% of THP speedup in total. In the case of the \u0026lsquo;splash2x/ocean_ncp\u0026rsquo;, \u0026rsquo;ethp\u0026rsquo; removes 80.30% of THP memory waste while preserving 30.79% of THP speedup.\nProactive Reclamation As similar to the original work, I use 4G \u0026lsquo;zram\u0026rsquo; swap device for this configuration. Also note that we use DAMOOS-tuned ethp schemes for each workload.\nIn total, our 1 line implementation of Proactive Reclamation, \u0026lsquo;prcl\u0026rsquo;, incurred 7.64% runtime overhead in total while achieving 6.14% system memory footprint reduction. Even in the worst case, the runtime overhead was only 16.02%.\nNonetheless, as the memory usage is calculated with \u0026lsquo;MemFree\u0026rsquo; in \u0026lsquo;/proc/meminfo\u0026rsquo;, it contains the SwapCached pages. As the swapcached pages can be easily evicted, I also measured the residential set size of the workloads::\nrss.avg orig rec (overhead) prec (overhead) thp (overhead) ethp (overhead) prcl (overhead) parsec3/blackscholes 587536.800 585720.000 (-0.31) 586233.400 (-0.22) 587045.400 (-0.08) 586753.400 (-0.13) 252207.400 (-57.07) parsec3/bodytrack 32302.200 32290.600 (-0.04) 32261.800 (-0.13) 32215.800 (-0.27) 32173.000 (-0.40) 6798.800 (-78.95) parsec3/canneal 842370.600 841443.400 (-0.11) 844012.400 (0.19) 838074.400 (-0.51) 841700.800 (-0.08) 840804.000 (-0.19) parsec3/dedup 1180414.800 1164634.600 (-1.34) 1188886.200 (0.72) 1207821.000 (2.32) 1193896.200 (1.14) 572359.200 (-51.51) parsec3/facesim 311848.400 311709.800 (-0.04) 311790.800 (-0.02) 317345.800 (1.76) 315443.400 (1.15) 188488.000 (-39.56) parsec3/fluidanimate 531868.000 531885.600 (0.00) 531828.800 (-0.01) 532988.000 (0.21) 532959.600 (0.21) 415153.200 (-21.94) parsec3/freqmine 552491.000 552718.600 (0.04) 552807.200 (0.06) 556574.200 (0.74) 554374.600 (0.34) 36573.400 (-93.38) parsec3/raytrace 879683.400 880752.200 (0.12) 879907.000 (0.03) 870631.000 (-1.03) 880952.200 (0.14) 293119.200 (-66.68) parsec3/streamcluster 110991.800 110937.200 (-0.05) 110964.600 (-0.02) 115606.800 (4.16) 116199.000 (4.69) 110108.200 (-0.80) parsec3/swaptions 5665.000 5718.400 (0.94) 5720.600 (0.98) 5682.200 (0.30) 5628.600 (-0.64) 3613.800 (-36.21) parsec3/vips 32143.600 31823.200 (-1.00) 31912.200 (-0.72) 33164.200 (3.18) 33925.800 (5.54) 27813.600 (-13.47) parsec3/x264 81534.000 81811.000 (0.34) 81708.400 (0.21) 83052.400 (1.86) 83758.800 (2.73) 81691.800 (0.19) splash2x/barnes 1220515.200 1218291.200 (-0.18) 1217699.600 (-0.23) 1228551.600 (0.66) 1220669.800 (0.01) 681096.000 (-44.20) splash2x/fft 9915850.400 10036461.000 (1.22) 9881242.800 (-0.35) 10334603.600 (4.22) 10006993.200 (0.92) 8975181.200 (-9.49) splash2x/lu_cb 511327.200 511679.000 (0.07) 511761.600 (0.08) 511971.600 (0.13) 511711.200 (0.08) 338005.000 (-33.90) splash2x/lu_ncb 511505.000 506816.800 (-0.92) 511392.800 (-0.02) 496623.000 (-2.91) 511410.200 (-0.02) 404734.000 (-20.87) splash2x/ocean_cp 3398834.000 3405017.800 (0.18) 3415287.800 (0.48) 3443604.600 (1.32) 3416264.200 (0.51) 3387134.000 (-0.34) splash2x/ocean_ncp 3947092.800 3939805.400 (-0.18) 3952311.600 (0.13) 7165858.800 (81.55) 4610075.000 (16.80) 3944753.400 (-0.06) splash2x/radiosity 1475024.000 1474053.200 (-0.07) 1475032.400 (0.00) 1483718.800 (0.59) 1475919.600 (0.06) 99637.200 (-93.25) splash2x/radix 2431302.200 2416928.600 (-0.59) 2455596.800 (1.00) 2568526.400 (5.64) 2479966.800 (2.00) 2437406.600 (0.25) splash2x/raytrace 23274.400 23278.400 (0.02) 23287.200 (0.05) 28828.000 (23.86) 27800.200 (19.45) 5667.000 (-75.65) splash2x/volrend 44106.800 44151.400 (0.10) 44186.000 (0.18) 45200.400 (2.48) 44751.200 (1.46) 16912.000 (-61.66) splash2x/water_nsquared 29427.200 29425.600 (-0.01) 29402.400 (-0.08) 28055.400 (-4.66) 28572.400 (-2.90) 13207.800 (-55.12) splash2x/water_spatial 664312.200 664095.600 (-0.03) 663025.200 (-0.19) 664100.600 (-0.03) 663597.400 (-0.11) 261214.200 (-60.68) total 29321300.000 29401500.000 (0.27) 29338300.000 (0.06) 33179900.000 (13.16) 30175600.000 (2.91) 23393600.000 (-20.22) In total, 20.22% of residential sets were reduced.\nWith parsec3/freqmine, \u0026lsquo;prcl\u0026rsquo; reduced 93.38% of residential sets and 23.63% of system memory usage while incurring only 1.22% runtime overhead.\n","permalink":"https://sjp38.github.io/posts/ko/damon_evaluation/","summary":"DAMON is lightweight. It increases system memory usage by 0.39% and slows target workloads down by 1.16%.\nDAMON is accurate and useful for memory management optimizations. An experimental DAMON-based operation scheme for THP, namely \u0026rsquo;ethp\u0026rsquo;, removes 76.15% of THP memory overheads while preserving 51.25% of THP speedup. Another experimental DAMON-based \u0026lsquo;proactive reclamation\u0026rsquo; implementation, namely \u0026lsquo;prcl\u0026rsquo;, reduces 93.38% of residential sets and 23.63% of system memory footprint while incurring only 1.22% runtime overhead in the best case (parsec3/freqmine).","title":"DAMON Evaluation"},{"content":"2022년 마지막 날을 맞아, 저의 간단하고 버그가 많은 스크립트와[1] github 을 통해 저의 오픈소스 커밋 통계를 내봤습니다.\n리눅스 커널 통계 리눅스 커널의 메모리 관리 서브시스템과 커널 전체의 2022년 통계를 위해 제 버그 많은 스크립트를[1] 아래와 같이 돌려 봤습니다.\n메모리 관리 서브시스템 2022년 한해, 305명의 사람들이 리눅스 커널 메모리 관리 서브시스템 개발에 참여해 81,631 라인의 변경을 2,135 개 커밋으로 만들었습니다.\n변경한 라인 수와 커밋 갯수 기준으로 저는 그 305명 가운데 두번째와 (10,537 라인) 세번째로 (106 커밋) 큰 변경을 만들었군요.\n리눅스 커널 전체 2022년 한해, 5,286명의 사람들이 리눅스 커널 개발에 참여해 6,841,739 라인의 변경을 77,636 개 커밋으로 만들었습니다.\n변경한 라인 수와 커밋 갯수 기준으로 저는 그 5,286명 가운데 85번째와 (11,907 라인) 89번째로 (155 커밋) 큰 변경을 만들었군요.\nGithub Github 에서 저는 2022년 한해동안 2,316 개 커밋을 만들었습니다. 이건 제 github 메인 계정의 이메일 주소로 만들어진 커밋만 세기 때문에 리눅스 커널을 포함한 일부 프로젝트로의 제 커밋은 포함 안된 수치이긴 합니다. 2022년은 사흘 빼고는 매일 커밋을 만들었군요.\n아무래도 2022년은 제게도 세계에게도 바쁜 해였던 것 같습니다. 저도 커뮤니티도 2023년에도 즐거운 해킹을 이어갈 수 있길 바랍니다.\n[1] https://github.com/sjp38/lazybox/blob/master/git_helpers/authors.py\n","permalink":"https://sjp38.github.io/posts/ko/my_opensource_commits_stat_2022/","summary":"2022년 마지막 날을 맞아, 저의 간단하고 버그가 많은 스크립트와[1] github 을 통해 저의 오픈소스 커밋 통계를 내봤습니다.\n리눅스 커널 통계 리눅스 커널의 메모리 관리 서브시스템과 커널 전체의 2022년 통계를 위해 제 버그 많은 스크립트를[1] 아래와 같이 돌려 봤습니다.\n메모리 관리 서브시스템 2022년 한해, 305명의 사람들이 리눅스 커널 메모리 관리 서브시스템 개발에 참여해 81,631 라인의 변경을 2,135 개 커밋으로 만들었습니다.\n변경한 라인 수와 커밋 갯수 기준으로 저는 그 305명 가운데 두번째와 (10,537 라인) 세번째로 (106 커밋) 큰 변경을 만들었군요.","title":"2022년 오픈소스 커밋 통계"},{"content":"As today is the last day of 2022, I checked some open source commits statistics using my simple and buggy script[1], and github.\nLinux kernel statistics I ran my buggy script[1] to show some 2022 statistics for memory management subsystem and whole tree of Linux kernel as below.\nMemory Management In 2022, 305 people participated in Linux kernel memory management subsystem development by making 81,631 lines of changes with 2,135 commits.\nI made 2nd and 3rd biggest changes among the 305 people, for lines of changes (10,537) and commits (106).\nLinux kernel Whole Tree In 2022, 5,286 people participated in Linux kernel development by making 6,841,739 lines of changes with 77,636 commits.\nI made 85th and 89th biggest changes among the 5,286 people, for lines of changes (11,907) and commits (155).\nGithub On github, I made 2,316 commits in 2022. It\u0026rsquo;s counting only the commits that I made with my github main account\u0026rsquo;s email address, so it doesn\u0026rsquo;t cover some of my commits for some projects including Linux kernel. I made commits everyday except three days in 2022.\nApparently 2022 was a busy year for me and the world. Hope I and the community to continue happy hacking in 2023.\n[1] https://github.com/sjp38/lazybox/blob/master/git_helpers/authors.py\nAfter sharing this to Linkedin and Twitter, I got more than 190 Linkedin reactions, 50 Linkedin connection requests, 45 Twitter heart, and 30 Twitter followers within a day. So impressive. Thank you for motivating me!\n","permalink":"https://sjp38.github.io/posts/my_opensource_commits_stat_2022/","summary":"As today is the last day of 2022, I checked some open source commits statistics using my simple and buggy script[1], and github.\nLinux kernel statistics I ran my buggy script[1] to show some 2022 statistics for memory management subsystem and whole tree of Linux kernel as below.\nMemory Management In 2022, 305 people participated in Linux kernel memory management subsystem development by making 81,631 lines of changes with 2,135 commits.","title":"My opensource commits statistics in 2022"},{"content":"A summary of DAMON development in 2022 has posted: https://lore.kernel.org/damon/20221229171209.162356-1-sj@kernel.org/\n2022 was a year of active and healthy DAMON development.\nSeven new DAMON major features were delivered to users. Some of those were featured in articles and academic papers.\nIt was possible thanks to the DAMON community. The community has expanded with its own mailing list and an open bi-weekly chat series. 40 people contributed their great code to DAMON via making their 275 commits merged into the mainline. About 33% of the commits were made by Amazon-external contributors.\nThe amount of DAMON changes in 2022 (v5.15..v6.2-rc1) was not that tiny compared to other subsystems. About 0.2% of the commits for whole Linux tree was for DAMON. Among the changes for DAMON\u0026rsquo;s parent subsystem, mm, about 8% of commits and 14% of lines of changes were made for DAMON.\n","permalink":"https://sjp38.github.io/posts/damon_stat_2022/","summary":"A summary of DAMON development in 2022 has posted: https://lore.kernel.org/damon/20221229171209.162356-1-sj@kernel.org/\n2022 was a year of active and healthy DAMON development.\nSeven new DAMON major features were delivered to users. Some of those were featured in articles and academic papers.\nIt was possible thanks to the DAMON community. The community has expanded with its own mailing list and an open bi-weekly chat series. 40 people contributed their great code to DAMON via making their 275 commits merged into the mainline.","title":"Summary of DAMON Development in 2022"},{"content":"Today is the 10th anniversary of my Linux kernel contribution. Including the tiny and trivial patch, I made 381 patches merged in the mainline during the 10 years.\n$ git log --author SeongJae --reverse commit cf174b0ef52ad8184779e1da4132e2d9d17247e5 Author: SeongJae Park \u0026lt;sj38.park@gmail.com\u0026gt; Date: Tue Oct 16 16:47:50 2012 +0900 staging: csr: csr_framework_ext_types.h: fix coding style Fix coding style of csr_framework_ext_types.h Signed-off-by: SeongJae Park \u0026lt;sj38.park@gmail.com\u0026gt; Signed-off-by: Greg Kroah-Hartman \u0026lt;gregkh@linuxfoundation.org\u0026gt; [...] $ git log --author SeongJae --oneline | wc -l 381 I\u0026rsquo;m looking forward to the next 10 years.\n","permalink":"https://sjp38.github.io/posts/linux_kernel_contribution_10th_anniversary/","summary":"Today is the 10th anniversary of my Linux kernel contribution. Including the tiny and trivial patch, I made 381 patches merged in the mainline during the 10 years.\n$ git log --author SeongJae --reverse commit cf174b0ef52ad8184779e1da4132e2d9d17247e5 Author: SeongJae Park \u0026lt;sj38.park@gmail.com\u0026gt; Date: Tue Oct 16 16:47:50 2012 +0900 staging: csr: csr_framework_ext_types.h: fix coding style Fix coding style of csr_framework_ext_types.h Signed-off-by: SeongJae Park \u0026lt;sj38.park@gmail.com\u0026gt; Signed-off-by: Greg Kroah-Hartman \u0026lt;gregkh@linuxfoundation.org\u0026gt; [...] $ git log --author SeongJae --oneline | wc -l 381 I\u0026rsquo;m looking forward to the next 10 years.","title":"My 10th anniversary of the Linux kernel contribution"},{"content":"오늘은 제가 리눅스 커널에 처음 기여를 한지 10년이 되는 날입니다. 그 작고 사소했던 패치를 포함해, 지난 10년간 총 381개의 패치를 메인라인에 기여했네요.\n$ git log --author SeongJae --reverse commit cf174b0ef52ad8184779e1da4132e2d9d17247e5 Author: SeongJae Park \u0026lt;sj38.park@gmail.com\u0026gt; Date: Tue Oct 16 16:47:50 2012 +0900 staging: csr: csr_framework_ext_types.h: fix coding style Fix coding style of csr_framework_ext_types.h Signed-off-by: SeongJae Park \u0026lt;sj38.park@gmail.com\u0026gt; Signed-off-by: Greg Kroah-Hartman \u0026lt;gregkh@linuxfoundation.org\u0026gt; [...] $ git log --author SeongJae --oneline | wc -l 381 다음 10년을 기대합니다.\n","permalink":"https://sjp38.github.io/posts/ko/linux_kernel_contribution_10th_anniversary/","summary":"오늘은 제가 리눅스 커널에 처음 기여를 한지 10년이 되는 날입니다. 그 작고 사소했던 패치를 포함해, 지난 10년간 총 381개의 패치를 메인라인에 기여했네요.\n$ git log --author SeongJae --reverse commit cf174b0ef52ad8184779e1da4132e2d9d17247e5 Author: SeongJae Park \u0026lt;sj38.park@gmail.com\u0026gt; Date: Tue Oct 16 16:47:50 2012 +0900 staging: csr: csr_framework_ext_types.h: fix coding style Fix coding style of csr_framework_ext_types.h Signed-off-by: SeongJae Park \u0026lt;sj38.park@gmail.com\u0026gt; Signed-off-by: Greg Kroah-Hartman \u0026lt;gregkh@linuxfoundation.org\u0026gt; [...] $ git log --author SeongJae --oneline | wc -l 381 다음 10년을 기대합니다.","title":"나의 리눅스 커널 컨트리뷰션 10주년"},{"content":"I will present current status and future plans for DAMON in KernelSummit'22. The title of the talk is \u0026ldquo;Current Status and Future Plans of DAMON\u0026rdquo;.\nhttps://lpc.events/event/16/contributions/1224/\n","permalink":"https://sjp38.github.io/posts/kernelsummit2022_talk/","summary":"I will present current status and future plans for DAMON in KernelSummit'22. The title of the talk is \u0026ldquo;Current Status and Future Plans of DAMON\u0026rdquo;.\nhttps://lpc.events/event/16/contributions/1224/","title":"I will have a talk at the Linux Kernel Summit 2022"},{"content":"My paper introducing DAMON and related works for making Linux a more data access-aware operating system has been accepted to be presented by the HPDC'22. The title of the paper is \u0026ldquo;DAOS: Data Access-aware Operating System\u0026rdquo;.\n","permalink":"https://sjp38.github.io/posts/hpdc2022_talk/","summary":"My paper introducing DAMON and related works for making Linux a more data access-aware operating system has been accepted to be presented by the HPDC'22. The title of the paper is \u0026ldquo;DAOS: Data Access-aware Operating System\u0026rdquo;.","title":"My paper introducing DAMON and related works has accepted to appear in the HPDC 2022"},{"content":"Whenever reading the kernel development statistics report for each release from LWN, I wanted to scope it down to specific subsystems. For that, I wrote a script.\nBelows are the top 10 kernel hackers who contributed to the memory management subsystem of Linux kernel, sorted by number of commits and changed (added, deleted, or modified) lines, respectively.\n$ ./authors.py ~/linux --file mm/ --since 2021-01-01 --author_identity name --sortby lines --max_nr_authors 10 1. SeongJae Park: 4860 lines 2. Matthew Wilcox (Oracle): 4391 lines 3. Muchun Song: 2091 lines 4. Mel Gorman: 1737 lines 5. Yang Shi: 1615 lines 6. Marco Elver: 1442 lines 7. Mike Kravetz: 1419 lines 8. Alexander Potapenko: 1383 lines 9. Miaohe Lin: 1256 lines 10. Vlastimil Babka: 1245 lines # 262 authors, 45700 lines in total $ $ ./authors.py ~/linux --file mm/ --since 2021-01-01 --author_identity name --sortby commits --max_nr_authors 10 1. Matthew Wilcox (Oracle): 133 commits 2. Miaohe Lin: 125 commits 3. Linus Torvalds: 78 commits 4. Muchun Song: 51 commits 5. Mel Gorman: 46 commits 6. Vlastimil Babka: 44 commits 7. SeongJae Park: 43 commits 8. Hugh Dickins: 41 commits 9. Yang Shi: 38 commits 10. David Hildenbrand: 33 commits # 265 authors, 1527 commits in total ","permalink":"https://sjp38.github.io/posts/linux-mm-dev-stat-2021-short/","summary":"Whenever reading the kernel development statistics report for each release from LWN, I wanted to scope it down to specific subsystems. For that, I wrote a script.\nBelows are the top 10 kernel hackers who contributed to the memory management subsystem of Linux kernel, sorted by number of commits and changed (added, deleted, or modified) lines, respectively.\n$ ./authors.py ~/linux --file mm/ --since 2021-01-01 --author_identity name --sortby lines --max_nr_authors 10 1.","title":"Linux Memory Management Subsystem Development Statistics in 2021 (Short)"},{"content":"The Five-minute Rule Thirty Years Later and its Impact on the Storage Hierarchy http://www.renata.borovica-gajic.com/data/adms2017_5minuterule.pdf\nAppuswamy, Raja, et al. \u0026ldquo;The five minute rule thirty years later and its impact on the storage hierarchy.\u0026rdquo; Proceedings of the 7th International Workshop on Accelerating Analytics and Data Management Systems Using Modern Processor and Storage Architectures. No. CONF. 2017.\nIn 1987, five minute rule, which means data accessed for every 5 or less minutes are better to be in DRAM than HDD, has found. As the storage devices emerge, the rule has revisited for every decade. This paper revisits it again, in 2017.\nThis paper classifies storage devices in four tiers: performance, capacity, archival, and backup.\nData for latency-sensitive interactive analytics should be in the performance tier, while data for latency-insensitive batch analytics should be in the storage tier.\nFor state-of-the-art PCIe SSDs, the bread-even interval predicted by the five-minute rule is less than a minute.\nThe break-even interval between the devices are as below:\nDRAM-HDD: 5m in 1987, 5m in 1997, 1.5h in 2007, and 4h in 2017 DRAM-SSD: 15m in 2007, 7m for read / 24m for write in 2017 (a sentence in the paper says this is only 40 seconds in 2017, confusing\u0026hellip; Maybe for 3D XPoint like things only) SSD-HDD: 2.26h in 2007, 1d in 2017 Exploring the Design Space of Page Management for Multi-Tiered Memory Systems https://www.usenix.org/conference/atc21/presentation/kim-jonghyeon\nKim, Jonghyeon, Wonkyo Choe, and Jeongseob Ahn. \u0026ldquo;Exploring the Design Space of Page Management for Multi-Tiered Memory Systems.\u0026rdquo; 2021 {USENIX} Annual Technical Conference ({USENIX}{ATC} 21). USENIX} Association, 2021.\nThis paper explores a better way for tiered memory management. It considers access tier of each page in addition to the access locality (whether the page is placed on the local memory or remote memory). That is, Linux uses local PMEM instead of remote DRAM, when local DRAM is full. This paper says it should use remote DRAM instead in the case, as remote DRAM is faster than local PMEM. Based on the finding, the authors proposes their new page placement scheme, which uses AutoNUMA facility to check access frequency and do demotion/promotion proactively. The authors says it achieves 3.5x speedup compared to Intel\u0026rsquo;s recent approach, which Huang Ying is doing.\nFor the evaluation, the authors has used graph500, SpecACCEL, GraphMat, and Liblinear.\n","permalink":"https://sjp38.github.io/posts/paper_reading_2021_q4/","summary":"record interesting papers that I (partially) read","title":"Papers I read in 2021 Q4"},{"content":"I will present DAMON/DAMOS in KernelSummit'21. The title of the talk is \u0026ldquo;Writing a fine-grained access pattern-oriented lightweight kernel module using DAMON/DAMOS in 10 minutes\u0026rdquo;.\nhttps://linuxplumbersconf.org/event/11/contributions/984/\n","permalink":"https://sjp38.github.io/posts/kernelsummit2021_talk/","summary":"I will present DAMON/DAMOS in KernelSummit'21. The title of the talk is \u0026ldquo;Writing a fine-grained access pattern-oriented lightweight kernel module using DAMON/DAMOS in 10 minutes\u0026rdquo;.\nhttps://linuxplumbersconf.org/event/11/contributions/984/","title":"I will have a talk at the Linux Kernel Summit 2021"},{"content":"KernelSummit'21 에서 DAMON/DAMOS 를 발표하게 되었습니다. 발표 제목은 \u0026ldquo;Writing a fine-grained access pattern-oriented lightweight kernel module using DAMON/DAMOS in 10 minutes\u0026rdquo; 입니다.\nhttps://linuxplumbersconf.org/event/11/contributions/984/\n","permalink":"https://sjp38.github.io/posts/ko/kernelsummit2021_talk/","summary":"KernelSummit'21 에서 DAMON/DAMOS 를 발표하게 되었습니다. 발표 제목은 \u0026ldquo;Writing a fine-grained access pattern-oriented lightweight kernel module using DAMON/DAMOS in 10 minutes\u0026rdquo; 입니다.\nhttps://linuxplumbersconf.org/event/11/contributions/984/","title":"I will have a talk at the Linux Kernel Summit 2021"},{"content":"This post is for recording some notes from a few OSDI'21 papers that I got fun.\nDMon: Efficient Detection and Correction of Data Locality Problems Using Selective Profiling https://www.usenix.org/system/files/osdi21-khan.pdf\nDMon is a compiler-based data locality optimization system. The approach is quite similar to that of daphicx or similar things. It injects data access profiling code in the target program, build and run it with some workload, collect the profiling code-generated results, analyze the profile results to figure out what kind of optimization can provide some benefit to the program, injects the optimization code in the program, built it again, and deploy the version to the production.\nBiggest novelty of DMon is its selective profiling. It first figure out for what resource (e.g., CPU, L1/L2/L3$, or memory) the program\u0026rsquo;s performance is bounded, and select what information to collect based on that. It also uses a simple sampling technique. The default sampling rate is 1 sample per 1000 events, though it can be tuned by user. In this way, DMon profile only necessary information and therefore incurs only small overhead (1.36% on average). This allows DMon to do the profiling not only under production-like workloads but also real production.\nFor the optimization, it uses some existing well-known techniques including (in)direct prefetching, and structure merging, based on the analyzed profiling results. The paper claims this provide 16.83% speedup on average. For the evaluation, the authors use some benchmarks including PARSEC3/SPLASH-2X, NPB, TPC-H on PostgreSQL, and Renaissance benchmark suite.\nThe idea is novel and makes sense. However, because this is a compiler-based approach, it has a limitation in language. It supports only C and C++ for now. Also, though it claims it can be used on production, I unsure if real production people agrees. Especially, the re-deployment of the optimized version would not be so easy for long-running systems.\nRearchitecting Linux Storage Stack for µs Latency and High Throughput https://www.usenix.org/conference/osdi21/presentation/hwang\nWhen latency-sensitive apps and throughput-bound apps are co-running, Linux kernel cannot achieve microseconds-scale latency and high throughput. Both SPDK and advanced SPDK usage are same. This paper finds the storage stack of Linux kernel is somewhat like network switch, because it routes I/O request from CPU cores to input queues of storage devices. This paper introduces blk-switch, which modifies the stack to decouple request processing from the application cores and utilizing multiple egress queue having several advanced features including prioritization and steering. It achieves microseconds-scale latency and high throughput under the situation, without modification of the application.\nBeyond malloc efficiency to fleet efficiency: a hugepage-aware memory allocator https://www.usenix.org/conference/osdi21/presentation/hunter\nThis paper optimizes TCMALLOC by making it more aware of hugepage and using it on Google\u0026rsquo;s warehouse scale computing. The optimization is mostly based on some model-based heuristics. It\u0026rsquo;s description on TCMALLOC internal and the problem background is quite useful.\nNap: A Black-Box Approach to NUMA-Aware Persistent Memory Indexes https://www.usenix.org/conference/osdi21/presentation/wang-qing\nIntel released Optane PM DIMM, so real PM world has already started long time ago. This paper explores the performance of the PM indexing on NUMA systems. It finds PM performance is degraded on NUMA systems, and current NUMA-aware PM indexing systems are not working good enough for NUMA systems. Based on findings that most of the real world workloads have highly skewed access pattern, the authors implemented a system called Nap, which translates the PM indexing to be NUMA-awared.\n","permalink":"https://sjp38.github.io/posts/osdi2021_papers_review/","summary":"This post is for recording some notes from a few OSDI'21 papers that I got fun.\nDMon: Efficient Detection and Correction of Data Locality Problems Using Selective Profiling https://www.usenix.org/system/files/osdi21-khan.pdf\nDMon is a compiler-based data locality optimization system. The approach is quite similar to that of daphicx or similar things. It injects data access profiling code in the target program, build and run it with some workload, collect the profiling code-generated results, analyze the profile results to figure out what kind of optimization can provide some benefit to the program, injects the optimization code in the program, built it again, and deploy the version to the production.","title":"OSDI 2021 papers summary"},{"content":"리눅스 커널이 처음 공개된지 올해로 30년이 되었고, 이를 맞아 한 tag1 에서 리누스 토발즈와 인터뷰 를 했습니다. 분량이 많아 두 파트로 나눠 올렸는데요, 해당 매체에 허락을 받고 이곳에 그 중 두번째 파트의 번역을 올립니다.\n아래 분들께서 오타 등을 찾고 글을 다듬는 걸 도와주셨습니다. 감사의 말씀을 전합니다.\nJaehoon Kim Tag1 의 원본 글은 다음 링크에서 보실 수 있습니다: https://www.tag1consulting.com/blog/interview-linus-torvalds-open-source-and-beyond-part-2\n첫번째 파트의 번역은 여기서 보실 수 있습니다.\n오픈소스 프로젝트의 관리 JA: 우린 최근에 Drupal 을 만든 Dries Buytaert 와 이야기 해봤는데, 그는 당신에게 받은 많은 영감과 가끔의 멘토링, 그리고 그가 지난 20년동안 그 유명한 Drupal CMS 를 관리하는 동안 받은 조언을 이야기하며 당신을 칭찬했습니다. 당신은 다른 오픈소스 프로젝트 메인테이너들과 자주 소통하며 멘토쉽을 제공하거나 기록들을 공유하나요? 얼마나 자주 다른 오픈소스 메인테이너들이 당신의 조언을 위해 연락해 옵니까?\nLT: 전 다른 사람들은 잘 모르지만, 안그럽니다, 전 개인적으로 다른 오픈소스 프로젝트와 그다지 교류하지는 않는데, 그건 그저 제가 상당히 \u0026ldquo;한가지만 생각하는\u0026rdquo; 경향이 있는 사람이기 때문입니다. 그게 제가 30년이 지나서도 여전히 커널을 관리하고 있는 이유라고 생각합니다: 어떤 사람들은 한 프로젝트에서 다른 프로젝트로 자주 이동하지만, (저같은) 또다른 사람들은 더 오랜 시간동안 한가지 일에 상당히 집중해 있곤 합니다.\n하지만, 둘 이상의 오픈소스 프로젝트에 참여하는 개발자들 사이에 겹치는 부분이 제법 있는 경우도 많습니다. 그리고 다른 프로젝트들이 공통된 인프라를 통해 서로에게 분명 영향을 끼칩니다. 그러니까, 그런 종류의 다른 프로젝트간 모임은 분명 있고, 컨퍼런스라던지에서 (다시 대면 컨퍼런스가 이뤄지게 되면) 그런 사람들을 만나게 되곤 합니다.\nJA: 한 오픈소스 프로젝트의 메인테이너로써, 다른 사람들이 프로젝트를 더 성공적으로 관리하는데 도움이 될만한 핵심 교훈을 배운게 있나요?\nLT: 이건 대답하기 어려운 질문인데요, 왜냐하면 전 성공을 위한 열쇠가 무엇인지 정말 모르기 때문입니다. 그래요, 리눅스는 무척 성공적인 것이 되었고, Git 역시 성공했죠, 하지만 그걸 무언가 더 깊은 이유로 연관시키는 건 항상 무척 어렵습니다. 어쩌면 저는 그저 운이 좋았을지도요?\n행운과 타이밍, 그리고 \u0026ldquo;옳은 시간에 옳은 장소에\u0026rdquo; 있는 것은 정말로 중요하니까요. 전 리눅스와 Git 두 경우 모두, 제가 시작한 프로젝트들이 많은 사람들에게, 설령 그 사람들은 자신들에게 그것들이 필요하다는 걸 몰랐다고 해도, 필요한 것이 되었다고 생각합니다. 그게 그저 행운이었을까요? 아마도요. 또는, 그 프로젝트들이 필요했던 그 수많은 사람들 가운데 저만이 유일하게 그 일을 실제로 행하고 그걸 되게 만든 것이었을까요?\n저의 자존심은 후자를 선호합니다만, 정직성은 행운 역시 정말 필요하며 옳은 프로젝트, 사람들이 정말로 필요로 하는 프로젝트를 고르는게 정말 필요하다고 말하도록 하는군요.\n하지만 그런 종류의 \u0026ldquo;큰 질문들\u0026rdquo; 을 무시하고 생각해 보면, 오픈소스 메인테이너라면 중요하다고 제가 생각하는, 몇가지 실용적이고 현실적인 것들이 있습니다.\n그런 중요한 것 중 하나는 당신이 거기에 있어야 한다는 겁니다. 당신은 거기에 있어야 하고, 다른 개발자들을 위해 거기 있어야 하며, 항상 거기 있어야 합니다. 당신은 기술적 문제를 맞닥뜨릴 테고, 그건 무척 좌절감을 줄 겁니다. 당신은 그 기술적 문제들을 어떻게 해결할지에 대한 다른 아이디어를 가졌을 수 있는 사람들과 일하게 될겁니다. 그리고 기술적 문제들은 어떤 측면에서 보자면 쉬운 부분인데, 보통은 기술적 해결법이 존재하고, 당신은 종종 객관적으로 \u0026ldquo;이게 더 낫다/빠르다/간단하다/\u0026rdquo; 또는 뭐라고든 말할 수 있습니다.\n그보다 어려운 부분은 당신이 좋아하지 않는, 또는 당신을 좋아하지 않는 사람들과도 결국은 소통해야 할 수 있다는 것이고 성격적 부딪힘도 있을겁니다. 그러면 여러분은 \u0026ldquo;내게 숫자를 보여줘\u0026rdquo; 전략으로 후퇴할 수 없습니다 - 사람들은 항상 혼자 있지 않게 마련이며, 그건 숫자 놀이가 아닙니다. 여러분은 궂은 날들을 겪게 될 것이며, 당신이 함께 일하는 사람들도 마찬가지일 겁니다. 그리고 여러분은 그걸 모두 뚫고 나아가야 합니다.\n당신은 휴식을 취할 수 없다고 말하는 게 아닙니다. 전 항상 그러고 있습니다. 지치면, 전 그냥 컴퓨터 앞을 떠나서 책이나 뭔가를 읽을 겁니다. 당신이 지치거나 화났을 때 무언가 생산적인 일 (또는 토론) 을 억지로 하려 하는건 좋지 않습니다. 그리고 전 분명 이걸 항상 잘하지는 못했고, 사람들을 모욕하고 너무 거친 말을 사용했습니다. 이제는 좀 나아졌다고 생각합니다만, 제가 그걸 더 잘하는 한가지 방법은 말 그대로 더 자주 물러나는 겁니다 - 적극적으로 \u0026ldquo;난 지금 나쁜 기분에 빠져 있습니다\u0026rdquo; 라고 알리고 컴퓨터에서 물러나기를 시도하는 거죠.\n그러니 끊임없다는 의미로 \u0026ldquo;항상\u0026rdquo; 거기 있어야 하는 건 아닙니다. 하루 쉬는 건 괜찮습니다. 일주일을 쉬어야 하는 건 사람들에게 알려야 하는 일일 수 있습니다. 한달을 쉬는건? 그 때에는 관리 계획을 세워야만 하고, 리눅스의 30년간 그게 실제로 두번 일어났습니다: 한번은 kernel.org 가 망가져서 사람들이 모든게 고쳐졌다는 걸 분명히 하기 위해 많은 시간을 쏟았던 때이고, 두번째는 제가 제 행동을 통제 하에 두어 보려 휴식을 취했을 때입니다.\n제가 말하고자 하는건 큰 프로젝트를 관리하는 건 상당한 양의 일이고, 여러분이 오랫동안 지속해야 하는 무언가라는 점입니다. 그게 모두 즐겁기만 하지는 않습니다. 그건 흥미로운 일입니다. 도전적이라는게 최선의 설명 같군요. 전 커널 메인테이너로써의 일에 따분해지진 않았습니다. 하지만 항상 장밋빛인 것도 아닙니다. 모두가 그런 종류의 일을 하고 싶어하지는 않습니다.\n또다른 중요한 건 당신이 개방적이어야 한다는 겁니다. 그리고 전 이걸 여러 방향으로 의미합니다. 일을 사적으로 토론하는 내부 비밀집단을 만들고 최종 결과만을 (또는 핵심이 아닌 작업물만을) 공개하는 형태의, 일종의 \u0026ldquo;파벌\u0026rdquo; 을 만드는 건 정말 쉽습니다, 모든 중요한 것들은 회사 내부나 핵심 그룹 내에서 일어나며 외부 사람들은 그 파벌 내부로 들어가기가 힘들며, 그건 무척 사적이고 배타적인 관계로 그 핵심 그룹 내에서 무슨 일이 일어나고 있는지 알아보는 것만 해도 힘들기 때문입니다.\n이게 제가 공개된 메일링 리스트를 좋아하는 이유 가운데 하나입니다. \u0026ldquo;초대 기반\u0026rdquo; 리스트가 아니라요. 참여하기 위해 서명을 할 필요조차 없죠. 정말 열려 있습니다. 그리고 거의 모든 개발 관련 토론이 거기서 이루어져야 합니다.\n하지만 \u0026ldquo;개방성\u0026rdquo; 은 또다른 방향으로도 중요합니다 - 다른 사람의 해결책에 개방적이 되고, 무엇이 어떻게 되어야 하는지에 대한 매우 분명하고 유동성 없는 아이디어를 갖지 않는 것. 리눅스가 성공한 이유 가운데 하나는 제가 실제로 거대한 계획을 가지고 있지 않았다는 점, 그리고 그게 어떻게 되어야 할지에 대한 높은 기대감을 갖지 않았으며, 때문에 사람들이 패치나 기능들을 위한 요청을 보내기 시작했을 때, 제게 그것들은 모두 소중했고 리눅스가 어떠해야 하는지에 대한 선입견이 없었다는 사실이라고 생각합니다. 결과적으로: 리눅스 커널 개발에 참여하고자 했던 그 개개인 (그리고 나중에는 큰 회사들) 모두는 그러기가 쉬웠는데, 전 제가 처음에 정말 흥미 없던 것들을 리눅스가 하게 되는 것에 상당히 개방적이었기 때문입니다.\n그리고 마지막으로, 전 \u0026ldquo;개방성\u0026rdquo; 이 정직성 측면에서도 중요하다고 생각합니다. 사람들 뒤에서 정치질 하는 걸 원치 마세요. 여러분의 동기를 공개하고, 여러분이 왜 그걸 하고 무얼 하고 싶은지 공개하세요. 함께 일하는 모두를 좋아해야 할 필요는 없고, 그들도 당신을 좋아할 필요는 없습니다, 하지만 사람들이 자신들이 무얼 하고자 하며 무얼 하고 있는지에 대해 공개적이 된다면, 여러분이 항상 최고의 친구가 되어야만 하는건 아닙니다 - 가장 중요한 건 여러분이 그들을 믿을 수 있다는 겁니다.\n믿음은 중요하니까요. 많이.\nJA: 덜 코딩하는 것, 소통과 리딩을 더 하는 것에 대해서 이미 말씀하신 것에서 더 나아가서, 당신이 배워야 했는데 그게 어려웠던 특별한 기술이 있었나요? 예를 들어, 권한 위임하기, 더 나은 글쓰기, 그리고 다른 코딩 외의 기술들 - 그리고 그렇다면, 그걸 어떻게 배웠나요? 실습을 했나요, 책에서 배웠나요, 또는 다른 사람으로부터? 또는 학교에서 가르치는 것인가요?\nLT: 저를 위한 거의 모든 프로세스는 상당히 점진적이었고 학습하는 경험이었다는 것을 말하는 것으로 대답을 시작하겠습니다. 30년은 긴 시간이고, 무척 적은 변경들만이 매우 갑작스러운 것이었으며, 우리가 일을 하는 방식은 매우 \u0026ldquo;유기적인\u0026rdquo; 방식으로 성장했습니다.\n달리 말하자면, 미리 계획하고 관리 교과서 등을 읽는 것의 결과가 아니라는 겁니다. 대부분의 경우 그건 그 스스로 벌어졌고, 우리가 지금 가지고 있는 모든 구조는 어떤 조직도로부터 만들어진 게 아니라, 그저 사람들이 \u0026ldquo;각자의 자리를 찾은\u0026rdquo; 결과입니다.\n사람들이 어렵다고 생각하는 한가지 분명한 기술은 \u0026ldquo;제어를 놓는 것\u0026rdquo; 입니다. 저는 초창기에, 사람들이 제게 패치를 보내면 그걸 패치 그대로 적용하지 않고 그걸 읽고 사람들이 무얼 하고 싶은지 알아낸 후, 그걸 저 스스로 했던 걸 기억합니다. 제가 프로젝트를 그렇게 시작했고, 그걸 제가 더 편하게 느꼈으며, 그걸 통해 코드를 더 잘 알 수 있었으니까요.\n결국엔 그게 제게 있어 큰 문제가 아닌 걸로 드러났습니다. 전 꽤 빨리 그러는 걸 그만뒀는데, 그저 제가 게으르기 때문입니다. 전 패치를 읽고 그 사람이 뭘 한 건지 잘 이해할 수 있게 되었고, 그 후부터는 그 패치들을 그대로 적용했습니다. 그러니 제가 제어에 집작하던 날들은 꽤 금방 끝났습니다. 제 생각에 저는 믿을 만한 사람을 찾는걸 잘했고, 그 후로는 그냥 그렇게 했습니다 - 그들을 믿고, 지나친 마이크로매니징은 하지 않기.\n그러니 권한 넘기기는 제게는 큰 문제가 아니었습니다만, 다른 몇몇 프로젝트들에는 그랬음을 알고 있습니다. 다시 말하지만, 이건 부분적으로는, 우리의 메인테이너쉽 모델이 절대적인 믿음을 요구하지 않는, 덕분에 모든 일을 훨씬 쉽게 만들어주는 것이기 때문입니다.\n대화 기술은 무척 많이 중요합니다. 저는 저널리스트 가족 출신이며 (제 부모님 두분 모두 저널리스트였고, 제 삼촌도 그렇고, 제 증조부는 시인 겸 저널리스트였습니다), 덕분에 매우 어릴 때부터 읽기와 쓰기가 상당히 당연하게 여겨지는 집에서 자랐습니다. 영어는 제 세번째 언어지만 제가 리눅스 개발을 시작했을 때는 이미 익숙했고, 따라서 소통이 큰 문제는 아니었습니다. 하지만 이게 개인적 (어쩌면 성격) 이유로도 언어 장벽 이유로도 큰 문제가 될 수 있음을 알고 있습니다.\n하지만 일반적으로, 대부분의 것은 저는 직접 하면서 배웠습니다. 다시 말하지만, 기억해 주세요 - 리눅스의 어떤 것도 하룻밤에 이뤄지지 않았습니다. 30년 전의 그 프로젝트는 오늘날의 모습과 무척 달랐습니다.\nJA: 오픈소스가 상당히 성공적인 것이 되었지만, 가장 큰 유저들 가운데 다수, 예를 들어 회사들은, 그들이 의존하고 있는 그 오픈소스 프로젝트에 기여를 하거나 지원을 하는 일을 하지 않거나 아주 조금만 합니다. 사용자 수로만 따지면 놀랍도록 크고 성공적인 프로젝트의 개발자들조차 일주일치 커피를 사기 위한 돈을 버는게 행운인 경우가 있습니다. 이게 해결 가능할까요? 오픈소스 모델은 지속 가능합니까?\nLT: 전 이에 대한 답을 갖고 있지 않습니다, 그리고 어떤 이유로든 커널은 이 문제를 겪지 않았습니다. 그래요, 리눅스의 순수한 \u0026ldquo;사용자\u0026rdquo; 인 회사들이 있습니다만 그들도 결국은 지원을 받고 싶어하고, 따라서 계약자나 리눅스 배포판에 의존하게 되어서 이는 분명 결과적으로 커널 개발자 일자리의 큰 원천이 됩니다.\n그리고 커널을 사용하는 거대 기술 기업 중 다수가 종종 개발 프로세스에 적극적으로 참여하게 됩니다. 어떤 경우에는 그들은 내부 작업을 더 많이 하게 되고 그것들을 업스트림으로 도로 기여하는데 썩 열심이진 않습니다 (그 이름들을 거론하진 않겠습니다, 그리고 그 중 몇몇은 그걸 개선하려 정말 열심히 노력하고 있어요), 하지만 얼마나 많은 대기업이 업스트림 커널 개발에 개방적으로 참여하고 있는지, 그리고 커뮤니티의 중요한 부분인지에 대한 결과적 사실은 실로 고무적입니다.\n그러므로 어떤 이유로든, 커널 개발 커뮤니티는 모든 상업적 관심들과 통합되는데 상당히 성공적이었습니다. 물론, 그 중 일부는 매우 의도적인 것이었습니다: 리눅스는 거의 항상 상업적 사용자에게 열려 있었고, 전 의도적으로 \u0026ldquo;자유 소프트웨어 (역자 주: Free Software)\u0026rdquo; 그룹의 극단적 형태의 일부로부터 분명 찾을 수 있는 그 모든 상업성 반대적 사고방식을 피했고, 저는 - 그리고 리눅스는 - \u0026ldquo;오픈소스\u0026rdquo; 로의 브랜드 교체의 큰 부분을 차지했습니다.\n왜냐하면 솔직하게 말해서, rms (역자 주: 리처드 스톨먼) 와 FSF 의 거의 종교적인 분위기 중 일부는 그저 어리석은 것이었고 그 커뮤니티의 일부는 적극적으로 상업적 이용을 못하게 하려 했습니다.\n그리고 전 그걸 상업적 관심에 의해 더럽혀지는 걸 항상 걱정하는 누군가라고 부릅니다. 예를 들면 저는 한 리눅스 회사를 위해 일하고 싶지 않다고 의식적으로 생각했습니다. 저는 첫 10년간은 리눅스 관리를 직업으로써 하지 않았습니다. 그건 제가 상업적 관심이 잘못되었다고 생각해서가 아니라, 사람들이 저를 분명한 중립적 관계자라고 여기지, \u0026ldquo;경쟁자\u0026rdquo; 라고 느끼지 않을 수 있도록 하기 위함이었습니다.\n하지만 일부 프로젝트는 지나치게 상업 반대 성향을 가짐으로써, 그리고 회사들이 참여하기 어렵게 함으로써 자기 발등에 총을 쐈다고 생각합니다.\n그리고, 회사와 일하는게 항상 쉽지는 않습니다. 회사에 오픈소스와 일을 어떻게 해야 하는지 가르치는 걸 도우려 노력하는데 무척 적극적인 몇몇 커널 메인테이너들이 있습니다: 그건 리눅스 재단이 하는 일 가운데 하나이고 (기술적 분야에서만이 아니구요: 법적 문제 등을 위한 수업도 있습니다), 주요 커널 메인테이너 가운데에서는 Greg KH 가 그 쪽으로 무척 적극적입니다. 그러니 노력이 좀 들어갑니다.\n하지만 그게 지속 가능하냐구요? 그렇습니다. 저는 개인적으로 오픈소스가 지속가능할 뿐만 아니라 복잡한 기술 문제는 그 문제가 하나의 단일 회사에서 관리하기에는, 심지어 거대하고 능력 있는 기술 회사라 할지라도, 지나치게 복잡하게 되기 때문에 결국은 오픈소스가 여러분에게 정말 필요하게 됨을 100% 믿고 만족하고 있습니다.\n하지만 이는 양쪽 모두에 상당한 개방성을 필요로 합니다. 모든 회사가 좋은 파트너가 되지는 않을 겁니다, 그리고 일부 개발자는 대기업과 일하고 싶어하지 않을 수도 있습니다.\nJA: 장기간 일한 오픈소스 메인테이너들과 대화하며 우리가 발견한 공통적 주제는 번아웃으로, 부분적으로는 프로젝트를 매우 공개적으로 유지하는데 대한 변함없는 압력, 그리고 자기가 무언가를 빚쟁이라도 되는듯 요청을 해대는 사용자들 때문입니다. 당신도 이걸 경험하셨나요? 어떻게 이걸 처리하고, 어떻게 번아웃을 피하시나요? 커널 개발을 그만두는 걸 고려해 본 적이 있습니까?\nLT: 글쎄요, 앞의 \u0026ldquo;핵심 교훈들\u0026rdquo; 질문에서 이 문제를 넌지시 이야기 한 것 같은데요.\n왜냐하면, 그래요, 그런 압박이 있습니다. 그리고, 예, 저 또한 진저리를 친 적이 있습니다.\n동시에, 저 개인적으로는, 저의 \u0026ldquo;됐어, 이걸로 충분해\u0026rdquo; 발작은 \u0026ldquo;오늘은 이걸로 충분해\u0026rdquo; 를 의미하는데 훨씬 가깝습니다. 저도 스트레스를 받고, 짜증이 날 때가 있습니다. 전 분명 사람들 앞에서 몇번 폭발했고, 그때는 흉했습니다 (그리고 저는 그런 일이 재발되지 않도록 하기 위해 적극적으로 노력해오고 있습니다). 여러분은 제가 무언가나 누군가를 모욕하는 걸 그만두는 건 분명 보지 못할 겁니다.\n하지만.\n전 자리에서 일어나고, 책을 읽고, 바깥 날씨가 좋으면 드라이브를 잠깐 하기도 하고, 휴식을 취합니다. 그러면 전 거기서 극복됩니다. 그리고 다음날 복귀하는데, 결국 저는 제가 하고 있는 걸 정말 즐기기 때문입니다. 커널 개발을 하지 않으면 매일을 눈물로 지새울 겁니다.\n그러므로 휴가를 갈 때에도 (전 일년에 두번 스쿠버 다이빙을 합니다, 판데믹 덕에 작년엔 그러지 못했지만요) 저는 제가 개발을 계속할 수 있도록 랩탑을 챙깁니다. 제가 평소만큼 즉각적으로 응답하지 않을 것을 사람들에게 알리지만 개발 기간 내에 일을 끝마칠 수 있는 한은 그건 일반적으로 큰 문제가 되지 않습니다. 정전된 환경에 놓이는 경우는 제게 매우 드뭅니다, 그게 몇번 일어난 적 있긴 하지만 말이죠 (다시 말하지만 - 가끔 스쿠버 다이빙을 하는 건 오늘날에도 \u0026ldquo;인터넷 없는 진귀한 곳\u0026rdquo; 을 의미합니다), 때문에 저는 몇번 그로 인해 일주일 가량 연락이 끊긴 적 있습니다.\n그리고 전 해외에 머무는 것, 일주일간 하루에 다섯번씩 다이빙 하는 것, 그리고 말 그대로 이메일을 읽을 수조차 없는 걸 정말 좋아합니다. 지난 5년간 이걸 세번 했습니다, 아마도요. 멋진 시간이었어요.\n하지만 그러고 나선 복귀합니다, 그리고 복귀하는 것도 정말 행복합니다.\nJA: 30년은 긴 시간입니다, 그리고 미래를 예측하는 건 불가능하단 걸 저도 알지만 이 질문을 하고 싶군요: 다음 30년동안 리눅스는 어떻게 될까요? 그리고 그 동안 당신의 역할은 무엇이 될거라 생각하나요?\nLT: 이건 제가 답변할 수 없는 질문인데, 제가 이걸 회피하려 해서가 아니라 그건 제가 일하는 방법, 제가 프로젝트를 생각하는 방법이 아니기 때문입니다.\n전 \u0026ldquo;30년 계획\u0026rdquo; 이 없습니다. 5년짜리 계획조차 없어요. 사실, 저는 한두개 릴리즈 (겨우 수개월) 이상은 계획하지 않아요.\n엔지니어로써, 저는 \u0026ldquo;세부사항이 중요하다\u0026rdquo; 는 강한 의견을 갖고 있습니다. 세부사항이 중요한 거의 유일한 것입니다. 세부사항을 옳게 했다면, 나머지는 따라올 겁니다.\n이게 좀 이상하게 들릴 수 있을 겁니다, 제가 이미 \u0026ldquo;좋은 취향\u0026rdquo; 에 대해 이야기 한 사실을, 그리고 제가 유닉스 철학 (\u0026ldquo;모든 것은 파일이다\u0026rdquo; 가 핵심 원칙 중 하나죠) 이 옳다고 이야기하는 게 기록되어 있음을 생각해 보면 말이죠.\n그리고 Git 의 경우, 저는 전반적인 \u0026ldquo;설계\u0026rdquo; 역시 원했고, Git 에는 모든 것에 앞서는 큰 컨셉 몇가지 (\u0026ldquo;모든 것은 변형 불가한 객체다\u0026rdquo; 가 Unix 의 것과 같은 Git 의 것일 겁니다) 가 존재합니다.\n하지만 그런 \u0026ldquo;높은 수준의 설계\u0026rdquo; 같은 건 주로 결속력 있는 결과 같은 걸 위해, 그리고 커뮤니티에 일종의 \u0026ldquo;설계 방향 지침\u0026rdquo; 을 위해 필요합니다. 그게 결과적으로 가장 중요한 것은 아닙니다. 현실은 복잡하고 때로는 추합니다, 그리고 그런 높은 수준의 큰 설계는 세부 사항, 그리고 현실에서는 실제로 필요하게 될 모든 특수한 경우들을 담지 못합니다.\n그래서 저는 제가 \u0026ldquo;꾸준히 일하는 엔지니어\u0026rdquo; 라고 이야기 하길 좋아합니다. 전 지금 무슨 일이 일어나는지 보고, 우리가 지금 가진 문제를 보고, \u0026ldquo;내가 그 결과를 관리해야만 한다\u0026rdquo; 를 아는 것 외의 어떤 미래도 계획하지 않으며, 우리가 오늘 하는 일이 내일 큰 문제가 되지 않음을 분명히 하기를 원합니다.\n이게 당신의 질문의 마지막 부분에 일종의 답이 될 겁니다: 전 제가 계속 거기 있을 거라 생각합니다. 다음 30년동안 계속은 아니겠지만, 전 제가 하는 일을 즐기고, 제가 프로젝트에 실제 도움이 된다고 느끼는 동안은 계속 거기 있을 겁니다.\nJA: 자신의 오픈소스 개발 작업을 지원할 돈이 늘어나기를 원하는 개발자를 위한 조언이 있습니까?\nLT: 이건 제가 정말로 아무런 답도 갖고 있지 않은 첫번째 질문이군요.\n전 리눅스를 긴 시간동안 지속될 순수한 취미라고, 그게 진짜 제 직업이 될거라고는 전혀 생각하지 않고 시작했습니다. 제 첫번째 (처음 몇년은 일했던 학계가 아닌) 업계에서의 직업은 리눅스와 연관되지 않은 것이었고, 전 제 계약서가 제 리눅스 관련 작업은 회사의 일이 아님을 명시하게 했습니다 (Transmeta 가 - 역자 주: Transmeta 는 리누스 토발즈가 처음 일했던 회사입니다 - 리눅스를 사용하긴 했지만 그건 제 진짜 일이 아니었습니다, Transmeta 가 내부적으로 가지고 있는 리눅스 문제 - 주로 초기의 SMP 문제 - 를 제가 해결하게 된다고 해도 말이죠).\n사실, 리눅스 2.6 릴리즈를 위해 (좋아요, 분명한 버전이 뭐였는지 지금은 솔직히 확신이 들지 않는군요, 그건 오래전 일이예요. 그건 2.5.x 로 스트레스 받던 시절의, 그리고 제가 2.6 릴리즈를 위해 전업으로 집중할 필요가 있다고 느꼈던 때라고 생각합니다) Transmeta 에 무급 휴가를 신청할 계획을 세웠을 정도로 제게 있어 리눅스는 일이 아닌 것에 가까웠습니다. 그때 OSDL (\u0026ldquo;Open Source Development Labs\u0026rdquo; - 나중에 리눅스 재단이 되었죠) 이 나타나서 제가 상업적 리눅스 회사를 위해 일하지 않고도 실질적으로 리눅스 작업을 위해 돈을 받을 수 있게 되었죠.\n그러니 리눅스 개발의 첫 10년간은 돈을 더 버는 것 같은 것은 제게 있어 문제로 여겨지지 않았습니다 - 전 그걸 다른 측면에서 했습니다. 그리고 그 10년간 그렇게 일한 후, 제가 그걸 전업으로 해야 할 것 같다고 느꼈을 때에는, \u0026ldquo;그냥 그렇게 되었을\u0026rdquo; 정도로 리눅스가 이미 중요해 졌습니다.\n하지만 전 이게 정말 정말 평범하지 않은 경우임을 알고 있고, 당신의 질문에 대한 일반적 경우를 위한 답은 정말 갖고 있지 않습니다.\n그러니까, 그 답이 정확히 \u0026ldquo;10년간은 그걸 취미로 계획하고, 그게 더이상 취미일 수 없을 정도로 성장하면, 당신은 이미 후원 문제를 해결했을 겁니다\u0026rdquo; 가 아니라면 말이죠.\n주의 바랍니다! 여기가 핀란드에서 자랐다는 사실이 제게 있어 얼마나 행운이었는지 이야기 하고 싶은 지점입니다. 세계 최고 수준에 완전히 무료인 교육 시스템 하에서, 저는 리눅스를 취미로 여기는게, 그리고 제가 상업적 소프트웨어 개발자로써 돈을 벌 수 있음을 아는게 완전히 말이 되는 배경 하에서 자랐습니다. 저는 대략 7000 달러의 - 첨단 기술의 세계에서는 걱정할 가치가 있지는 않은 - 학비 지원 같은 걸 받고 8년간 세계에서 손꼽히는 수준의 대학교에서 공부를 했습니다.\n미국의 많은 사람들이 그게 삶에 주는 자유에 대해 정말로 이해하지 못함을 저는 실로 깨달았습니다. 정말 여러분이 좋아하는 일을 고를 수 있게 됩니다, 왜냐면 여러분이 그 비용을 지불할 수 있으니까요.\nThe Linux Foundation JA: 리눅스 재단의 생성에 당신은 얼마나 관여했나요? 당신의 역할은 무엇입니까? 당신이 상업적 리눅스 회사를 위해 일하지 않고도 급여를 받을 수 있게 하는 것 외에 그 재단이 커널에 영향을 끼쳤나요?\nLT: 전 OSDL (나중에 리눅스 재단이 되었죠) 의 생성에 아무런 일도 하지 않았습니다. 전 말 그대로 그저 직원입니다, \u0026ldquo;펠로우\u0026rdquo; 라는 남의 시선을 끄는 타이틀을 가지고 있긴 하지만요.\nOSDL 은 회사들이 일을 함께 하는 걸 위한, - 특히 엔터프라이즈적 가능성에의 협력을 위한 - 그리고 개발자들이 사용 가능한 기계들을 (예를 들어 개발자들이 접근 권한을 갖지 않고는 사용할 수 없는 종류의 하드웨어) 갖추는 걸 중시하는 비영리 업계 협회로 시작되었습니다. 이 모든게 제가 그들에게 고용되기 전에 시작되었고 그 모든게 저와 연관 없이 일어났습니다.\n그러고 나서 OSDL 이 또다른 비영리 업계 협회인 Free Standard Group 과 병합되면서 리눅스 재단이 되었습니다. 하드웨어 지원쪽 일은 곁가지가 되었고, \u0026ldquo;업계 협회\u0026rdquo; 부분이 주요한 일이 되었습니다. 다시 말하지만, 그러고 나서 제가 그들에게 고용되었긴 하지만, 이건 제가 개인적으로 속한 무언가가 아니었습니다: 저는 의도적으로 기술적 커널 개발 측면에만 집중해 있기를 유지했습니다.\nLF (역자 주: 리눅스 재단 - Linux Foundation) 는 저와 Greg KH 같은 일부 핵심 개발자들을 지원하는 것 외에도 많은 일을 하고 있습니다. 사실, 여러분이 LF 웹사이트 (또는 위키피디아 페이지) 에서 찾아보는게 정말 나을 정도로 LF 는 많은 일을 하고 있습니다. LF 는 다양한 종류의 인프라 관련 일을 하고 있습니다: 어떤건 기술적입니다만 (kernel.org 같은), 다른 \u0026ldquo;지원\u0026rdquo; 쪽 일도 많습니다 - 컨퍼런스를 조직하고, 업계 파트너들을 위한 실무 그룹을 만들고, 등등.\n그러니까, LF 는 기본적으로 인프라와 리눅스를 둘러싼 다양한 것을 위한 많은 프로젝트들을 지원합니다. 그리고 저는 그저 기본적으로 제가 하는 모든 일은 오픈소스가 되어야 한다는, 그리고 LF 는 제게 리눅스를 가지고 뭘 해야 한다고 할 수 없는, 상당히 특수한 고용 계약을 가진 직원일 뿐입니다. 전 행복하고, 재단의 멤버인 회사들도 행복한 듯 보이는데, 그들 모두가 전 어떤 회사 정책에도 정말로 속박되지 않음을 알고 있기 때문입니다.\nOther Interests JA: 무엇이 당신을 미국으로 이끌었나요? 핀란드를 그리워하거나 그리로 돌아가는 걸, 또는 다른 나라로 이주하는 걸 고려해 봤나요?\nLT: 전 97년에 미국으로 이사왔는데 부분적으로는 제가 상당히 젊었고 제가 무척 익숙한 영역에서 (예를 들어 평범하지 않은 80386 아키텍쳐 - 그걸 뜯어보는게 리눅스가 시작된 목적이었죠) 매우 흥미로운 일을 하는 스타트업으로부터 고용 제안을 받았기 때문이었습니다.\n그리고 당시 핀란드는 상당한 기술 강국이었지만 휴대전화 위주였습니다 (노키아는 핀란드 기업이고 당시에는 세계에서 가장 큰 휴대전화 회사였고 매우 큰 점유율을 가진 핀란드 최대 기업이었습니다).\n전 전화기에 관심이 없었습니다 (이건 그게 성장해서 작은 컴퓨터가 되기 전의 일입니다 - 여러분이 믿을지 모르겠지만 사람들은 실제로 그걸 다른 사람들과 대화하기 위해 사용했습니다). 그리고 미국은 흥미로워 보였고, 저는 제 부인과 우리의 (당시에) 태어난 지 10주 된 첫째 딸을 데리고 여기로 이사 왔습니다.\n첫 아이가 생겼을 때, 그리고 도와줄 다른 가족이 없는데 다른 나라로 이사하는 것은 가장 현명한 일은 아마 아닐 겁니다. 하지만 봐요, 우린 젋었고, \u0026ldquo;시도해보자\u0026rdquo; 전략을 취했으며, 그게 모두 잘 통했습니다. 우리가 2월에 어떻게 이사했는지, 그리고 우리가 떠나던 때의 헬싱키는 추웠던 것 (섭씨 -20도, 그러니까 화씨로 대략 0도였습니다), 샌프란시스코 공항에 도착해 비행기에서 내렸을 때에는 맑고 향기로운 화씨 70도였던 걸 (역자 주: 섭씨로 대략 20도) 아직도 기억합니다.\n흥미로운 일입니다. 미국은 지금은 제 집이 있는 나라입니다, 그리고, 그래요, 전 핀란드의 어떤 부분들은 그리워 합니다. 미국의 교육 시스템은 재앙입니다. 좋은 학교를 위해선 올바른 지역으로 이사를 해야만 하고, 좋은 대학을 위해선 말도 안되게 비싼 학비를 지불해야 합니다. 이건 부끄러운 일입니다. 건강 보험 시스템도 마찬가지입니다. 그리고 미국의 정치적 분위기는 \u0026ldquo;약간 이상함\u0026rdquo; 에서 완전히 공포스러움으로 변했습니다. 핀란드에서는요? 대부분 잘 작동합니다.\n하지만 보세요, 장점들도 있는데, 그건 날씨만이 아닙니다 (그래요, 우린 그 후에 오레곤 포틀랜드로 이사했고 여기 날씨는 Bay Area 만큼 좋지는 않죠, 하지만 절 믿으세요 - 핀란드보다는 여기 날씨가 여전히 훨씬 나아요). 그리고 우린 우리 아이들이 핀란드 말을 못할 정도로 여기서 오래 살았고 (저와 제 부인 둘 다 스웨덴 말을 사용하는 핀란드의 소수 집단 출신이라, 집에서는 스웨덴 말을 씁니다), 미국에 친구들이 있고 사회적으로 묶여 있습니다. 그리고 좋은 직업을 가지고 있다면 미국 사회의 문제들을 대다수 무시할 수 있습니다.\n우리가 핀란드로 돌아가는 걸 고려해 봤느냐구요? 몇번요. 처음은 아이들이 학교를 다니기 시작했을 때입니다. 고등학교를 다니기 시작했을 때도 그랬구요. 대학교에 갈때도 그랬습니다. 어떤 패턴이 보이나요? 그리고 트럼프가 재당선 될 수도 있을 것 같아 보였을 때 또 고려했습니다.\nJA: 세계의 많은 사람들이 그 선거에 주의를 기울였고, 그게 어떤 의미가 될지 걱정했죠. 그리고 지금조차도, 칠천만의 미국인이 그의 재당선을 지지했음을 생각할 때, 미래에 대한 어떤 전조가 보입니다. 트럼프의 재당선을 지지하는 사람들과의 대화는 어떻게 하시나요?\nLT: 일반적으로 미국의 정치 시스템은 절 근심하게 만들고, 미국의 예외주의와 민족주의는 슬프고 공포스럽습니다. 특히 그게 자신들이 무슨 말을 하고 있는지 말그대로 전혀 이해하지 못하고 다른 나라에 살아본 적도 없는 사람들에 의해 행해질 때에요.\n미국은 여러 측면에서 멋진 나라이고 많은 문화와 사람들로 (그리고 자연으로) 가득한, 다양성이 풍부한 나라이며 전 그걸 좋아합니다. 사실 이게 제가 핀란드로 돌아가기를 가장 힘들게 하는 부분일 겁니다 - 핀란드는 매우 친절하고, 이성적이고 안전한 나라지만 매우 작고 매우 단일한 곳입니다.\n하지만 교육받지 않은, 그 \u0026ldquo;랄라, 아메리카 넘버원!\u0026rdquo; 류의 것들은 매우 짜증나기도 합니다. 여러분은 아메리카 깃발로 가득한 트럭들을 볼 것이고, 종종 부끄러움에 얼굴을 감싸게 될겁니다.\n그리고 가끔은 교육받은 사람들조차 그럽니다. 트럼프가 당선되기 전, 저는 무척 친절한 의사와 이야기한 적 있는데, 그는 미국 건강 보험 체계가 세계 최고라고 절대적으로 믿고 있었습니다. 그는 다른 나라에서 살아본 적 없으면서 그렇게 생각했고, 때문에 다른 나라가 실제로 더 나은 건강 보험 체계를 가지고 있을 거라 인정할 수 없었을 겁니다 - 그 더 나은 건강보험 체계를 실제로 목격한 누군가와 토론하면서도 말이죠. 그는 의대에서 수년의 세월을 보낸, 상당히 교육된 사람인데도 그 \u0026ldquo;아메리카, x나 좋군!\u0026rdquo; 정신상태를 가지고 있었습니다.\n그리고 맞아요, 그는 트럼프 지지자였습니다.\n제 말을 오해하지 마세요 - 민족주의는 유럽을 포함해 어디에나 존재합니다. 핀란드조차도 예외가 아닙니다. 하지만 그것의 미국 버전은 무척 독소로 가득해 보입니다.\n그리고 솔직히, 그게 제가 서부 해안에 사는 이유 중 하나입니다. 오레곤은 대부분 무척 진보적인데 적어도 모든 인구 밀집 지역에서는 그렇습니다 (동부 오레곤은 무척 다릅니다만, 거기에 정말로 살기는 거의 누구에게나 어려울 겁니다 - 영역은 넓은데 매우 적은 인구만이 거기 삽니다). 그러니 제가 사는 곳에서는 남부연합 깃발 (또는 트럼프 깃발) 을 잘 보기 어렵습니다, 어디선가 큰 트럭을 탄 사람이 때때로 나타나긴 하지만 말이죠.\n하지만, 전 미국이 정말 변화하고 있다고 생각합니다. 우린 이제 여기서 거의 25년간 살아왔고, 그 동안에만도 변화가 있었다고 느낍니다. 광적인 신앙심은 사라지고 있습니다, 이것도 어디 사는가에 무척 연관된 문제지만 말이죠. 그리고 여러 측면에서 미국은 분명 사회 억압적 정책을 해결하려 노력했습니다 (예를 들어 동성애자 결혼 합법화, 마약류와의 전쟁의 실질적인 종료 등등). 그러므로 전체적으로 저는 꽤 낙관적이고 트럼프 현상은 필경 (바라건대) 그 전체적인 긍정적 변화의 결과일 뿐이라 생각합니다. 고전적인 반동적 보수화죠.\nJA: 리눅스 커널 외에 어떤 흥미와 취미를 가지고 있나요? 커널 개발에 집중하고 있지 않을 때에는 뭘 합니까?\nLT: 이미 몇번 그 주요한 두가지를 이야기 했습니다: 전 독서를 많이 하고 (진지한 것 말고 판타지나 공상과학류를 아무거나 골라서 제 킨들에서 읽는 경향이 있습니다), 여행을 할때는 가능하면 스쿠버 다이빙을 하려 노력합니다.\n그리고 전 정말 평범한 가족적 삶을 유지합니다. 전 세 딸이 있지만 모두 충분히 자랐고 거의 독립했습니다. 막내는 여전히 대학교를 다니고 있고 여름에는 집에 올겁니다. 둘째는 대학원을 다니고 있고 여름에도 집에 오진 않을 겁니다. 첫째는 이 나라의 반대편 (역자 주: 미국 동부가 되겠네요) 에서 일을 하고 있습니다. 우린 여전히 가족 휴가를 가지려 노력합니다만 (하지만 둘째만 스쿠버 다이빙 자격증을 땄어요 - 모두 그러도록 노력했지만, 현재로썬 그렇습니다), 작년은 정말 좋지 못했죠.\n그러니 요즘은, 주로 저와 제 부인과 우리의 두 반려견들, 그리고 반려묘 한마리와 살고 있습니다. 전 제 첫번째 백신 접종을 받았고 몇달 내로 약간은 더 평범한 삶으로 돌아갈 수 있기를 기다리고 있습니다.\nJA: 항상 새로운 책을 찾는 한명의 열렬한 공상과학 소설 독자로써, 저는 당신이 다른 것들보다 더 즐기는 작가나 시리즈가 있는지 궁금하군요. 당신이 여전히 때때로 생각하는, 언급할만한 좋은 책들이 있을까요?\nLT: 솔직히, 저는 \u0026ldquo;읽고는 잊어버리는\u0026rdquo; 종류의 사람입니다 - 전 대부분 금방 기억에서 잊혀질, 나중에도 생각하게 되지는 않을게 분명한 것들을 무작위로 읽습니다. Lios McMaster Bujold 의 Miles Vorkosigan 시리즈 같은 것들은 제 기준으로 교양서 수준의 것입니다 - 전 작가에 관계 없이 공짜 또는 99센트짜리 킨들 공상과학과 판타지 소설들을 읽었던 것 같습니다. 대부분 판타지 소설이었는데, 찾기 쉬운 게 주요한 이유였습니다 (그리고 저는 나쁜 판타지 소설보다 나쁜 공상과학소설에 더 짜증납니다).\n\u0026ldquo;쓰레기는 아닌\u0026rdquo; 부류의 판타지 소설 쪽에는 Brandon Sanderson 과, 어쩌면 Robin Hobb 이 있다고 생각합니다. 하지만 Sanderson 의 작품에는 대략 50개는 되는, 금방 기억에서 잊혀질 법한 아무런 검과 마법 이야기가 있죠.\n제가 다시 손에 집어드는 것들도 몇개 있는데, 저는 Dune saga 를 10년에 한번씩은 다시 읽는 것 같습니다. 그건 시간이 지나도 여전하고 세월을 잘 버텨낸 (매우 희귀한) 것 중 하나입니다. 10대였을 때에는 Heinlein 을 좋아했습니다만 지금은 싫증났습니다.\n그러니, 제게서 읽을 것에 대한 단서를 구하지 마세요. 제게 있어, 독서는 휴식을 위한 것이지 지식을 위한 것이나 매우 진지한 것이 아닙니다.\nJA: 예전에 하신, 당신의 다이빙에 대한 배경을 설명한 이 인터뷰 가 흥미로웠습니다. 여전히 당신이 시작한 다이빙 기록 프로그램인 Subsurface 를 사용하고 거기에 기여하시나요?\nLT: 여전히 사용합니다, 작년엔 분명한 이유로 그걸 사용하지 못했지만요. Subsurface 는 제가 만들고 싶어서가 아니라 필요로 인해 만들었다는 점에서 Git 과 약간 비슷합니다. 그리고 Git 처럼, 전 그걸 위한 메인테이너를 구했고, 지금은 Dirk Hohndel 이 오랫동안 그걸 유지보수해 왔으며 저만을 위한 것보다 훨씬 더한 무언가로 만들었습니다 (처음에는 리눅스만 지원했는데 윈도우즈, MacOS, iOS 그리고 안드로이드도 지원하게 만들었죠).\n그리고 다이빙 없이는 그걸 위한 작업을 할 동기가 없습니다, 보고된 문제 일부를 고치는 걸 작년에 돕긴 했지만요.\n제 두번째 백신 접종은 2주 뒤이고, 몇달 내로 다이빙을 다시 할겁니다. 그러니 그게 제가 문제들 몇개를 더 고치게 만들겠군요.\nJA: 감사합니다. 제 커리어 전체는 당신의 \u0026ldquo;취미\u0026rdquo; 에서 성장했습니다, 직접적으로는 리눅스의 사용을 통해, 그리고 간접적으로는 리눅스와 Git 으로 인해 존재하게 된 셀 수 없이 많은 다른 프로젝트를 통해서 말이죠. 이 인터뷰를 통해 당신은 여전히 당신이 하는 일을 사랑하고 있음을 알게 되어 다행입니다. 당신이 완전한 백신 접종을 곧 마칠 거라니 기쁩니다. 그리고 이 모든 질문들에 상세하고 통찰력 있는 답변들을 위해 당신의 많은 시간을 공유해 준 데 대해 진심으로 감사합니다! 다시 말하지만, 감사합니다!\n첫번째 파트의 번역은 여기서 보실 수 있습니다.\n","permalink":"https://sjp38.github.io/posts/ko/torvalds_interview_for_30th_anniversary_of_linux_kernel_part2/","summary":"리눅스 커널이 처음 공개된지 올해로 30년이 되었고, 이를 맞아 한 tag1 에서 리누스 토발즈와 인터뷰 를 했습니다. 분량이 많아 두 파트로 나눠 올렸는데요, 해당 매체에 허락을 받고 이곳에 그 중 두번째 파트의 번역을 올립니다.\n아래 분들께서 오타 등을 찾고 글을 다듬는 걸 도와주셨습니다. 감사의 말씀을 전합니다.\nJaehoon Kim Tag1 의 원본 글은 다음 링크에서 보실 수 있습니다: https://www.tag1consulting.com/blog/interview-linus-torvalds-open-source-and-beyond-part-2\n첫번째 파트의 번역은 여기서 보실 수 있습니다.\n오픈소스 프로젝트의 관리 JA: 우린 최근에 Drupal 을 만든 Dries Buytaert 와 이야기 해봤는데, 그는 당신에게 받은 많은 영감과 가끔의 멘토링, 그리고 그가 지난 20년동안 그 유명한 Drupal CMS 를 관리하는 동안 받은 조언을 이야기하며 당신을 칭찬했습니다.","title":"리눅스 30주년 맞이 리누스 토발즈 인터뷰 번역 - 파트 2"},{"content":"리눅스 커널이 처음 공개된지 올해로 30년이 되었고, 이를 맞아 tag1 에서 리누스 토발즈와 인터뷰 를 했습니다: https://www.tag1consulting.com/blog/interview-linus-torvalds-linux-and-git 분량이 길어 두 파트로 나눠 올라왔는데, 해당 매체에 허락을 받고 이곳에 그 중 첫번째 파트의 번역을 올립니다.\n두번째 파트는 여기서 보실 수 있습니다.\n아래 분들께서 오타 등을 찾고 글을 다듬는 걸 도와주셨습니다. 감사의 말씀을 전합니다.\nganadist Jaehoon Kim 리눅스 커널 개발 Jeremy Andrews: 리눅스는 어디에나 사용되고 있고, 전체 오픈소스 세계에 영향을 끼쳤습니다. 물론, 처음부터 그런 건 아니었습니다. 당신은 comp.os.minix 의 Usenet 메일링 리스트에 겸손한 메일을 보냄으로써 1991년에 리눅스 커널을 릴리즈 했고 이는 무척 유명해졌죠. 10년 후, 당신은 그 역사를 이야기 하는\u0026quot;Just for Fun: The Story of an Accidental Revolutionary\u0026quot; 라는 매력적이고도 개인적인 책을 냈습니다. 올해 8월, 리눅스는 30주년을 맞이하게 되었습니다! 대단해요, 축하합니다! 이 여정 가운데 언제쯤부터 당신은 리눅스가 \u0026ldquo;그저 취미 (just a hobby)\u0026rdquo; 보다는 더한 무엇이 되었음을 깨달았나요?\nLinus Torvalds: 좀 웃기게 들리겠지만, 그건 무척 초반부터였습니다. 이미 1991년 말부터 (그리고 1992년 초부터는 분명히) 리눅스는 이미 제가 예상한 것보다 훨씬 커져 있었습니다.\n그리고 그때 대략 수백명의 사용자가 있었는데 (\u0026ldquo;사용자\u0026rdquo; 라고 하는 것도 너무 어감이 강할지도요 - 사람들은 그걸 이리저리 뜯어보고 있었습니다), 리눅스가 나중에는 그보다 훨씬 거대해졌다는 점을 생각해 보면 이건 좀 이상하게 들릴 거예요. 하지만 제게 개인적으로는 다른 사람들이 활발하게 그걸 사용하고 있음을, 그리고 그것이 스스로의 삶을 시작했음을 깨달은 때가 여러 의미로 큰 변곡점이었습니다. 사람들은 패치를 보내기 시작했고, 시스템은 제가 처음에 상상했던 것보다 훨씬 많은 것들을 하기 시작했죠.\nX11 이 92년 4월에 리눅스로 포팅된 걸로 기억하는데 (날짜는 틀릴 수 있어요 - 그건 오~~래전 일이예요), 이는 GUI 와 모든 새로운 기능들이 가능하게 한, 또다른 큰 한걸음이었습니다.\n이 모든걸 놓고 보면 - 나는 높은 기대치의 큰 계획을 가지고 시작하지 않았습니다. 그건 새로운 운영체제를 만들어내기 위한 어떤 큰 꿈으로부터 시작된 게 아니라 말 그대로 그저 제 새 PC 하드웨어가 어떻게 작동하는지 알아보려 시작한데서 우발적으로 시작된 개인 프로젝트였습니다.\n그래서 제가 최초 버전을 릴리즈 했을 때, 그건 정말 \u0026ldquo;내가 뭘 만들었는지 보세요\u0026rdquo; 에 더 가까웠고, 다른 사람들이 거기에 흥미를 갖길 제가 원했던 건 분명하지만, 그건 정말 진지하고 사용할 수 있는 OS 는 아니었습니다. 그건 그보단 컨셉의 증명에 가까웠고 제가 몇달의 시간동안 일한 개인 프로젝트에 불과했습니다.\n그리고 그 \u0026ldquo;개인 프로젝트\u0026rdquo; 가 다른 사람들이 가져다 사용하고 피드백 (과 버그 레포트), 그리고 심지어 패치를 보내주는 것이 되어가는 과정은 제게 큰 변화였습니다.\n단지, 정말 기본적인 무언가 예를 들어 주기 위해서 사용한 리눅스 원래의 저작권 라이센스는 \u0026ldquo;당신은 이걸 소스 형태로 배포할 수 있습니다만, 상업적으로는 안됩니다\u0026rdquo; 같은 것이었습니다.\n왜냐하면 제게 있어 큰 문제들 중 하나는 말 그대로 상업용 유닉스는 비쌌다는 것이고 (글쎄요, 자기 돈을 모두 새로운 PC 사는데 쓴 가난한 학생에게는 말이죠), 때문에 제게 있어 (사람들이 그걸 고칠 수 있게끔) 소스코드가 사용 가능해야 한다는 건 크고 중요한 일 중 하나였습니다, 그리고 대안을 구매할 돈이 없는 바로 저같은 사람들에게 열려 있기를 바랬어요.\n그리고 전 그 라이센스를 91년 말 (또는 92년 초일지도) GPLv2 로 바꿨는데요, 그걸 지역 유닉스 사용자 그룹에 플로피 디스크를 사용해 배포하고자 하는데 최소한 그 플로피 디스크와 그 복사본을 만드는데 들인 시간을 보상받고 싶어하는 사람들이 있었기 때문입니다. 그리고 저는 그건 분명 완전 합리적인 일임을, 그리고 정말 중요한 건 \u0026ldquo;비상업성\u0026rdquo; 이 아니라 \u0026ldquo;소스코드는 개방되어야 한다\u0026rdquo; 는 부분임을 깨달았습니다.\n그 결과, 사람들은 그걸 유닉스 사용자 그룹 모임에 배포할 뿐만 아니라, SLS 와 Slackware 같은 플로피 디스크 기반 배포판들을 몇달만에 만들었습니다.\n초기의 정말 기본적인 변화들에 비교해서, 다른 모든 것은 \u0026ldquo;점진적\u0026rdquo; 이었습니다. 맞아요, 그런 점진적 변화 가운데 일부는 정말 거대했습니다 (IBM 이 참여하고, 오라클 DB 가 포팅되고, 레드햇이 상장하고, 안드로이드가 전화기 등에서 거대해지고), 하지만 그것들은 정말 초기의 \u0026ldquo;내가 알지도 못하는 사람들이 리눅스를 사용함\u0026rdquo; 에 비하면 제 개인적으로는 덜 혁명적이었어요.\nJA: 라이센스 선택에 대해, 또는 당신이 만든 것을 이용해 다른 사람이나 회사가 많은 돈을 벌어들이는 것에 대해 후회한 적은 없습니까?\nLT: 전혀요.\n일단, 전 꽤 잘 살고 있습니다. 전 미친듯한 부자는 아닙니다만, 좋은 보수를 받는 소프트웨어 엔지니어이고, 제가 좋아하는 걸 제 스스로의 스케쥴에 맞춰 하고 있습니다. 전혀 상처받지 않아요.\n하지만 이와 똑같이 중요한게, 그 라이센스가 리눅스 (그리고 Git) 의 성공의 큰 이유 중 하나였음에 100% 만족하고 있습니다. 저는 프로젝트에 참여하는 모두가 모든 사람이 동일한 권리를 가졌고, 누구도 라이센스에 관해선 특별하지 않음을 깨달을 때 훨씬 행복해진다고 생각합니다.\n원래 소유자가 상업성 라이센스를 소유하며 (\u0026ldquo;우리에게 라이센스 비용을 지불하면 당신은 이걸 당신의 독점 상품에 사용할 수 있습니다\u0026rdquo;), 다른 한편으로는 오픈소스의 경우엔 GPL 같은 무언가 하에 사용될 수도 있는 많은 수의 \u0026ldquo;듀얼 라이센스\u0026rdquo; 프로젝트들이 존재합니다.\n그리고 전 그런 종류의 상황 하에서는 커뮤니티를 만들기가 정말 어렵다고 생각하는데, 항상 오픈소스 쪽은 \u0026ldquo;두번째 클래스\u0026rdquo; 임을 알기 때문입니다. 또한 이는 특수한 집단이 항상 특수한 권리를 유지하기 위해 단순한 라이센스 서류 작업을 많이 해야 하게 합니다. 때문에 이는 프로젝트에 많은 마찰을 일으킵니다.\n다른 한편으로, 전 여러 BSD (또는 MIT 나 비슷한 것들) 라이센스를 사용하는 오픈소스 프로젝트들이 상업적으로 중요해질 만큼 거대해지는 순간 분열되고, 관련된 회사들이 자신들의 부분들을 독점화 하기로 결정해야만 하게 되는 것을 봤습니다.\n따라서 저는 GPLv2 가 \u0026ldquo;모두가 같은 규칙 아래 일한다\u0026rdquo;, 그리고 그 사람들은 커뮤니티에 얻은 것을 공헌한다 (\u0026ldquo;팃포탯\u0026rdquo;) 의 완벽한 밸런스라고 생각합니다. 그리고 모두가 참여자는 같은 규칙 아래 있음을 알게 되므로, 매우 공평하고 정당합니다.\n물론, 이것의 또다른 측면은 여러분 또한 공헌한 만큼 받아간다는 겁니다. 맞아요, 여러분은 프로젝트 변방에 머무르고 단순한 사용자가 될수도 있습니다, 그리고 그래도 되요. 하지만 그런다면, 여러분에겐 해당 프로젝트에 대한 제어권이 없습니다. 이것 역시 완전히 괜찮습니다, 여러분이 정말 기본적인 운영체제를 원할 뿐이라면 말이죠, 그리고 리눅스는 이미 여러분이 필요한 모든걸 하고 있습니다. 하지만 여러분에게 특수한 요구사항이 있다면, 프로젝트에 영향을 끼치는 유일한 방법은 참여하는 겁니다.\n이게 모두를 정직하게 만듭니다. 저를 포함해서요. 누구나 프로젝트를 포크 (fork) 해서 스스로의 방향으로 나아가고 \u0026ldquo;안녕히 리누스, 난 내 버전의 리눅스의 관리권을 가져갑니다\u0026rdquo; 라고 할 수 있습니다. 전 그저 사람들이 제가 일을 잘 할거라 믿기 때문에 - 그리고 그 믿음이 지속되는 동안만 - \u0026ldquo;특별\u0026rdquo; 합니다. 그리고 실로 그래야만 합니다.\n이 \u0026ldquo;누구나 스스로의 버전을 관리할 수 있다\u0026rdquo; 부분이 어떤 사람들을 GPLv2 에 대해 걱정하게 만듭니다, 하지만 전 그건 강점이지 약점이 아니라 생각해요. 어떤 면에선 의도된 바는 아니지만, 전 그게 리눅스의 파편화를 막아준 것이라고 생각합니다: 모두가 각자의 포크 (fork) 를 소유할 수 있고, 그래도 됩니다. 사실, 그건 \u0026ldquo;Git\u0026rdquo; 의 핵심 설계 철학 중 하나입니다 - 저장소의 모든 복사본은 그 자체로 작은 포크 (fork) 이고, 사람들 (그리고 회사들) 이 그들 스스로의 포크를 만드는 것이 바로 개발 이 이루어지는 과정입니다.\n그러므로 포크 (fork) 를 하는 건 문제가 아니예요, 그들로부터 좋은 부분들을 다시 머지할 수 있는 한 말이죠. 그리고 이게 GPLv2 가 해주는 일입니다. 포크하고 여러분 스스로의 일을 할 수 있는 권한을 갖는 건 중요합니다, 하지만 동전의 반대면도 똑같이 중요합니다 - 성공적이었다 여겨지는 포크를 다시 원본으로 병합 (merge) 할 수 있는 권리.\n또다른 문제는 여러분에게는 이 작업흐름을 지원하는 도구도 필요하지만, 이를 위한 마음가짐 또한 가져야만 한다는 점입니다. 포크를 원본으로 병합하는 경우의 큰 장애물에는 단순한 라이센스 문제 외에도 \u0026ldquo;나쁜 혈통\u0026rdquo; 이 있습니다. 어떤 포크가 적대적 이유로 시작되었다면, 두개의 포크를 하나로 합치는 건 무척 어려울 수 있습니다 - 라이센스나 기술적 이유가 아니라 그 포크가 무척 험악했기 때문에요. 다시 말하지만, 전 리눅스가 그걸 잘 피했으며, 이는 우리가 항상 포크 하는 행위를 자연적인 것이라 여겼고, 그럼 어떤 포크에서의 작업이 성공적이었다 여겨질 때 이를 원본에 도로 병합시키고자 하는 행위 역시 자연스러운 행위가 된다는 점 때문이 크다고 생각합니다.\n그러니까, 답변이 좀 옆길로 샜습니다만, 전 이게 중요한 점이라고 생각합니다 - 전 그 라이센스 선택을 전혀 후회하지 않아요, 왜냐하면 전 정말로 GPLv2 가 리눅스의 성공의 이유 중 큰 부분이라고 생각하거든요.\n돈은 정말 그렇게나 대단한 동기부여장치는 아닙니다. 그건 사람들을 끌어모으지 않아요. 공동의 프로젝트를 가지고 해당 프로젝트에 있어 여러분이 정말로 완전한 파트너가 될 수 있다고 정말로 느끼는 것, 그것이 사람들을 동기부여 시킵니다, 제 생각에는요.\nJA: 요즘 사람들이 소스코드를 GPLv2 아래 릴리즈 하면, 그건 보통 리눅스 때문입니다. 당신은 그 라이센스를 어떻게 발견했고, 다른 라이센스들을 검토해 보는데는 얼마나 많은 시간과 노력을 기울였나요?\nLT: 그당시, 사람들은 여전히 BSD vs GPL 에 대한 격렬하게 불타는 전쟁을 벌이고 있었습니다 (부분적으로는 rms 가 사람들을 욕하는데 가진 재능이 이를 부추겼다고 생각합니다), 따라서 저는 제가 구독중이던 일부 usenet 뉴스그룹을 통해 (comp.arch 나 comp.os.minix 등) 라이센스 토론 중 일부를 봤습니다.\n하지만 제가 GPLv2 를 선택한 두가지 주요 이유는 분명, 그저 gcc - 리눅스가 돌아가게 하는데 매우 주된 역할을 했습니다, 왜냐면 전 당연하게도 C 컴파일러가 필요했으니까요 - 와 제가 당시 다니던 대학교의 스웨덴말을 하는 (핀란드에서 스웨덴어는 작은 비주류층을 형성합니다) 컴퓨터학과 학생이었던 Lars Wirzenius (\u0026ldquo;Lasu\u0026rdquo;) 때문이었습니다.\nLasu 는 저보다 훨씬 더 라이센스 토론 등에 심취해 있었습니다.\n제게 있어, GPLv2 의 선택은 큰 정치적 문제가 아니었습니다, 그건 주로 제 원래 라이센스가 임시 변통의 것이고 업데이트되어야 할 필요가 있다는 것에 대한 것이었고, 전 gcc 에 신세를 졌을 뿐더러 GPLv2 는 저의 \u0026ldquo;당신은 소스코드를 되돌려줘야 합니다\u0026rdquo; 기대에 부합하는 것이었습니다.\n따라서 다른 라이센스를 만드는 것보다는 (또는 원래의 것을 수정하는 것 - 그저 \u0026ldquo;상업적으로 쓰이면 안됨\u0026rdquo; 부분만 제거하는 게 하나의 선택이 될 수 있었을 겁니다 - 보다는), 전 다른 사람들이 이미 알고 있는것을 고르고 일부 법률가들을 참여하게 하고 싶었습니다.\nJA: 당신의 평범한 하루는 어떻습니까? 얼마나 많은 시간을 코딩, 코드 리뷰, 이메일 읽고 쓰기에 사용하나요? 그리고 개인적 삶과 리눅스 커널을 위해 일하는 사이의 균형을 어떻게 잡습니까?\nLT: 요즘 저는 매우 적은 코드만을 작성합니다, 그런지 꽤 됐어요. 그리고 제가 코드를 작성하는 가장 흔한 상황은 어떤 특정한 문제에 대한 토론이 있을때 제가 제안하는 해결책을 설명하기 위함을 주목적으로 하는 패치를 만들어 보내는 때입니다.\n달리 말하면, 제가 작성하는 대부분의 코드는 \u0026ldquo;보세요, 이렇게 하면 어떨까요\u0026rdquo; 하는데 매우 구체적인 예를 드는 패치에 가깝습니다. 무언가를 어떻게 해결하는가에 대한 고수준의 이론적 토론에 빨려들어가기가 쉽습니다, 그리고 어떤 해결책을 설명하는 최선의 방법은 많은 경우 전체가 아니라 약간의 코드를 작성하고 그걸 구체적으로 만드는 것임을 알고 있습니다.\n저의 진짜 작업시간은 이메일을 읽고 쓰는데 쓰이기 때문입니다. 그건 대부분 소통을 하는 것이지, 코딩하는 게 아닙니다. 사실, 저는 지금과 같이 저널리스트나 기술 블로거들 등과 대화하는 종류의 것들을 말 그대로 제 업무시간의 한 부분으로 여깁니다 - 실제 기술적 토론에 비해 낮은 우선순위를 가질 수 있겠지만, 전 이런 종류의 일에도 적지 않은 시간을 사용합니다.\n그리고, 맞습니다, 전 코드리뷰에도 시간을 씁니다만, 솔직히 제가 풀리퀘스트를 받는 시점에서는 해당 코드는 일반적으로 이미 여러 사람들에게 리뷰가 되어 있어야 합니다. 따라서 저는 여전히 패치들을 들여다 보긴 합니다만, 실제로는 그 패치에 대한 설명과 그 패치가 어떻게 제게 오게 되었는지에 대한 과정을 더 보는 경향이 있습니다. 그리고 제가 오랫동안 함께 일한 사람들에 대해서는 그것조차 하지 않습니다: 그들은 그들의 서브시스템의 메인테이너이고, 전 그들의 일을 마이크로매니징 하기 위해 존재하지 않습니다.\n따라서 상당히 자주, 제 주된 일은 \u0026ldquo;거기 있는 것\u0026rdquo;, 취합 지점이 되는것, 그리고 릴리즈를 관리하고 강제하는 사람이 되는 것입니다. 달리 말하자면, 제 일은 일반적으로 낮은 수준의 코드보다는 관리 프로세스에 대한 것입니다.\nJA: 당신의 작업 환경은 어떤가요? 예를 들어, 방해 없는 어두운 방을, 아니면 경치가 좋은 방을 선호하나요? 주로 조용한 곳에서 일합니까, 아니면 음악을 들으며 일합니까? 어떤 하드웨어를 주로 사용하나요? 터미널에서 \u0026lsquo;vi\u0026rsquo; 를 사용해 코드리뷰를 하나요, 아니면 화려한 IDE 를 사용하나요? 그리고, 이 일을 위해 선호하는 리눅스 배포판이 있나요?\nLT: 제 방은 완전히 어둡지는 않습니다만 제 책상 옆 창문에 블라인드를 닫아두고는 있는데, 밝은 태양빛을 (오레곤의 이맘때에는 흔치 않지만요) 원치 않기 때문입니다. 그러니 경치는 없어요, 그저 (혼잡한) 책상과 두개의 4k 모니터 그리고 책상 아래 고성능 데스크탑 컴퓨터 만 있습니다. 그리고 제가 밖에 있을 때 테스트를 하기 위해 두개의 랩탑이 있습니다.\n그리고 저는 조용한데서 일하길 바랍니다. 전 기계식 디스크 드라이브의 - 지금으로부터 10년도 전에 SSD 만을 사용했기에 행복하게도 쓰레기통에 버렸죠 - 소음을 싫어해왔고 시끄러운 CPU fan 도 받아들일 수 없어요.\n그리고 모든 일은 전통적인 터미널에서 합니다, \u0026lsquo;vi\u0026rsquo; 를 사용하진 않지만요. 저는 \u0026ldquo;micro-emacs\u0026rdquo; 라고 불리는, 일부 키 바인딩이 비슷하단 점을 제외하면 GNU emacs 와 전혀 관련없는 혐오스런 것을 사용합니다. 전 헬싱키 대학에 있던 어린 시절부터 이것에 익숙해졌고, 이로부터 아직 졸업하지 못했어요, 조만간 그래야만 한다고 생각하지만요. 저는 몇년 전에 이 에디터에 (매우 약간의) utf-8 지원 기능을 추가했습니다만, 이젠 정말 이 도구의 나이가 보이기 시작하고, 80년대에 만들어졌다는 모든 징표를 보이고 있으며 제가 사용하는 버전은 90년대 중반부터 관리되지 않고 있는 한 fork 입니다.\n헬싱키 대학은 이게 DOS, VAX/VMS 와 유닉스에서 동작한다는 이유로 이걸 사용했고, 그게 제가 이걸 소개받은 이유입니다. 지금 제 손가락은 이것에 너무 익숙해졌습니다. 전 이제 정말 관리되고 있고 utf-8 을 올바르게 지원하는 무언가로 옮겨타야만 합니다. 아마도 \u0026rsquo;nano\u0026rsquo; 로 넘어갈 수 있겠죠. 하지만 제 과거의 쓰레기 작업물들은 제 늙은 손가락들에게 새로운 기술을 가르치도록 강제할 만한 것이 되진 않았죠.\n그러니 제 데스크탑 환경은 매우 간단합니다: 몇개의 텍스트 기반 터미널이 열려 있고, 웹브라우저에 이메일이 (그리고 몇개 더 탭이 있는데, 대부분 뉴스와 기술 사이트를 열어둡니다) 열려 있죠. 전 충분한 데스크탑 공간을 갖길 원하는데, 제법 큰 터미널 윈도우들에 (전 터미널을 100x40 크기로 일단 띄우고 필요에 따라 크기를 조정해 나갑니다) 익숙하고, 여러 터미널을 나란히 띄워두기 때문입니다. 그래서 두개의 4k 모니터를 사용하죠.\n전 제 컴퓨터에 페도라를 사용합니다, 그걸 \u0026ldquo;선호\u0026rdquo; 하기 때문은 아니고, 제가 거기 익숙하기 때문입니다. 전 배포판에 대해선 크게 신경쓰지 않습니다 - 제게 있어 그건 대부분 어떤 기계의 커널을 교체하고 그 위에서 일할 수 있게끔 리눅스를 설치하고 제 도구들을 셋업하기 위한 하나의 방법일 뿐입니다.\nJA: 리눅스 커널 메일링 리스트 는 커널 개발이 공개적으로 일어나는 곳이고, 매우 소통량이 많습니다. 그 수많은 이메일을 어떻게 다루시나요? 메일링 리스트 외부에서 협업하고 소통하기 위한 다른 방법들을 알아보셨나요, 또는 당신이 하는 일을 위해 완벽한 간단한 메일링 리스트 같은게 있나요?\nLT: 오, 전 커널 메일링 리스트를 직접 읽지 않아요, 수년째 그래왔어요. 그건 너무 너무 많아요.\n커널 메일링 리스트의 핵심은 그게 모든 토론에 cc로 붙는다는 (음 - 여러개의 커널 메일링 리스트들 가운데 하나가요, 그리고 전통적인 lkml 리스트는 더 적당한 리스트가 없을 때 사용됩니다) 점입니다. 그리고 그런 방법으로, 새로운 사람이 토론에 참여하게 될 때, 그들은 커널 메일링 리스트를 봄으로써 과거 기록과 배경을 알 수 있는 거죠.\n그러므로 저는 이 리스트를 구독하지만 제가 개인적으로 cc 되지 않은 모든 lkml 이메일은 자동으로 기록함으로 가게 해서 기본적으로는 전 그것들을 읽지 않게 해왔습니다. 하지만 이후에 어떤 문제가 제게 올라오면, 그 모든 토론은 필요해지기 전까지는 제 인박스에 있진 않았지만 제 이메일에 있기 때문에, 제게 보이게 되는 거죠.\n요즘은 저는 lore.kernel.org 기능을 대신 사용하는데, 그게 잘 작동하기도 하고 그걸 바탕으로 만들어진 도구들도 몇가지 있기 때문입니다. 따라서 제 메일 저장함으로 자동으로 옮겨지도록 하는 대신, 토론들이 그 방법으로 보여지게 합니다. 하지만 기본적인 워크플로우는 개념적으로 동일합니다.\n전 여전히 상당한 양의 이메일을 받습니다, 분명히요 - 하지만 여러 측면에서 수년간 상황이 좋아져 가고 있습니다. 그 중 큰 부분은 Git 과 커널 릴리즈 흐름이 잘 동작하고 있다는 점입니다: 우린 코드 흐름과 도구들에 대한 많은 문제들을 가져왔습니다. 제 이메일 상황은 20세기에서 21세기로 넘어오던 시절, 즉 여전히 거대한 패치 폭탄을 다뤄야 했고 개발 흐름에 큰 확장성 문제를 가지고 있던 때에는 정말 훨씬 훨씬 더 나빴습니다.\n그리고 이 메일링 리스트 (와 이를 둘러싼 도구 사용) 모델은 정말 잘 동작했습니다. 이는 사람들이 이메일 (1대1 메일과 메일링 리스트) 에 더해 다른 소통 수단을 사용하지 않는다는 말이 아닙니다: 다양한 실시간 채팅을 (IRC 가 전통적인 수단이죠) 좋아하는 사람들이 있습니다. 전 그걸 사용하지 않았지만, 어떤 사람들은 브레인스토밍에 그걸 사용하는 걸 좋아하는게 분명합니다. 하지만 \u0026ldquo;저장소로써의 메일링 리스트\u0026rdquo; 모델은 매우 잘 동작하며, 모든 \u0026ldquo;개발자간에 패치를 이메일로 보내기\u0026rdquo; 와 \u0026ldquo;문제 보고서를 이메일로 보내기\u0026rdquo; 와 함께 매끄럽게 잘 동작합니다.\n그러므로 이메일은 주요 소통 채널로 남아있고, 이메일에 패치를 포함시킴으로써 기술 문제를 토론하기 쉽게 합니다. 그리고 이건 여러 시간대에서 협업하는 환경에서도 잘 동작하는데, 이는 사람들이 지리적으로 흩어져 있을 때 매우 중요합니다.\nJA: 전 대략 10년간 커널 개발 동향을 자세히 들여다보며 이를 KernelTrap 에 블로깅하고 새로운 기능이 발전될 때마다 그에 대해서도 글을 써왔습니다. 전 이를 8년간 지속된 2.6.x 버전을 이어 3.0 커널이 릴리즈 되던 즈음부터 그만뒀습니다. 3.0 릴리즈 후 커널에 일어난 더 흥미로운 일들 몇가지를 요약해 주실 수 있을까요?\nLT: 헤헤. 그건 제가 요약을 시작할수도 없을 만큼 오래 전 일입니다. 3.0 이후 10년이 지났습니다, 그리고 그 시간 동안 많은 기술적 변화가 있었습니다. ARM 이 성장했고 ARM64 는 우리의 주요 아키텍쳐 중 하나가 되었습니다. 무척 많은 새로운 드라이버들과 핵심 기능들이 추가되었습니다.\n지난 10년간 흥미로운 것이 있다면 우리가 실제 개발 모델을 어떻게 정말 매끄럽게 유지했는가, 그리고 무엇이 변화되지 않았는가일 겁니다.\n우린 수십년간 여러 버전명 규칙과 개발 모델들을 사용해 왔지만, 3.0 릴리즈는 우리가 그간 사용해온 모델을 완성시켰습니다. \u0026ldquo;릴리즈는 시간 기반의 것임, 버전명의 숫자는 그저 숫자일 뿐이며 어떤 기능에 종속적이지 않음\u0026rdquo; 이라는 모든 원칙을 공식적이게 만든 것이죠.\n우리는 이 시간 기반 릴리즈를 2.6.x 시대 머지 윈도우부터 시작했으므로, 그 부분은 새로운 건 아니었습니다. 하지만 3.0 은 \u0026ldquo;숫자가 의미를 가지는\u0026rdquo; 것에 대한 마지막 흔적을 지워버렸습니다.\n우린 무작위 숫자 규칙을 가졌었고 (주로 1.0 전), \u0026ldquo;홀수 마이너 버전 숫자는 개발 커널을 의미하고 짝수 마이너 버전 숫자는 안정화된 제품 커널을 의미함\u0026rdquo; 모델을 사용했고, 그 후 2.6.x 시작과 함께 시간 기반 릴리즈 모델을 사용했습니다. 하지만 사람들은 여전히 \u0026ldquo;메이저 버전 숫자를 올리는 건 무슨 의미를 가질까\u0026rdquo; 라는 질문을 가지고 있었죠. 그리고 3.0 은 메이저 버전 숫자 또한 의미가 없음을, 우린 그저 숫자들이 쉽게 다룰 수 있도록, 너무 커지지 않도록 노력할 뿐임을 공식화 했습니다.\n지난 10년간, 우린 분명 거대한 변화들을 만들었습니다 (Git 이 통계 숫자를 쉽게 볼 수 있게 해줍니다: 17,000여명의 개발자에 의해 만들어진 75만여개의 커밋). 하지만 그 개발 모델 자체는 정말로 상당히 매끄럽고 안정적이었습니다.\n그리고 항상 그랬던 건 아닙니다. 커널 개발의 처음 20년간은 무척 고통스런 개발 모델 변화로 가득했습니다. 최근 10년은 릴리즈 측면에서 훨씬 예측 가능하게 되었습니다.\nJA: 지금 기준으로 가장 최신 릴리즈는 5.12-rc5 입니다. 릴리즈 프로세스는 얼마나 표준화 되었나요? 예를 들어, 어떤 종류의 변경사항들이 -rc1, -rc2 등으로 들어갑니까? 그리고 어느 시점에서 당신은 해당 릴리즈가 공식적으로 이뤄질 준비가 되었다고 결정하나요? 만약 당신이 틀렸고 최종 릴리즈 후에 큰 퇴행적 문제가 발견되면 어떤 일이 벌어지며, 그런 일이 얼마나 자주 일어나나요? 이 프로세스는 수년간 어떻게 발전해 왔습니까?\nLT: 전 이걸 앞에서 암시적으로 언급했습니다: 프로세스 자체는 정말 상당히 표준화 되었습니다, 그리고 지난 10년간 변하지 않았습니다. 그 전에는 여러번의 대격변을 거쳐왔습니다만 3.0 부터는 사실상 거의 시계장치처럼 되었습니다 (그리고 사실 그로부터 수년 전 - Git 으로의 전환이 여러 측면에서 오늘날의 프로세스의 시작이었으며, 모두가 거기 익숙해지기까진 시간이 조금 걸렸습니다).\n그러니까, 제가 생각하기로는 우린 지금까지 대략 15년간 \u0026ldquo;2주일의 머지 기간\u0026rdquo; 에 이어 최종 릴리즈 전에 대략 6-8개의 주간 릴리즈 후보를 내놓기를 계속해 왔습니다.\n그리고 그 규칙은 항상 동일했습니다, 항상 완전하고 엄격하게 강제된 건 아니었지만요: 머지 기간은 \u0026ldquo;테스트 되었고 준비되었다\u0026rdquo; 생각되는 새로운 코드를 위한 시간이고, 이어지는 대략 두달의 기간은 수정사항들을 받아들이고 모든 문제가 해결되었음을 확실히 하기 위한 시간입니다. 항상 그랬던 건 아니고, 어떤 때에는 \u0026ldquo;준비되었다\u0026rdquo; 여겨진 코드가 비활성화되거나 릴리즈 전에 완전히 제거되기도 했습니다.\n그리고 이게 반복됩니다 - 그러니 우린 대략 매 10주 정도마다 릴리즈를 합니다.\n그리고 이 릴리즈 기준은 제가 충분히 준비되었다는 자신감을 느끼는가로, 어떤 종류의 문제들이 여전히 보고되고 있는가에 기반합니다. 어떤 영역이 여전히 이 rc 게임 기준으로는 늦은 문제들을 보인다면, 전 문제에 연관된 변경사항들을 무효화 시켜버리고 \u0026ldquo;우린 이걸 완전히 이해한 후에 나중 릴리즈에서 처리합시다\u0026rdquo; 라고 말하는데 무척 적극적이 됩니다, 다만 전체적으로 이런 경우는 상당히 드뭅니다.\n이게 항상 잘 동작할까요? 아니요. 커널이 일단 릴리즈 되면 - 그리고 특히 어떤 배포판이 그걸 일단 골라잡으면 - 새로운 사용자가 생기고, 개발 중에는 그걸 테스트 하지 않았던, rc 시리즈 기간에 우리가 발견하지 못했던, 제대로 동작하지 않는 것들을 발견해내는 사람들이 생깁니다. 이건 피할 수 없는 문제에 가깝습니다. 이게 우리가 릴리즈 후에 수정 사항들을 추가하는 \u0026ldquo;안정화 (stable) 커널\u0026rdquo; 트리들을 갖는 이유 중 하나입니다. 그리고 일부 안정화 커널들은 다른 것들보다 더 오래 관리되어서 LTS (\u0026ldquo;Long Term Support\u0026rdquo;) 커널이라 불립니다.\n이 모든 것들이 지난 10년간 거의 변하지 않았습니다, 더 많은 자동화를 하게 되곤 했지만 말이죠. 커널 테스트 자동화는 일반적으로 어렵습니다만 - 부분적으로는 커널의 많은 부분이 하드웨어가 있어야 돌아갈 수 있는 드라이버들이기 때문이죠 - 부팅과 성능, 다양한 무작위적 부하 테스트를 하는 여러 곳이 존재합니다. 그리고 이게 수년간 상당히 개선되었습니다.\nJA: 작년 11월에 당신은 애플의 새 컴퓨터들에 장착된 애플의 신형 ARM64 칩에 감명받았다고 알려졌습니다. 리눅스에서 그것들을 지원하기 위한 개발 노력을 팔로우 하고 있나요? 그걸 위한 작업물이 \u0026lsquo;for-next\u0026rsquo; 에 머지된 걸 봤습니다. 조만간 나올 5.13 커널부터는 애플의 맥북 하드웨어가 리눅스로 부팅될 수 있을까요? 당신은 얼리어답터가 되곤 합니까? ARM64 는 얼마나 중요합니까?\nLT: 저는 매우 가끔 그걸 체크합니다만, 아직 그 작업은 초기 단계에 있습니다. 당신도 이야기 했듯, 이 초기 지원 기능이 5.13 에 머지될 확률이 높습니다, 하지만 그건 그저 시작 단계일 뿐이란 걸, 그리고 아직은 리눅스를 가지고 애플 하드웨어를 유용하게 운용할 수 있게 만들 수준은 아님을 알아두셔야 합니다.\n문제가 되는건 arm64 부분이 아니라, 그 주변에 위치하는 하드웨어를 (특히 SSD 와 GPU) 위한 드라이버들입니다. 지금까지, 그 초기 작업물은 일부 낮은 단계의 것들을 동작하게 만들어냈지만, 부팅 초기에 하드웨어를 사용 가능하게 하는것 외의 유용한 것은 어느것도 해내지 못했습니다. 사람들이 시도해 볼만한 진짜 선택 사항이 되기까지는 시간이 걸릴 겁니다.\n하지만 개선된 건 애플 하드웨어만이 아닙니다 - arm64 를 위한 인프라는 상당히 발전했고, 그 코어는 서버 환경에서 \u0026ldquo;그저 그런\u0026rdquo; 수준을 넘어서서 훨씬 경쟁적인 것이 되었습니다. 얼마전만 해도 arm64 서버 환경은 무척 슬픈 상황이었습니다만, Amazon 의 Graviton2 와 Ampere 의 Altra 프로세서들은 - 둘 다 훨씬 개선된 ARM Neoverse IP 에 기반해 있습니다 - 수년전에 제공되던 것들에 비해 훨씬 낫습니다.\n전 사용할 수 있는 ARM 기계를 이제 10년도 넘게 기다려왔습니다, 그리고 여전히 그 단계는 아니지만, 어느때보다도 그 때가 가까워진게 분명합니다.\n사실, 전 제가 ARM 기계를 그보다도 훨씬 오랫동안 원해왔다고 말할 수 있다고 생각합니다 - 제가 10대이던 시절, 제가 정말 원했던 건 Acorn Archimedes 였는데, 구하기도 어렵고 가격도 비싸서 Sinclair QL (M68008 프로세서) 쪽으로 방향을 틀어야 했고, 수년 후에는 i386 PC 를 대신 사용했죠.\n그러니 말하자면 수십년간의 개발이 이어졌습니다만, 그것들은 여전히 어디서나 구하기가 쉽지는 않고 컴퓨터로써의 가성비가 제게는 충분하지 않습니다. 어느 날인가는 그렇게 될겁니다. 바라건대, 너무 멀지는 않은 미래에요.\nJA: 커널 내에 최적화 되어 있지 않으며 그걸 제대로 해결하려면 완전히 재작성해야 하는 부분이 있을까요? 달리 말하자면, 커널은 서른살이나 나이를 먹었고 지식, 언어, 그리고 하드웨어는 그 30년간 많이 바뀌었습니다: 만약 당신이 지금부터 무언가를 바닥부터 다시 작성한다면, 무엇을 바꾸겠습니까?\nLT: 사실 우린 필요하다면 무언가를 완전히 재작성하는데에도 무척 훌륭했습니다, 따라서 해결되지 않은, 재앙이 될만한 것들은 재작성된 지 오래입니다.\n물론, 우린 상당히 많은 \u0026ldquo;호환성\u0026rdquo; 계층들이 있습니다만, 그것들은 일반적으로 끔찍하지는 않아요. 그리고 설령 그것들을 바닥부터 재작성 한다고 해도 그 호환성 계층들이 사라질 것인지도 분명치 않습니다 - 그것들은 오래된 바이너리들을 위한 하위 호환에 대한 (그리고 종종 오래된 아키텍쳐, 예를 들어 32-bit x86 앱을 x86-64 에서 돌리는, 하위 호환을 위한) 것들입니다. 전 하위 호환을 매우 중요하다고 여기기 때문에, 저는 설령 재작성을 하더라도 그것들은 유지하고 싶습니다.\n모든 것은 개선될 수 있다는 점에서 \u0026ldquo;최적화 되지 않은\u0026rdquo; 것들은 분명 많습니다, 하지만 당신의 질문의 논조를 놓고 보건대, 그 중 제가 경멸하는 것은 어느 것도 없다고 말해야겠습니다. 누구도 정리를 할만큼 신경쓰지도 않을, 따라서 추한 일들을 할지도 모르는 구식 드라이버들이 있습니다, 하지만 여기서 핵심은 \u0026ldquo;아무도 신경쓰지 않음\u0026rdquo; 입니다. 그건 문제가 되지 않아왔습니다, 그리고 그게 문제가 되는데 그게 우리가 그걸 신경쓸 사람을 찾을 수 없는 구식 지원이라면 그걸 제거해 버리는 데에 상당히 적극적이 되곤 합니다. 따라서 수년간 우리는 많은 수의 드라이버를 제거해 왔고, 더이상 유지보수할 의미가 없는 경우엔 아키텍쳐 전체 지원도 제거해 왔습니다.\n\u0026ldquo;재작성\u0026rdquo; 의 유일한 주요 이유는 전체 구조가 더이상 말이 되지 않는 어떤 사용 사례를 찾았을 경우일 겁니다. 가장 있을법한 시나리오는 리눅스가 제공하는 모든 것을 필요로 하지 않는, 그리고 매우 적은 하드웨어 사용량을 가져서 지난 세월동안 거대해진 리눅스보다는 더 작고 간단한 무언가를 원하는, 어떤 작은 임베디드 시스템 같은 경우가 되겠습니다.\n리눅스는 거대해졌으니까요. 오늘날에는 작은 하드웨어 (예를 들어 휴대폰을 생각해 봅시다) 도 리눅스가 처음 개발된 기계보다 훨씬 기능이 많습니다.\nJA: 성능과 안전성을 위해 특별히 설계된 언어인 Rust 를 이용해 최소 일부 부분을 재작성하는 건 어떻게 생각합니까? 이 방법으로 개선해볼 곳이 있습니까? Rust 같은 다른 언어가 커널의 C 를 대체하는 것이 가능할 수는 있다고 느끼십니까?\nLT: 우린 지켜볼 겁니다. 전 Rust 가 커널의 핵심부에 사용될 거라고는 생각지 않습니다, 하지만 개별 드라이버들 (그리고 어쩌면 전체 드라이버 서브시스템들) 을 그걸로 돌리는 건 완전히 불가능하게 들리지는 않습니다. 어쩌면 파일시스템도요. 그러니 \u0026ldquo;C 를 대체\u0026rdquo; 하는 건 아니지만, \u0026ldquo;말 되는 곳에서는 C 코드를 강화\u0026rdquo; 시키는 것에 가깝겠습니다.\n물론, 특히, 드라이버는 실제 커널 코드의 절반 가량을 차지합니다, 따라서 Rust 로 개선할 공간이 많습니다, 하지만 누구도 현존하는 드라이버들을 대대적으로 Rust 로 재작성할 것이라 기대하진 않는다고, 그보다는 \u0026ldquo;어떤 사람들은 새 드라이버를 Rust 로 짤 수도, 몇몇개의 드라이버는 그게 말이 된다면 재작성될 수도 있겠다\u0026rdquo; 고 생각하는 편에 가깝습니다.\n하지만 지금 당장의 상황은 \u0026ldquo;사람들이 그걸 시도해 보고 가지고 놀고 있다\u0026rdquo; 에 불과합니다. 장점을 내세우기는 쉽지만, 분명한 복잡성도 존재합니다, 따라서 저는 그 약속된 장점들이 정말로 실현될 것인지 기다리며 지켜보는 접근법을 취할 겁니다.\nJA: 개인적으로 커널에서 가장 자랑스러운 특별한 부분이 있습니까?\nLT: 제가 이야기 하곤 하는 부분은 VFS (\u0026ldquo;virtual filesystem\u0026rdquo;) 계층 (그리고 특히 pathname 탐색) 과 VM 코드입니다. 앞의 것은 리눅스가 그 기본적인 일들을 (pathname 을 탐색하는 건 운영체제의 매우 핵심 작업입니다) 현존하는 그 무엇보다도 훨씬 잘 하기 때문입니다. 그리고 뒤의 것은 우리가 20개 이상의 아키텍쳐를 지원하고, 우린 여전히 통합된 VM 계층으로 그걸 해내고 있는데, 제 생각에 이건 무척 인상적이기 때문입니다.\n하지만, 이는 또한 \u0026ldquo;커널의 어떤 부분을 당신은 신경쓰십니까\u0026rdquo; 라는 질문이기도 합니다. 커널은 뭐가 가장 중요한지에 대해 다른 개발자들은 (그리고 다른 사용자들이) 다른 의견을 가질 수 있기 충분할 정도로 거대합니다. 어떤 사람들은 스케쥴링이 커널의 가장 짜릿한 부분이라 생각합니다. 또다른 사람들은 디바이스 드라이버의 핵심을 찌르는 부분을 (우린 그런 것들을 많이 가지고 있습니다) 좋아합니다. 전 개인적으로 VM 과 VFS 영역에 더 참여하는 경향이 있으므로, 자연적으로 그것들을 꼽게 됩니다.\nJA: Pathname 탐색에 대한 설명 을 찾았는데, 제가 생각한 것보다 더 복잡하군요. 무엇이 리눅스의 구현을 다른 운영체제의 것들에 비해 훨씬 낫게 만듭니까? 그리고 \u0026ldquo;더 낫다\u0026rdquo; 는 말로 당신이 의미하는 건 뭡니까?\nLT: Pathname 탐색은 커널 개발자 외의 대부분의 사람들은 그걸 문제라고 여기지도 않을 정도로 흔하고 기본적인 것입니다: 그들은 그저 파일을 열고 그 모든 걸 당연한 것으로 여기죠.\n하지만 그건 정말 잘하기가 무척 복잡합니다. 모든 것들이 항상 pathname 탐색을 하기 때문에, 그건 무척 성능에 중요하고, SMP 환경에서 당신 역시 확장 가능하길 바라는 영역 중 하나일 것이 분명하고, 락킹 (locking) 관련한 복잡성이 높기 때문입니다. 그리고 당신은 어떤 IO 도 하고 싶지 않을 게 분명합니다, 따라서 캐쉬 사용이 매우 중요합니다. 사실, pathname 탐색은 그걸 낮은 단계의 파일시스템이 하도록 둘 수 없을 정도로 중요한데, 우린 20개가 넘는 다른 파일시스템을 가지고 있고 그것들이 각자의 캐쉬 사용과 락킹을 하도록 두는건 완전한 재앙이 될 것이기 때문입니다.\n따라서 VFS 계층이 하는 주요 작업 중 하나는 pathname 요소들의 모든 락킹과 캐쉬 사용을 처리하고, 모든 직렬화와 mount point 횡단을 처리하고, 모든 일을 대부분 lock-free 알고리즘 (RCU) 으로 , 경우에 따라선 일부 무척 영리한 lock 같은 것들을 (리눅스 커널의 \u0026ldquo;lockref\u0026rdquo; lock 은 매우 특수한 \u0026ldquo;레퍼런스 카운트를 갖는 spinlock\u0026rdquo; 으로 말 그대로 dcache 사용을 위해 설계되었으며, 기본적으로는 많은 일반적 상황에서 lock 사용을 제거할 수 있는 특수한 락을 인지하는 레퍼런스 카운트입니다) 사용해 처리하는 것입니다.\n결과: 낮은 단계의 파일 시스템들은 캐쉬에 올라오지 않은 것들을 위해선 여전히 탐색을 해야 하지만, pathname 탐색을 위한 캐쉬 사용과 모든 일관성 규칙들과 원자성 규칙들에 대해선 걱정하지 않아도 됩니다. VFS 가 그것들을 위해 이 모든 걸 처리합니다.\n그리고 그건 모든 다른 운영체제들이 구현한 모든 것보다 성능이 나으며, 수천개의 CPU 를 가진 기계에서조차 기본적으로는 완전하게 확장됩니다. 그리고 그 기계들이 같은 디렉토리들을 건드는 경우에조차 그렇습니다 (루트 디렉토리나 프로젝트 홈 디렉토리 같은 것들에는 많은 수의 쓰레드로 돌아가는 어플리케이션이라 해도 쓰레드별 행동 같은 것으로 분산되지 않고 모두 동시에 접근하려 할 것이니까요).\n따라서 이건 단순히 \u0026ldquo;더 나은\u0026rdquo; 게 아니라, \u0026ldquo;더 나은\u0026rdquo; 것입니다, \u0026lsquo;더\u0026rsquo; 에 대한 강조와 함께 말이죠. 어떤 것도 여기 근접하지 않고 있습니다. 리눅스의 dcache 는 자신만의 클래스에 있습니다.\nJA: 작년은 전세계적으로 힘든 해였습니다. COVID-19 판데믹은 커널 개발 프로세스에 어떤 영향을 끼쳤습니까?\nLT: 실제로 매우 최소한의 영향만을 끼쳤습니다, 우리가 항상 일해온 방식 때문입니다. Email 은 실로 놀라운 도구임이 드러났고, 우린 대면 미팅에 의존하지 않았습니다.\n그래요, 작년의 연간 커널 서밋에는 영향을 미쳤습니다 (그리고 올해도 불투명합니다 \u0026ndash; 역자 주: 2021년 커널 서밋도 virtual 로 가게 되었습니다), 그리고 대부분의 컨퍼런스가 취소되거나 가상으로 전환되었습니다. 그리고 전에는 사무실에서 일하던 사람들이 집에서 일하기 시작했습니다 (하지만 많은 코어 커널 메인테이너들은 이미 그래왔습니다). 그러니 많은 것들이 바뀌었지만, 핵심 개발 그 자체는 전과 동일하게 동작했습니다.\n그리고 그건 우리 모두의 삶에 다른 형태로 영향을 끼친 것 같습니다 - 그저 일반적인 사회적 영향이요. 하지만 전체적으로 보면 우린 이미 사람들과 거의 전부 이메일로만 소통해오던 커널 개발자들이었기에 가장 적게 영향받은 사람들일 겁니다.\n분산 버전 컨트롤 시스템, Git JA: 리눅스는 당신의 오픈소스에의 여기저기 퍼져있는 공헌들 가운데 하나에 불과합니다. 2005년에 당신은 또한 엄청나게 인기 있는 분산 소스 컨트롤 시스템인 Git 을 만들었죠. 당신은 리눅스 커널 소스 트리를 독점 소프트웨어인 Bitkeeper 에서 새로 만들어진 오픈소스 기반의 Git 으로 곧바로 옮겼고, 같은 해에 관리 권한을 Junio Hamano 에게 넘겼습니다. 여기에 매력적인 역사적 일들이 많이 있습니다, 무엇이 당신에게 이 프로젝트의 리더쉽을 그렇게 빨리 넘기도록 만들었으며, 당신은 어떻게 Junio 를 발견하고 선택했습니까?\nLT: 이에 대한 답변은 두 부분으로 나뉠 수 있겠습니다.\n첫번째 부분은 저는 새로운 소스 컨트롤 시스템을 만들고 싶지 않았다는 겁니다. 리눅스는 제가 하드웨어와 소프트웨어 간의 낮은 단계의 인터페이스가 매력적임을 발견했기 때문에 만들었습니다. 반면에, Git 은 필요에 의해 만들어졌습니다: 제가 소스 컨트롤이 흥미롭다고 여겨서가 아니라, 당시 존재하던 대부분의 소스 컨트롤 시스템을 경멸했고, 제가 발견한 입에 맞고 리눅스 개발 모델을 위해 상당히 잘 동작했던 것 (BitKeeper) 은 더이상 사용할 수 없게 되었기 때문이었습니다.\n그 결과: 전 리눅스를 30년 넘게 개발하고 있습니다 (첫번째 릴리즈의 기념일은 아직 몇달 남았습니다만 전 리눅스가 될 것의 개발을 30년 전에 이미 시작했습니다), 그리고 그동안 이것을 계속 유지보수해 왔습니다. 하지만 Git 은요? 전 제가 그걸 장기적으로 유지보수하고 싶다고 한번도 생각하지 않았습니다. 전 그걸 사용하는 건 좋아합니다, 그리고 분명히 세계에 존재하는 최고의 SCM 이라고 생각합니다, 하지만 그건 제 근본적인 열정과 흥미가 아닙니다, 제가 말하고자 하는게 뭔지 안다면 이해하시겠죠.\n그렇기 때문에 전 항상 누군가가 그 SCM 을 저를 위해 유지보수해 주기를 원했습니다 \u0026ndash; 사실 애초에 그걸 만들 일도 없었다면 가장 행복했을 겁니다.\n이게 말하자면 그 배경입니다.\nJunio 에 대해 말하자면 - 그는 Git 개발자로 나선 바로 첫번째 사람들 가운데 한명이었습니다. 그는 제가 Git 의 첫번째 (그리고 매우 조악한) 버전을 공개한지 몇일만에 그의 변경사항들을 보내왔습니다. 그러니 Junio 는 실제로 Git 의 초창기부터 함께해 왔습니다.\n하지만 제가 첫번째로 나타난 아무에게나 프로젝트를 넘긴 건 아니었습니다. 전 Git 을 몇달동안 유지보수했고, 제가 Junio 에게 그가 메인테이너가 되고 싶은지 물어보게끔 만든 것은 설명하기 어려운 \u0026ldquo;좋은 취향\u0026rdquo; 에 대한 것이었습니다. 이걸 위한 더 나은 설명을 저는 못하겠습니다: 프로그래밍은 기술적 문제를 해결하는 것입니다만, 그걸 어떻게 해결하는가, 그걸 어떻게 생각하는가 또한 중요하고, 그건 시간에 걸려 깨닫게 되는 것들 중 하나입니다: 많은 사람들이 그 \u0026ldquo;좋은 취향\u0026rdquo; 을 갖고 \u0026ldquo;옳은\u0026rdquo; 해결책을 고릅니다.\n저는 프로그래밍이 예술이라 말하고 싶지는 않습니다, 그건 대부분 그저 \u0026ldquo;좋은 엔지니어링\u0026rdquo; 이기 때문입니다. 전 토마스 에디슨의 \u0026ldquo;1퍼센트의 영감과 99퍼센트의 땀\u0026rdquo; 이야기를 믿습니다: 그건 작은 디테일들과 매일 끙끙대는 일의 거의 본질입니다. 하지만 그 \u0026ldquo;영감\u0026rdquo; 부분도 존재합니다, 단순히 어떤 문제를 해결하는 것을 넘어서는 그 \u0026ldquo;좋은 취향\u0026rdquo; 이요 - 깨끗하고 훌륭하게, 그리고 그래요, 심지어 아름답게.\n그리고 Junio 는 그 \u0026ldquo;좋은 취향\u0026rdquo; 을 가지고 있었습니다.\n그리고 매번 Git 이 이야기 될 때마다, 전 그걸 아주 아주 분명하게 기억하려 노력합니다: 제가 Git 의 개발을 시작했고 그 핵심 아이디어들을 설계했을 거예요, 하지만 전 종종 그 부분만을 가지고 너무 많은 명성을 받습니다. 15년이 넘게 지났습니다, 그리고 전 그 첫번째 해에만 Git 에 참여했습니다. Junio 는 모범적인 메인테이너가 되었고, 그가 Git 을 오늘날의 모습으로 만든 바로 그 사람입니다.\n그건 그렇고, 이 모든 \u0026ldquo;좋은 취향\u0026rdquo; 그리고 그걸 가진 사람을 찾는것, 그리고 그들을 믿는 것 - 그건 Git 에 대한 것만이 아닙니다. 그건 또한 리눅스의 역사이기도 합니다. Git 과 달리, 리눅스는 분명 제가 여전히 활발히 관리하는 프로젝트입니다만, Git 과 매우 유사하게, 많은 다른 사람들이 참여하는 프로젝트이기도 하고, 리눅스의 큰 성공의 이유 중 하나는 말 그대로 수백명의, 그 정의하기 어려운 \u0026ldquo;좋은 취향\u0026rdquo; 을 가진, 그리고 커널의 각 부분을 관리하는 메인테이너들을 가졌다는 점이라고 생각합니다.\nJA: 어떤 메인테이너에게 권한을 줬지만 그건 잘못된 판단이었음이 드러난 적이 있나요?\nLT: 우리의 메인테이너쉽 구조는 그렇게 흑백논리적이거나 경직되어 있던 적이 없기 때문에 그런 문제가 일어난 적은 없습니다. 실제로, 우린 심지어 메인테이너쉽 제어를 제대로 문서화 하지도 않았습니다: 우린 MAINTAINERS 파일을 가지고 있습니다, 하지만 그건 여러분이 옳은 사람들을 찾기 위함이지, 어떤 배타적 소유권의 표시가 아닙니다.\n따라서 그 모든 \u0026ldquo;누가 무얼 소유하는가\u0026rdquo; 는 유동성 있는 가이드라인일 뿐이고, \u0026ldquo;이 사람이 활발히 활동 중이고 일을 잘 합니다\u0026rdquo; 에 가깝지 \u0026ldquo;앗, 우리가 저 사람에게 소유권을 줬는데 저사람이 일을 망쳤어\u0026rdquo; 같은게 아닙니다.\n그리고 그건 여러분이 한 서브시스템의 메인테이너인데 다른 서브시스템에서 필요한 게 생긴다면 종종 그 영역을 가로지를 수도 있다는 점에서 유동적입니다. 물론, 사람들은 실제로 그러기 전에 매우 많은 대화를 먼저 합니다만, 핵심은 그런 일이 실제로 벌어지고 있으며, \u0026ldquo;너만이 그 파일을 만질 수 있어\u0026rdquo; 부류의 규칙이 아니란 겁니다.\n사실, 이건 라이센스에 대해 이야기한 앞의 토론과 관계되어 있는 것이고, 어떻게 \u0026ldquo;Git\u0026rdquo; 의 설계 규칙 중 하나가 \u0026ldquo;모두가 각자의 트리를 가지고, 어떤 트리도 기술적으로 특별하지 않음\u0026rdquo; 이 되었는지에 대한 또다른 예입니다.\n많은 다른 프로젝트들이 기본적으로 어떤 사람들을 특별하게 만드는 도구들 - CVS 나 SVN 같은 - 을 사용했기 때문에 그리고 그게 기본적으로 그와 함께 \u0026ldquo;소유권\u0026rdquo; 을 가졌기 때문입니다. BSD 세계에서는 그걸 \u0026ldquo;commit bit\u0026rdquo; 이라 부르죠: 메인테이너에게 \u0026ldquo;commit bit\u0026rdquo; 을 부여함은 그 사람은 이제 그 중앙 저장소에 (또는 그 중 한 부분에) 커밋을 할 수 있음을 의미합니다.\n전 항상 그 모델을 싫어했는데, 그건 어쩔 수 없이 정치와, 어떤 사람들은 특별하고 암묵적으로 믿어지는 \u0026ldquo;파벌\u0026rdquo; 개발 모델을 초래하기 때문입니다. 그리고 문제는 \u0026ldquo;암묵적으로 믿어지는\u0026rdquo; 부분도 아닙니다 - 그건 사실 이 동전의 반대면으로, 다른 사람들은 믿음받지 못한다, 즉 정의에 따라 그들은 아웃사이더이며, 감시하에서만 움직일 수 있다는 겁니다.\n다시 말하지만, Git 에서 그런 상황은 존재하지 않습니다. 모두가 동등합니다. 누구나 저장소를 복사할 수 있고, 각자의 개발을 하며, 훌륭한 일을 해냈다면 그건 도로 원본 저장소로 병합될 수 있습니다 (그리고 그들이 뛰어난 일을 해낸다면, 그들은 메인테이너가 되어, 그 병합 작업을 스스로의 트리에 하는 사람들 중 하나가 될 겁니다).\n그러니 사람들에게 특별한 권한을 줄 필요가 없습니다 - 그 \u0026ldquo;commit bit\u0026rdquo; 은 필요 없습니다. 그리고 이는 또한 여러분이 정치행위를 방지하며, 암묵적으로 사람들을 믿을 필요도 없음을 의미합니다. 그들이 나쁜 일을 해버리는 경우가 생긴다면 - 또는 더 흔하게, 또다른 흥미를 찾아서 이 개발 커뮤니티에서 사라진다면 - 그것들은 도로 병합되지 않고, 신선한 새 아이디어를 가진 다른 사람들을 방해하지 않게 됩니다.\nJA: Git 의 새로운 기능들이 당신에게 감동을 주고, 당신의 워크플로우의 한 부분을 차지하게 되곤 하나요? 추가되길 바라는 기능이 있습니까?\nLT: 저의 사용처는 당연하게도 충족되어야 하는 첫번째 것이었습니다, 따라서 제게 있어 새로운 기능은 드물게만 필요했습니다.\n수년간, Git 은 상당히 개선되었고 그 중 일부는 제 워크플로우에도 눈에 띄는 것이 되었습니다. 예를 들어, Git 은 항상 무척 빨랐습니다만 - 무엇보다, 그건 제 설계 목표 중 하나였습니다 - 그 중 많은 것들은 일부 코어 프로그램들 간의 상호작용을 이루어지게 하는 셸 스크립트를 통해 이루어졌습니다. 수년간, 그 셸 스크립트 작업 중 대다수는 사라졌는데, 이는 제가 Andrew Morton 으로부터 받은 패치 폭탄을 제가 원래 할 수 있던 것보다도 빠르게 적용할 수 있음을 의미합니다. 이건 매우 만족스러운 일입니다, 그건 실제로 제가 성능 테스트를 위해 사용하던 초기의 벤치마크 중 하나였으니까요.\n그러니 Git 은 항상 제게 훌륭했지만, 더 나아져 가고 있습니다.\n바라는 큰 개선사항은 \u0026ldquo;규칙적인 사용자\u0026rdquo; 로써 사용하기에 더 나아지는 것입니다. 그것은 Git 워크플로우를 배우는 사람들과 이제 막 그것에 익숙해진 사람들 (Git 은 사람들이 기존에 익숙한 CVS 나 다른 것들과 무척 다른 워크플로우를 갖습니다) 에 달려있던 것이지만, 그 중 많은 부분은 Git 자체가 사용하기 더 즐거운 것이 되어가는 것에 달려 있습니다.\n두번째 파트는 여기서 보실 수 있습니다.\n","permalink":"https://sjp38.github.io/posts/ko/torvalds_interview_for_30th_anniversary_of_linux_kernel_part1/","summary":"리눅스 커널이 처음 공개된지 올해로 30년이 되었고, 이를 맞아 tag1 에서 리누스 토발즈와 인터뷰 를 했습니다: https://www.tag1consulting.com/blog/interview-linus-torvalds-linux-and-git 분량이 길어 두 파트로 나눠 올라왔는데, 해당 매체에 허락을 받고 이곳에 그 중 첫번째 파트의 번역을 올립니다.\n두번째 파트는 여기서 보실 수 있습니다.\n아래 분들께서 오타 등을 찾고 글을 다듬는 걸 도와주셨습니다. 감사의 말씀을 전합니다.\nganadist Jaehoon Kim 리눅스 커널 개발 Jeremy Andrews: 리눅스는 어디에나 사용되고 있고, 전체 오픈소스 세계에 영향을 끼쳤습니다. 물론, 처음부터 그런 건 아니었습니다.","title":"리눅스 30주년 맞이 리누스 토발즈 인터뷰 번역 - 파트 1"},{"content":"2019-09-27 이후로 perfbook 번역을 멈췄었군요. 이제 perfbook 2nd 에디션도 나왔으니[0], 바닥부터 번역을 다시 시작해 봅니다[1]. 물론, 예전 번역본은 여전히 있습니다[2].\n[0] https://mirrors.edge.kernel.org/.../perfbook/perfbook.html\n[1] https://github.com/sjp38/perfbook-ko_KR/commit/1c44ef30179b\n[2] https://github.com/sjp38/perfbook-ko_KR-pdf\n","permalink":"https://sjp38.github.io/posts/ko/perfbook_translate_restart/","summary":"2019-09-27 이후로 perfbook 번역을 멈췄었군요. 이제 perfbook 2nd 에디션도 나왔으니[0], 바닥부터 번역을 다시 시작해 봅니다[1]. 물론, 예전 번역본은 여전히 있습니다[2].\n[0] https://mirrors.edge.kernel.org/.../perfbook/perfbook.html\n[1] https://github.com/sjp38/perfbook-ko_KR/commit/1c44ef30179b\n[2] https://github.com/sjp38/perfbook-ko_KR-pdf","title":"perfbook 번역 재시작"},{"content":"I stopped translation of perfbook since 2019-09-27. Because the 2nd edition of perfbook is released[0], I\u0026rsquo;m starting the translation again[1], from the scratch. The old versions are still available, of course[2].\n[0] https://mirrors.edge.kernel.org/.../perfbook/perfbook.html\n[1] https://github.com/sjp38/perfbook-ko_KR/commit/1c44ef30179b\n[2] https://github.com/sjp38/perfbook-ko_KR-pdf\n","permalink":"https://sjp38.github.io/posts/perfbook_translate_restart/","summary":"I stopped translation of perfbook since 2019-09-27. Because the 2nd edition of perfbook is released[0], I\u0026rsquo;m starting the translation again[1], from the scratch. The old versions are still available, of course[2].\n[0] https://mirrors.edge.kernel.org/.../perfbook/perfbook.html\n[1] https://github.com/sjp38/perfbook-ko_KR/commit/1c44ef30179b\n[2] https://github.com/sjp38/perfbook-ko_KR-pdf","title":"Starting perfbook translation again"},{"content":"I realized I didn\u0026rsquo;t introduce a good, intuitive example use case of DAMON[0] for profiling so far, though DAMON is not for only profiling. One straightforward and realistic usage of DAMON as a profiling tool would be recording the monitoring results with callstack and visualize those by timeline together.\nFor example, below shows that visualization for a realistic workload, namely \u0026lsquo;fft\u0026rsquo; in SPLASH-2X benchmark suite. The upper-most graph shows how DAMON-detected working set size of the workload (y-axis) changes by time (x-axis). The middle graph shows when (x-axis) which address range of the memory (y-axis) has how frequency accessed (color). The lower-most graph, finally, shows when (x-axis) what function the workload was executing, and by what function call chain it was called.\nFrom this, you can know there are three memory access bursting phases in the workload and FFT1DOnce.cons::prop.2() looks responsible for the first and second hot phase, while Transpose() is responsible for the last one. Now the programmer can take a deep look in the functions and optimize the code (e.g., adding madvise() or mlock() calls).\nWe used the mlock()-based optimization approach to a range of other realistic benchmark workloads. The optimized versions achieved up to about 2.5x performance improvement under memory pressure[1].\nNote: I made the uppermost two figures of above \u0026lsquo;fft\u0026rsquo; visualization (working set size and access frequency of each memory region by time) via the DAMON user space tool[2], while the lowermost one (callstack by time) is made using perf and speedscope[3]. We have no descent and totally automated tool for that yet (will be implemented soon, maybe under perf as a perf-script[4]), but you could reproduce that with below commands.\n$ # run the workload $ sudo damo record $(pidof \u0026lt;the workload\u0026gt;) \u0026amp; $ sudo perf record -g --pid $(pidof \u0026lt;the workload\u0026gt;) $ # after your workload finished (you should also finish perf on your own) $ damo report wss --sortby time --plot wss.pdf $ damo report heats --heatmap freq.pdf $ sudo perf script | speedscope - $ # open wss.pdf and freq.pdf with our favorite pdf viewer [0] https://damonitor.github.io\n[1] https://linuxplumbersconf.org/event/4/contributions/548/attachments/311/590/damon_ksummit19.pdf\n[2] https://lore.kernel.org/linux-mm/20201215115448.25633-8-sjpark@amazon.com/\n[3] https://www.speedscope.app/\n[4] https://lore.kernel.org/linux-mm/20210107120729.22328-1-sjpark@amazon.com/\n","permalink":"https://sjp38.github.io/posts/damon_profile_callstack_example/","summary":"I realized I didn\u0026rsquo;t introduce a good, intuitive example use case of DAMON[0] for profiling so far, though DAMON is not for only profiling. One straightforward and realistic usage of DAMON as a profiling tool would be recording the monitoring results with callstack and visualize those by timeline together.\nFor example, below shows that visualization for a realistic workload, namely \u0026lsquo;fft\u0026rsquo; in SPLASH-2X benchmark suite. The upper-most graph shows how DAMON-detected working set size of the workload (y-axis) changes by time (x-axis).","title":"An example of DAMON usage for profiling"},{"content":"DAMON[0] 이 프로파일링만을 위한 건 아니지만, DAMON 을 프로파일링에 활용하는 방법에 대한 괜찮은 직관적 예를 여태 소개한 적이 없다는 걸 깨달았습니다. 간단하지만 현실적인 DAMON 의 프로파일링 도구로써의 사용법은 모니터링 결과를 콜스택과 함께 기록한 후 시간대에 맞춰 시각화 하는 것입니다.\n예를 들어, 아래 그림은 SPLASH-2X 벤치마크의 \u0026lsquo;fft\u0026rsquo; 라는 워크로드에 대한 그런 시각화 결과입니다. 여기서, 우린 이 워크로드에 세개의 폭발적 메모리 액세스가 이루어지는 구간이 있는 것을 알 수 있으며, FFT1DOnce.cons::prop.2() 가 그 첫번째와 두번째 구간에, 그리고 Transpose() 는 세번째 구간에 연관되어 있음을 알 수 있습니다. 이제 프로그래머는 이 함수들을 깊게 들여다보고 코드를 최적화 (ex: madvise() 나 mlock() 을 호출하기) 할 수 있을 겁니다.\n우린 이 기법을 다양한 실제에 가까운 벤치마크 워크로드들의 mlock() 기반 최적화에 사용해 보았습니다. 그렇게 최적화 되 버전은 메모리 부족 상태에서 최대 2.5배까지의 성능 향상을 기록했습니다[1].\n주의: 위의 \u0026lsquo;fft\u0026rsquo; 시각화에서 위쪽 두개의 그림 (시간에 따른 워킹셋 크기와 메모리 영역별 접근 빈도) 는 DAMON 유저 스페이스 툴[2] 을 이용해서 그렸고, 가장 아래의 그림 (시간에 따른 콜스택) 은 perf 와 speedscope[3] 을 이용해 그렸습니다. 아직 이걸 완전히 자동화 하는 도구는 없습니다만 (조만간 구현할 계획입니다, 아마도 perf 아래에 perf-script[4] 의 형태로요), 여러분도 아래의 커맨드를 이용해 직접 만들어 보실 수 있습니다.\n$ # run the workload $ sudo damo record $(pidof \u0026lt;the workload\u0026gt;) \u0026amp; $ sudo perf record -g --pid $(pidof \u0026lt;the workload\u0026gt;) $ # after your workload finished (you should also finish perf on your own) $ damo report wss --sortby time --plot wss.pdf $ damo report heats --heatmap freq.pdf $ sudo perf script | speedscope - $ # open wss.pdf and freq.pdf with our favorite pdf viewer [0] https://damonitor.github.io\n[1] https://linuxplumbersconf.org/event/4/contributions/548/attachments/311/590/damon_ksummit19.pdf\n[2] https://lore.kernel.org/linux-mm/20201215115448.25633-8-sjpark@amazon.com/\n[3] https://www.speedscope.app/\n[4] https://lore.kernel.org/linux-mm/20210107120729.22328-1-sjpark@amazon.com/\n","permalink":"https://sjp38.github.io/posts/ko/damon_profile_callstack_example/","summary":"DAMON[0] 이 프로파일링만을 위한 건 아니지만, DAMON 을 프로파일링에 활용하는 방법에 대한 괜찮은 직관적 예를 여태 소개한 적이 없다는 걸 깨달았습니다. 간단하지만 현실적인 DAMON 의 프로파일링 도구로써의 사용법은 모니터링 결과를 콜스택과 함께 기록한 후 시간대에 맞춰 시각화 하는 것입니다.\n예를 들어, 아래 그림은 SPLASH-2X 벤치마크의 \u0026lsquo;fft\u0026rsquo; 라는 워크로드에 대한 그런 시각화 결과입니다. 여기서, 우린 이 워크로드에 세개의 폭발적 메모리 액세스가 이루어지는 구간이 있는 것을 알 수 있으며, FFT1DOnce.cons::prop.2() 가 그 첫번째와 두번째 구간에, 그리고 Transpose() 는 세번째 구간에 연관되어 있음을 알 수 있습니다.","title":"DAMON 을 이용한 프로파일링의 한 예"},{"content":"차일 피일 미루고 있던 OSDI'20 발표 영상 비디오를 휴가 기간동안 하루 한편이라도 보기로 했습니다.\nA large scale analysis of hundreds of in-memory cache clusters at Twitter https://www.youtube.com/watch?v=OQtMM5vdhlI\u0026amp;feature=emb_title\n트위터의 in-memory 캐시 시스템의 워크로드를 트레이스하고 그 특성을 분석한 논문입니다. 개인적으로 아래 내용이 흥미로웠습니다.\n쓰기 리퀘스트가 많음. 각 오브젝트의 크기는 작아서 (중간값이 200 바이트), 오브젝트별 메타데이터 (64 바이트) 가 공간을 많이 차지함. 키의 크기가 밸류의 크기보다 그렇게 작지 않음. 트레이스 데이터는 github[1] 통해 받을 수 있습니다. 압축해도 2.8TB, 압출 풀면 14TB 군요.\n[1] https://github.com/twitter/cache-trace\nAIFM: High-Performance, Application-Integrated Far Memory https://www.youtube.com/watch?v=xHhaniGXTUg\u0026amp;feature=emb_title\nOS 수준에서의 fast network 기반 far memory 접근법은 어플리케이션의 수정이 필요없다는 장점을 갖지만 고정된 크기의 페이지 abstraction 에 따른 semantic 차이와 어플리케이션에 대한 지식이 없는 커널에서의 주요 오퍼레이션 수행으로 인해 성능이 떨어집니다. AIFM 은 새로운 데이터 구조 abstraction 을 사용해 semantic 차이를 해결하고 user space 런타임 시스템을 사용해 kernel space 에서의 시간 낭비를 제거했습니다. 결과적으로 어플리케이션은 수정이 필요하지만 저자들은 약간의 수정일 뿐이라 주자합니다. 또다른 state-of-the-art (FastSwap, EuroSys'20) 대비 13배 성능 향상을 이뤘다는군요.\nLinnOS: Predictability on Unpredictable Flash Storage with a Light Neural Network https://www.youtube.com/watch?v=yzv9lcjxhAg\u0026amp;feature=emb_title\n최신 고속 저장장치는 캐싱, 웨어레벨링, 가비지 콜렉션 등의 복잡한 내부 구조를 가지고 있어서, 각 I/O 에 대한 응답시간을 예측하기가 어렵습니다. 이에 대한 잘 알려진 해결책은 Hedging 입니다. 여러 SSD 를 준비해 두고, I/O 요청을 그 중 하나의 SSD 에 일단 던지고, 그 응답이 미리 지정된 한계치를 넘도록 돌아오지 않으면 해당 요청을 취소하고 다른 SSD 를 쓰는 것이죠. 한계치 만큼은 기다려야 한다는 게 약점입니다. LinnOS 는 Hedging 과 유사하지만 각 SSD 로의 각 I/O 가 빠르게 처리될지 예측하는 신경망을 이용합니다. 이를 위해, 해당 신경망은 현재 I/O queue depth, 최근의 몇개 I/O 시 queue depth 와 latency 를 입력으로 받고 그 결과 레이턴시가 빠를지 느릴지만 예측합니다. 잘못된 예측으로 인한 문제를 처리하기 위해선 biased learning 과 예측 정확도에 따른 adaptive hedging 을 사용합니다. 신경망의 학습은 오프라인으로 이루어집니다.\nDo OS abstractions make sense on FPGAs? https://www.youtube.com/watch?v=k-cp4U3JKug\u0026amp;feature=emb_title\nHeterogeneous computing system 이라고도 불리는, FPGA 를 내장한 컴퓨터 시스템이 널리 사용되고 있습니다. 이런 시스템에는 운영 복잡성이 높게 마련이며, 특히 FPGA 용 어플리케이션의 개발과 배포가 복잡합니다. 때문에 FPGA 관리를 위해 운영체제의 추상화 개념이 일부 사용되고 있습니다. 저자는 Coyote 라고 하는, 운영체제의 일반적 추상화 개념을 모두 지원하는 FPGA 관리 도구를 만들어 운영체제 추상화 개념이 FPGA 에 잘 적용되는지 실험했고, 그에 대한 긍정적 결과를 얻었습니다.\nFast RDMA-based Ordered Key-Value Store using Remote Learned Cache https://www.youtube.com/watch?v=Qv-0YL_SII4\u0026amp;feature=emb_title\n서버 중심적 key-value store (KVS) 는 서버의 CPU 에 성능이 제한되므로, RDMA 기반의 방법들이 제안되어왔습니다. 한번의 RDMA 에 한번의 RTT 가 소요되므로, 이 방법은 여러번 네트워크 순회를 해야 하는 문제가 있어 성능이 떨어지는 문제가 있습니다. 인덱스를 클라이언트 내에 캐시해 두는 해결책도 있습니다만, 클라이언트의 메모리 사용량을 급격하게 늘린다는 문제가 있습니다. 이 논문의 저자들은 신경망을 인덱스로 사용하자는 제안을 합니다. 키를 입력으로 받아 밸류의 주소를 내놓는 신경망을 서버 측에서 학습시키고, 전체 인덱스에 비해 훨씬 작은 이 신경망을 클라이언트로 전송, 각 클라이언트가 이 신경망을 캐시로 사용해 밸류의 서버내 주소를 알아내고, RDMA 로 한번에 밸류를 얻어오는 방법입니다.\nA Simpler and Faster NIC Driver Model for Network Functions https://www.youtube.com/watch?v=zKJIY4vbBDA\u0026amp;feature=emb_title\nBridge, router, firewall 등의 기능을 소프트웨어로 구현하려는 software-defined network 방식이 널리 사용되고 있습니다. 이 과정에서 성능과 유연성을 위해 소프트웨어 복잡도를 높이는 경향이 있었습니다. 결과, software-defined network stack 의 안정성을 검증하기도 어려워졌습니다. 저자팀은 약간의 유연성을 희생함으로써 단순하면서 성능 높은 network stack 구현이 가능함을 주장하며, 자신들의 새로운 네트워크 드라이버 모델, tinynf 로 이를 증명합니다. 이 드라이버 모델을 바탕으로 구현된 Intel 82599 드라이버는 550줄밖에 안되는 코드로 기존 state-of-the-art 드라이버보다 7배 빨리 formal verification 을 마칠 수 있었고, 성능 역시 1.6배 높았습니다.\nTheseus: an experiment in operating system structure and state management https://www.youtube.com/watch?v=i1pLDZKtlBI\n이 논문에서 저자들은 Theseus 라는 이름의, state spill 문제를 해결할 수 있도록 설계된 운영체제를 선보입니다. 해당 문제의 해결을 위해 \u0026lsquo;cell\u0026rsquo; 이라 불리는 다수의 작은 컴포넌트로 운영체제를 구성시켰으며, Rust 와 같은 언어 수준에서의 안전성 보장 메커니즘들을 운영체제 단계에 적용시켰습니다.\nSpecification and verification in the field: Applying formal methods to BPF just-in-time compilers in the Linux kernel https://www.youtube.com/watch?v=2V3ts5-W_9g\u0026amp;feature=emb_title\nBPF 프로그램은 수행되기 전에 검증되지만, 그 검증 이후에 JIT 를 통해 컴파일 된 후에 수행됩니다. 따라서, JIT 에 버그가 있다면 문제가 생길 수 있습니다. 이 논문의 저자들은 JIT 의 정확성 명세 프레임웍, jitterbug 를 사용해 RISC-V 를 위한 새로운 BPF JIT 를 개발했습니다. 이 과정에서 만들어진 커널 변경사항은 메인라인 리눅스 커널에 머지되었습니다.\nStorage Systems are Distributed Systems (So Verify Them That Way!) https://www.youtube.com/watch?v=4s8EeXcu_8Y\u0026amp;feature=emb_title\n스토리지 시스템도 높은 복잡도를 갖기에 기계적으로 검증을 하기 까다롭습니다. 이 논문의 저자들은 그런 스토리지 시스템의 구조가 분산 시스템과 비슷한 측면이 있음을 발견하고 분산 시스템의 기계적 검증을 위해 제안된 방법을 보다 범용화 해서 스토리지 시스템에 적용합니다. 이를 바탕으로 저자팀은 VeriSafeKV 라는 검증 가능한 key-value storage 를 만들었습니다. VeriSafeKV 는 검증이 되지 않는 DB 들과 비슷한 수준의 성능을 보였습니다.\nCaladan: Mitigating Interference at Microsecond Timescales https://www.youtube.com/watch?v=G-v3ndwixOI\u0026amp;feature=emb_title\n시스템 상에는 서로 다른 요구사항을 가진 워크로드들이 함께 스케쥴링 됩니다. 예를 들어, 어떤 워크로드는 최선의 리소스만 주어지면 되지만 어떤 것들은 tail latency 에 민감하죠. 워크로드들이 LLC 나 memory bandwidth 같은 하드웨어 리소스를 공유하므로, 모든 요구사항을 지켜주기가 어렵습니다. 이에 대한 잘 알려진 해결책은 리소스 파티셔닝입니다. 하지만 정적 파티셔닝은 리소스 사용률을 낮출 수 있기 때문에 동적 파티셔닝이 제안되어왔습니다. 하지만 저자들의 주장에 따르면 tail latency 문제를 위해선 100 마이크로세컨드 내에 동적 파티셔닝이 이루어져야 하는데 기존 해결책들은 그정도로 빠르지 않습니다. 때문에 저자들은 간섭을 알아채기 위해 다른 시그널을 사용하면서 시스템 전체를 마이크로세컨드 레벨로 재설계 했습니다.\nSemeru: A Memory-Disaggregated Managed Runtime https://www.youtube.com/watch?v=MFA3MmNDKaM\u0026amp;feature=emb_title\nCPU 작업과 메모리 작업들 같이 다른 일을 위한 분산된 기계들을 가지고 시스템을 구축하는 resource-disaggregated 아키텍쳐가 널리 사용되어가고 있습니다. 하지만, 이 구조는 보통 native 어플리케이션을 위해 만들어졌지, GC 기반 어플리케이션을 위해 만들어지진 않았습니다. 이 논문은 resource-disaggregation 구조를 위해 설계된 JVM, Semeru 를 소개합니다.\nPANIC: A High-Performance Programmable NIC for Multi-tenant Networks https://www.youtube.com/watch?v=EB6dK3L8Jzg\u0026amp;feature=emb_title\nMulti-tenant 네트웍은 programmable NIC 에게 범용성, 유연한 chaining, isolation, 그리고 성능을 요구합니다. 하지만 현재의 programmable NIC 들은 그걸 제공하지 않고 있죠. 이 논문의 저자들은 이를 위한 새로운 programmable NIC 설계를 제안하고 PANIC 이라는 이름의 FPGA 기반 구현을 소개합니다.\nServing DNNs like Clockwork: Performance Predictability from the Bottom Up https://www.youtube.com/watch?v=wHOpY_MY57Y\u0026amp;feature=emb_title\n오늘날 데이터 센터는 수많은 머신러닝 모델을 다른 사용자들을 위해 수행해 주고 있습니다. 각각의 인퍼런스는 조건적 실행 분기문 같은게 없으므로 그 응답시간을 쉽게 예측 가능합니다만 모델 서빙 시스템 자체의 복잡도로 인해 끝단 사이의 응답시간을 예측 불가능하게 만들고 있습니다. 이 논문은 이 문제를 해결하기 위해 응답시간을 고려해 재설계된 머신러닝 모델 서빙 스케쥴러 시스템을 소개합니다.\nTeting Configuration Changes in Context to Prevent Production Failures https://www.youtube.com/watch?v=QrGKmp3ALKQ\u0026amp;feature=emb_title\n이 논문은 \u0026lsquo;ctest\u0026rsquo; 라는, 제품 환경에서의 설정 변경이 옳은지 검증할 수 있는 테스트 프레임웍을 제안합니다. 형태는 Junit 등의 다른 테스트 프레임웍과 비슷합니다.\n","permalink":"https://sjp38.github.io/posts/ko/osdi2020_videos_review/","summary":"차일 피일 미루고 있던 OSDI'20 발표 영상 비디오를 휴가 기간동안 하루 한편이라도 보기로 했습니다.\nA large scale analysis of hundreds of in-memory cache clusters at Twitter https://www.youtube.com/watch?v=OQtMM5vdhlI\u0026amp;feature=emb_title\n트위터의 in-memory 캐시 시스템의 워크로드를 트레이스하고 그 특성을 분석한 논문입니다. 개인적으로 아래 내용이 흥미로웠습니다.\n쓰기 리퀘스트가 많음. 각 오브젝트의 크기는 작아서 (중간값이 200 바이트), 오브젝트별 메타데이터 (64 바이트) 가 공간을 많이 차지함. 키의 크기가 밸류의 크기보다 그렇게 작지 않음. 트레이스 데이터는 github[1] 통해 받을 수 있습니다.","title":"OSDI 2020 발표 영상 감상"},{"content":"I set watching at least one OSDI'20 presentation video per day during the long vacation as one of my plans.\nA large scale analysis of hundreds of in-memory cache clusters at Twitter https://www.youtube.com/watch?v=OQtMM5vdhlI\u0026amp;feature=emb_title\nThe authors traced and analyzed the workloads on the Twitter\u0026rsquo;s in-memory cache systems. To me, below findings were interesting.\nThere are many write requests. Size of each object is not so big (median 200 bytes), so metadata, which sizes 64 bytes per each object, is a burden Size of each key is not small compared to the size of each value. The trace data is available via github[1]. It\u0026rsquo;s 2.8TB for compressed version, and 14TB for uncompressed version.\n[1] https://github.com/twitter/cache-trace\nAIFM: High-Performance, Application-Integrated Far Memory https://www.youtube.com/watch?v=xHhaniGXTUg\u0026amp;feature=emb_title\nOS-level fast-network-based far memory approaches provide transparency to the application but wastes performance due to the semantic gap due to the fixed-size page abstraction and the kernel space time consumption. AIFM solves the semantic gap using new data structure abstraction and provides user space runtime that don\u0026rsquo;t need kernel space time consumption. As a result, the application is required to be modified, but the authors argue it\u0026rsquo;s only modest change. Compared to other state-of-the-art (FastSwap from EuroSys'20), it achieved 13x speedup.\nLinnOS: Predictability on Unpredictable Flash Storage with a Light Neural Network https://www.youtube.com/watch?v=yzv9lcjxhAg\u0026amp;feature=emb_title\nIt\u0026rsquo;s not easy to predict each I/O speed of modern fast storage devices, due to their complex internals like the caching, the wear-leveling and the garbage collection. One well-known solution is hedging. It prepare an array of SSDs, issue I/O to one of them, and if the response doesn\u0026rsquo;t made until a timeout, revoke the request and try with another SSD. The wait time limit bounds the latency. LinnOS uses an approach similar to the hedging, but it uses a neural network that can predict if each I/O to each SSD will be served fast or not. For this, the neural network receives current I/O queue depth and queue depths and latencies of last few I/Os as input. Then, it predicts if the latency will be only fast or slow. To mitigate with the effect from wrong predictions, it uses biased learning and adaptive hedging based on the prediction accuracy. The network is learned offline.\nDo OS abstractions make sense on FPGAs? https://www.youtube.com/watch?v=k-cp4U3JKug\u0026amp;feature=emb_title\nComputer systems embedding FPGA in addition to CPU, called heterogeneous computing systems, are widesparead nowadays. These systems typically have high operational complexity. Especially developing and deploying FPGA application is quite complicated. For the reason, some manufacturers provide some FPGA shells providing some of the OS abstractions. The authors developed a FPGA shell called Coyote, which provides full abstraction sets of the OS and experimented if it works well for the systems. The result was very positive.\nFast RDMA-based Ordered Key-Value Store using Remote Learned Cache https://www.youtube.com/watch?v=Qv-0YL_SII4\u0026amp;feature=emb_title\nBecause server-centric key-value store (KVS) performance bound to the server CPUs, RDMA-based approaches were proposed. Because one RTT is required for one RDMA, the approaches require many round trips and therefore doesn\u0026rsquo;t show high performance. Caching the index in client is one solution, but it makes huge client memory footage. The authors propose to use neural network as the index cache. They train neural network to receive key and provide logical address of the value for the key in server. The network retrained for dynamci updates and copyied to clients. Then, client use the nerual network, which is much smaller than the full index tree to know the address of the value and fetch it via the RDMA.\nA Simpler and Faster NIC Driver Model for Network Functions https://www.youtube.com/watch?v=zKJIY4vbBDA\u0026amp;feature=emb_title\nSoftware-defined network approach, which implements functionality of appliances like bridege, router, firewall is widespread. For better performance and flexibility, the software complexity has increased so that it\u0026rsquo;s hard to do formal verification of the network stacks. The authors argue that by sacrificing some of the fliexibility, it\u0026rsquo;s available to implement simple and fast network stack. They prove their idea with a new network driver model, tinynf. They implemented a driver for Intel 82599 based on the driver model with only 550 lines of code. It was able to finish formal verification 7x faster than a state-of-the-art driver. Also, it achieved 1.6x performance compared to the state-of-the-art.\nTheseus: an experiment in operating system structure and state management https://www.youtube.com/watch?v=i1pLDZKtlBI\nIn this paper, the authors present an OS called Theseus that designed for state spill problem. For this, they made it to composed with many tiny components called \u0026lsquo;cell\u0026rsquo;, and applied rust-like language level safe guaranteeness mechanisms in the OS level.\nSpecification and verification in the field: Applying formal methods to BPF just-in-time compilers in the Linux kernel https://www.youtube.com/watch?v=2V3ts5-W_9g\u0026amp;feature=emb_title\nBPF program is verified before run, but it runs after compiled via JIT, after the verification. Therefore, if there is a bug in the JIT, real problem occurs. The authors of this paper devloped a new BPF JIT for RISC-V with a JIT correctness specification framework, jitterbug. The changes made to the kernel are merged into the mainline kernel.\nStorage Systems are Distributed Systems (So Verify Them That Way!) https://www.youtube.com/watch?v=4s8EeXcu_8Y\u0026amp;feature=emb_title\nStorage systems have high complexity, so it\u0026rsquo;s hard to do the verification. The authors of this paper realized the architecture and charactersitics of the storage systems are similar to those of distributed systems, and applied the verification methodologies for distributed systems to the storage systems after making it more general. Based on this, they implemented a verifiable key-value storage, VeriSafeKV. The performance of it was similar to unverified DB systems.\nCaladan: Mitigating Interference at Microsecond Timescales https://www.youtube.com/watch?v=G-v3ndwixOI\u0026amp;feature=emb_title\nOn a system, multiple workloads that has different requirements co-scheduled. For example, some workloads only need best-effort resources while others require strict tail latency. Because the workloads share some hardware resources like LLC and memory bandwidth, it\u0026rsquo;s hard to fulfill all the requirements. Well know solution is resource partitioning. Because static partitioning could result in low resource utilization, dynamic partitioning solutions were previously proposed. However, the dynamic partitioning doesn\u0026rsquo;t provide microsecond granularity decision, while 100 microseconds is the marginal timewindow to guarantee the tail latency problem, according to the authors\u0026rsquo; arguments. The authors propose to use different interference signals and design the system to work in micro-second level.\nSemeru: A Memory-Disaggregated Managed Runtime https://www.youtube.com/watch?v=MFA3MmNDKaM\u0026amp;feature=emb_title\nConstructing system as distributed machines for different works such as CPU works and memory works are know ans resource-disaggregated architecture and gaining popularity. However, the architecture is usually written for native applications rather than GC-based applications. This paper introduces JVM runtime, Semeru, which is designed for resource-disaggregation architecture.\nPANIC: A High-Performance Programmable NIC for Multi-tenant Networks https://www.youtube.com/watch?v=EB6dK3L8Jzg\u0026amp;feature=emb_title\nMulti-tenant networks require generality, flexible chaining, isolation, and performance to programmable NIC. However, current programmable NICs doesn\u0026rsquo;t support those. Authors propose a new programmable NIC design for the requirements and introduce an implementation on FPGA, PANIC.\nServing DNNs like Clockwork: Performance Predictability from the Bottom Up https://www.youtube.com/watch?v=wHOpY_MY57Y\u0026amp;feature=emb_title\nNowadays, data center serves for many machine learning models for different users. Even though the latency of each inference is predictable because it has no conditional branches, the models serving system could result in unpredictable end-to-end latency. This paper proposes a new machine learning models serving system that designed do protect the latency.\nTeting Configuration Changes in Context to Prevent Production Failures https://www.youtube.com/watch?v=QrGKmp3ALKQ\u0026amp;feature=emb_title\nIn this paper, a new test framework called \u0026lsquo;ctest\u0026rsquo; is proposed for validation of configuration changes that can made in production environment. It\u0026rsquo;s similar to other test frameworks like Junit in its form.\n","permalink":"https://sjp38.github.io/posts/osdi2020_videos_review/","summary":"I set watching at least one OSDI'20 presentation video per day during the long vacation as one of my plans.\nA large scale analysis of hundreds of in-memory cache clusters at Twitter https://www.youtube.com/watch?v=OQtMM5vdhlI\u0026amp;feature=emb_title\nThe authors traced and analyzed the workloads on the Twitter\u0026rsquo;s in-memory cache systems. To me, below findings were interesting.\nThere are many write requests. Size of each object is not so big (median 200 bytes), so metadata, which sizes 64 bytes per each object, is a burden Size of each key is not small compared to the size of each value.","title":"Watching OSDI 2020 presentation videos"},{"content":"올해 초, 우연히 전자잉크 태블릿인 Remarkable 2 의 소개 영상 을 보게 되었습니다. 간단하지만 분명한 목표 (\u0026lsquo;종이\u0026rsquo;와 같은 사용경험) 에 집중한 디자인과 기능이 무척 매력적으로 다가왔습니다. 망설이다 7월에 한번 더 사이트에 들어가 봤는데, 선주문 기간인데다 팬데믹 등의 영향으로 11월에야 배송된다고 하더군요. 한달 내로는 무료 반품도 된다길래 고민할 시간은 많으니 일단 지르고 고민해 보자는 생각으로 질렀습니다.\n한참의 시간이 지나, 지난 월요일에 마침내 제품을 받게 되었습니다. 개인적으로 처음 구매해 본 전자잉크 기기인데, 이제 겨우 일주일 됐지만 제법 만족스럽게 사용 중입니다. 사용 경험을 간략히 정리해 봅니다.\n화면 예전에 논문이나 전자책을 읽을 요량으로 크롬북을 구매 했죠. 12.3인치 크기에 2400x1600 해상도라 책과 논문을 읽기에도 괜찮은 경험이었지만 진짜 종이를 보는 느낌은 확연히 아니었습니다. 특히 침대에서 보기에는 확실히 눈이 조금 피로하더군요. 비행기나 버스와 같이 종이책을 꺼내기 어려운 상황에서 무척 유용했지만 여건이 되는 상황에서는 종이를 다시 찾게 되었습니다.\n리마커블 2는 10.3인치 전자잉크 화면입니다. 다른 전자잉크 기기를 많이 사용해 보지 않아 비교를 하긴 어렵지만 기대했던 대로 정말 종이를 보는 듯한 경험입니다. 확실히 눈이 편안합니다.\n회색 바탕이고 명암이 강한 편은 아니라 새하얀 종이책에 비교하면 화면이 어두운 느낌도 듭니다. 한밤에 어두운 조명에서 작은 글씨를 읽기는 조금 불편합니다. 형광등 아래에서라면 아무 문제 없을 것 같습니다.\n10.3인치 화면은 논문이나 일부 전공 서적을 보기엔 좀 작은 느낌도 듭니다만 전자잉크라 눈이 피로해지지 않고, 그래서인지 내용이 제법 눈에 들어옵니다. 소프트웨어에서 pdf 의 불필요 여백을 자동으로 제거해주고 사용자가 직접 여백 조정을 할 수 있어서 더욱 편합니다.\n이동성 크롬북을 전자책 리더로 쓰기 어려웠던 이유 중 하나가 이동성입니다. 랩톱에 비하면 많이 가볍지만 최신 태블릿이랑 비교하면 여전히 조금 무거워서 독서대를 사용하지 않으면 조금 불편했습니다.\n리마커블2의 두께는 4.7mm, 무게는 403.5g 입니다. 세상에서 가장 얇고 가벼운 태블릿이라고 홍보하는데요. 얇은 두께는 그립감에는 나쁘게 작용하기도 합니다만, 가방에 넣거나 할 때엔 큰 장점이 될 것 같습니다. 책상 위에 놓을 때에도 a4 종이 뭉치 정도 느낌밖에 안들어 부담이 없고 미관을 해치지 않아 좋습니다. 무게는 가볍긴 하지만 한손으로 들고 장시간 독서를 하기엔 손목에 조금 무리가 왔습니다. 양손으로 들면 거의 부담이 없습니다.\n배터리 이북 리더에 자꾸 눈이 갔던 이유 중 하나가 배터리입니다. 월요일에 받은 후 한번 충전하고 이후 일부러 충전 없이 사용 중인데요, 현재 배터리 잔량이 57%군요. 충전 속도는 조금 느린 편입니다. 랩톱에 연결해 충전했을 때 대략 50% 에서 100% 까지 충전하는데 몇시간은 걸렸던 것 같습니다.\n필기감 책은 깨끗이 보자는 주의라 태블릿들의 필기 능력에 대한 홍보에 큰 관심을 가지지 않아왔습니다. 여러 기능을 가진 필기 어플을 태블릿들이 광고하지만 그 어플을 켜는 것도 귀찮을 것 같았고, 무엇보다 유리화면에 미끄러지는 필기감과 약간씩 있는 레이턴시가 마음에 들지 않아 항상 a4 이면지에 모나미 볼펜으로 필기하는게 제 최고 선택이었습니다. 거친 질감의 반투명 필터를 화면에 씌워 필기감을 살리는 대안도 봤지만 화면이 흐려지는 게 영 맘에 안들고 필기감도 너무 거칠거려서 별로더군요.\n리마커블2 역시 필기 기능을 제공합니다만 기존 선입견 때문에 제게는 크게 매력적으로 보이지 않았습니다. 기기를 받으면 어디까지나 리더로만 사용할 생각이었고, 나는 쓰지도 않을 필기 기능에 돈을 쓰는 거 아닐까 걱정하기도 했죠. 하지만 막상 기기를 받은 후 사용해 보니 생각이 180도 달라졌습니다.\n뒤에 소프트웨어 섹션에서 한번 더 설명하겠지만 인터페이스가 무척 간단하면서 편리해서 필기 기능을 켜기가 간단합니다. 꼭 필기 앱을 켜지 않더라도 읽는 중인 책 위에 끄적거린 후 메모로 가져갈 수 있습니다. 책을 깨끗이 유지하면서 메모할 수 있는 거죠. 이 기능은 다른 태블릿들도 많이 제공할 지 모르겠지만 제겐 중요한 기능입니다.\n펜을 자석식으로 붙여두는 것도 제겐 큰 장점입니다. 갤럭시와 같이 기기 내에 끼워두는 형태가 안전하긴 하지만 넣었다 꺼냈다 하기가 제겐 꽤 귀찮았거든요. 펜이 항상 태블릿 측면에 붙어 있으니 그냥 집어들어 필기하면 되기 때문에 무척 편리합니다.\n필기하는 느낌도 종이에 필기하는 맛과 무척 유사합니다. 모나미의 볼이 굴러가는 필기감을 선호하는 제게는 여전히 조금 거친 필기감이긴 하지만 허용범위 내입니다. 레이턴시가 조금 있기는 한데 빠른 속도로 사인을 하거나 할 때에나 느껴지지, 천천히 생각을 정리하며 그림을 그리고 글을 쓰는 단계에선 느껴지지 않을 정도입니다.\n또한, 저는 글씨를 작게 쓰는 편인데 기존의 다른 태블릿에서는 글씨를 작게 쓰면 보기도 불편하고 필기하는 느낌도 좀 만족스럽지 않았습니다. 리마커블2에서는 작은 글씨를 쓰는 것도 간단하고 가독성도 괜찮은 편입니다. 실제로 평소에 노트에 하는 필기와 크기를 비교해 봐도 손색 없습니다.\n소프트웨어 리마커블2의 기능은 무척 간단합니다. 어떤 경쟁 태블릿은 안드로이드 기반이라 수많은 안드로이드 앱도 돌릴 수 있고 웹브라우징도 할 수 있는데 리마커블2는 pdf 또는 E-book 파일의 읽기와 필기 기능, 그걸로 끝입니다. 썰렁한 느낌마저 들 정도입니다. 하지만 덕분에 다른 곳에 정신이 분산되지 않고 리마커블2를 꺼내들었을 때 하려던 원래 목적에 충실할 수 있습니다. 인터페이스는 간단하다 못해 투박하기도 하지만 필요한 기능은 모두 있습니다. 간단한 하나의 목표를 완벽하게 구현하자는 유닉스 정신이 느껴지기도 합니다.\n패스워드가 적용된 pdf 는 지원하지 않는다고 하며 (시도해 보지 않았습니다), pdf 내의 링크 기능 역시 지원하지 않습니다. 다행히 특정 섹션 또는 페이지로의 이동 기능은 있습니다.\n앞에서도 잠깐 이야기 했지만 pdf 여백을 자동으로 잘라내서 보여주며 사용자가 직접 이 여백을 조정할 수 있습니다. 자동으로 잘라주는 기능이 제법 괜찮아서 저는 직접 여백을 조정하는 경우는 별로 없는 것 같습니다. 덕분에 논문 등의 글이 많은 문서를 읽기에도 큰 불편함이 없습니다.\n리마커블2는 리눅스 기반의 운영체제를 사용합니다. 제가 구매를 결정하는데 큰 이유가 되기도 했습니다. 흥미롭게도 ssh 접속도 가능합니다. 4.14 버전 커널을 사용하는군요.\n$ ssh root@10.11.99.1 root@10.11.99.1\u0026#39;s password: ｒｅＭａｒｋａｂｌｅ ╺━┓┏━╸┏━┓┏━┓ ┏━┓╻ ╻┏━╸┏━┓┏━┓ ┏━┛┣╸ ┣┳┛┃ ┃ ┗━┓┃ ┃┃╺┓┣━┫┣┳┛ ┗━╸┗━╸╹┗╸┗━┛ ┗━┛┗━┛┗━┛╹ ╹╹┗╸ reMarkable: ~/ uname -r 4.14.78 reMarkable: ~/ 파일 전송 및 클라우드 동기화 리마커블2에 파일을 전송하는 가장 간단한 방법은 USB 연결입니다. 랩톱 등의 컴퓨터와 USB 를 통해 연결하면 웹 인터페이스를 통해 리마커블2와 pdf 파일을 주고받을 수 있습니다. 문제는 이 웹 인터페이스가 디렉토리 기능을 제대로 지원하지 않습니다. 컴퓨터에서 리마커블2로의 파일 전송은 루트 디렉토리로만 전송되며, 따라서 디렉토리별로 파일을 정리하려면 기기에서 다시 정리해야 합니다.\n리마커블에서 별도의 클라우드 서비스를 제공합니다. 8GB 공간이 제공되어, 기기에 인터넷이 연결되면 자동으로 모든 파일이 동기화 백업 됩니다. 여타 클라우드 서비스와의 동기화는 되지 않습니다.\n리마커블2 외의 기기에서 이 클라우드 서비스에 접근하기 위해선 앱을 설치해야 합니다. 데스크탑, 안드로이드, iOS 용 앱이 있는데 데스크탑 앱은 윈도우용입니다. 이 부분이 개인적으로 가장 실망스러운 부분입니다. 와인 등을 이용해 리눅스에서도 돌릴 수 있다고 합니다만 저는 시도하지 않았습니다.\n하지만 Read on reMarkable 이라는 크롬 익스텐션이 이 아쉬움들을 제법 해소해 줍니다. 버튼을 하나 누름으로써 인터넷 사이트의 내용 또는 pdf 를 바로 리마커블2에 보낼 수 있습니다.\n가격 리마커블2의 가격은 399달러입니다. 제가 주문할 때엔 선주문 단계라 펜과 Folio 를 이 가격에 포함해 줬는데 지금은 별도 가격을 받는군요. 같은 구성으로 하면 총 517달러입니다. Folio 를 제하면 448달러. 아슬아슬하게 합리적인 가격이라 생각합니다.\n총평 가히 궁극의 종이 대체제가 될 수 있는 기기라고 평하겠습니다. 필기와 pdf / epub 파일 읽기라는 최소한의 목적에 맞추어 깔끔하게 만들어진 기기입니다. 목적이 일치한다면 돈값을 할거라 생각합니다. 만약 웹브라우징도 되고 앱도 설치/구동되는 범용 태블릿을 원한다면 다른 기기를 알아보는 게 좋을 겁니다.\n","permalink":"https://sjp38.github.io/posts/ko/remarkable2_review/","summary":"올해 초, 우연히 전자잉크 태블릿인 Remarkable 2 의 소개 영상 을 보게 되었습니다. 간단하지만 분명한 목표 (\u0026lsquo;종이\u0026rsquo;와 같은 사용경험) 에 집중한 디자인과 기능이 무척 매력적으로 다가왔습니다. 망설이다 7월에 한번 더 사이트에 들어가 봤는데, 선주문 기간인데다 팬데믹 등의 영향으로 11월에야 배송된다고 하더군요. 한달 내로는 무료 반품도 된다길래 고민할 시간은 많으니 일단 지르고 고민해 보자는 생각으로 질렀습니다.\n한참의 시간이 지나, 지난 월요일에 마침내 제품을 받게 되었습니다. 개인적으로 처음 구매해 본 전자잉크 기기인데, 이제 겨우 일주일 됐지만 제법 만족스럽게 사용 중입니다.","title":"Remarkable 2 리뷰"},{"content":"다양한 형태로 생각을 기록하고 가끔은 공유도 해왔습니다. 그 생각들을 오래도록 안전히 보관하고 싶었지만 몇차례 시행착오를 거치며 그게 쉽지 않음을 깨달았습니다.\n시작은 일기장과 노트였습니다. 분실하기도 쉽고 구석에 쳐박아 두면 다시 볼일도 거의 없더군요.\n클라우드 문서 서비스가 매력적이어 보였습니다. 하지만 영원한 건 없고 결국 그때 그때 흥하는, 또는 사용 가능한 서비스를 옮겨다녀야 하더군요. 그러다보니 서비스마다의 호환성이 문제가 됩니다.\nhttps://yargerdotblog.files.wordpress.com/2019/02/cloudmeme.jpg\nHugo 와 같은 README 등 표준적 포맷의 plain text 기반 static site generator 를 사용하고 Git 으로 원격 repo 도 관리하는 게 괜찮은 방법 같아 보였습니다. 지금 이 블로그도 이 방법으로 관리하고 있습니다. 하지만 다른 테마로 이동할 때마다 생각보다 만질 부분이 꽤 있더군요. 또한 혼자 간직하고 싶은, 또는 잠깐 떠오르는 짧은 생각들을 간단하게 기록하기엔 생각보다 번거로웠습니다.\n결국 나만의 규칙 아래 plain text 로 파일에 생각을 적어 git 으로 관리하게 되었습니다. 가장 낫긴 한데 여러 기계를 사용하면 동기화 하는걸 가끔 잊어버려 곤란한 상황에 직면하곤 했습니다. 나만의 규칙이라 해봤자 날짜를 기록하는 정도인데 그 포맷도 그때그때 헷갈리구요. 생각마다 다른 파일에 적을지 달마다 다른 파일에 적을지도 고민이었습니다. 그때그때 git 커맨드를 추가로 작성해야 하는것도 정말 짧은 생각만 관리하기엔 부담으로 느껴지더군요. 특히 핸드폰에서는 파일 수정하고 git 을 사용하기가 쉽지 않으니 사실상 다른 앱에 생각을 적어두고 나중에 컴퓨터 앞에서 git 으로 옮겨 관리하는데 그것도 별로였습니다.\n결국 제가 원하는 건 트위터 수준으로 간단히 짧은 생각들을 작성하는 인터페이스와 third party 의존성 없는 안전한 관리였습니다.\n그래서 간단한 도구를 만들었습니다. 날짜와 같은 주요 메타데이터를 Git 으로 안전히 관리하며, 모든 생각을 그때 그때 원격 저장소로 동기화 합니다. 핸드폰에서 tmux 등으로 사용하기 충분할 정도로 간단한 커맨드 라인 인터페이스를 제공합니다. 예를 들면:\n$ st new \u0026#34;Thanks for all the fish\u0026#34; $ st show Sat Oct 3 11:21:14 2020 +0200 Thanks for all the fish 아주 간단한 포맷의 plain text file 로의 export / import 기능을 제공하므로 복잡한 히스토리 관리는 물론 다른 포맷으로의, 으로부터의 변환 역시 간단합니다. 예전에 매뉴얼하게 Git 으로 관리하던 기록들을 최근에 이 기능을 이용해 import 했는데 드디어 하나의 통합된 제 생각 관리가 가능할 것으로 기대합니다.\n무엇보다, 아날로그 때의, 마음가는대로 아무 페이지나 펴서 무작위로 글을 읽으며 추억에 빠지는 경험을 되살리고 싶었는데, 됩니다.\n$ st show --random Wed Mar 8 22:30:00 1978 +0000 The first episode of \u0026#34;The Hitchhiker\u0026#39;s Guide to the Galaxy\u0026#34; will now broadcast. 아직 다듬을 부분이 많고 추가할 기능도 많지만 일단 제 개인 목적으로 쓰기 시작한지는 제법 되었고 이제는 남들도 사용은 해볼 수 있을 것 같아 이렇게 소개해 봅니다.\n","permalink":"https://sjp38.github.io/posts/ko/shallow_thought/","summary":"다양한 형태로 생각을 기록하고 가끔은 공유도 해왔습니다. 그 생각들을 오래도록 안전히 보관하고 싶었지만 몇차례 시행착오를 거치며 그게 쉽지 않음을 깨달았습니다.\n시작은 일기장과 노트였습니다. 분실하기도 쉽고 구석에 쳐박아 두면 다시 볼일도 거의 없더군요.\n클라우드 문서 서비스가 매력적이어 보였습니다. 하지만 영원한 건 없고 결국 그때 그때 흥하는, 또는 사용 가능한 서비스를 옮겨다녀야 하더군요. 그러다보니 서비스마다의 호환성이 문제가 됩니다.\nhttps://yargerdotblog.files.wordpress.com/2019/02/cloudmeme.jpg\nHugo 와 같은 README 등 표준적 포맷의 plain text 기반 static site generator 를 사용하고 Git 으로 원격 repo 도 관리하는 게 괜찮은 방법 같아 보였습니다.","title":"Shallow Thought: Simple and safe thoughts management"},{"content":"DAMON 은 kselftest 와 kunit 에 기반한 여러 테스트를 자신의 패치셋에 포함시켜 두고 있습니다. 커널 트리에 위치하는 테스트는 짧은 수행시간만 가지는게 바람직하므로, 시간을 오래 소요하는 테스트들을 패키지화 해서 저희 회사 내에서만 사용해 오고 있었습니다. 테스트는 좋은 문서로 사용될 수 있고 컨트리뷰터들에게도 필요하죠. 그런 이유로, 이 패키지를 오픈소스로 만들겠다고 지난 커널 서밋 발표에서 이야기 했었습니다 (https://linuxplumbersconf.org/event/7/contributions/659/).\n어제, 이 패키지 를 마침내 GPL v2 라이센스의 오픈소스로 릴리즈 했습니다. 이제 DAMON 인터페이스를 이해하고 여러분의 기계 위에서 스스로 DAMON 을 테스트 하는데 이 패키지를 사용하실 수 있습니다.\n","permalink":"https://sjp38.github.io/posts/ko/damon-tests_open_sourced/","summary":"DAMON 은 kselftest 와 kunit 에 기반한 여러 테스트를 자신의 패치셋에 포함시켜 두고 있습니다. 커널 트리에 위치하는 테스트는 짧은 수행시간만 가지는게 바람직하므로, 시간을 오래 소요하는 테스트들을 패키지화 해서 저희 회사 내에서만 사용해 오고 있었습니다. 테스트는 좋은 문서로 사용될 수 있고 컨트리뷰터들에게도 필요하죠. 그런 이유로, 이 패키지를 오픈소스로 만들겠다고 지난 커널 서밋 발표에서 이야기 했었습니다 (https://linuxplumbersconf.org/event/7/contributions/659/).\n어제, 이 패키지 를 마침내 GPL v2 라이센스의 오픈소스로 릴리즈 했습니다. 이제 DAMON 인터페이스를 이해하고 여러분의 기계 위에서 스스로 DAMON 을 테스트 하는데 이 패키지를 사용하실 수 있습니다.","title":"DAMON 테스트 패키지가 GPL v2 로 릴리즈 되었습니다"},{"content":"DAMON contains a number of tests based on the kselftest and kunit in its patchset itself. As it is preferred to contain only tests having short runtime in kernel tree, I organized time consuming tests in a package and used it in my company only. Tests could be used as a good document and essential for contributors. For the reason, I promised I will make it open source in the last kernel summit talk (https://linuxplumbersconf.org/event/7/contributions/659/).\nYesterday, I finally publicly released the package under GPL v2. Now you can use the package to understand the DAMON interface and test it on your machine by yourself.\n","permalink":"https://sjp38.github.io/posts/damon-tests_open_sourced/","summary":"DAMON contains a number of tests based on the kselftest and kunit in its patchset itself. As it is preferred to contain only tests having short runtime in kernel tree, I organized time consuming tests in a package and used it in my company only. Tests could be used as a good document and essential for contributors. For the reason, I promised I will make it open source in the last kernel summit talk (https://linuxplumbersconf.","title":"Tests package for DAMON is released under GPL v2"},{"content":"My talk proposal to the Linux Kernel Summit of this year which is co-located with the Linux Plumbers Conference has accepted! Hope to (virtually) see you there. The title of the talk is, \u0026ldquo;DAMON: Data Access Monitoring Framework for Fun and Memory Management Optimizations\u0026rdquo;.\n","permalink":"https://sjp38.github.io/posts/kernelsummit2020_talk/","summary":"My talk proposal to the Linux Kernel Summit of this year which is co-located with the Linux Plumbers Conference has accepted! Hope to (virtually) see you there. The title of the talk is, \u0026ldquo;DAMON: Data Access Monitoring Framework for Fun and Memory Management Optimizations\u0026rdquo;.","title":"I will have a talk at the Linux Kernel Summit 2020"},{"content":"A DAMON showcase website[1] is open. There are\nthe official documentation of DAMON[2], the heatmap format dynamic access pattern of various realistic workloads for heap area[3], mmap()-ed area[4], and stack[5] area, the dynamic working set size distribution[6] and chronological working set size changes[7], and the latest performance test results[8]. [1] https://damonitor.github.io\n[2] https://damonitor.github.io/doc/html/latest\n[3] https://damonitor.github.io/test/result/visual/latest/heatmap.0.html\n[4] https://damonitor.github.io/test/result/visual/latest/heatmap.1.html\n[5] https://damonitor.github.io/test/result/visual/latest/heatmap.2.html\n[6] https://damonitor.github.io/test/result/visual/latest/wss_sz.html\n[7] https://damonitor.github.io/test/result/visual/latest/wss_time.html\n[8] https://damonitor.github.io/test/result/perf/latest/html/index.html\n","permalink":"https://sjp38.github.io/posts/damon_github_page/","summary":"A DAMON showcase website[1] is open. There are\nthe official documentation of DAMON[2], the heatmap format dynamic access pattern of various realistic workloads for heap area[3], mmap()-ed area[4], and stack[5] area, the dynamic working set size distribution[6] and chronological working set size changes[7], and the latest performance test results[8]. [1] https://damonitor.github.io\n[2] https://damonitor.github.io/doc/html/latest\n[3] https://damonitor.github.io/test/result/visual/latest/heatmap.0.html\n[4] https://damonitor.github.io/test/result/visual/latest/heatmap.1.html\n[5] https://damonitor.github.io/test/result/visual/latest/heatmap.2.html\n[6] https://damonitor.github.io/test/result/visual/latest/wss_sz.html\n[7] https://damonitor.github.io/test/result/visual/latest/wss_time.html\n[8] https://damonitor.github.io/test/result/perf/latest/html/index.html","title":"Opening a Showcase Website for DAMON"},{"content":"DAMON 소개를 위한 웹사이트[1] 를 열었습니다.\nDAMON 공식 문서[2], 실제에 가까운 여러 워크로드의 힙[3], mmap() 된 영역[4], 그리고 스택[5] 에 대한 히트맵 포맷의 동적 액세스 패턴들, 동적 워킹셋 사이즈의 분포[6] 와 시간대에 따른 워킹셋 사이즈의 변화양상[7], 그리고 성능 테스트 결과[8] 를 확인해 보실 수 있습니다.\n[1] https://damonitor.github.io\n[2] https://damonitor.github.io/doc/html/latest\n[3] https://damonitor.github.io/test/result/visual/latest/heatmap.0.html\n[4] https://damonitor.github.io/test/result/visual/latest/heatmap.1.html\n[5] https://damonitor.github.io/test/result/visual/latest/heatmap.2.html\n[6] https://damonitor.github.io/test/result/visual/latest/wss_sz.html\n[7] https://damonitor.github.io/test/result/visual/latest/wss_time.html\n[8] https://damonitor.github.io/test/result/perf/latest/html/index.html\n","permalink":"https://sjp38.github.io/posts/ko/damon_github_page/","summary":"DAMON 소개를 위한 웹사이트[1] 를 열었습니다.\nDAMON 공식 문서[2], 실제에 가까운 여러 워크로드의 힙[3], mmap() 된 영역[4], 그리고 스택[5] 에 대한 히트맵 포맷의 동적 액세스 패턴들, 동적 워킹셋 사이즈의 분포[6] 와 시간대에 따른 워킹셋 사이즈의 변화양상[7], 그리고 성능 테스트 결과[8] 를 확인해 보실 수 있습니다.\n[1] https://damonitor.github.io\n[2] https://damonitor.github.io/doc/html/latest\n[3] https://damonitor.github.io/test/result/visual/latest/heatmap.0.html\n[4] https://damonitor.github.io/test/result/visual/latest/heatmap.1.html\n[5] https://damonitor.github.io/test/result/visual/latest/heatmap.2.html\n[6] https://damonitor.github.io/test/result/visual/latest/wss_sz.html\n[7] https://damonitor.github.io/test/result/visual/latest/wss_time.html\n[8] https://damonitor.github.io/test/result/perf/latest/html/index.html","title":"DAMON 쇼케이스 웹사이트를 열었습니다"},{"content":"최근, Sphynx 빌드 시스템[1] 을 사용해 html 로 빌드한 리눅스 커널 문서를 Github page[2] 에 올리려 했습니다. DAMON[3] 문서를 어디서나 볼 수 있게 하려 함이었는데요. 업로드는 쉬웠습니다. 리포지토리 만들고, Sphynx 로 빌드된 Documentation/output/ 의 문서를 여기에 집어넣고 푸시했죠. 하지만, 테마가 적용되지 않아 보기 안좋더군요.\nGithub 은 모든 Github page 들이 Jekyll[4] 에 기반하고 있다고 생각하며, Jekyll 에서는 _ 로 시작하는 이름의 모든 파일과 디렉토리가 특수하게 처리되기 때문에, Sphynx 에서 생성한 일부 디렉토리가 무시되고 있었습니다.\n.nojekyll 이라는 이름의 파일을 리포지토리의 루트에 놓고 푸시해 줌으로써 Github page 가 여러분의 사이트가 Jekyll 로 만들어진 것이 아님을 알게 해줄 수 있습니다. 예를 들면 다음과 같습니다.\n$ cd \u0026lt;your github page repo\u0026gt; $ touch .nojekyll $ git add .nojekyll; git commit -m \u0026#34;Add .nojekyll\u0026#34;; git push 이 파일은 다른 곳이 아닌 리포지토리의 루트에 위치해야함을 기억하세요.\n이 수정 후, 제 문서[5] 역시 기대한 대로 동작합니다 :)\n[1] https://www.kernel.org/doc/html/latest/doc-guide/sphinx.html#sphinx-build\n[2] https://pages.github.com/\n[3] https://sjp38.github.io/post/damon/\n[4] https://jekyllrb.com/\n[5] https://damonitor.github.io/doc/html/latest/admin-guide/mm/data_access_monitor.html\n","permalink":"https://sjp38.github.io/posts/ko/sphynx_doc_on_github_pages_needs_nojekyll/","summary":"최근, Sphynx 빌드 시스템[1] 을 사용해 html 로 빌드한 리눅스 커널 문서를 Github page[2] 에 올리려 했습니다. DAMON[3] 문서를 어디서나 볼 수 있게 하려 함이었는데요. 업로드는 쉬웠습니다. 리포지토리 만들고, Sphynx 로 빌드된 Documentation/output/ 의 문서를 여기에 집어넣고 푸시했죠. 하지만, 테마가 적용되지 않아 보기 안좋더군요.\nGithub 은 모든 Github page 들이 Jekyll[4] 에 기반하고 있다고 생각하며, Jekyll 에서는 _ 로 시작하는 이름의 모든 파일과 디렉토리가 특수하게 처리되기 때문에, Sphynx 에서 생성한 일부 디렉토리가 무시되고 있었습니다.","title":"Sphynx document on Github pages Needs `.nojekyll` File"},{"content":"I recently tried to upload the Linux kernel document which is generated in html form using the Sphynx build system[1] on a Github page[2] so that people can read DAMON[3] document from everywhere. The upload was very easy. I simply created the repo, put the generated html doc at Documentation/output/ into the repo and pushed. However, the theme was not applied.\nGithub assumes every Github pages to be based on Jekyll[4], and because every files and directories starting with underscores are handled special in Jekyll, some directories Sphynx created were ignored.\nYou can simply let Github pages to know your site is not generated with Jekyll by putting .nojekyll file with no content on your root of the repo and push. For example,\n$ cd \u0026lt;your github page repo\u0026gt; $ touch .nojekyll $ git add .nojekyll; git commit -m \u0026#34;Add .nojekyll\u0026#34;; git push Note that the file should be located in the root of the repo, not somewhere else.\nAfter this fix, my document[5] also works :)\n[1] https://www.kernel.org/doc/html/latest/doc-guide/sphinx.html#sphinx-build\n[2] https://pages.github.com/\n[3] https://sjp38.github.io/post/damon/\n[4] https://jekyllrb.com/\n[5] https://damonitor.github.io/doc/html/latest/admin-guide/mm/data_access_monitor.html\n","permalink":"https://sjp38.github.io/posts/sphynx_doc_on_github_pages_needs_nojekyll/","summary":"I recently tried to upload the Linux kernel document which is generated in html form using the Sphynx build system[1] on a Github page[2] so that people can read DAMON[3] document from everywhere. The upload was very easy. I simply created the repo, put the generated html doc at Documentation/output/ into the repo and pushed. However, the theme was not applied.\nGithub assumes every Github pages to be based on Jekyll[4], and because every files and directories starting with underscores are handled special in Jekyll, some directories Sphynx created were ignored.","title":"Sphynx document on Github pages Needs `.nojekyll` File"},{"content":"ACM has decided to allow open access to every article in ACM DL until June 30, to help people doing remote works due to COVID-19. I found this by checking my papers in ACM DL. I believe this is a great decision of ACM.\n","permalink":"https://sjp38.github.io/posts/acmdl_is_open_until_june/","summary":"ACM has decided to allow open access to every article in ACM DL until June 30, to help people doing remote works due to COVID-19. I found this by checking my papers in ACM DL. I believe this is a great decision of ACM.","title":"ACM DL is allowing open access to every article until June"},{"content":"COVID-19 로 인해 원격 업무를 해야하는 사람들을 위해 ACM 이 ACM DL 의 모든 논문을 6월 30일까지 누구나 볼 수 있게 했습니다. ACM DL 에 올라와 있는 제 논문들을 보러 갔다가 우연히 알게 됐네요. ACM 이 참 잘한 선택 같습니다.\n","permalink":"https://sjp38.github.io/posts/ko/acmdl_is_open_until_june/","summary":"COVID-19 로 인해 원격 업무를 해야하는 사람들을 위해 ACM 이 ACM DL 의 모든 논문을 6월 30일까지 누구나 볼 수 있게 했습니다. ACM DL 에 올라와 있는 제 논문들을 보러 갔다가 우연히 알게 됐네요. ACM 이 참 잘한 선택 같습니다.","title":"ACM DL is allowing open access to every article until June"},{"content":"With the upload of the accepted papers list, EuroSys homepage also updated its notice about COVID-19 related notification. It previously tried to reschedule the offline meeting, however seems they changed mind and decided to do virtual (online) conference. It\u0026rsquo;s a bad news for authors and people who planned to participate the offline meetings, but a good new for other people, because they would be allowed to participate in the conference without fee.\n","permalink":"https://sjp38.github.io/posts/eurosys20_will_be_held_online/","summary":"With the upload of the accepted papers list, EuroSys homepage also updated its notice about COVID-19 related notification. It previously tried to reschedule the offline meeting, however seems they changed mind and decided to do virtual (online) conference. It\u0026rsquo;s a bad news for authors and people who planned to participate the offline meetings, but a good new for other people, because they would be allowed to participate in the conference without fee.","title":"Eurosys'20 will be held online"},{"content":"Accepted paper 리스트 업로드와 함께 EuroSys 홈페이지의 COVID-19 관련 공지도 업데이트 되었습니다. 이전에는 오프라인 미팅 일정을 재조정하려 하고 있다 했지만, 가상 (온라인) 컨퍼런스로 치루기로 결정되었나봅니다. 논문 저자들과 오프라인 미팅을 참여하려고 했던 사람들에겐 안좋은 소식입니다만 다른 사람들에겐 좋은 소식이기도 합니다, 무료로 컨퍼런스에 참여할 수 있을테니까요.\n","permalink":"https://sjp38.github.io/posts/ko/eurosys20_will_be_held_online/","summary":"Accepted paper 리스트 업로드와 함께 EuroSys 홈페이지의 COVID-19 관련 공지도 업데이트 되었습니다. 이전에는 오프라인 미팅 일정을 재조정하려 하고 있다 했지만, 가상 (온라인) 컨퍼런스로 치루기로 결정되었나봅니다. 논문 저자들과 오프라인 미팅을 참여하려고 했던 사람들에겐 안좋은 소식입니다만 다른 사람들에겐 좋은 소식이기도 합니다, 무료로 컨퍼런스에 참여할 수 있을테니까요.","title":"Eurosys'20 이 온라인 컨퍼런스로 치뤄집니다"},{"content":"Read-copy update (RCU) can provide ideal scalability for read-mostly workloads, but some believe that it provides only poor performance for updates. This belief is due to the lack of RCU-centric update synchronization mechanisms. RCU instead works with a range of update-side mechanisms, such as locking. In fact, many developers embrace simplicity by using global locking. Logging, hardware transactional memory, or fine-grained locking can provide better scalability, but each of these approaches has limitations, such as imposing overhead on readers or poor scalability on non-uniform memory access (NUMA) systems, mainly due to their lack of NUMA-aware design principles.\nThis project introduces an RCU extension (RCX) that provides highly scalable RCU updates on NUMA systems while retaining RCU’s read-side benefits. RCX combines hardware transactional memory (HTM) and traditional locking based on our NUMA-aware design principles for RCU. Micro-benchmarks on a NUMA system having 144 hardware threads show RCX has up to 22.61 times better performance and up to 145.00 times lower HTM abort rates compared to a state-of-the-art RCU/HTM combination. To demonstrate the effectiveness and applicability of RCX, we have applied RCX to parallelize some of the Linux kernel memory management system and an in-memory database system. The optimized kernel and the database show up to 24 and 17 times better performance compared to the original version, respectively.\nSource Code The source code of RCX is available at: https://github.com/rcx-sync.\nPublications and Presentations SeongJae Park, Paul E. McKenney, Laurent Dufour, Heon Y. Yeom, An HTM-Based Update-side Synchronization for RCU on NUMA systems. In 15th ACM European Conference on Computer Systems (EuroSys), April 2020. Paper, Video (Short), Video (Long), Slides, Link News 2020-04-19: The EuroSys'20 paper is uploaded at ACM DL.\n2020-04-04: The accepted papers list of EuroSys'20 has uploaded\n2020-02-14: The paper introducing RCX has accepted to be presented by EuroSys'20.\n","permalink":"https://sjp38.github.io/posts/ko/rcx/","summary":"Read-copy update (RCU) can provide ideal scalability for read-mostly workloads, but some believe that it provides only poor performance for updates. This belief is due to the lack of RCU-centric update synchronization mechanisms. RCU instead works with a range of update-side mechanisms, such as locking. In fact, many developers embrace simplicity by using global locking. Logging, hardware transactional memory, or fine-grained locking can provide better scalability, but each of these approaches has limitations, such as imposing overhead on readers or poor scalability on non-uniform memory access (NUMA) systems, mainly due to their lack of NUMA-aware design principles.","title":"RCX: Read-Copy Transact"},{"content":"Read-copy update (RCU) can provide ideal scalability for read-mostly workloads, but some believe that it provides only poor performance for updates. This belief is due to the lack of RCU-centric update synchronization mechanisms. RCU instead works with a range of update-side mechanisms, such as locking. In fact, many developers embrace simplicity by using global locking. Logging, hardware transactional memory, or fine-grained locking can provide better scalability, but each of these approaches has limitations, such as imposing overhead on readers or poor scalability on non-uniform memory access (NUMA) systems, mainly due to their lack of NUMA-aware design principles.\nThis project introduces an RCU extension (RCX) that provides highly scalable RCU updates on NUMA systems while retaining RCU’s read-side benefits. RCX combines hardware transactional memory (HTM) and traditional locking based on our NUMA-aware design principles for RCU. Micro-benchmarks on a NUMA system having 144 hardware threads show RCX has up to 22.61 times better performance and up to 145.00 times lower HTM abort rates compared to a state-of-the-art RCU/HTM combination. To demonstrate the effectiveness and applicability of RCX, we have applied RCX to parallelize some of the Linux kernel memory management system and an in-memory database system. The optimized kernel and the database show up to 24 and 17 times better performance compared to the original version, respectively.\nSource Code The source code of RCX is available at: https://github.com/rcx-sync.\nPublications and Presentations SeongJae Park, Paul E. McKenney, Laurent Dufour, Heon Y. Yeom, An HTM-Based Update-side Synchronization for RCU on NUMA systems. In 15th ACM European Conference on Computer Systems (EuroSys), April 2020. Paper, Video (Short), Video (Long), Slides, Link News 2020-04-19: The EuroSys'20 paper is uploaded at ACM DL.\n2020-04-04: The accepted papers list of EuroSys'20 has uploaded\n2020-02-14: The paper introducing RCX has accepted to be presented by EuroSys'20.\n","permalink":"https://sjp38.github.io/posts/rcx/","summary":"Read-copy update (RCU) can provide ideal scalability for read-mostly workloads, but some believe that it provides only poor performance for updates. This belief is due to the lack of RCU-centric update synchronization mechanisms. RCU instead works with a range of update-side mechanisms, such as locking. In fact, many developers embrace simplicity by using global locking. Logging, hardware transactional memory, or fine-grained locking can provide better scalability, but each of these approaches has limitations, such as imposing overhead on readers or poor scalability on non-uniform memory access (NUMA) systems, mainly due to their lack of NUMA-aware design principles.","title":"RCX: Read-Copy Transact"},{"content":"The last research paper I wrote before joining my current team, has been accepted to be presented by the EuroSys'20. The title of the paper is “An HTM-Based Update-side Synchronization for RCU on NUMA systems”.\n","permalink":"https://sjp38.github.io/posts/eurosys2020_talk/","summary":"The last research paper I wrote before joining my current team, has been accepted to be presented by the EuroSys'20. The title of the paper is “An HTM-Based Update-side Synchronization for RCU on NUMA systems”.","title":"My paper has accepted to appear in the EuroSys2020"},{"content":"지금 회사에 합류하기 전에 마지막으로 쓴 제 연구 논문이 EuroSys'20 에 액셉되었습니다. 논문의 제목은 “An HTM-Based Update-side Synchronization for RCU on NUMA systems” 입니다.\n","permalink":"https://sjp38.github.io/posts/ko/eurosys2020_talk/","summary":"지금 회사에 합류하기 전에 마지막으로 쓴 제 연구 논문이 EuroSys'20 에 액셉되었습니다. 논문의 제목은 “An HTM-Based Update-side Synchronization for RCU on NUMA systems” 입니다.","title":"My paper has accepted to appear in the EuroSys2020"},{"content":"In some case, we need to send patches that made by other people instead. git send-email command can know this situation by itself by comparing the commit author information and mail sender\u0026rsquo;s information. In that case, git send-email automatically add From: line pointing the real author of the patch in the body of the mail so that maintainers applying the patches can set the author information correctly.\nFor example, if \u0026ldquo;Alice alice@abc.com\u0026rdquo; has made a commit and \u0026ldquo;Bob bob@abc.com\u0026rdquo; formats the commit into a patch file and sends it, git send-email automatically adds From: Alice \u0026lt;alice@abc.com\u0026gt; line in the body of the mail. And, when a maintainer is applying the patch using git am, the patch is applied with author \u0026ldquo;Alice alice@abc.com\u0026rdquo;.\nHowever, please note that git send-email knows the situation by comparing the author information and the command caller\u0026rsquo;s git user eamil configuration or given \u0026lsquo;\u0026ndash;from\u0026rsquo; option only, not considering real smtp email account.\nFor example, suppose that Alice has two email accounts, alice@abc.com and alice@def.com. And, Alice wants to use alice@abc.com as her email address in the git history, but needs to send her patches using def.com SMTP server. She might use below commands.\n$ git config sendemail.smtpserver smtp.def.com $ git config sendemail.smtpuser alice@def.com $ git config user.email \u0026#34;alice@abc.com\u0026#34; $ git commit -as -m \u0026#39;the patch\u0026#39; $ git format-patch HEAD^ $ git send-email 0001_the_patch.patch Because her git config is saying the user.email is alice@abc.com and the patch is authored by alice@abc.com, git send-email thinks same people is sending the patch. Thus, it doesn\u0026rsquo;t add the \u0026lsquo;From:\u0026rsquo; line in the body of the mail. Of course, git send-email tries to set the from of the mail as alice@abc.com, but as the additionally specified \u0026lsquo;from\u0026rsquo; information is usually (at least gmail does) ignored by the SMTP server, the maintainer will receive the mail saying author email as \u0026lsquo;alice@def.com\u0026rsquo; only.\nNote that git send-email considers the email address it tries to use as the from address, not the final one that SMTP server will use. Thus, this problem can be worked around in weird way using the --from option of the git send-email. In the above case, giving --from \u0026quot;Alice \u0026lt;alice@def.com\u0026gt;\u0026quot; option to git send-email makes the command to think the sender is not the author (alice@abc.com) and as a result, it adds the From: line in the body.\nAlso, please note that adding --from option does not always add the From: line in the body. Rather than that, it can even hide the From: line you intended to add, if you give the address that same with the commit\u0026rsquo;s author, regardless of what SMTP server you use. For example,\n$ git config sendemail.smtpserver smtp.def.com $ git config sendemail.smtpuser alice@def.com $ git config user.email \u0026#34;alice@abc.com\u0026#34; $ git commit -as -m \u0026#39;the patch\u0026#39; $ git format-patch HEAD^ $ git config user.email \u0026#34;alice@def.com\u0026#34; $ git send-email --from alice@abc.com 0001_the_patch.patch If the final command had no --from option, it would added the From: in-body line. However, because it specifies the real author address using --from option, git send-email thinks the real author is sending this mail and omits the From: line in the body.\n","permalink":"https://sjp38.github.io/posts/git_send_email_multiple_email_caution/","summary":"In some case, we need to send patches that made by other people instead. git send-email command can know this situation by itself by comparing the commit author information and mail sender\u0026rsquo;s information. In that case, git send-email automatically add From: line pointing the real author of the patch in the body of the mail so that maintainers applying the patches can set the author information correctly.\nFor example, if \u0026ldquo;Alice alice@abc.","title":"A thing you should know if you are using multiple email accounts with `git send-email`"},{"content":"많은 개발 커뮤니티가 요즘은 Github 을 사용합니다만, 일부 커뮤니티는 여전히 메일링 리스트 기반 개발 스타일을 고수하고 있습니다. 리눅스 커널 커뮤니티가 좋은 예가 되겠죠. 이런 스타일에서는 모든 주요 커뮤니케이션이 이메일을 통해 이루어집니다. 패치는 메인테이너와 하나 이상의 공개 메일링 리스트를 향해 메일의 형태로 보내어집니다. 리뷰 또한 이에 대한 답장의 형태로 이루어지지요.\n그런데, 일부 이메일 클라이언트는 ``rich user experience\u0026rsquo;\u0026rsquo; 라는 명목하에 원래 내용을 오염시키곤 합니다. 탭을 스페이스로 바꾸거나 html 코드를 집어넣거나 하는 식이죠. 때문에 패치를 보내는 사람은 자신의 메일 내용이 원래 의도한대로 읽는 사람에게 보내지도록 조심해야합니다. 이건 짜증나거니와 일부 메일 클라이언트에서는 불가능하기까지 합니다.\n이런 이유로, git 은 패치를 만들고 SMTP 를 통해 이메일로 보내는 걸 돕는 기능을 갖고 있습니다. 이 포스트는 git 을 이용해 이메일을 어떻게 보낼 수 있는지 간략히 정리해 봅니다.\n필요 패키지 설치 여러분이 패키지 매니저를 이용해 git 을 설치했다면, git 패키지 외에도 git-email 패키지를 설치해야 합니다. apt 패키지 매니저를 사용하신다면, 아래 커맨드를 입력해 주세요: $ sudo apt install git-email on the terminal.\nSMTP 설정 이제, 여러분의 smtp 서버 관련 설정을 할 차례입니다. 물론, 여러분의 메일 계정의 smtp 설정을 먼저 활성화 해둬야 합니다. 이게 되었다면 git 에게 여러분의 메일 계정을 smtp 를 통해 사용하기 위한 정보를 입력해야겠죠. git config 를 사용하는데요, 예를 들어 Gmail 계정을 사용하고자 하신다면, 아래와 같습니다:\n$ git config --global sendemail.smtpserver smtp.gmail.com $ git config --global sendemail.smtpserverport 587 $ git config --global sendemail.smtpencryption tls $ git config --global sendemail.smtpuser \u0026lt;your-gmail-account@gmail.com\u0026gt; 해당 메일 계정의 패스워드도 아래와 같이 저장해 둘 수 있습니다만, 이런 방법은 보안에 위험할 수 있으니 추천하진 않습니다.\n$ git config --global sendemail.smtppass \u0026lt;your_password\u0026gt; 메일 보내기 메일을 보내긴 매우 간단합니다. 먼저 여러분이 보내고자 하는 메일 내용을 파일에 저장하세요. git format-patch 를 통해 만든 패치 파일이 될 수도 있겠습니다. 그러고 나서, 누구에게 메일을 보낼 건지를 확실해 기억해 두시구요. 이제, 아래 커맨드를 입력합니다.\n$ git send-email --to \u0026lt;수신인들\u0026gt; \u0026lt;the file containing your message\u0026gt; 앞서 메일 계정 패스워드를 저장해 주지 않았다면 (다시 말하지만 저장하지 말 것을 추천합니다), 이 커멘드는 메일 계정 패스워드를 물어볼 겁니다. 이제, 해당 메일이 여러분이 지정한 수신인에게 전달될 겁니다.\n더 자세한 정보를 위해선, $ git help send-email 커맨드를 사용하세요.\n결론 어떻게 Git 을 이용해 이메일을 보낼 수 있는지 정리해 보았습니다. 패키지를 설치하고, SMTP 설정하고, 보내고자 하는 메세지를 파일에 저장 후, git send-email. 그게 답니다. :)\n","permalink":"https://sjp38.github.io/posts/ko/git_email_setup/","summary":"많은 개발 커뮤니티가 요즘은 Github 을 사용합니다만, 일부 커뮤니티는 여전히 메일링 리스트 기반 개발 스타일을 고수하고 있습니다. 리눅스 커널 커뮤니티가 좋은 예가 되겠죠. 이런 스타일에서는 모든 주요 커뮤니케이션이 이메일을 통해 이루어집니다. 패치는 메인테이너와 하나 이상의 공개 메일링 리스트를 향해 메일의 형태로 보내어집니다. 리뷰 또한 이에 대한 답장의 형태로 이루어지지요.\n그런데, 일부 이메일 클라이언트는 ``rich user experience\u0026rsquo;\u0026rsquo; 라는 명목하에 원래 내용을 오염시키곤 합니다. 탭을 스페이스로 바꾸거나 html 코드를 집어넣거나 하는 식이죠. 때문에 패치를 보내는 사람은 자신의 메일 내용이 원래 의도한대로 읽는 사람에게 보내지도록 조심해야합니다.","title":"Git 을 사용해 이메일 보내기"},{"content":"Many communities are using Github nowadays, but some communities still use mailing list based development style. The Linux kernel community would be a good example. In the style, all major communications are made by email only. Patches are submitted to the maintainers and one more open mailing lists as a mail. Reviews are also made as replies to the mail.\nBecause some email clients can distort the original content for so-called ``rich user experience\u0026rsquo;\u0026rsquo; (e.g., changing tabs to spaces or inserting html code), patch submitting people should aware of it and try to keep their mail content to be plain. This can be awful or even impossible on some mail clients.\nGit can help formatting and sending your patch files using SMTP. This post describes how you can use git to send email.\nPackage Install If you installed git using the package manager, you should install not only git package, but also git-email package. If you are using apt package manager, simply type $ sudo apt install git-email on the terminal.\nSMTP Setting Then, set smtp server configurations for you. Of course, you should enable the smtp configuration on your mail accout first. If your mail account is ready for the smtp, now you should let git to know how it can access to your mail account using \u0026lsquo;git config\u0026rsquo;. If you want to use your Gmail account, it will be as below:\n$ git config --global sendemail.smtpserver smtp.gmail.com $ git config --global sendemail.smtpserverport 587 $ git config --global sendemail.smtpencryption tls $ git config --global sendemail.smtpuser \u0026lt;your-gmail-account@gmail.com\u0026gt; You can also set the mail account password as below, but I will recommend you to not store your password in that way, because it can harm your security.\n$ git config --global sendemail.smtppass \u0026lt;your_password\u0026gt; Send Mail Sending mail is so easy. You should first save your mail message in a file. This could be patch file, which can also easily formatted using git format-patch. After that, make sure you know who you want your mail to be sent to. Now, just type below command.\n$ git send-email --to \u0026lt;recipients\u0026gt; \u0026lt;the file containing your message\u0026gt; If you have not set your password (again, I recommend you do not save your password), this command will ask your password. Just type it on the prompt. Then, your mail will delivered to the recipients you specified.\nFor more detail, $ git help send-email.\nConclusion Summarised how you can send email using Git. Install packages, set SMTP, write your mail in a plain file, and git send-email. That\u0026rsquo;s it. :)\n","permalink":"https://sjp38.github.io/posts/git_email_setup/","summary":"Many communities are using Github nowadays, but some communities still use mailing list based development style. The Linux kernel community would be a good example. In the style, all major communications are made by email only. Patches are submitted to the maintainers and one more open mailing lists as a mail. Reviews are also made as replies to the mail.\nBecause some email clients can distort the original content for so-called ``rich user experience\u0026rsquo;\u0026rsquo; (e.","title":"Setting Git for email send"},{"content":"!! NOTE !!\nThis post has migrated to https://damonitor.github.io/posts/damon. This out-dated post will be removed soon.\nWith increasingly data-intensive workloads and limited DRAM capacity, optimal memory management based on dynamic access patterns is becoming increasingly important. Such mechanisms are only possible if accurate and efficient dynamic access pattern monitoring is available.\nDAMON is a Data Access MONitoring framework subsystem for the Linux kernel developed for such memory management. It is designed with some key mechanism (refer to Design for the detail) that make it\naccurate (the monitoring output is useful enough for DRAM level memory management; It might not be appropriate for CPU Cache levels, though), light-weight (the monitoring overhead is low enough to be applied online), and scalable (the upper-bound of the overhead is in constant range regardless of the size of target workloads). Therefore, DAMON can be used to develop memory management based on any access pattern. To make it easier to develop such systems, DAMON provides a feature called DAMON-based Operation Schemes (DAMOS). This allows DAMON users to develop and execute access-aware memory management without code but with a simple setup.\nSimple mechanisms based on DAMOS can achieve up to 12% performance improvement and 91% memory savings. Detailed evaluation of DAMON and DAMON-based system optimizations are available at another post.\nDAMON is also currently being used in real-world products including AWS Aurora Serverless v2 and SK hynix HMSDK v2.\nTable Of Contents Demo Video Demo Screenshot Recent News Getting Started Install Source Code User-space Tool Tests Package Official Document Showcase Website Evaluation Results DAMON-based System Optimization Guide Profile-Guided Optimization Example Community Contribution Publications and Presentations Demo Video Demo Screenshot Recent News Below are only a short list of recent news. For complete list of the news, please refer to a dedicated post.\n2024-10-15: DAMON debugfs interface removal RFC patch has posted.\n2024-10-10: Monthly PyPI downloads of DAMON user-space too, DAMO, doubled again after ten days. !damo_9000_monthly_downloads !damo_rolling_monthly_downloads_2024-10-10\n2024-10-08: Videos for DAMON recipes at Open Source Summit EU'2024 and DAMON long-term plans at Kernel Memory Management Microconference'2024 are uploaded to YouTube.\n2024-10-01: 2024-Q3 DAMON news letter including news for new features, more users, repos reorganizations, and conference talks is posted.\n2024-09-30: DAMON User Space Tool, DAMO, surpasses 4,000 monthly PyPI downloads! Getting Started You can start using DAMON by\ninstalling DAMON-enabled kernel and its user-space tool, following the tutorial of the user-space tool, and run the automated tests suite. By following those, you will be able to know if DAMON works on your machine and how you can use it.\nYou can also participate in the development if you\u0026rsquo;re interested.\nInstall DAMON is implemented in the Linux kernel, so you should install DAMON-enabled Linux kernel to use it. To check if you\u0026rsquo;re already running DAMON-enabled kernel, you could:\n$ if grep -q '^CONFIG_DAMON=y' /boot/config-$(uname -r); then echo \u0026quot;installed\u0026quot; else echo \u0026quot;not installed\u0026quot; fi As of 2024-09-23, kernels of Linux distros including Amazon Linux, Android, Arch, CentOS, Debian, Fedora, and Oracle Linux are known to have enabled DAMON.\nYou could further find a list of DAMON-enabled Linux kernels from Oracle\u0026rsquo;s kconfigs tool. The tool doesn\u0026rsquo;t support every distros at the moment, though.\nIf your package system doesn\u0026rsquo;t support DAMON-enabled kernel, you can fetch a DAMON-merged Linux kernel source tree, build, and install it. Note that you should enable kernel configuration options for DAMON, depending on your demands. For example:\n$ cd $THE_FETCHED_DAMON_KERNEL_SOURCE_TREE $ make olddefconfig $ echo 'CONFIG_DAMON=y' \u0026gt;\u0026gt; ./.config $ echo 'CONFIG_DAMON_VADDR=y' \u0026gt;\u0026gt; ./.config $ echo 'CONFIG_DAMON_PADDR=y' \u0026gt;\u0026gt; ./.config $ echo 'CONFIG_DAMON_SYSFS=y' \u0026gt;\u0026gt; ./.config $ echo 'CONFIG_DAMON_DBGFS=y' \u0026gt;\u0026gt; ./.config $ echo 'CONFIG_DAMON_RECLAIM=y' \u0026gt;\u0026gt; ./.config $ echo 'CONFIG_DAMON_LRU_SORT=y' \u0026gt;\u0026gt; ./.config $ make -j$(nproc) $ sudo make modules_install install Source Code There are several Linux kernel source trees having DAMON for different users. You may pick one among those based on your needs.\nFor users who want a stable version of DAMON, Linus Torvalds' mainline tree is recommended.\nIf you have interests in DAMON features under development, below trees will be appropriate. These trees contain latest version of DAMON which having features under development.\nmm-unstable contains the latest DAMON patches, which are under testing with other unstable memory management subsystem patches. So this tree is likely unstable and frequently updated, but would be a good baseline for your DAMON development. damon/next contains the latest changes, which might not tested at all. So this tree is likely more unstable and frequently updated than mm-unstable. This tree also contains some changes that exist only for DAMON hacks itself rather than eventually be merged in the mainline. For people who have interest in DAMON features under development but use LTS kernels as their baseline, three were trees that based on three latest LTS kernels.\nNOTE: Below trees were continuously getting DAMON backports on latest 5.4.y, 5.10.y, and 5.15.y. But those are deprecated as of 2022-09-03, and therefore there will be no update to the trees.\ndamon/for-v5.15.y damon/for-v5.10.y damon/for-v5.4.y The source code of DAPTRACE, which is a prototype of DAMON, is also available.\nUser-space Tool A user-space tool for DAMON, which is called DAMO (Data Access Monitoring Operator), is available at Github and PyPi. You may start using DAMON by following the Getting Started of the tool for start.\nTests Package There is a tests suite for correctness verification and performance evaluation of DAMON. Those are actively used for the development of DAMON. Using that, you can test DAMON on your machine with only a few simple commands or deeply understand the user interface of DAMON.\nSo, if you finished the tutorial but have no idea about what to do next, running the tests would be a good start. If any test fails, please report that to the maintainer via mail (sj@kernel.org or damon@lists.linux.dev) or github.\nOfficial Document The official document of DAMON in the latest mainline for users/sysadmins and kernel programmers are available. Those for next major release are also available(users/sysadmins doc, kernel programmers doc).\nShowcase Website There is a showcase website that you can get more information of DAMON. The site hosts\nthe heatmap format dynamic access pattern of various realistic workloads for heap area, mmap()-ed area, and stack area, the dynamic working set size distribution and chronological working set size changes, and daily performance test results. Evaluation Results Evaluation of DAMON and DAMON-based system optimizations are available.\nDAMON-based System Optimization Guide A guide for DAMON-based system optimizations are also available.\nProfile-Guided Optimization Example An example of DAMON-based profile-guided optimization is also available.\nCommunity DAMON is maintained and developed by its own community, which is a sub-set of the linux kernel development community.\nThe community is mainly driven by the mailing list (damon@lists.linux.dev). All the patches are posted there and reviewed. Almost every discussions are also made there.\nFor easy communication, a mailing tool called HacKerMaiL is recommended. The tool is maintained by DAMON maintainer and committed to support DAMON community.\nIf you prefer web-based interface for reading the mails, you can use lore. If you prefer the traditional subscription based mailing workflow, you can subscribe to the mailing list via subspace.kernel.org following the instruction.\nThe community also have an open, regular, and informal virtual bi-weekly meeting series for DAMON community called DAMON Beer/Coffee/Tea chat series.\nContribution DAMON and its related projects including damo and hackermail are open source projects. You can contribute to the development following the guidelines. Please refer to below contribution guidelines of each project to further look into the process.\nDAMON damo hkml Publications and Presentations Below are featured and/or upcoming publications and presentations covering DAMON. For more complete list of those, please refer to another dedicated post.\nWhat to read/cite?\nFor people who more familiar to academic papers, DAMON papers for Middleware'19 Industry and HPDC'22 are recommended to read and/or cite. The paper for Middleware'19 covers DAMON\u0026rsquo;s monitoring mechanisms and access pattern profiling-guided optimizations. The paper for HPDC'22 extends the coverage to DAMOS (automated access-aware system operations) and user-space driven auto-tuning.\nSeongJae Park, DAMON: Long-term Plans for Kernel That {Just Works,Extensible}. In Linux Kernel Memory Management Microconferenct at Linux Plumbers, Sep 2024. Slides, Video, Link SeongJae Park, DAMON Recipes: Ways to Save Memory Using a Linux Kernel Subsystem in the Real World. In Open Source Summit Europe, Sep 2024. Slides 1, Slides 2, Video, Link Jonathan Corbet, An update and future plans for DAMON. In Linux Weekly News, May 2024. Article SeongJae Park, DAMON Updates and Plans: Automation of DAMON tuning, tiering, and VM guest scaling. In Linux Storage | Filesystem | MM \u0026amp; BPF Summit, May 2024. Slides, Video, Link Jonathan Corbet, An update and future plans for DAMON. In Linux Weekly News, May 2024. Article SeongJae Park, DAMO[N,S]?: Implementing Self-Driven Data Access-Aware Efficient Linux System. In Open Source Summit North America, Apr 2024. Slides, Video, Link SeongJae Park, DAMON: Current Status and Future Plans. In Kernel Summit, Nov 2023. Slides, Video, Link SeongJae Park, Data Access Monitoring Operator (DAMO): User-Space Tool/Python Library for Access-Aware Profiling and Optimization of Your Linux Systems. In Open Source Summit Europe, Sep 2023. Slides, Video, Link Jonathan Corbet, A 2023 DAMON update. In Linux Weekly News, May 2023. Article SeongJae Park, DAMON, DAMOS, and DAMO: Kernel Subsystems and User-Space Tools for Data Access-Aware System Analysis/Optimizations. In Open Source Summit North America, May 2023. Slides, Video, Link SeongJae Park, DAMON updates and future plans. In Linux Storage | Filesystem | MM \u0026amp; BPF Summit, May 2023. Slides, Video, Link SeongJae Park, Current Status and Future Plans of DAMON. In The Linux Kernel Summit, September 2022. Slides, Video, Link Jonathan Corbet, LRU-list manipulation with DAMON. In Linux Weekly News, August 2022. Article SeongJae Park, Madhuparna Bhowmik, Alexandru Uta, DAOS: Data Access-aware Operating System. In The 31st International ACM Symposium on High-Performance Parallel and Distributed Computing (HPDC'22), June 2022. Paper, Slides, Poster Jonathan Corbet, Using DAMON for proactive reclaim. In Linux Weekly News, July 2021. Article Jonathan Corbet, Memory-management optimization with DAMON. In Linux Weekly News, February 2020. Article SeongJae Park, Yunjae Lee, Heon Y. Yeom, Profiling Dynamic Data Access Patterns with Controlled Overhead and Quality. In 20th ACM/IFIP International Middleware Conference Industry, December 2019. Paper ","permalink":"https://sjp38.github.io/posts/damon/","summary":"!! NOTE !!\nThis post has migrated to https://damonitor.github.io/posts/damon. This out-dated post will be removed soon.\nWith increasingly data-intensive workloads and limited DRAM capacity, optimal memory management based on dynamic access patterns is becoming increasingly important. Such mechanisms are only possible if accurate and efficient dynamic access pattern monitoring is available.\nDAMON is a Data Access MONitoring framework subsystem for the Linux kernel developed for such memory management. It is designed with some key mechanism (refer to Design for the detail) that make it","title":"DAMON: Data Access Monitor"},{"content":"!! NOTE !!\nThis post has migrated to https://damonitor.github.io/posts/damon. This out-dated post will be removed soon.\nWith increasingly data-intensive workloads and limited DRAM capacity, optimal memory management based on dynamic access patterns is becoming increasingly important. Such mechanisms are only possible if accurate and efficient dynamic access pattern monitoring is available.\nDAMON is a Data Access MONitoring framework subsystem for the Linux kernel developed for such memory management. It is designed with some key mechanism (refer to Design for the detail) that make it\naccurate (the monitoring output is useful enough for DRAM level memory management; It might not be appropriate for CPU Cache levels, though), light-weight (the monitoring overhead is low enough to be applied online), and scalable (the upper-bound of the overhead is in constant range regardless of the size of target workloads). Therefore, DAMON can be used to develop memory management based on any access pattern. To make it easier to develop such systems, DAMON provides a feature called DAMON-based Operation Schemes (DAMOS). This allows DAMON users to develop and execute access-aware memory management without code but with a simple setup.\nSimple mechanisms based on DAMOS can achieve up to 12% performance improvement and 91% memory savings. Detailed evaluation of DAMON and DAMON-based system optimizations are available at another post.\nDAMON is also currently being used in real-world products including AWS Aurora Serverless v2 and SK hynix HMSDK v2.\nTable Of Contents Demo Video Demo Screenshot Recent News Getting Started Install Source Code User-space Tool Tests Package Official Document Showcase Website Evaluation Results DAMON-based System Optimization Guide Profile-Guided Optimization Example Community Contribution Publications and Presentations Demo Video Demo Screenshot Recent News Below are only a short list of recent news. For complete list of the news, please refer to a dedicated post.\n2024-10-15: DAMON debugfs interface removal RFC patch has posted.\n2024-10-10: Monthly PyPI downloads of DAMON user-space too, DAMO, doubled again after ten days. !damo_9000_monthly_downloads !damo_rolling_monthly_downloads_2024-10-10\n2024-10-08: Videos for DAMON recipes at Open Source Summit EU'2024 and DAMON long-term plans at Kernel Memory Management Microconference'2024 are uploaded to YouTube.\n2024-10-01: 2024-Q3 DAMON news letter including news for new features, more users, repos reorganizations, and conference talks is posted.\n2024-09-30: DAMON User Space Tool, DAMO, surpasses 4,000 monthly PyPI downloads! Getting Started You can start using DAMON by\ninstalling DAMON-enabled kernel and its user-space tool, following the tutorial of the user-space tool, and run the automated tests suite. By following those, you will be able to know if DAMON works on your machine and how you can use it.\nYou can also participate in the development if you\u0026rsquo;re interested.\nInstall DAMON is implemented in the Linux kernel, so you should install DAMON-enabled Linux kernel to use it. To check if you\u0026rsquo;re already running DAMON-enabled kernel, you could:\n$ if grep -q '^CONFIG_DAMON=y' /boot/config-$(uname -r); then echo \u0026quot;installed\u0026quot; else echo \u0026quot;not installed\u0026quot; fi As of 2024-09-23, kernels of Linux distros including Amazon Linux, Android, Arch, CentOS, Debian, Fedora, and Oracle Linux are known to have enabled DAMON.\nYou could further find a list of DAMON-enabled Linux kernels from Oracle\u0026rsquo;s kconfigs tool. The tool doesn\u0026rsquo;t support every distros at the moment, though.\nIf your package system doesn\u0026rsquo;t support DAMON-enabled kernel, you can fetch a DAMON-merged Linux kernel source tree, build, and install it. Note that you should enable kernel configuration options for DAMON, depending on your demands. For example:\n$ cd $THE_FETCHED_DAMON_KERNEL_SOURCE_TREE $ make olddefconfig $ echo 'CONFIG_DAMON=y' \u0026gt;\u0026gt; ./.config $ echo 'CONFIG_DAMON_VADDR=y' \u0026gt;\u0026gt; ./.config $ echo 'CONFIG_DAMON_PADDR=y' \u0026gt;\u0026gt; ./.config $ echo 'CONFIG_DAMON_SYSFS=y' \u0026gt;\u0026gt; ./.config $ echo 'CONFIG_DAMON_DBGFS=y' \u0026gt;\u0026gt; ./.config $ echo 'CONFIG_DAMON_RECLAIM=y' \u0026gt;\u0026gt; ./.config $ echo 'CONFIG_DAMON_LRU_SORT=y' \u0026gt;\u0026gt; ./.config $ make -j$(nproc) $ sudo make modules_install install Source Code There are several Linux kernel source trees having DAMON for different users. You may pick one among those based on your needs.\nFor users who want a stable version of DAMON, Linus Torvalds' mainline tree is recommended.\nIf you have interests in DAMON features under development, below trees will be appropriate. These trees contain latest version of DAMON which having features under development.\nmm-unstable contains the latest DAMON patches, which are under testing with other unstable memory management subsystem patches. So this tree is likely unstable and frequently updated, but would be a good baseline for your DAMON development. damon/next contains the latest changes, which might not tested at all. So this tree is likely more unstable and frequently updated than mm-unstable. This tree also contains some changes that exist only for DAMON hacks itself rather than eventually be merged in the mainline. For people who have interest in DAMON features under development but use LTS kernels as their baseline, three were trees that based on three latest LTS kernels.\nNOTE: Below trees were continuously getting DAMON backports on latest 5.4.y, 5.10.y, and 5.15.y. But those are deprecated as of 2022-09-03, and therefore there will be no update to the trees.\ndamon/for-v5.15.y damon/for-v5.10.y damon/for-v5.4.y The source code of DAPTRACE, which is a prototype of DAMON, is also available.\nUser-space Tool A user-space tool for DAMON, which is called DAMO (Data Access Monitoring Operator), is available at Github and PyPi. You may start using DAMON by following the Getting Started of the tool for start.\nTests Package There is a tests suite for correctness verification and performance evaluation of DAMON. Those are actively used for the development of DAMON. Using that, you can test DAMON on your machine with only a few simple commands or deeply understand the user interface of DAMON.\nSo, if you finished the tutorial but have no idea about what to do next, running the tests would be a good start. If any test fails, please report that to the maintainer via mail (sj@kernel.org or damon@lists.linux.dev) or github.\nOfficial Document The official document of DAMON in the latest mainline for users/sysadmins and kernel programmers are available. Those for next major release are also available(users/sysadmins doc, kernel programmers doc).\nShowcase Website There is a showcase website that you can get more information of DAMON. The site hosts\nthe heatmap format dynamic access pattern of various realistic workloads for heap area, mmap()-ed area, and stack area, the dynamic working set size distribution and chronological working set size changes, and daily performance test results. Evaluation Results Evaluation of DAMON and DAMON-based system optimizations are available.\nDAMON-based System Optimization Guide A guide for DAMON-based system optimizations are also available.\nProfile-Guided Optimization Example An example of DAMON-based profile-guided optimization is also available.\nCommunity DAMON is maintained and developed by its own community, which is a sub-set of the linux kernel development community.\nThe community is mainly driven by the mailing list (damon@lists.linux.dev). All the patches are posted there and reviewed. Almost every discussions are also made there.\nFor easy communication, a mailing tool called HacKerMaiL is recommended. The tool is maintained by DAMON maintainer and committed to support DAMON community.\nIf you prefer web-based interface for reading the mails, you can use lore. If you prefer the traditional subscription based mailing workflow, you can subscribe to the mailing list via subspace.kernel.org following the instruction.\nThe community also have an open, regular, and informal virtual bi-weekly meeting series for DAMON community called DAMON Beer/Coffee/Tea chat series.\nContribution DAMON and its related projects including damo and hackermail are open source projects. You can contribute to the development following the guidelines. Please refer to below contribution guidelines of each project to further look into the process.\nDAMON damo hkml Publications and Presentations Below are featured and/or upcoming publications and presentations covering DAMON. For more complete list of those, please refer to another dedicated post.\nWhat to read/cite?\nFor people who more familiar to academic papers, DAMON papers for Middleware'19 Industry and HPDC'22 are recommended to read and/or cite. The paper for Middleware'19 covers DAMON\u0026rsquo;s monitoring mechanisms and access pattern profiling-guided optimizations. The paper for HPDC'22 extends the coverage to DAMOS (automated access-aware system operations) and user-space driven auto-tuning.\nSeongJae Park, DAMON: Long-term Plans for Kernel That {Just Works,Extensible}. In Linux Kernel Memory Management Microconferenct at Linux Plumbers, Sep 2024. Slides, Video, Link SeongJae Park, DAMON Recipes: Ways to Save Memory Using a Linux Kernel Subsystem in the Real World. In Open Source Summit Europe, Sep 2024. Slides 1, Slides 2, Video, Link Jonathan Corbet, An update and future plans for DAMON. In Linux Weekly News, May 2024. Article SeongJae Park, DAMON Updates and Plans: Automation of DAMON tuning, tiering, and VM guest scaling. In Linux Storage | Filesystem | MM \u0026amp; BPF Summit, May 2024. Slides, Video, Link Jonathan Corbet, An update and future plans for DAMON. In Linux Weekly News, May 2024. Article SeongJae Park, DAMO[N,S]?: Implementing Self-Driven Data Access-Aware Efficient Linux System. In Open Source Summit North America, Apr 2024. Slides, Video, Link SeongJae Park, DAMON: Current Status and Future Plans. In Kernel Summit, Nov 2023. Slides, Video, Link SeongJae Park, Data Access Monitoring Operator (DAMO): User-Space Tool/Python Library for Access-Aware Profiling and Optimization of Your Linux Systems. In Open Source Summit Europe, Sep 2023. Slides, Video, Link Jonathan Corbet, A 2023 DAMON update. In Linux Weekly News, May 2023. Article SeongJae Park, DAMON, DAMOS, and DAMO: Kernel Subsystems and User-Space Tools for Data Access-Aware System Analysis/Optimizations. In Open Source Summit North America, May 2023. Slides, Video, Link SeongJae Park, DAMON updates and future plans. In Linux Storage | Filesystem | MM \u0026amp; BPF Summit, May 2023. Slides, Video, Link SeongJae Park, Current Status and Future Plans of DAMON. In The Linux Kernel Summit, September 2022. Slides, Video, Link Jonathan Corbet, LRU-list manipulation with DAMON. In Linux Weekly News, August 2022. Article SeongJae Park, Madhuparna Bhowmik, Alexandru Uta, DAOS: Data Access-aware Operating System. In The 31st International ACM Symposium on High-Performance Parallel and Distributed Computing (HPDC'22), June 2022. Paper, Slides, Poster Jonathan Corbet, Using DAMON for proactive reclaim. In Linux Weekly News, July 2021. Article Jonathan Corbet, Memory-management optimization with DAMON. In Linux Weekly News, February 2020. Article SeongJae Park, Yunjae Lee, Heon Y. Yeom, Profiling Dynamic Data Access Patterns with Controlled Overhead and Quality. In 20th ACM/IFIP International Middleware Conference Industry, December 2019. Paper ","permalink":"https://sjp38.github.io/posts/ko/damon/","summary":"!! NOTE !!\nThis post has migrated to https://damonitor.github.io/posts/damon. This out-dated post will be removed soon.\nWith increasingly data-intensive workloads and limited DRAM capacity, optimal memory management based on dynamic access patterns is becoming increasingly important. Such mechanisms are only possible if accurate and efficient dynamic access pattern monitoring is available.\nDAMON is a Data Access MONitoring framework subsystem for the Linux kernel developed for such memory management. It is designed with some key mechanism (refer to Design for the detail) that make it","title":"DAMON: Data Access Monitor"},{"content":"This post describes how you can build, install, and use QEMU on an Ubuntu machine. I basically refererenced http://wiki.qemu.org/Hosts/Linux. The test has proceeded on an Ubuntu 18.04 server machine.\nQEMU Build sudo apt install libglib2.0-dev libfdt-dev libpixman-1-dev zlib1g-dev \\ libgtk-3-dev git clone git://git.qemu-project.org/qemu.git cd qemu git checkout v4.2.0 mkdir -p $HOME/qemu.sandbox/bin cd $HOME/qemu.sandbox/bin ../../qemu/configure --enable-debug --enable-gtk time make -j143 ./x86_64-softmmu/qemu-system-x86_64 -L pc-bios Guest OS Install Get an Ubuntu server install image:\n$ wget http://releases.ubuntu.com/18.04/ubuntu-18.04.3-live-server-amd64.iso Make qcow2 format image file:\ncd .. $ ./bin/qemu-img create -f qcow2 qc2img 32G Formatting \u0026#39;qc2img\u0026#39;, fmt=qcow2 size=34359738368 encryption=off cluster_size=65536 lazy_refcounts=off refcount_bits=16 $ ls -alh total 830M drwxrwxr-x 3 sjpark sjpark 4.0K Jun 1 20:34 . drwxr-xr-x 28 sjpark sjpark 4.0K Jun 1 20:15 .. drwxrwxr-x 94 sjpark sjpark 12K Jun 1 20:19 bin -rw-r--r-- 1 sjpark sjpark 193K Jun 1 20:34 qc2img -rw-rw-r-- 1 sjpark sjpark 848M Feb 16 05:37 ubuntu-18.04.3-live-server-amd64.iso And, boot QEMU VM with the install image:\n$ sudo ./bin/x86_64-softmmu/qemu-system-x86_64 -m 8G -enable-kvm \\ -drive if=virtio,file=qc2img,cache=none \\ -cdrom ubuntu-18.04.3-live-server-amd64.iso If your session is connected with X, above command opens QEMU GUI for the booted VM. The VM will be booted with the Ubuntu server install image, as same as when you boot a machine with an install media. As usual, proceed the install of the Ubuntu server on the VM. This post will use ssh to connect to the VM. Install openssh pacakge while the install process.\nNow, you can boot your Ubuntu VM as below:\n$ sudo ./bin/x86_64-softmmu/qemu-system-x86_64 -m 20G -smp 32 -enable-kvm \\ -drive if=virtio,file=qc2img,cache=none \\ -net user,hostfwd=tcp::2242-:22 -net nic -nographic Because of the -nographic option, it will not give you GUI interface but shows Booting from Hard Disk... message only. But, the VM is booted well. You can ssh to the VM via the port, 2242.\n$ ssh localhost -p 2242 Connect Console to Terminal Let\u0026rsquo;s connect the VM\u0026rsquo;s console to the QEMU executing terminal. Modify the /etc/default/grub file\u0026rsquo;s GRUB_CMDLINE_LINUX_DEFAULT to have \u0026quot;console=ttyS0 earlyprintk=ttyS0 ftrace_dump_on_oops\u0026quot;.\nYou may also want to show GRUB when boot. Comment out GRUB_TIMEOUT_STYLE=hidden, give none-zero value to GRUB_TIMEOUT=, and Uncomment GRUB_TERMINAL=console.\nFinally, commit the change by:\n$ sudo update-grub $ sudo shutdown -h now After this, if you start the VM again using the QEMU command, the terminal you executed the QEMU command will be connected with the console of the VM and will show boot log and login prompt.\nReturn to VM Monitor Console If you want to go back to the VM monitor console, which you have seen before connecting the QEMU executed terminal to the VM\u0026rsquo;s console, press Ctrl+a c. If you want to go back to the guest console again, press Ctrl+a c enter.\nReference: https://serverfault.com/questions/471719/how-to-start-qemu-directly-in-the-console-not-in-curses-or-sdl\nBoot with Kernel in Host You can boot the VM to use a kernel image in the file system of the host machine. If you want to keep your development environment on your host machine but use the QEMU as a test target device, this is useful. Give the path to the kernel image file via -kernel option and give the kernel parameter you want to use using -append option. For example:\n$ sudo ../qemu/build/x86_64-softmmu/qemu-system-x86_64 -m 2048 -smp 2 \\ -enable-kvm -drive if=virtio,file=debian.img,cache=none \\ -net user,hostfwd=tcp::2242-:22 -net nic -nographic \\ -kernel /linux.out/arch/x86/boot/bzImage \\ -append “root=/dev/vda1 console=ttyS0 earlyprintk=ttyS0 debug ignore_loglevel ftrace_dump_on_oops” For the root= in the kernel parameter, check which device file is mounted as the rootfs by the guest OS and use it.\nAlso, you cannot use modules built on the host in the VM, unless you send the module binary files into the VM. If you don\u0026rsquo;t want to do that, simply build the modules you need in static. For example, as this post uses the ssh, I statically built the ethernet driver.\nImage Resize The guest os disk might be full soon, if you configured it too small. You can enlarge the qcow2 image\u0026rsquo;s size as below:\n$ qemu-img resize qc2img +160G $ sudo apt install libguestfs-tools $ cp qc2img qc2img.bak $ sudo virt-resize --expand /dev/sda1 qc2img.bak qc2img $ sudo virt-resize --expand /dev/sda1 qc2img.bak qc2img [ 0.0] Examining qc2img.bak ◓ 25% ⟦▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒═════════════════════════════════════════════════════════════════════⟧ --:-- 100% ⟦▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒⟧ 00:00 ****** Summary of changes: /dev/sda1: This partition will be resized from 24.0G to 184.0G. The filesystem ext4 on /dev/sda1 will be expanded using the \u0026#39;resize2fs\u0026#39; method. /dev/sda2: This partition will be left alone. ****** [ 49.9] Setting up initial partition table on qc2img [ 56.7] Copying /dev/sda1 100% ⟦▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒⟧ 00:00 [ 594.9] Copying /dev/sda2 100% ⟦▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒⟧ 00:00 100% ⟦▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒⟧ 00:00 [ 767.4] Expanding /dev/sda1 using the \u0026#39;resize2fs\u0026#39; method Resize operation completed with no errors. Before deleting the old disk, carefully check that the resized disk boots and works correctly. $ $ $ ./bin/qemu-img info qc2img image: qc2img file format: qcow2 virtual size: 192G (206158430208 bytes) disk size: 32G cluster_size: 65536 Format specific information: compat: 1.1 lazy refcounts: false refcount bits: 16 corrupt: false $ $ $ virt-filesystems --long -h --all -a qc2img libguestfs: warning: current user is not a member of the KVM group (group ID 117). This user cannot access /dev/kvm, so libguestfs may run very slowly. It is recommended that you \u0026#39;chmod 0666 /dev/kvm\u0026#39; or add the current user to the KVM group (you might need to log out and log in again). Name Type VFS Label MBR Size Parent /dev/sda1 filesystem ext4 - - 184G - /dev/sda2 filesystem unknown - - 1.0K - /dev/sda5 filesystem swap - - 8.0G - /dev/sda1 partition - - 83 184G /dev/sda /dev/sda2 partition - - 05 1.0K /dev/sda /dev/sda5 partition - - 82 8.0G /dev/sda /dev/sda device - - - 192G - After that, if you boot the guest VM again and check, you can use the enlarged space:\n$ df -h Filesystem Size Used Avail Use% Mounted on udev 9.7G 0 9.7G 0% /dev tmpfs 2.0G 8.6M 2.0G 1% /run /dev/vda1 181G 24G 149G 14% / tmpfs 9.8G 0 9.8G 0% /dev/shm tmpfs 5.0M 0 5.0M 0% /run/lock tmpfs 9.8G 0 9.8G 0% /sys/fs/cgroup tmpfs 2.0G 0 2.0G 0% /run/user/1000 Reference: https://fatmin.com/2016/12/20/how-to-resize-a-qcow2-image-and-filesystem-with-virt-resize/\nQCOW2 Image Mount You might want to access to the guest VM image directly from the host. It is available using qemu-nbd tool. For that, load the nbd kernel module and connect the qcow2 format VM image via qemu-nbd:\n$ cd qemu.sandbox $ sudo modprobe nbd max_part=8 $ sudo ./bin/qemu-nbd --connect=/dev/nbd0 ./qc2img.bak Now you can see the partitions in the image using fdisk as below:\n$ sudo fdisk -l /dev/nbd0 Disk /dev/nbd0: 192 GiB, 206158430208 bytes, 402653184 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0xe513ef69 Device Boot Start End Sectors Size Id Type /dev/nbd0p1 * 2048 385877631 385875584 184G 83 Linux /dev/nbd0p2 385877632 402650753 16773122 8G 5 Extended /dev/nbd0p5 385877634 402650753 16773120 8G 82 Linux swap / Solaris Mount a partition you want to access:\n$ sudo mount /dev/nbd0p1 ./mnt/ $ cd mnt/ $ ls bin etc initrd.img.old lib64 media proc sbin sys var boot home lib libx32 mnt root snap tmp vmlinuz dev initrd.img lib32 lost+found opt run srv usr vmlinuz.old If you are done, unmount and disconnect the device using qemu-nbd.\n$ sudo umount ./mnt $ sudo ./bin/qemu-nbd --disconnect /dev/nbd nbd0 nbd0p2 nbd1 nbd11 nbd13 nbd15 nbd3 nbd5 nbd7 nbd9 nbd0p1 nbd0p5 nbd10 nbd12 nbd14 nbd2 nbd4 nbd6 nbd8 $ sudo ./bin/qemu-nbd --disconnect /dev/nbd0 /dev/nbd0 disconnected $ ","permalink":"https://sjp38.github.io/posts/qemu_setup_on_ubuntu/","summary":"This post describes how you can build, install, and use QEMU on an Ubuntu machine. I basically refererenced http://wiki.qemu.org/Hosts/Linux. The test has proceeded on an Ubuntu 18.04 server machine.\nQEMU Build sudo apt install libglib2.0-dev libfdt-dev libpixman-1-dev zlib1g-dev \\ libgtk-3-dev git clone git://git.qemu-project.org/qemu.git cd qemu git checkout v4.2.0 mkdir -p $HOME/qemu.sandbox/bin cd $HOME/qemu.sandbox/bin ../../qemu/configure --enable-debug --enable-gtk time make -j143 ./x86_64-softmmu/qemu-system-x86_64 -L pc-bios Guest OS Install Get an Ubuntu server install image:","title":"Build, Install, and Use QEMU on Ubuntu"},{"content":"Ubuntu 에서 QEMU 를 빌드, 설치, 사용하는 법을 설명합니다. 기본적으로 http://wiki.qemu.org/Hosts/Linux 문서를 참고했습니다. 테스트는 Ubuntu 18.04 머신 위에서 진행되었습니다.\nQEMU Build sudo apt install libglib2.0-dev libfdt-dev libpixman-1-dev zlib1g-dev \\ libgtk-3-dev git clone git://git.qemu-project.org/qemu.git cd qemu git checkout v4.2.0 mkdir -p $HOME/qemu.sandbox/bin cd $HOME/qemu.sandbox/bin ../../qemu/configure --enable-debug --enable-gtk time make -j143 ./x86_64-softmmu/qemu-system-x86_64 -L pc-bios Guest OS Install Ubuntu 서버 이미지를 가져오고,\n$ wget http://releases.ubuntu.com/18.04/ubuntu-18.04.3-live-server-amd64.iso qcow2 포맷으로 스토리지를 만들고,\ncd .. $ ./bin/qemu-img create -f qcow2 qc2img 32G Formatting \u0026#39;qc2img\u0026#39;, fmt=qcow2 size=34359738368 encryption=off cluster_size=65536 lazy_refcounts=off refcount_bits=16 $ ls -alh total 830M drwxrwxr-x 3 sjpark sjpark 4.0K Jun 1 20:34 . drwxr-xr-x 28 sjpark sjpark 4.0K Jun 1 20:15 .. drwxrwxr-x 94 sjpark sjpark 12K Jun 1 20:19 bin -rw-r--r-- 1 sjpark sjpark 193K Jun 1 20:34 qc2img -rw-rw-r-- 1 sjpark sjpark 848M Feb 16 05:37 ubuntu-18.04.3-live-server-amd64.iso 다운로드 받은 서버 이미지로 부팅을 합니다:\n$ sudo ./bin/x86_64-softmmu/qemu-system-x86_64 -m 8G -enable-kvm \\ -drive if=virtio,file=qc2img,cache=none \\ -cdrom ubuntu-18.04.3-live-server-amd64.iso X 연결이 되어있다면 곧바로 qemu GUI 가 뜨며, 여기에 우분투 서버 이미지로 부팅된 화면이 나옵니다. 여기서 평소에 하던대로 ubuntu 서버 설치를 진행하면 됩니다. OpenSSH 패키지도 이 과정에서 미리 설치해 줍시다.\n이제, 다음과 같이 우분투 가상머신을 가동할 수 있습니다.\n$ sudo ./bin/x86_64-softmmu/qemu-system-x86_64 -m 20G -smp 32 -enable-kvm \\ -drive if=virtio,file=qc2img,cache=none \\ -net user,hostfwd=tcp::2242-:22 -net nic \\ -nographic 여기선 -nographic 옵션을 줬으므로 GUI 인터페이스가 뜨지 않으며, Booting from Hard Disk... 라는 메세지 후로 화면에 아무것도 나오지 않습니다. 하지만 잘 부팅되어 있습니다. 2242 포트에 ssh 로 접속할 수 있습니다:\n$ ssh localhost -p 2242 호스트에서 qemu 를 수행한 터미널은 그대로 심심하게 있으므로, 여기에 VM 의 콘솔을 붙이겠습니다. VM 에 설치된 grub 설정을 수정해 부팅 시 커널에 줄 옵션을 바꿔 줍니다. Guest os 의 /etc/default/grub 의 GRUB_CMDLINE_LINUX_DEFAULT 를 \u0026quot;console=ttyS0 earlyprintk=ttyS0 ftrace_dump_on_oops\u0026quot; 로 바꿔주고 다음 명령을 수행합니다.\n$ sudo update-grub $ sudo shutdown -h now 이후 다시 qemu 를 통해 시작하면 qemu 커맨드 날린 호스트의 터미널에 콘솔이 연결되어 부팅 로그 등이 뜨고 로그인 프롬프트까지 나옵니다.\nMonitor Console 돌아가기 VM 의 콘솔에서 QEMU 모니터 콘솔로 돌아가고자 한다면 Ctrl+a c 를 입력합니다. 다시 게스트 콘솔로 돌아가려면 Ctrl+a c enter 를 입력합니다.\n참고: https://serverfault.com/questions/471719/how-to-start-qemu-directly-in-the-console-not-in-curses-or-sdl\nBoot with Kernel in Host -kernel, -append 옵션을 주면 호스트 머신의 파일시스템 상에 존재하는 커널을 이용해 vm을 부팅시킬 수 있습니다. 호스트에서 개발과 빌드를 하고자 하면 이게 간편합니다. -kernel 옵션은 커널 이미지 파일을, -append 옵션은 커널 패러미터를 넣어주면 되며, 패러미터중 root= 을 통해 게스트 vm 의 파일시스템을 사용하도록 하면 됩니다. 예를 들면 다음과 같습니다:\n$ sudo ../qemu/build/x86_64-softmmu/qemu-system-x86_64 -m 2048 -smp 2 \\ -enable-kvm -drive if=virtio,file=debian.img,cache=none \\ -net user,hostfwd=tcp::2242-:22 -net nic -nographic -kernel /linux.out/arch/x86/boot/bzImage \\ -append “root=/dev/vda1 console=ttyS0 earlyprintk=ttyS0 debug ignore_loglevel ftrace_dump_on_oops” 커널 패러미터의 root= 값은 실제 게스트 OS가 어떤 디바이스 파일을 마운트 하고 있는지 미리 확인하고 적어줍시다.\n또한, 이렇게 부팅되면 module 을 사용할 수가 없습니다. 주요한 모듈은 static 으로 빌드하도록 합시다. 이 글에서는 ssh 로 붙는걸 가정하고 있으므로, 이더넷 드라이버를 static 으로 빌드해야 합니다.\nImage Resize 뭐 이거저거 하다보면 guest os 디스크 용량이 금방 꽉차버립니다. 아래 커맨드는 기존에 사용하던 qcow2 이미지의 크기를 키워줍니다.\n$ qemu-img resize qc2img +160G $ sudo apt install libguestfs-tools $ cp qc2img qc2img.bak $ sudo virt-resize --expand /dev/sda1 qc2img.bak qc2img $ sudo virt-resize --expand /dev/sda1 qc2img.bak qc2img [ 0.0] Examining qc2img.bak ◓ 25% ⟦▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒═════════════════════════════════════════════════════════════════════⟧ --:-- 100% ⟦▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒⟧ 00:00 ****** Summary of changes: /dev/sda1: This partition will be resized from 24.0G to 184.0G. The filesystem ext4 on /dev/sda1 will be expanded using the \u0026#39;resize2fs\u0026#39; method. /dev/sda2: This partition will be left alone. ****** [ 49.9] Setting up initial partition table on qc2img [ 56.7] Copying /dev/sda1 100% ⟦▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒⟧ 00:00 [ 594.9] Copying /dev/sda2 100% ⟦▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒⟧ 00:00 100% ⟦▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒⟧ 00:00 [ 767.4] Expanding /dev/sda1 using the \u0026#39;resize2fs\u0026#39; method Resize operation completed with no errors. Before deleting the old disk, carefully check that the resized disk boots and works correctly. $ $ $ ./bin/qemu-img info qc2img image: qc2img file format: qcow2 virtual size: 192G (206158430208 bytes) disk size: 32G cluster_size: 65536 Format specific information: compat: 1.1 lazy refcounts: false refcount bits: 16 corrupt: false $ $ $ virt-filesystems --long -h --all -a qc2img libguestfs: warning: current user is not a member of the KVM group (group ID 117). This user cannot access /dev/kvm, so libguestfs may run very slowly. It is recommended that you \u0026#39;chmod 0666 /dev/kvm\u0026#39; or add the current user to the KVM group (you might need to log out and log in again). Name Type VFS Label MBR Size Parent /dev/sda1 filesystem ext4 - - 184G - /dev/sda2 filesystem unknown - - 1.0K - /dev/sda5 filesystem swap - - 8.0G - /dev/sda1 partition - - 83 184G /dev/sda /dev/sda2 partition - - 05 1.0K /dev/sda /dev/sda5 partition - - 82 8.0G /dev/sda /dev/sda device - - - 192G - 그러고나서 guest vm 을 다시 켜고 확인해 보면, 용량이 넉넉해져 있습니다:\n$ df -h Filesystem Size Used Avail Use% Mounted on udev 9.7G 0 9.7G 0% /dev tmpfs 2.0G 8.6M 2.0G 1% /run /dev/vda1 181G 24G 149G 14% / tmpfs 9.8G 0 9.8G 0% /dev/shm tmpfs 5.0M 0 5.0M 0% /run/lock tmpfs 9.8G 0 9.8G 0% /sys/fs/cgroup tmpfs 2.0G 0 2.0G 0% /run/user/1000 참고 사이트: https://fatmin.com/2016/12/20/how-to-resize-a-qcow2-image-and-filesystem-with-virt-resize/\nQCOW2 Image Mount 이런저런 이유로 host 에서 qcow2 이미지에 직접 접근하고자 할 때가 있습니다. qemu 의 qemu-nbd 도구를 사용해 곧바로 host system 에서 mount 해 접근할 수 있습니다.\n먼저, nbd 커널 모듈을 로드하고 qemu-nbd 로 qcow2 이미지를 디바이스로 연결합니다.\n$ cd qemu.sandbox $ sudo modprobe nbd max_part=8 $ sudo ./bin/qemu-nbd --connect=/dev/nbd0 ./qc2img.bak 이제 fdisk 로 해당 이미지 파일의 파티션을 볼 수 있습니다:\n$ sudo fdisk -l /dev/nbd0 Disk /dev/nbd0: 192 GiB, 206158430208 bytes, 402653184 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0xe513ef69 Device Boot Start End Sectors Size Id Type /dev/nbd0p1 * 2048 385877631 385875584 184G 83 Linux /dev/nbd0p2 385877632 402650753 16773122 8G 5 Extended /dev/nbd0p5 385877634 402650753 16773120 8G 82 Linux swap / Solaris 원하는 파티션을 다음과 같이 마운트합니다. 여기선 리눅스가 설치된 root 파티션을 마운트 합니다:\n$ sudo mount /dev/nbd0p1 ./mnt/ $ cd mnt/ $ ls bin etc initrd.img.old lib64 media proc sbin sys var boot home lib libx32 mnt root snap tmp vmlinuz dev initrd.img lib32 lost+found opt run srv usr vmlinuz.old 사용이 끝났다면 언마운트, qemu-nbd 를 통한 디바이스 연결 해제 순서로 정리합니다.\n$ sudo umount ./mnt $ sudo ./bin/qemu-nbd --disconnect /dev/nbd nbd0 nbd0p2 nbd1 nbd11 nbd13 nbd15 nbd3 nbd5 nbd7 nbd9 nbd0p1 nbd0p5 nbd10 nbd12 nbd14 nbd2 nbd4 nbd6 nbd8 $ sudo ./bin/qemu-nbd --disconnect /dev/nbd0 /dev/nbd0 disconnected $ ","permalink":"https://sjp38.github.io/posts/ko/qemu_setup_on_ubuntu/","summary":"Ubuntu 에서 QEMU 를 빌드, 설치, 사용하는 법을 설명합니다. 기본적으로 http://wiki.qemu.org/Hosts/Linux 문서를 참고했습니다. 테스트는 Ubuntu 18.04 머신 위에서 진행되었습니다.\nQEMU Build sudo apt install libglib2.0-dev libfdt-dev libpixman-1-dev zlib1g-dev \\ libgtk-3-dev git clone git://git.qemu-project.org/qemu.git cd qemu git checkout v4.2.0 mkdir -p $HOME/qemu.sandbox/bin cd $HOME/qemu.sandbox/bin ../../qemu/configure --enable-debug --enable-gtk time make -j143 ./x86_64-softmmu/qemu-system-x86_64 -L pc-bios Guest OS Install Ubuntu 서버 이미지를 가져오고,\n$ wget http://releases.ubuntu.com/18.04/ubuntu-18.04.3-live-server-amd64.iso qcow2 포맷으로 스토리지를 만들고,\ncd .. $ ./bin/qemu-img create -f qcow2 qc2img 32G Formatting \u0026#39;qc2img\u0026#39;, fmt=qcow2 size=34359738368 encryption=off cluster_size=65536 lazy_refcounts=off refcount_bits=16 $ ls -alh total 830M drwxrwxr-x 3 sjpark sjpark 4.","title":"Ubuntu 환경에서 QEMU 빌드 / 설치 / 사용하는 법"},{"content":"제가 아마존에 입사하기 전에 썼던 논문 한편이 ACM/IFIP MIDDLEWARE'19 Industry 세션 에서 발표되게 되었습니다. 발표 제목은 \u0026ldquo;Profiling Dynamic Data Access Patterns with Controlled Overhead and Quality\u0026rdquo; 입니다.\n","permalink":"https://sjp38.github.io/posts/ko/middleware19_paper/","summary":"제가 아마존에 입사하기 전에 썼던 논문 한편이 ACM/IFIP MIDDLEWARE'19 Industry 세션 에서 발표되게 되었습니다. 발표 제목은 \u0026ldquo;Profiling Dynamic Data Access Patterns with Controlled Overhead and Quality\u0026rdquo; 입니다.","title":"My recent research will be presented at the MIDDLEWARE'19"},{"content":"A research paper, which I wrote before joining Amazon, will be presented at the Industry session of the ACM/IFIP MIDDLEWARE'19. The title of the paper is \u0026ldquo;Profiling Dynamic Data Access Patterns with Controlled Overhead and Quality\u0026rdquo;.\n","permalink":"https://sjp38.github.io/posts/middleware19_paper/","summary":"A research paper, which I wrote before joining Amazon, will be presented at the Industry session of the ACM/IFIP MIDDLEWARE'19. The title of the paper is \u0026ldquo;Profiling Dynamic Data Access Patterns with Controlled Overhead and Quality\u0026rdquo;.","title":"My recent research will be presented at the MIDDLEWARE'19"},{"content":"몇일 전, 리차드 스톨만이 FSF 회장은 물론이고 의장직에서도 사임한다는 소식이 전해졌습니다. 무슨 일이 있었는지 아래의 reddit 코멘트가 가장 잘 설명하고 있다는 LWN 코멘트[1] 를 참고해, 해당 reddit 코멘트를 번역해 봅니다.\n[1] https://lwn.net/Articles/799391/\n최근 공개된 한 여성의 증언에 따르면 그녀가 17세 때, Epstein 이 그녀에게 Marvin Minsky 와 성관계를 가지라고 했습니다. Minsky 는 MIT Media Lab 창시자이자 A.I 선도자였으며, 2016년에 사망했습니다. 스톨만은 한 메일링 리스트에서 (Minsky 를 성폭행으로 비난하는 어느 시위 주도자의 주장에 대한 답변으로) 이렇게 주장했습니다, 자신도 Epstein 은 비난하지만, Minsky 는 그녀가 강요당한 걸 몰랐을 가능성이 있다구요:\n많은 시나리오를 상상해 볼 수 있겠습니다만, 가장 그럴싸한 시나리오는 그에게는 그녀가 스스로 원해서 그러는듯 보였을 거라는 겁니다. Epstein 이 그녀를 강요했다면, 그는 그가 연관된 것을 그녀가 감추도록 해야 했을 겁니다. 일부 SJW 는 \u0026ldquo;Remove Richard Stallman\u0026rdquo; 이라는 Medium 포스트를 작성했습니다. Vice 와 The Daily Beast 와 같은 미디어 직판장은 Stallman 이 그 여성이 \u0026ldquo;완전히 원했다\u0026rdquo; 그리고 \u0026ldquo;Epstein 을 방어하고 있다\u0026rdquo; 라고 했다고 거짓말하고 그의 발언을 잘못된 의미로 인용했습니다. Stallman 은 이제 MIT 에서 사퇴하라는 압력을 받고 있습니다.\n더 나아가서 이 증언에 그녀가 Minsky 와 성관계를 가졌다는 이야기는 없고, Epstein 이 그녀에게 그러라 했을 뿐이라는 이야기만 있습니다, 그리고 물리학자 Greg Benford 에 따르면 그녀가 Minsky 를 유혹했고 그는 그녀를 거절했다고 합니다:\n내가 알죠, 내가 거기 있었습니다. Minsky 는 그녀를 거절했고, 제게 그 이야기를 했습니다. 그녀는 우리가 이야기 하는걸 보았고 제게 다가오지 않았습니다. 이는 Stallman 의 생각에 대한 완전한 검증 같습니다. Minsky 가 무엇을 알았는지가 중요치 않다면, \u0026ldquo;Minsky 가 한 여성을 성폭행 했다\u0026rdquo; 와 \u0026ldquo;Epstein 이 17살 여성에게 그의 강요를 Minsky 에게 알리지 않은 채 성행위를 가지라 했다\u0026rdquo; 사이에 차이가 없다면, 왜 그는 그녀를 거절했을까요?\n추가 수정: 그는 그가 설립한 Free Software Foundation 에서도 사임했습니다. 자유 소프트웨어에의 우울한 소식입니다, 저는 Stallman 같은 순수한 믿음을 가진 사람이 다양한 종류의 피해야할 선택을 막는데 필수적이라 생각하거든요.\nContext: In a recently unsealed deposition a woman testified that, at the age of 17, Epstein told her to have sex with Marvin Minsky. Minsky was a founder of the MIT Media Lab and pioneer in A.I. who died in 2016. Stallman argued on a mailing list (in response to a statement from a protest organizer accusing Minsky of sexual assault) that, while he condemned Epstein, Minsky likely did not know she was being coerced:\nWe can imagine many scenarios, but the most plausible scenario is that she presented herself to him as entirely willing. Assuming she was being coerced by Epstein, he would have had every reason to tell her to conceal that from most of his associates. Some SJW responded by writing a Medium post called \u0026ldquo;Remove Richard Stallman\u0026rdquo;. Media outlets like Vice and The Daily Beast then lied and misquoted Stallman as saying that the woman was likely \u0026ldquo;entirely willing\u0026rdquo; and as \u0026ldquo;defending Epstein\u0026rdquo;. He has now been pressured to resign from MIT\nFurthermore the deposition doesn\u0026rsquo;t say she had sex with Minsky, only that Epstein told her to do so, and according to physicist Greg Benford she propositioned Minsky and he turned her down:\nI know; I was there. Minsky turned her down. Told me about it. She saw us talking and didn’t approach me. This seems like a complete validation of the distinction Stallman was making. If what Minsky knew doesn\u0026rsquo;t matter, if there\u0026rsquo;s no difference between \u0026ldquo;Minsky sexually assaulted a woman\u0026rdquo; and \u0026ldquo;Epstein told a 17-year-old to have sex with Minsky without his knowledge or consent\u0026rdquo;, then why did he turn her down?\nEdit: He has also resigned from the Free Software Foundation, which he founded. Grim news for free software, since I think true-believing purists like Stallman are vital to prevent various kinds of co-option.\n","permalink":"https://sjp38.github.io/posts/ko/rms_resigns/","summary":"몇일 전, 리차드 스톨만이 FSF 회장은 물론이고 의장직에서도 사임한다는 소식이 전해졌습니다. 무슨 일이 있었는지 아래의 reddit 코멘트가 가장 잘 설명하고 있다는 LWN 코멘트[1] 를 참고해, 해당 reddit 코멘트를 번역해 봅니다.\n[1] https://lwn.net/Articles/799391/\n최근 공개된 한 여성의 증언에 따르면 그녀가 17세 때, Epstein 이 그녀에게 Marvin Minsky 와 성관계를 가지라고 했습니다. Minsky 는 MIT Media Lab 창시자이자 A.I 선도자였으며, 2016년에 사망했습니다. 스톨만은 한 메일링 리스트에서 (Minsky 를 성폭행으로 비난하는 어느 시위 주도자의 주장에 대한 답변으로) 이렇게 주장했습니다, 자신도 Epstein 은 비난하지만, Minsky 는 그녀가 강요당한 걸 몰랐을 가능성이 있다구요:","title":"Richard Stallman Resigns"},{"content":"몇일 전, 리차드 스톨만이 FSF 회장은 물론이고 의장직에서도 사임한다는 소식이 전해졌습니다. 무슨 일이 있었는지 아래의 reddit 코멘트가 가장 잘 설명하고 있다는 LWN 코멘트[1] 를 참고해, 해당 reddit 코멘트를 번역해 봅니다.\n[1] https://lwn.net/Articles/799391/\n최근 공개된 한 여성의 증언에 따르면 그녀가 17세 때, Epstein 이 그녀에게 Marvin Minsky 와 성관계를 가지라고 했습니다. Minsky 는 MIT Media Lab 창시자이자 A.I 선도자였으며, 2016년에 사망했습니다. 스톨만은 한 메일링 리스트에서 (Minsky 를 성폭행으로 비난하는 어느 시위 주도자의 주장에 대한 답변으로) 이렇게 주장했습니다, 자신도 Epstein 은 비난하지만, Minsky 는 그녀가 강요당한 걸 몰랐을 가능성이 있다구요:\n많은 시나리오를 상상해 볼 수 있겠습니다만, 가장 그럴싸한 시나리오는 그에게는 그녀가 스스로 원해서 그러는듯 보였을 거라는 겁니다. Epstein 이 그녀를 강요했다면, 그는 그가 연관된 것을 그녀가 감추도록 해야 했을 겁니다. 일부 SJW 는 \u0026ldquo;Remove Richard Stallman\u0026rdquo; 이라는 Medium 포스트를 작성했습니다. Vice 와 The Daily Beast 와 같은 미디어 직판장은 Stallman 이 그 여성이 \u0026ldquo;완전히 원했다\u0026rdquo; 그리고 \u0026ldquo;Epstein 을 방어하고 있다\u0026rdquo; 라고 했다고 거짓말하고 그의 발언을 잘못된 의미로 인용했습니다. Stallman 은 이제 MIT 에서 사퇴하라는 압력을 받고 있습니다.\n더 나아가서 이 증언에 그녀가 Minsky 와 성관계를 가졌다는 이야기는 없고, Epstein 이 그녀에게 그러라 했을 뿐이라는 이야기만 있습니다, 그리고 물리학자 Greg Benford 에 따르면 그녀가 Minsky 를 유혹했고 그는 그녀를 거절했다고 합니다:\n내가 알죠, 내가 거기 있었습니다. Minsky 는 그녀를 거절했고, 제게 그 이야기를 했습니다. 그녀는 우리가 이야기 하는걸 보았고 제게 다가오지 않았습니다. 이는 Stallman 의 생각에 대한 완전한 검증 같습니다. Minsky 가 무엇을 알았는지가 중요치 않다면, \u0026ldquo;Minsky 가 한 여성을 성폭행 했다\u0026rdquo; 와 \u0026ldquo;Epstein 이 17살 여성에게 그의 강요를 Minsky 에게 알리지 않은 채 성행위를 가지라 했다\u0026rdquo; 사이에 차이가 없다면, 왜 그는 그녀를 거절했을까요?\n추가 수정: 그는 그가 설립한 Free Software Foundation 에서도 사임했습니다. 자유 소프트웨어에의 우울한 소식입니다, 저는 Stallman 같은 순수한 믿음을 가진 사람이 다양한 종류의 피해야할 선택을 막는데 필수적이라 생각하거든요.\nContext: In a recently unsealed deposition a woman testified that, at the age of 17, Epstein told her to have sex with Marvin Minsky. Minsky was a founder of the MIT Media Lab and pioneer in A.I. who died in 2016. Stallman argued on a mailing list (in response to a statement from a protest organizer accusing Minsky of sexual assault) that, while he condemned Epstein, Minsky likely did not know she was being coerced:\nWe can imagine many scenarios, but the most plausible scenario is that she presented herself to him as entirely willing. Assuming she was being coerced by Epstein, he would have had every reason to tell her to conceal that from most of his associates. Some SJW responded by writing a Medium post called \u0026ldquo;Remove Richard Stallman\u0026rdquo;. Media outlets like Vice and The Daily Beast then lied and misquoted Stallman as saying that the woman was likely \u0026ldquo;entirely willing\u0026rdquo; and as \u0026ldquo;defending Epstein\u0026rdquo;. He has now been pressured to resign from MIT\nFurthermore the deposition doesn\u0026rsquo;t say she had sex with Minsky, only that Epstein told her to do so, and according to physicist Greg Benford she propositioned Minsky and he turned her down:\nI know; I was there. Minsky turned her down. Told me about it. She saw us talking and didn’t approach me. This seems like a complete validation of the distinction Stallman was making. If what Minsky knew doesn\u0026rsquo;t matter, if there\u0026rsquo;s no difference between \u0026ldquo;Minsky sexually assaulted a woman\u0026rdquo; and \u0026ldquo;Epstein told a 17-year-old to have sex with Minsky without his knowledge or consent\u0026rdquo;, then why did he turn her down?\nEdit: He has also resigned from the Free Software Foundation, which he founded. Grim news for free software, since I think true-believing purists like Stallman are vital to prevent various kinds of co-option.\n","permalink":"https://sjp38.github.io/posts/rms_resigns/","summary":"몇일 전, 리차드 스톨만이 FSF 회장은 물론이고 의장직에서도 사임한다는 소식이 전해졌습니다. 무슨 일이 있었는지 아래의 reddit 코멘트가 가장 잘 설명하고 있다는 LWN 코멘트[1] 를 참고해, 해당 reddit 코멘트를 번역해 봅니다.\n[1] https://lwn.net/Articles/799391/\n최근 공개된 한 여성의 증언에 따르면 그녀가 17세 때, Epstein 이 그녀에게 Marvin Minsky 와 성관계를 가지라고 했습니다. Minsky 는 MIT Media Lab 창시자이자 A.I 선도자였으며, 2016년에 사망했습니다. 스톨만은 한 메일링 리스트에서 (Minsky 를 성폭행으로 비난하는 어느 시위 주도자의 주장에 대한 답변으로) 이렇게 주장했습니다, 자신도 Epstein 은 비난하지만, Minsky 는 그녀가 강요당한 걸 몰랐을 가능성이 있다구요:","title":"Richard Stallman Resigns"},{"content":"LWN 의 \u0026ldquo;Memory: the flat, the discontiguous, and the sparse\u0026rdquo; 라는 제목의 글의 한글 번역입니다. 원문은 LWN 에서 볼 수 있습니다: https://lwn.net/Articles/789304/\nMay 27, 2019\n이 기사는 Mike Rapoport 에 의해 기여되었습니다.\n컴퓨터 시스템에서 물리 메모리는 소중한 자원이어서, 이를 효율적으로 관리하기 위한 많은 노력이 기울여져왔습니다. 이 일은 현대의 시스템에서의 메모리 구조가 복잡해짐에 따라 더 어려워졌습니다. 물리 메모리가 실제로 어떻게 위치해 있는가를 다루기 위한 여러 계층의 추상화가 존재합니다; 그런 추상화 중 하나는 \u0026ldquo;메모리 모델\u0026rdquo; 이라고 불립니다. 커널은 세개의 모델을 지원하고 있는데, 그 중 하나는 지원이 멈춰져 가고 있습니다. 이 변경을 이해하기 위한 방법으로, 이 기사는 커널의 메모리 모델들의 진화, 현재 상태, 그리고 있을 법한 미래에 대해 자세히 들여다 봅니다.\nFLATMEM 리눅스가 처음 나왔을 때, 메모리는 평평했습니다: 메모리는 0 부터 수 메가바이트의 물리 주소를 갖는 단순한 선형적 배열일 뿐이었습니다. 각 물리 페이지 프레임은 커널의 mem_map 배열에 하나의 원소와 연관되었으며, 이 당시에 이 배열은 해당 페이지가 가진 레퍼런스의 갯수를 세는 하나의 unsigned short 원소로 이루어져 있었습니다. 하지만, 얼마 있지 않아서, 이 mem_map 의 원소들은 스왑 관리를 위한 age 와 dirty counter 를 포함하도록 커졌습니다. Linux 1.3.50 에서 mem_map 의 원소들은 마침내 struct page 로 이름지어졌습니다.\n이 평평한 메모리 매핑은 물리 페이지 프레임 번호 (page-frame number : PFN) 와 그에 대응되는 struct page 사이의 쉽고 빠른 변환을 제공했습니다; 이 변환 작업은 간단한 배열 인덱스 계산 문제였습니다. 이후 struct page 의 레이아웃 변경이 있었는데, 새로운 사용처 (예컨대, page cache) 들과 struct page 의 캐시 성능 최적화를 위한 것이었습니다. 메모리 매핑은 깔끔하고 효율적인 평평한 배열로 유지되었습니다만, 이는 중요한 단점을 가지고 있었습니다: 물리 주소 공간 상의 큰 공백을 처리할 수 없었습니다. 이 메모리 매핑 가운데 공백에 연관된 부분은 낭비되어지거나, ARM 에서처럼, 메모리 매핑 자체가 공백을 가질 수 있었습니다.\nDISCONTIGMEM 상당히 비연속적인 물리 메모리를 효율적으로 처리하기 위한 지원이 리눅스를 NUMA 기계들 위에서 잘 동작하도록 하기 위한 노력의 일환으로 1999년에 메모리 관리 서브시스템으로 들어왔습니다. 이 코드는 CONFIG_DISCONTIGMEM 설정 옵션에 종속적이어서, 이 메모리 모델은 DISCONTIGMEM 이라 이름지어진 첫번째 모델이었습니다.\n이 DISCONTIGMEM 모델은 메모리 노드 (memory node) 라는 개념을 소개했는데, 이 개념은 여전히 NUMA 메모리 관리의 기본으로 남아있습니다. 각 노드는 free-page lists, in-use page lists, least-recently-used (LRU) 정보, 사용 통계 등을 포함한, (대부분) 독립적인 메모리 관리 서브시스템을 갖습니다. 이런 것들 가운데, struct pglist_data (또는 짧게 pg_data_t) 로 표현되는 노드 데이터는 하나의 노드에 대한 메모리 매핑 정보를 가지고 있습니다. 각 노드가 연속적인 물리 메모리를 가지고 있다는 가정 하에, 노드당 하나의 struct page 배열을 갖는 것은 평평한 메모리 매핑 안의 거대한 공백 문제를 해결했습니다.\n하지만 이게 공짜로 된 건 아닙니다. DISCONTIGMEM 에서는, 예를 들면 어떤 PFN 을 그에 연관된 struct page 로 변환하기 위해 특정 페이지를 어떤 노드가 가지고 있는지를 알 수 있어야 합니다. 비슷하게, 페이지를 가지고 PFN 을 구하기 위해 어떤 노드의 메모리 맵이 해당 struct page 를 가지고 있는지도 알 수 있어야 합니다. 긴 진화의 끝에, KVADDR_TO_NID(), LOCAL_MAP_BASE(), ADDR_TO_MAPBASE(), 그리고 LOCAL_BASE_ADDR() 매크로를 처음 정의한 mips64 부터 시작해서 PFN 의 struct page 로의 변환과 그 반대 작업은 include/asm-generic/memory_model.h 안에 정의된, 비교적 간단한 pfn_to_page() 와 page_to_pfn() 매크로로 수행되게 되었습니다.\n하지만, DISCONTIGMEM 은 약점이 있었습니다: 메모리 핫플러그 (hotplug) 와 핫리무브 (hot remove) 입니다. 실제 NUMA 노드는 실제 핫플러그를 지원하기엔 너무 굵은 크기였고, 노드를 쪼개는 것은 불필요한게 많은 단편화와 오버헤드를 가져올 것이었습니다. 각 노드가 독립적인 메모리 관리 구조체들을 연관된 비용과 함께 가짐을 기억해 보세요; 노드를 쪼개는 것은 그런 비용을 상당히 증가시킬 겁니다.\nSPARSEMEM 이 한계는 SPARSEMEM 을 통해 해결되었습니다. 이 모델은 메모리 매핑을 아키텍쳐별로 정의된 임의의 크기의 섹션들의 집합으로 추상화 했습니다. 각 섹션은 struct mem_section 으로 표현되며, (코드에 설명된 바에 따르면): \u0026ldquo;논리적으로, struct page 의 배열로의 포인터입니다. 하지만, 다른 마술을 통해 저장됩니다\u0026rdquo;. 이 섹션들의 배열은 SECTION_SIZE 크기로 효율적으로 쪼개질 수 있는 메타 메모리 매핑입니다. PFN 과 struct page 사이의 효율적인 변환을 위해, PFN 의 상위 비트 몇개는 이 섹션 배열로의 인덱스로 사용됩니다. 반대 방향 변환을 위해선, 이 섹션 넘버가 page 의 flag 로 인코딩 됩니다.\n이 모델이 리눅스 커널에 소개되고 몇달 후, SPARSEMEM 은 SPARSEMEM_EXTREME 으로 확장되었는데, 이 모델은 산재하는 물리 주소 공간을 갖는 시스템에 적합합니다. SPARSEMEM_EXTREME 에서는, 첫번째 레벨은 mem_section 구조체들로의 포인터가 되고, 실제 mem_section 객체는 실제로 꽂힌 물리 메모리에 기반해서 동적으로 할당됩니다.\n2007년에 SPARSEMEM 의 또다른 개선이 이루어졌습니다; 이는 SPARSEMEM 의 일반적인 가상 메모리 매핑 지원 또는 SPARSEMEM_VMEMMAP 이라고 불렸습니다. SPARSEMEM_VMEMMAP 의 아이디어는 전체 메모리 매핑이 가상 연속 공간에 매핑되어 있지만, 활성화된 섹션들만이 물리 페이지로 연결되어 있도록 하자는 것입니다. 이 모델은 32-bit 시스템에서는 물리 메모리의 크기가 가상 주소 공간을 넘을 수 있기 때문에 잘 동작하지 못할 수 있습니다. 하지만, 64-bit 시스템에서 SPARSEMEM_VMEMMAP 은 확실히 우수합니다. 추가적인 페이지 테이블 엔트리 사용이라는 비용 아래, page_to_pfn() 과 pfn_to_page() 는 평평한 모델만큼이나 간단해 졌습니다.\nSPARSEMEM 메모리 모델의 마지막 확장은 꽤 최근 (2016) 이었습니다; 이는 persistent 메모리 디바이스의 사용 증가로 인해 이루어졌습니다. 메모리 매핑을 메인 메모리가 아니라 그런 디바이스들 내에 직접 저장하는 걸 지원하기 위해, 이 가상 메모리 매핑은 struct vmem_altmap 을 사용할 수 있게 되었는데, 이 구조체는 persistent 메모리 안의 페이지 구조체를 제공합니다.\n2005년으로 돌아가보면, SPARSEMEM 은 \u0026ldquo;새로운, 그리고 실험적인 discontiguous memory 의 대체재\u0026rdquo; 로 설명되었습니다. SPARSEMEM_VMEMMAP 을 추가한 커밋은 그것을 \u0026ldquo;우리가 SPARSEMEM 을 대부분의 시스템에 기본 (그리고 유일한) 옵션이 되게 할 가능성이 있다\u0026rdquo; 고 했습니다. 그리고 실제로, 일부 아키텍쳐는 DISCONTIGMEM 에서 SPARSEMEM 으로 옮겨탔습니다. 2008년, SPARSEMEM_VMEMMAP 은 x86-64 를 위한 유일한 메모리 모델이 되었는데, FLATMEM 보단 조금 비싸지만 DISCONTIGMEM 보다는 효율적이기 때문입니다.\n메모리 핫플러그, persistent 메모리 지원, 다양한 성능 최적화와 같은 최근의 메모리 관리 분야 개발은 모두 SPARSEMEM 모델을 타겟으로 하고 있습니다. 하지만 과거의 모델들은 여전히 존재해서, 아키텍쳐와 메모리 관리 코드 상의 많은 #ifdef 블록의 존재와, 관련된 구성 옵션의 특별한 미로의 존재라는 추가비용을 유발하고 있습니다. 남아있는 DISCONTIGMEM 사용자들을 SPARSEMEM 으로 완전히 바꿔타게 하려는 노력들이 있습니다만, ia64 나 mips64 와 같은 아키텍쳐들을 그렇게 변화시키기는 쉬운 작업이 아닐 겁니다. 그리고 ARC 아키텍쳐의 DISCONTIGMEM 사용은 \u0026ldquo;normal\u0026rdquo; 메모리 아래 \u0026ldquo;high memory\u0026rdquo; 영역의 존재를 갖는데, 이는 분명 변경하기 어려울 겁니다.\n","permalink":"https://sjp38.github.io/posts/ko/lwn_memory_flat_discontiguous_sparse/","summary":"LWN 의 \u0026ldquo;Memory: the flat, the discontiguous, and the sparse\u0026rdquo; 라는 제목의 글의 한글 번역입니다. 원문은 LWN 에서 볼 수 있습니다: https://lwn.net/Articles/789304/\nMay 27, 2019\n이 기사는 Mike Rapoport 에 의해 기여되었습니다.\n컴퓨터 시스템에서 물리 메모리는 소중한 자원이어서, 이를 효율적으로 관리하기 위한 많은 노력이 기울여져왔습니다. 이 일은 현대의 시스템에서의 메모리 구조가 복잡해짐에 따라 더 어려워졌습니다. 물리 메모리가 실제로 어떻게 위치해 있는가를 다루기 위한 여러 계층의 추상화가 존재합니다; 그런 추상화 중 하나는 \u0026ldquo;메모리 모델\u0026rdquo; 이라고 불립니다.","title":"Memory: the flat, the discontiguous, and the sparse (Korean)"},{"content":"우연히 발견한 글 을 통해 NASA 의 코딩 규칙 10가지 를 알게 되었습니다. 너무 깐깐한 규칙 아닌가 싶기도 하지만 ping 하나 날리는데 40분이 걸리고 물리적으로는 접근할 수 없는 화성에 로봇을 보내야 한다면 이런 규칙은 합리적이라 볼 수 있겠죠. 제가 참고한 저 글은 이걸 파이썬이나 자바스크립트와 같은 곳에서도 어떻게 적용해 볼 수 있을지를 고찰해 보고 있습니다. 이 포스트에선 단순히 이 10개의 규칙을 번역해 봅니다.\ngoto 또는 재귀호출과 같은 복잡한 수행 흐름을 피하라. 원문: 모든 코드를 매우 간단한 수행 흐름으로 제한하라 - goto 문, setjmp 또는 longjmp 명령, 그리고 직/간접적 재귀 호출을 사용하지 말라.\nAvoid complex flow constructs, such as goto and recursion. Restrict all code to very simple control flow constructs – do not use goto statements, setjmp or longjmp constructs, and direct or indirect recursion.\n모든 루프 (반복문) 은 고정된 최대 반복 횟수를 가져야 한다. 이는 무한반복 코드를 방지한다. 모든 루프는 고정된 최대 반복 횟수를 가져야 한다. 코드 체크 도구가 정적으로 어떤 루프의 반복 횟수가 미리 설정된 최대 횟수를 넘는지를 쉽게 검사할 수 있어야 한다. 이 반복 한계가 정적으로 검증될 수 없다면, 이 규칙이 깨어진 것으로 간주한다.\nAll loops must have fixed bounds. This prevents runaway code. All loops must have a fixed upper-bound. It must be trivially possible for a checking tool to prove statically that a preset upper-bound on the number of iterations of a loop cannot be exceeded. If the loop-bound cannot be proven statically, the rule is considered violated.\n힙 메모리 할당을 피하라. 초기화 단계 후에는 동적 메모리 할당을 사용하지 말라.\nAvoid heap memory allocation. Do not use dynamic memory allocation after initialization.\n함수의 크기를 한장의 종이에 적힐 수 있게 제한하라. 어떤 함수도 명령문당 한줄, 선언당 한줄을 갖는 표준 레퍼런스 포맷을 지킨 채로 한장의 종이에 프린트 될 수 있는 길이 이상을 가져선 안된다. 보통, 이는 함수당 60줄 이상의 코드를 가져선 안된다는 것을 의미한다.\nRestrict functions to a single printed page. No function should be longer than what can be printed on a single sheet of paper in a standard reference format with one line per statement and one line per declaration. Typically, this means no more than about 60 lines of code per function.\n최소 함수당 두개의 런타임 단정문을 사용하라. 평균적으로 함수당 최소 두개의 단정문이 있어야 한다. 단정문은 실제 수행 중에 일어나선 안되는 문제가 있는 조건을 검사하는데 사용되어야 한다. 단정문은 항상 사이드 이펙트로부터 자유로워야 하고 Boolean 테스트로 정의되어야 한다. 단정문이 실패한다면 명시적인 복구 동작이 행해져야 하는데, 예를 들면 이 실패한 단정문을 수행한 함수를 호출한 측에 에러 정보를 리턴하는 것이다. 정적 검사 도구가 절대 실패할 수 없거나 항상 성공한다고 증명해내는 단정문은 모두 이 규칙을 어기는 것이다. (예를 들어, 전혀 도움 되지 않을 assert(true) 문을 추가함으로써 이 규칙을 만족시킬 순 없다.)\nUse a minimum of two runtime assertions per function. The assertion density of the code should average to a minimum of two assertions per function. Assertions are used to check for anomalous conditions that should never happen in real-life executions. Assertions must always be side-effect free and should be defined as Boolean tests. When an assertion fails, an explicit recovery action must be taken, e.g., by returning an error condition to the caller of the function that executes the failing assertion. Any assertion for which a static checking tool can prove that it can never fail or never hold violates this rule. (I.e., it is not possible to satisfy the rule by adding unhelpful \u0026ldquo;assert(true)\u0026rdquo; statements.)\n데이터의 사용 영역을 가능한 작게 잡아라. 데이터 객체는 가능한 가장 작은 단계의 영역에서 선언되어야만 한다.\nRestrict the scope of data to the smallest possible. Data objects must be declared at the smallest possible level of scope.\n리턴 타입이 void 가 아닌 (non-void) 모든 함수의 리턴값은 검사되거나 리턴값이 무의미하다는 걸 알리기 위해 void 로 캐스팅 되어야 한다. non-void 함수의 리턴값은 각 호출 함수에 의해 체크되어야 하며, 패러미터의 유효성은 각 함수 안에서 검사되어야 한다.\nCheck the return value of all non-void functions, or cast to void to indicate the return value is useless. The return value of non-void functions must be checked by each calling function, and the validity of parameters must be checked inside each function.\n전처리기를 아껴 사용하라. 전처리기의 사용은 헤더 파일을 포함하는 용도와 간단한 매그로 정의로 국한되어야만 한다. 토큰 붙이기, 유동적 갯수의 인자 리스트, 그리고 재귀적 매크로 호출은 허용되지 않는다. 모든 매크로는 완전한 구문적 단위로 확장되어야만 한다. 조건적 컴파일 지시어의 사용은 많은 경우 모호하지만, 항상 금지될 수는 없다. 이는 거대한 소프트웨어 개발 노력이 든다 하더라도 동일한 헤더 파일의 중복 포함을 방지하는 상용문 외의 한두개의 조건적 컴파일 지시어를 위한 정당화가 필요하다는 것을 의미한다. 그런 모든 경우에는 도구 기반의 검사를 통한 플래그가 붙어있거나 코드 안에 사용의 정당성에 대한 설명이 있어야 한다.\nUse the preprocessor sparingly. The use of the preprocessor must be limited to the inclusion of header files and simple macro definitions. Token pasting, variable argument lists (ellipses), and recursive macro calls are not allowed. All macros must expand into complete syntactic units. The use of conditional compilation directives is often also dubious, but cannot always be avoided. This means that there should rarely be justification for more than one or two conditional compilation directives even in large software development efforts, beyond the standard boilerplate that avoids multiple inclusion of the same header file. Each such use should be flagged by a tool-based checker and justified in the code.\n포인터의 사용을 한단계 디레퍼런스로 제한하고, 함수 포인터는 사용하지 말라. 포인터의 사용은 제한되어야 한다. 구체적으로, 두단계 이상의 디레퍼런스는 허용되지 않는다. 포인터 디레퍼런스 오퍼레이션이 매크로 정의나 typedef 선언 안에 숨겨져선 안된다. 함수 포인터는 허용되지 않는다.\nLimit pointer use to a single dereference, and do not use function pointers. The use of pointers should be restricted. Specifically, no more than one level of dereferencing is allowed. Pointer dereference operations may not be hidden in macro definitions or inside typedef declarations. Function pointers are not permitted.\n모든 가능한 경고를 활성화 한 채 컴파일 하라; 그리고 모든 경고는 해당 소프트웨어의 배포 전에 해결되어야 한다. 모든 코드는 개발을 시작한 첫날부터 모든 컴파일러 경고가 가장 엄중한 설정으로 활성화 된 채 컴파일 되어야만 한다. 모든 코드는 이 설정 아래 아무런 경고 없이 컴파일 되어야 한다. 모든 코드는 최소 하루에 한번, 그러나 가급적 한번 넘게, 최신의 정적 소스 코드 분석도구를 통해 검사되어야 하며 이 검사를 어떤 경고도 없이 통과해야만 한다.\nCompile with all possible warnings active; all warnings should then be addressed before release of the software. All code must be compiled, from the first day of development, with allcompiler warnings enabled at the compiler’s most pedantic setting. All code must compile with these setting without any warnings. All code must be checked daily with at least one, but preferably more than one, state-of-the-art static source code analyzer and should pass the analyses with zero warnings.\n","permalink":"https://sjp38.github.io/posts/ko/nasa_coding_rules/","summary":"우연히 발견한 글 을 통해 NASA 의 코딩 규칙 10가지 를 알게 되었습니다. 너무 깐깐한 규칙 아닌가 싶기도 하지만 ping 하나 날리는데 40분이 걸리고 물리적으로는 접근할 수 없는 화성에 로봇을 보내야 한다면 이런 규칙은 합리적이라 볼 수 있겠죠. 제가 참고한 저 글은 이걸 파이썬이나 자바스크립트와 같은 곳에서도 어떻게 적용해 볼 수 있을지를 고찰해 보고 있습니다. 이 포스트에선 단순히 이 10개의 규칙을 번역해 봅니다.\ngoto 또는 재귀호출과 같은 복잡한 수행 흐름을 피하라.","title":"NASA's Power of 10 Coding Rules (Korean)"},{"content":"My talk proposal to the Linux Kernel Summit of this year which is co-located with the Linux Plumbers has accepted! Hope to see you in Lisbon. The title of the talk is, \u0026ldquo;Tracing Data Access Pattern with Bounded Overhead and Best-effort Accuracy\u0026rdquo;.\n","permalink":"https://sjp38.github.io/posts/kernelsummit2019_talk/","summary":"My talk proposal to the Linux Kernel Summit of this year which is co-located with the Linux Plumbers has accepted! Hope to see you in Lisbon. The title of the talk is, \u0026ldquo;Tracing Data Access Pattern with Bounded Overhead and Best-effort Accuracy\u0026rdquo;.","title":"I will have a talk at the Linux Kernel Summit 2019"},{"content":"[Linux Plumbers Conference 2019] (https://www.linuxplumbersconf.org/blog/2019/) 와 함께 열리는 올해의 [Linux Kernel Summit] (https://lwn.net/Articles/788378/) 에 제안한 발표 주제가 accept 되어 9월에 리스본에서 이에 대한 내용을 발표하게 되었습니다. 발표 제목은 \u0026ldquo;Tracing Data Access Pattern with Bounded Overhead and Best-effort Accuracy\u0026rdquo; 입니다.\n티켓이 너무 일찍 팔려버리는 바람에 올해는 들으러도 못가나 걱정했는데 갈 수 있게 됐네요, 다행입니다! :D\n","permalink":"https://sjp38.github.io/posts/ko/kernelsummit2019_talk/","summary":"[Linux Plumbers Conference 2019] (https://www.linuxplumbersconf.org/blog/2019/) 와 함께 열리는 올해의 [Linux Kernel Summit] (https://lwn.net/Articles/788378/) 에 제안한 발표 주제가 accept 되어 9월에 리스본에서 이에 대한 내용을 발표하게 되었습니다. 발표 제목은 \u0026ldquo;Tracing Data Access Pattern with Bounded Overhead and Best-effort Accuracy\u0026rdquo; 입니다.\n티켓이 너무 일찍 팔려버리는 바람에 올해는 들으러도 못가나 걱정했는데 갈 수 있게 됐네요, 다행입니다! :D","title":"I will have a talk at the Linux Kernel Summit 2019"},{"content":"프로젝트 a 와 프로젝트 b 를 병렬로 진행하고 있었는데, 두개의 리포지토리를 합치고 싶어지는 경우가 있습니다. 예컨대 프로젝트 a 의 성격이 보다 범용이 되었고 프로젝트 b 는 프로젝트 a 를 위한 도구적 성격이 되는 경우가 있겠죠. a 프로젝트에 \u0026lsquo;b\u0026rsquo; 디렉토리를 만들고 그 아래 기존 프로젝트 b 의 파일들을 위치하고 싶습니다. 하지만 기존 b 프로젝트의 git 히스토리들도 유지하고 싶습니다. 비슷한 사례로 리눅스 커널 메모리 모델 프로젝트는 별도의 리포지토리[1] 로 개발되었지만 리눅스 업스트림 리포지토리의 tools/ 디렉토리 아래로 머지[2] 되었는데, 이 때 기존 개발 히스토리를 유지했죠.\n이 포스트는 이렇게 특정 git 리포지토리를 그 히스토리를 유지한 채 다른 git 리포지토리의 하위 디렉토리로 옮기는 법을 설명합니다.\n[1] https://github.com/aparri/memory-model\n[2] https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/tools/memory-model\n초기 상황과 목표 먼저 현재 디렉토리 아래에 a 리포지토리와 b 리포지토리가 있다고 가정합니다:\n$ ls a b $ 우리는 a 리포지토리 아래 b/ 디렉토리를 만들고 그 아래 b 리포지토리를 넣고 싶습니다.\n전략 b 리포지토리가 b/ 디렉토리 아래 모든 파일을 위치하도록 변경한 후, 이 리포지토리를 a 리포지토리에서 --allow-unrelated-histories 옵션을 사용해 머지하도록 하겠습니다.\n합쳐질 리포지토리 파일 구조 변경 먼저 b 리포지토리의 파일들이 b/ 디렉토리 아래 위치하도록 만듭니다:\n$ cd b $ mkdir b $ git mv !(b) b $ git commit -a -m \u0026#34;Relocate files for inclusion\u0026#34; 리포지토리 병합 이제 b 리포지토리를 임시 remote 리포지토리로 등록하고 머지합니다:\n$ cd ../a $ git remote add temp ../b $ git fetch temp $ git merge --allow-unrelated-histories temp/master --allow-unrelated-histories 는 경로가 다른 파일에 대한 커밋들도 머지가 될 수 있게 해줍니다.\n임시로 등록한 remote 리포지토리는 지워줍시다:\n$ git remote rm temp 정리 이상과 같이 기존의 개발 히스토리를 유지하면서 특정 git 리포지토리를 다른 git 리포지토리의 하위 디렉토리로 병합하는 방법을 알아보았습니다.\n","permalink":"https://sjp38.github.io/posts/ko/integrate_external_git_repository_with_history/","summary":"프로젝트 a 와 프로젝트 b 를 병렬로 진행하고 있었는데, 두개의 리포지토리를 합치고 싶어지는 경우가 있습니다. 예컨대 프로젝트 a 의 성격이 보다 범용이 되었고 프로젝트 b 는 프로젝트 a 를 위한 도구적 성격이 되는 경우가 있겠죠. a 프로젝트에 \u0026lsquo;b\u0026rsquo; 디렉토리를 만들고 그 아래 기존 프로젝트 b 의 파일들을 위치하고 싶습니다. 하지만 기존 b 프로젝트의 git 히스토리들도 유지하고 싶습니다. 비슷한 사례로 리눅스 커널 메모리 모델 프로젝트는 별도의 리포지토리[1] 로 개발되었지만 리눅스 업스트림 리포지토리의 tools/ 디렉토리 아래로 머지[2] 되었는데, 이 때 기존 개발 히스토리를 유지했죠.","title":"Integrate external git repository with its history"},{"content":"이번 여름 졸업을 앞두고 구직 활동을 한 결과, 얼마전 운좋게도 미국에 본사를 두고 있는 한 글로벌 IT 기업의 커널/하이퍼바이저 팀으로부터 잡 오퍼를 받았습니다. 취업을 향한 한걸음 한걸음이 어둠 속을 더듬더듬, 때로는 막무가내로 헤쳐나가는 느낌이었는데, 이런 저의 경험을 공유하는게 어떤 분들께는 도움이 되지 않을까 싶어 공유해 봅니다.\n목표설정 취업을 할까 포닥을 할까 모호한 고민만 하다가 어느새 4월 중순이 되어서야 해외 IT 회사로 직장을 구하겠다는 목표가 설정되었습니다. 그제서야 든 생각은 너무 늦었다, 준비가 부족하다, 하는 것이었습니다. 취업을 위해 뭐 하나 준비한게 없더라구요.\n일단은 졸업 후 국내에서 취업 준비를 탄탄히 해서 내년 봄 시즌에 해외 글로벌 IT 기업에 취업하는걸 목표로 하되, 당장 취업 준비를 시작하고 붙을 가능성은 없겠지만 볼 수 있는 면접은 연습삼아서라도 보기로 마음을 먹었습니다.\n취업을 위한 준비 가장 시급한 건 영어 듣기 능력이었습니다. 토발즈의 인터뷰와 키노트, 리눅스 파운데이션 주최 컨퍼런스 발표들과 리눅스를 주제로 한 팟캐스트 등을 mp3 로 추출해 매일 출퇴근 길에 들었습니다.\n코딩 테스트를 연습하기 위해서는 유명한 cracking the coding interview 책도 읽어보고, 이 즈음에 우연히 지인에게 소개받은 leetcode 라는 사이트를 통해 코딩 문제도 풀어보기 시작했습니다. 작년 무렵 지인을 통해 cracking the coding interview 책을 이용한 오프라인 스터디도 진행했는데, 그 경험이 큰 도움이 되었습니다. Leetcode 는 왜 이제 알게 됐나 싶은 생각이 들 정도로 도움이 되었습니다.\n링크드인 및 이력서 지인들과의 대화 도중, 링크드인은 내가 지금 직업을 구하고 있는지 아닌지를 알리는 기능이 있다는 걸 우연히 알게 되었습니다. 이걸 켜니 몇몇 회사의 리크루터들이 연락을 줬습니다. 이 회사도 마찬가지였습니다. 채용하는 포지션에 대한 아주 짧막한 설명과 함께, 관심 있으면 이력서를 보내달라는 연락이 왔고, 이력서를 보내니 회사의 해당 포지션 채용 링크를 보내주며 시스템을 통해 지원해 달라고 했습니다.\n온라인 코딩 사흘만에 이 회사에서 구축한 코딩 테스트 시스템으로의 초대장이 왔습니다. Leetcode 와 같은 여타 코딩 테스트 사이트랑 비슷하게 되어 있는데, 네개 정도의 문제가 있습니다. 편한 시간을 골라서 문제를 풀 수 있으며, 테스트를 시작하면 중단은 못하고 두시간 내에 테스트를 반드시 끝내야 합니다. 실제 인터뷰어와 전화를 통해 진행하는게 아니다보니 내가 편한 시간을 고를 수 있고, 영어 듣기가 부족한 저로썬 문제가 글로 써져 있어 좋더군요. 제출하고 나면 곧바로 풀이에 대한 전체 테스트 결과도 볼 수 있었습니다.\n아주 어려운 문제는 없었고 간단한 자료구조와 알고리즘 위주였기에 무난하게 문제를 풀 수 있었습니다. 하지만 마지막 한문제는 일부 corner case 를 제대로 풀지 못해 점수가 만족스럽지는 않았습니다.\n전화 인터뷰 몇일 후, 전화 인터뷰 하고 싶으니 일정을 잡자는 메일이 왔습니다. 적당히 일정을 잡고 인터뷰를 진행했습니다.\n애초에 외국 회사는 온사이트 인터뷰까지 진행되면 후보에게 비행기표 등을 지불해야 되니 이 단계에서 가급적 많은 후보자를 탈락시킨다고 합니다. 전화 통화는 바디랭귀지가 일체 허용되지 않거니와 통화품질, 인터뷰어의 독특한 억양 등의 문제가 있을 수 있기에 저처럼 영어가 약한 사람에게는 정말 죽을 맛입니다. 다행히도 이번 인터뷰는 통화품질도 좋았고 인터뷰어의 발음도 제 귀에 또렷하게 들리는 억양이라 큰 문제는 없었습니다. 그래도 역시 기본 실력이 어디가진 않아서, 몇번은 못알아듣고 버벅이긴 했습니다.\n인터뷰는 약 한시간 정도 분량으로, 제가 채용되면 함께 일하게 될 팀과 업무, 그리고 인터뷰어 자신에 대한 간단한 소개를 시작으로, 제 소개와 그에 대한 문답, 업무적 경험에 대한 질문, 기술적 질문으로 이어졌고, 막판에 약 5분 정도 제가 회사에 대해 질문할 수 있는 시간으로 구성되었습니다.\n소개 후의 문답은 제가 소개한 제 연구들에 대해 깊은 질문이 왔는데, 평소 하는 일이라 쉽게 대답할 수 있었습니다.\n업무적 경험에 대한 문답에서는 어떤 특정 상황에 처했던 경험을 이야기 해달라고 하는데, 이게 꽤 어려웠습니다. 질문받은 경우에 처한 경험이야 많지만 그 중 어떤 걸 골라서 이야기해야 좋은 인상을 얻을까 고민하게 되거든요. 팀원의 반대 의견에 부딪혔을 때에 대한 경험도 요청받았는데, 재밌게도 그날 아침에 함께 연구를 진행하고 있는 친구와 격렬하게 토론했던 즐거운 경험이 있어 그걸 이야기 했습니다. 다른 질문들에는 오픈소스 활동과 개인 프로젝트에 대한 경험도 이야기 했습니다.\n기술적 질문은 커널의 동작 구조 및 원리에 대한 몇가지 질문이 있었습니다. 역시 밥먹고 하는 일이다 보니 어렵지 않게 답할 수 있었습니다.\n마지막 질답 시간엔 무슨 질문했는지 기억이 잘 안나는데, 내가 이 면접 통과하고 함께 일하게 되면 어떤 일을 하게 될지, 내가 소개한 연구들 중 어떤 내용이 회사에 도움 될 수 있을거라 생각하는지 뭐 그런 질문을 한 것 같습니다.\n전화 중에도 코딩 테스트가 있을 줄 알았는데, 없었습니다. 다행이었죠.\n온사이트 인터뷰 제의 다시 몇일 후, 2차 전화 인터뷰가 있겠거니 하고 있었는데, 온사이트 인터뷰를 보자는 메일이 왔습니다! 예전에 모 회사와는 대략 네다섯번까지 이어지는 전화 인터뷰를 하면서 파김치가 되었던 기억이 있는데, 이번엔 한번의 전화 인터뷰만에 스크리닝이 끝나서 정말 기뻤습니다. 메일은 온사이트 인터뷰 가능한 일정 (3주의 기한을 줬습니다), 일하게 된다면 언제부터 일할 수 있는지, 원하는 연봉은 얼마인지, 인터뷰 보러 오는데 비자 필요한지 등을 물어왔습니다.\n적당적당히 일정이 잡혔고, 회사에서 비행기표와 호텔을 예약해 줬습니다. 호텔은 이틀을 예약해 줬습니다. 앞에서 이야기했듯 사실 이때까지만 해도 전 이 회사에 붙을 거라는 생각은 없었습니다. 회사가 면접 통과하기 어렵기로 유명한 회사이기도 하고 준비가 부족하다고 생각했으니까요. 이 시점까지만 해도 그저 공짜로 외국여행 하는구나 싶었죠.\n온사이트 인터뷰 온사이트 인터뷰는 채용되면 실제 제가 일하게 될 오피스에서 아침 10시부터 오후 4시까지 6시간동안 이루어졌습니다. 한시간마다 한명씩 다른 인터뷰어가 들어왔는데, 중간에 한번은 두 인터뷰어가 함께 들어왔습니다. 따라서 총 여섯번의 인터뷰를 본 셈이며, 매 인터뷰마다 형식은 전화 인터뷰와 비슷했습니다. 인터뷰어의 회사와 자기 자신에 대한 소개, 제 소개와 그에 대한 문답, 업무적 경험 질문, 기술적 질문, 마지막으로 제가 질문하는 시간.\n붙을리가 있냐, 여행이나 하자 하는 생각으로 왔지만 막상 당일이 되자 굉장히 긴장되더군요. 그런데 이날 만난 직원들은 너무나도 친절하고 유쾌했습니다. 막상 면접이 시작되니 면접을 본다기보다는 기술 커뮤니티 밋업에서 만난 사람들이랑 즐거운 기술 이야기 하는 느낌이라 너무 즐거웠습니다.\n오후 12시부터 한시간은 점심시간이라 인터뷰어 한명과 함께 식사했습니다. 식사가 인터뷰의 연장인 셈이죠. 앞서 이야기한대로 어찌나 긴장이 풀렸는지 이 때 인터뷰어 앞에서 맥주까지 한잔 했습니다.\n그 중 두번의 인터뷰는 화이트보드를 사용한 코딩 인터뷰가 포함되었습니다. 그 와중에 가장 긴장한 시간이었긴 한데, 역시 즐겁게 진행되었습니다. 다행히 평범한 자료구조 문제였기에 조금 버벅이긴 했지만 일단 코딩을 하는건 어렵지 않았으며, 이후 관련한 질문에 답하고 개선을 어떻게 할 수 있을지 논의하고 추가 코딩을 했는데 이 과정 역시 즐거웠습니다.\n인터뷰가 끝나고 나선 붙든 떨어지든 상관 없지만 평생 잊지 못할 만큼 즐거운 시간이었고 이런 시간을 앞으로도 갖고 싶다, 떨어져도 여한이 없다는 생각이 들었습니다. 면접을 본게 아니라 커뮤니티 모임 같은데 가서 놀다 온 느낌이었죠.\n오퍼 온사이트 인터뷰가 금요일이었습니다. 현지 시간으로 화요일, 인터뷰에 통과했으니 정식 오퍼를 보내겠다는 연락을 받았습니다.\n정리 준비부터 오퍼를 받기까지의 제 경험을 정리해 봤습니다. 준비도 능력도 부족한데 어디까지나 운이 좋아서 면접을 통과한지라 다른 분들께 이 기록이 얼마나 도움이 될지 모르겠습니다. 그래도 공유하지 않는 것보다는 낫겠죠. 누군가에겐 이 기록이 도움이 되길 빌어봅니다.\n","permalink":"https://sjp38.github.io/posts/ko/my_job_interview/","summary":"이번 여름 졸업을 앞두고 구직 활동을 한 결과, 얼마전 운좋게도 미국에 본사를 두고 있는 한 글로벌 IT 기업의 커널/하이퍼바이저 팀으로부터 잡 오퍼를 받았습니다. 취업을 향한 한걸음 한걸음이 어둠 속을 더듬더듬, 때로는 막무가내로 헤쳐나가는 느낌이었는데, 이런 저의 경험을 공유하는게 어떤 분들께는 도움이 되지 않을까 싶어 공유해 봅니다.\n목표설정 취업을 할까 포닥을 할까 모호한 고민만 하다가 어느새 4월 중순이 되어서야 해외 IT 회사로 직장을 구하겠다는 목표가 설정되었습니다. 그제서야 든 생각은 너무 늦었다, 준비가 부족하다, 하는 것이었습니다.","title":"My Job Interview Record (2019 summer)"},{"content":"이번 여름 졸업을 앞두고 구직 활동을 한 결과, 얼마전 운좋게도 미국에 본사를 두고 있는 한 글로벌 IT 기업의 커널/하이퍼바이저 팀으로부터 잡 오퍼를 받았습니다. 취업을 향한 한걸음 한걸음이 어둠 속을 더듬더듬, 때로는 막무가내로 헤쳐나가는 느낌이었는데, 이런 저의 경험을 공유하는게 어떤 분들께는 도움이 되지 않을까 싶어 공유해 봅니다.\n목표설정 취업을 할까 포닥을 할까 모호한 고민만 하다가 어느새 4월 중순이 되어서야 해외 IT 회사로 직장을 구하겠다는 목표가 설정되었습니다. 그제서야 든 생각은 너무 늦었다, 준비가 부족하다, 하는 것이었습니다. 취업을 위해 뭐 하나 준비한게 없더라구요.\n일단은 졸업 후 국내에서 취업 준비를 탄탄히 해서 내년 봄 시즌에 해외 글로벌 IT 기업에 취업하는걸 목표로 하되, 당장 취업 준비를 시작하고 붙을 가능성은 없겠지만 볼 수 있는 면접은 연습삼아서라도 보기로 마음을 먹었습니다.\n취업을 위한 준비 가장 시급한 건 영어 듣기 능력이었습니다. 토발즈의 인터뷰와 키노트, 리눅스 파운데이션 주최 컨퍼런스 발표들과 리눅스를 주제로 한 팟캐스트 등을 mp3 로 추출해 매일 출퇴근 길에 들었습니다.\n코딩 테스트를 연습하기 위해서는 유명한 cracking the coding interview 책도 읽어보고, 이 즈음에 우연히 지인에게 소개받은 leetcode 라는 사이트를 통해 코딩 문제도 풀어보기 시작했습니다. 작년 무렵 지인을 통해 cracking the coding interview 책을 이용한 오프라인 스터디도 진행했는데, 그 경험이 큰 도움이 되었습니다. Leetcode 는 왜 이제 알게 됐나 싶은 생각이 들 정도로 도움이 되었습니다.\n링크드인 및 이력서 지인들과의 대화 도중, 링크드인은 내가 지금 직업을 구하고 있는지 아닌지를 알리는 기능이 있다는 걸 우연히 알게 되었습니다. 이걸 켜니 몇몇 회사의 리크루터들이 연락을 줬습니다. 이 회사도 마찬가지였습니다. 채용하는 포지션에 대한 아주 짧막한 설명과 함께, 관심 있으면 이력서를 보내달라는 연락이 왔고, 이력서를 보내니 회사의 해당 포지션 채용 링크를 보내주며 시스템을 통해 지원해 달라고 했습니다.\n온라인 코딩 사흘만에 이 회사에서 구축한 코딩 테스트 시스템으로의 초대장이 왔습니다. Leetcode 와 같은 여타 코딩 테스트 사이트랑 비슷하게 되어 있는데, 네개 정도의 문제가 있습니다. 편한 시간을 골라서 문제를 풀 수 있으며, 테스트를 시작하면 중단은 못하고 두시간 내에 테스트를 반드시 끝내야 합니다. 실제 인터뷰어와 전화를 통해 진행하는게 아니다보니 내가 편한 시간을 고를 수 있고, 영어 듣기가 부족한 저로썬 문제가 글로 써져 있어 좋더군요. 제출하고 나면 곧바로 풀이에 대한 전체 테스트 결과도 볼 수 있었습니다.\n아주 어려운 문제는 없었고 간단한 자료구조와 알고리즘 위주였기에 무난하게 문제를 풀 수 있었습니다. 하지만 마지막 한문제는 일부 corner case 를 제대로 풀지 못해 점수가 만족스럽지는 않았습니다.\n전화 인터뷰 몇일 후, 전화 인터뷰 하고 싶으니 일정을 잡자는 메일이 왔습니다. 적당히 일정을 잡고 인터뷰를 진행했습니다.\n애초에 외국 회사는 온사이트 인터뷰까지 진행되면 후보에게 비행기표 등을 지불해야 되니 이 단계에서 가급적 많은 후보자를 탈락시킨다고 합니다. 전화 통화는 바디랭귀지가 일체 허용되지 않거니와 통화품질, 인터뷰어의 독특한 억양 등의 문제가 있을 수 있기에 저처럼 영어가 약한 사람에게는 정말 죽을 맛입니다. 다행히도 이번 인터뷰는 통화품질도 좋았고 인터뷰어의 발음도 제 귀에 또렷하게 들리는 억양이라 큰 문제는 없었습니다. 그래도 역시 기본 실력이 어디가진 않아서, 몇번은 못알아듣고 버벅이긴 했습니다.\n인터뷰는 약 한시간 정도 분량으로, 제가 채용되면 함께 일하게 될 팀과 업무, 그리고 인터뷰어 자신에 대한 간단한 소개를 시작으로, 제 소개와 그에 대한 문답, 업무적 경험에 대한 질문, 기술적 질문으로 이어졌고, 막판에 약 5분 정도 제가 회사에 대해 질문할 수 있는 시간으로 구성되었습니다.\n소개 후의 문답은 제가 소개한 제 연구들에 대해 깊은 질문이 왔는데, 평소 하는 일이라 쉽게 대답할 수 있었습니다.\n업무적 경험에 대한 문답에서는 어떤 특정 상황에 처했던 경험을 이야기 해달라고 하는데, 이게 꽤 어려웠습니다. 질문받은 경우에 처한 경험이야 많지만 그 중 어떤 걸 골라서 이야기해야 좋은 인상을 얻을까 고민하게 되거든요. 팀원의 반대 의견에 부딪혔을 때에 대한 경험도 요청받았는데, 재밌게도 그날 아침에 함께 연구를 진행하고 있는 친구와 격렬하게 토론했던 즐거운 경험이 있어 그걸 이야기 했습니다. 다른 질문들에는 오픈소스 활동과 개인 프로젝트에 대한 경험도 이야기 했습니다.\n기술적 질문은 커널의 동작 구조 및 원리에 대한 몇가지 질문이 있었습니다. 역시 밥먹고 하는 일이다 보니 어렵지 않게 답할 수 있었습니다.\n마지막 질답 시간엔 무슨 질문했는지 기억이 잘 안나는데, 내가 이 면접 통과하고 함께 일하게 되면 어떤 일을 하게 될지, 내가 소개한 연구들 중 어떤 내용이 회사에 도움 될 수 있을거라 생각하는지 뭐 그런 질문을 한 것 같습니다.\n전화 중에도 코딩 테스트가 있을 줄 알았는데, 없었습니다. 다행이었죠.\n온사이트 인터뷰 제의 다시 몇일 후, 2차 전화 인터뷰가 있겠거니 하고 있었는데, 온사이트 인터뷰를 보자는 메일이 왔습니다! 예전에 모 회사와는 대략 네다섯번까지 이어지는 전화 인터뷰를 하면서 파김치가 되었던 기억이 있는데, 이번엔 한번의 전화 인터뷰만에 스크리닝이 끝나서 정말 기뻤습니다. 메일은 온사이트 인터뷰 가능한 일정 (3주의 기한을 줬습니다), 일하게 된다면 언제부터 일할 수 있는지, 원하는 연봉은 얼마인지, 인터뷰 보러 오는데 비자 필요한지 등을 물어왔습니다.\n적당적당히 일정이 잡혔고, 회사에서 비행기표와 호텔을 예약해 줬습니다. 호텔은 이틀을 예약해 줬습니다. 앞에서 이야기했듯 사실 이때까지만 해도 전 이 회사에 붙을 거라는 생각은 없었습니다. 회사가 면접 통과하기 어렵기로 유명한 회사이기도 하고 준비가 부족하다고 생각했으니까요. 이 시점까지만 해도 그저 공짜로 외국여행 하는구나 싶었죠.\n온사이트 인터뷰 온사이트 인터뷰는 채용되면 실제 제가 일하게 될 오피스에서 아침 10시부터 오후 4시까지 6시간동안 이루어졌습니다. 한시간마다 한명씩 다른 인터뷰어가 들어왔는데, 중간에 한번은 두 인터뷰어가 함께 들어왔습니다. 따라서 총 여섯번의 인터뷰를 본 셈이며, 매 인터뷰마다 형식은 전화 인터뷰와 비슷했습니다. 인터뷰어의 회사와 자기 자신에 대한 소개, 제 소개와 그에 대한 문답, 업무적 경험 질문, 기술적 질문, 마지막으로 제가 질문하는 시간.\n붙을리가 있냐, 여행이나 하자 하는 생각으로 왔지만 막상 당일이 되자 굉장히 긴장되더군요. 그런데 이날 만난 직원들은 너무나도 친절하고 유쾌했습니다. 막상 면접이 시작되니 면접을 본다기보다는 기술 커뮤니티 밋업에서 만난 사람들이랑 즐거운 기술 이야기 하는 느낌이라 너무 즐거웠습니다.\n오후 12시부터 한시간은 점심시간이라 인터뷰어 한명과 함께 식사했습니다. 식사가 인터뷰의 연장인 셈이죠. 앞서 이야기한대로 어찌나 긴장이 풀렸는지 이 때 인터뷰어 앞에서 맥주까지 한잔 했습니다.\n그 중 두번의 인터뷰는 화이트보드를 사용한 코딩 인터뷰가 포함되었습니다. 그 와중에 가장 긴장한 시간이었긴 한데, 역시 즐겁게 진행되었습니다. 다행히 평범한 자료구조 문제였기에 조금 버벅이긴 했지만 일단 코딩을 하는건 어렵지 않았으며, 이후 관련한 질문에 답하고 개선을 어떻게 할 수 있을지 논의하고 추가 코딩을 했는데 이 과정 역시 즐거웠습니다.\n인터뷰가 끝나고 나선 붙든 떨어지든 상관 없지만 평생 잊지 못할 만큼 즐거운 시간이었고 이런 시간을 앞으로도 갖고 싶다, 떨어져도 여한이 없다는 생각이 들었습니다. 면접을 본게 아니라 커뮤니티 모임 같은데 가서 놀다 온 느낌이었죠.\n오퍼 온사이트 인터뷰가 금요일이었습니다. 현지 시간으로 화요일, 인터뷰에 통과했으니 정식 오퍼를 보내겠다는 연락을 받았습니다.\n정리 준비부터 오퍼를 받기까지의 제 경험을 정리해 봤습니다. 준비도 능력도 부족한데 어디까지나 운이 좋아서 면접을 통과한지라 다른 분들께 이 기록이 얼마나 도움이 될지 모르겠습니다. 그래도 공유하지 않는 것보다는 낫겠죠. 누군가에겐 이 기록이 도움이 되길 빌어봅니다.\n","permalink":"https://sjp38.github.io/posts/my_job_interview/","summary":"이번 여름 졸업을 앞두고 구직 활동을 한 결과, 얼마전 운좋게도 미국에 본사를 두고 있는 한 글로벌 IT 기업의 커널/하이퍼바이저 팀으로부터 잡 오퍼를 받았습니다. 취업을 향한 한걸음 한걸음이 어둠 속을 더듬더듬, 때로는 막무가내로 헤쳐나가는 느낌이었는데, 이런 저의 경험을 공유하는게 어떤 분들께는 도움이 되지 않을까 싶어 공유해 봅니다.\n목표설정 취업을 할까 포닥을 할까 모호한 고민만 하다가 어느새 4월 중순이 되어서야 해외 IT 회사로 직장을 구하겠다는 목표가 설정되었습니다. 그제서야 든 생각은 너무 늦었다, 준비가 부족하다, 하는 것이었습니다.","title":"My Job Interview Record (2019 summer)"},{"content":"재미 삼아 리눅스 커널 릴리즈 때마다 git history 를 visualize 해서 올리는 유투브 채널[1]을 개설해 봤습니다. 지금은 visualization 에는 gource[2] 를 사용하고 있습니다. 이 비디오를 만드는데 사용되는 스크립트도 GPL v3 로 공개[3]했으니 필요한 분은 사용해 보셔도 좋을 것 같습니다.\n[1] https://www.youtube.com/channel/UCI7qoGt1hOfCsI8hFqriYCg\n[2] https://gource.io/\n[3] https://github.com/sjp38/linux_development_visualization\n","permalink":"https://sjp38.github.io/posts/ko/linux_develop_visualization_youtube/","summary":"재미 삼아 리눅스 커널 릴리즈 때마다 git history 를 visualize 해서 올리는 유투브 채널[1]을 개설해 봤습니다. 지금은 visualization 에는 gource[2] 를 사용하고 있습니다. 이 비디오를 만드는데 사용되는 스크립트도 GPL v3 로 공개[3]했으니 필요한 분은 사용해 보셔도 좋을 것 같습니다.\n[1] https://www.youtube.com/channel/UCI7qoGt1hOfCsI8hFqriYCg\n[2] https://gource.io/\n[3] https://github.com/sjp38/linux_development_visualization","title":"Linux Development History Visualization Youtube Channel"},{"content":"I created a Youtube channel[1]. I will upload videos for the git history between each release of the Linux kernel, just for jun. I use gource[2] for the visualization for now. The scripts I use for these videos are available[3] under GPL v3. If you want, you may use the scripts for your own video generation.\n[1] https://www.youtube.com/channel/UCI7qoGt1hOfCsI8hFqriYCg\n[2] https://gource.io/\n[3] https://github.com/sjp38/linux_development_visualization\n","permalink":"https://sjp38.github.io/posts/linux_develop_visualization_youtube/","summary":"I created a Youtube channel[1]. I will upload videos for the git history between each release of the Linux kernel, just for jun. I use gource[2] for the visualization for now. The scripts I use for these videos are available[3] under GPL v3. If you want, you may use the scripts for your own video generation.\n[1] https://www.youtube.com/channel/UCI7qoGt1hOfCsI8hFqriYCg\n[2] https://gource.io/\n[3] https://github.com/sjp38/linux_development_visualization","title":"Linux Development History Visualization Youtube Channel"},{"content":"Memory pressure is inevitable as the size of working sets is rapidly growing while the capacity of dynamic random access memory (DRAM) is not. Meanwhile, storage devices have evolved so that their speed is comparable to the speed of DRAM while their capacity scales are comparable to that of hard disk drives (HDD). Thus, hierarchial memory systems configuring DRAM as the main memory and high-end storages as swap devices will be common.\nDue to the unique characteristics of these modern storage devices, the swap target decision should be optimal. It is essential to know the exact data access patterns of workloads for such an optimal decision, although underlying systems cannot accurately estimate such complex and dynamic patterns. For this reason, memory systems allow programs to voluntarily hint their data access pattern. Nevertheless, it is exhausting for a human to manually figure out the patterns and embed optimal hints if the workloads are huge and complex.\nThis project introduces a compiler extension that automatically optimizes a program to voluntarily hint its dynamic data access patterns to the underlying swap system using a static/dynamic analysis based profiling result. To our best knowledge, this is the first profile-guided optimization (PGO) for modern swap devices. Our empirical evaluation of the scheme using realistic workloads shows consistent improvement in performance and swap device lifetime up to 2.65 times and 2.98 times, respectively.\nPublications And Presentations SeongJae Park, Yunjae Lee, Moonsub Kim Heon Y. Yeom, Automating Context Based Access Pattern Hint Injection for System Performance and Swap Storage Durability. In 11th USENIX Workshop on Hot Topics in Storage and File Systems (HotStorage), July 2019. Paper, Slides SeongJae Park, Yunjae Lee, Moonsub Kim, Heon Y. Yeom, Automated Data Access Pattern Hint Instrumentation for System Performance and Durability of Swap Storages. (WiP) In 17th USENIX Conference on File and Storage Technologies (FAST), February 2019. Link ","permalink":"https://sjp38.github.io/posts/daphicx/","summary":"Memory pressure is inevitable as the size of working sets is rapidly growing while the capacity of dynamic random access memory (DRAM) is not. Meanwhile, storage devices have evolved so that their speed is comparable to the speed of DRAM while their capacity scales are comparable to that of hard disk drives (HDD). Thus, hierarchial memory systems configuring DRAM as the main memory and high-end storages as swap devices will be common.","title":"DAPHICX: Data Access Pattern Hint Injecting Compiler Extension"},{"content":"Memory pressure is inevitable as the size of working sets is rapidly growing while the capacity of dynamic random access memory (DRAM) is not. Meanwhile, storage devices have evolved so that their speed is comparable to the speed of DRAM while their capacity scales are comparable to that of hard disk drives (HDD). Thus, hierarchial memory systems configuring DRAM as the main memory and high-end storages as swap devices will be common.\nDue to the unique characteristics of these modern storage devices, the swap target decision should be optimal. It is essential to know the exact data access patterns of workloads for such an optimal decision, although underlying systems cannot accurately estimate such complex and dynamic patterns. For this reason, memory systems allow programs to voluntarily hint their data access pattern. Nevertheless, it is exhausting for a human to manually figure out the patterns and embed optimal hints if the workloads are huge and complex.\nThis project introduces a compiler extension that automatically optimizes a program to voluntarily hint its dynamic data access patterns to the underlying swap system using a static/dynamic analysis based profiling result. To our best knowledge, this is the first profile-guided optimization (PGO) for modern swap devices. Our empirical evaluation of the scheme using realistic workloads shows consistent improvement in performance and swap device lifetime up to 2.65 times and 2.98 times, respectively.\nPublications And Presentations SeongJae Park, Yunjae Lee, Moonsub Kim Heon Y. Yeom, Automating Context Based Access Pattern Hint Injection for System Performance and Swap Storage Durability. In 11th USENIX Workshop on Hot Topics in Storage and File Systems (HotStorage), July 2019. Paper, Slides SeongJae Park, Yunjae Lee, Moonsub Kim, Heon Y. Yeom, Automated Data Access Pattern Hint Instrumentation for System Performance and Durability of Swap Storages. (WiP) In 17th USENIX Conference on File and Storage Technologies (FAST), February 2019. Link ","permalink":"https://sjp38.github.io/posts/ko/daphicx/","summary":"Memory pressure is inevitable as the size of working sets is rapidly growing while the capacity of dynamic random access memory (DRAM) is not. Meanwhile, storage devices have evolved so that their speed is comparable to the speed of DRAM while their capacity scales are comparable to that of hard disk drives (HDD). Thus, hierarchial memory systems configuring DRAM as the main memory and high-end storages as swap devices will be common.","title":"DAPHICX: Data Access Pattern Hint Injecting Compiler Extension"},{"content":"$ git clone https://go.googlesource.com/go go1.4; cd go1.4 $ git checkout release-branch.go1.4; cd src $ ./make.bash $ cd ../../ $ git clone https://github.com/mit-pdos/biscuit.git; cd biscuit/src $ ./make.bash $ cd ../biscuit/ $ make qemu CPUS=2 ","permalink":"https://sjp38.github.io/posts/biscuit_os_install/","summary":"$ git clone https://go.googlesource.com/go go1.4; cd go1.4 $ git checkout release-branch.go1.4; cd src $ ./make.bash $ cd ../../ $ git clone https://github.com/mit-pdos/biscuit.git; cd biscuit/src $ ./make.bash $ cd ../biscuit/ $ make qemu CPUS=2 ","title":"Biscuit (OS Written in Go) Install"},{"content":"$ git clone https://go.googlesource.com/go go1.4; cd go1.4 $ git checkout release-branch.go1.4; cd src $ ./make.bash $ cd ../../ $ git clone https://github.com/mit-pdos/biscuit.git; cd biscuit/src $ ./make.bash $ cd ../biscuit/ $ make qemu CPUS=2 ","permalink":"https://sjp38.github.io/posts/ko/biscuit_os_install/","summary":"$ git clone https://go.googlesource.com/go go1.4; cd go1.4 $ git checkout release-branch.go1.4; cd src $ ./make.bash $ cd ../../ $ git clone https://github.com/mit-pdos/biscuit.git; cd biscuit/src $ ./make.bash $ cd ../biscuit/ $ make qemu CPUS=2 ","title":"Biscuit (OS Written in Go) Install"},{"content":"어느날부터 Fedora 터미널에서 한글 입력이 매우 불편해졌습니다. 한글 모드에서는 backspace, enter, esc 등의 특수키가 하나도 안먹힙니다. Vim 을 쓰는 입장에선 매우 불편하죠. 알고보니 ibus-hangul 버그인 것 같습니다[1]. 아래 커맨드로 ibus-hangul 을 문제 없던 버전으로 다운그레이드 시키고 세션을 재시작 하면 문제가 사라집니다.\nsudo dnf downgrade ibus-hangul-1.5.0-12.fc28.x86_64 [1] http://www.fedoralinux.or.kr/board-read.do?boardId=bbs3\u0026amp;boardNo=153170459823549\u0026amp;command=READ\u0026amp;page=1\u0026amp;categoryId=-1\n","permalink":"https://sjp38.github.io/posts/fedora28_hangul_problem/","summary":"어느날부터 Fedora 터미널에서 한글 입력이 매우 불편해졌습니다. 한글 모드에서는 backspace, enter, esc 등의 특수키가 하나도 안먹힙니다. Vim 을 쓰는 입장에선 매우 불편하죠. 알고보니 ibus-hangul 버그인 것 같습니다[1]. 아래 커맨드로 ibus-hangul 을 문제 없던 버전으로 다운그레이드 시키고 세션을 재시작 하면 문제가 사라집니다.\nsudo dnf downgrade ibus-hangul-1.5.0-12.fc28.x86_64 [1] http://www.fedoralinux.or.kr/board-read.do?boardId=bbs3\u0026amp;boardNo=153170459823549\u0026amp;command=READ\u0026amp;page=1\u0026amp;categoryId=-1","title":"Fedora28 ibus-hangul input problem"},{"content":"어느날부터 Fedora 터미널에서 한글 입력이 매우 불편해졌습니다. 한글 모드에서는 backspace, enter, esc 등의 특수키가 하나도 안먹힙니다. Vim 을 쓰는 입장에선 매우 불편하죠. 알고보니 ibus-hangul 버그인 것 같습니다[1]. 아래 커맨드로 ibus-hangul 을 문제 없던 버전으로 다운그레이드 시키고 세션을 재시작 하면 문제가 사라집니다.\nsudo dnf downgrade ibus-hangul-1.5.0-12.fc28.x86_64 [1] http://www.fedoralinux.or.kr/board-read.do?boardId=bbs3\u0026amp;boardNo=153170459823549\u0026amp;command=READ\u0026amp;page=1\u0026amp;categoryId=-1\n","permalink":"https://sjp38.github.io/posts/ko/fedora28_hangul_problem/","summary":"어느날부터 Fedora 터미널에서 한글 입력이 매우 불편해졌습니다. 한글 모드에서는 backspace, enter, esc 등의 특수키가 하나도 안먹힙니다. Vim 을 쓰는 입장에선 매우 불편하죠. 알고보니 ibus-hangul 버그인 것 같습니다[1]. 아래 커맨드로 ibus-hangul 을 문제 없던 버전으로 다운그레이드 시키고 세션을 재시작 하면 문제가 사라집니다.\nsudo dnf downgrade ibus-hangul-1.5.0-12.fc28.x86_64 [1] http://www.fedoralinux.or.kr/board-read.do?boardId=bbs3\u0026amp;boardNo=153170459823549\u0026amp;command=READ\u0026amp;page=1\u0026amp;categoryId=-1","title":"Fedora28 ibus-hangul input problem"},{"content":"HotStorage'19 에 제출한 제 최근 연구에 대한 논문이 accept 되어 7월에 해당 워크샵에서 이에 대한 내용을 발표하게 되었습니다. 논문 제목은 \u0026ldquo;Automating Context Based Access Pattern Hint Injection for System Performance and Swap Storage Durability\u0026rdquo; 입니다.\n","permalink":"https://sjp38.github.io/posts/hotstorage2019_talk/","summary":"HotStorage'19 에 제출한 제 최근 연구에 대한 논문이 accept 되어 7월에 해당 워크샵에서 이에 대한 내용을 발표하게 되었습니다. 논문 제목은 \u0026ldquo;Automating Context Based Access Pattern Hint Injection for System Performance and Swap Storage Durability\u0026rdquo; 입니다.","title":"I will have a talk at the Hotstorage'19"},{"content":"HotStorage'19 에 제출한 제 최근 연구에 대한 논문이 accept 되어 7월에 해당 워크샵에서 이에 대한 내용을 발표하게 되었습니다. 논문 제목은 \u0026ldquo;Automating Context Based Access Pattern Hint Injection for System Performance and Swap Storage Durability\u0026rdquo; 입니다.\n","permalink":"https://sjp38.github.io/posts/ko/hotstorage2019_talk/","summary":"HotStorage'19 에 제출한 제 최근 연구에 대한 논문이 accept 되어 7월에 해당 워크샵에서 이에 대한 내용을 발표하게 되었습니다. 논문 제목은 \u0026ldquo;Automating Context Based Access Pattern Hint Injection for System Performance and Swap Storage Durability\u0026rdquo; 입니다.","title":"I will have a talk at the Hotstorage'19"},{"content":"LD_PRELOAD 환경변수를 사용하면 로더가 프로그램을 로드할 때 동적 로드해야 할 바이너리 코드를 해당 변수의 값의 디렉토리에서부터 뒤지도록 합니다. 따라서 이를 이용해 malloc(), free() 등의 일반적으로 사용하는 라이브러리 함수를 우리의 구현으로 대체하거나 후킹할 수 있습니다. 이 글은 이런 방법으로 malloc() 을 후킹하는 방법을 예제를 통해 간단히 설명합니다.\nOriginal Program 먼저 다음과 같은 프로그램이 있을 수 있을 겁니다:\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; int main(void) { char *abc; abc = (char *)malloc(8); printf(\u0026#34;malloced address: %p\\n\u0026#34;, abc); sprintf(abc, \u0026#34;hello\\n\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, abc); free(abc); return 0; } 단순히 malloc() 을 통해 8바이트 메모리를 할당받아 그 영역을 표시하고 종료하는 프로그램입니다. 위 코드를 program.c 라는 파일로 저장하고, 아래와 같이 컴파일하고 수행해 보면 우리가 익히 아는, 예상대로의 결과가 나옵니다.\n$ gcc -o program program.c $ ./program malloced address: 0x1cc5010 hello malloc Hooking Code 이제 malloc() 함수를 후킹하는 코드를 만들어 봅시다:\n#define _GNU_SOURCE #include \u0026lt;dlfcn.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; typedef void *(*malloc_t)(size_t size); void *malloc(size_t size) { malloc_t malloc_fn; fprintf(stderr, \u0026#34;malloc(%zu) hooked\\n\u0026#34;, size); malloc_fn = (malloc_t)dlsym(RTLD_NEXT, \u0026#34;malloc\u0026#34;); return malloc_fn(size); } 이 코드는 우리가 아는 malloc() 함수와 동일한 함수명, signature 의 함수를 구현하고 있습니다. 단순히 우리가 후킹했음을 알리고, 동적 라이브러리 구조를 통해 이 다음으로 검색되는 malloc 이름의 라이브러리 함수 (이게 우리가 익히 아는 그 malloc() 구현이겠죠) 를 찾아, 같은 인자로 수행하고 그 결과를 리턴합니다. 즉, 우리가 아는 malloc() 과 같은 일을 하긴 하지만 malloc() 이 호출되었음을 알리는 것이죠.\n이 코드를 mallochook.c 라는 이름으로 저장 후, 다음과 같이 라이브러리로 빌드합니다:\n$ gcc -shared -fPIC mallochook.c -o mallochook.so -ldl Install The Hook 프로그램이 기존 malloc() 대신 우리가 구현한 malloc() 을 수행하게 하는 건 LD_PRELOAD 를 활용하면 간단합니다.\n$ LD_PRELOAD=./mallochook.so ./program malloc(8) hooked malloc(1024) hooked malloced address: 0x20a5010 hello 두번째, 세번째 줄을 보면 malloc() 이 후킹되어 우리의 메세지가 나오는 걸 볼 수 있습니다. 앞의 program.c 에서는 8 바이트 malloc() 호출만 있었는데 세번째 줄의 1024 바이트 malloc()은 어디서 나온 걸까요? 아마도 뒤의sprintf()` 등의 라이브러리 함수가 호출한 거 아닐까 싶은데 그걸 분석하는 건 여러분의 몫으로 두겠습니다.\nConclusion 자세한 원리는 생략했습니다만, 간단히 주요 라이브러리 함수를 후킹하는 방법을 알아봤습니다. 여기서 사용된 예제 코드와 명령어는 제 [Github repo] (https://github.com/sjp38/mallochook) 에 올려뒀으니 필요하면 참고 바랍니다.\n","permalink":"https://sjp38.github.io/posts/ko/hooking_library_calls/","summary":"LD_PRELOAD 환경변수를 사용하면 로더가 프로그램을 로드할 때 동적 로드해야 할 바이너리 코드를 해당 변수의 값의 디렉토리에서부터 뒤지도록 합니다. 따라서 이를 이용해 malloc(), free() 등의 일반적으로 사용하는 라이브러리 함수를 우리의 구현으로 대체하거나 후킹할 수 있습니다. 이 글은 이런 방법으로 malloc() 을 후킹하는 방법을 예제를 통해 간단히 설명합니다.\nOriginal Program 먼저 다음과 같은 프로그램이 있을 수 있을 겁니다:\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; int main(void) { char *abc; abc = (char *)malloc(8); printf(\u0026#34;malloced address: %p\\n\u0026#34;, abc); sprintf(abc, \u0026#34;hello\\n\u0026#34;); printf(\u0026#34;%s\\n\u0026#34;, abc); free(abc); return 0; } 단순히 malloc() 을 통해 8바이트 메모리를 할당받아 그 영역을 표시하고 종료하는 프로그램입니다.","title":"Hooking Library Function Calls"},{"content":"디버깅 과정에선 현재 어떤 코드가 어떤 함수를 거쳐 수행됐는지를 통한 컨텍스트 파악이 중요합니다. Java, Python, Go 등 대부분의 언어가 이를 위해 콜스택을 뽑을 수 있는 기능을 제공하죠. C 언어의 경우 gdb 등을 사용하면 쉽게 이를 볼 수 있지만 경우에 따라선 gdb 를 포기하고 printf() 등에만 의존해야 하기도 합니다. 이를 위한 기능이 c 라이브러리에도 있습니다, backtrace() 함수입니다. man 에도 이에 대한 설명이 있습니다만, 여기서도 간단히 소개해 봅니다.\nExample Source Code 예제로 설명하는게 가장 쉽죠. 간단한 사용법은 아래와 같습니다.\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;execinfo.h\u0026gt; void baz(void) { void *callstack[128]; int i, frames; char **strs; frames = backtrace(callstack, 128); strs = backtrace_symbols(callstack, frames); for (i = 0; i \u0026lt; frames; i++) printf(\u0026#34;%s\\n\u0026#34;, strs[i]); free(strs); } void bar(void) { baz(); } void foo(void) { bar(); } int main(void) { foo(); return 0; } Compile 아래와 같이 컴파일 합니다:\n$ gcc -rdynamic -g -o hello ./hello.c -rdynamic 과 -g 옵션을 잊지 맙시다.\n이제 프로그램을 실행해 보면:\n$ ./hello ./hello(baz+0x2e) [0x400964] ./hello(bar+0x9) [0x4009fd] ./hello(foo+0x9) [0x400a09] ./hello(main+0x9) [0x400a15] /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0) [0x7f87c51e6830] ./hello(_start+0x29) [0x400869] main(), foo(), bar(), 를 거쳐 baz() 가 수행되었음을 보입니다. 더 나아가서 어떤 소스파일의 몇번 라인인지를 보고 싶다면 addr2line 커맨드를 사용할 수 있습니다.\n$ addr2line -e hello 0x400964 ./hello.c:10 $ addr2line -e hello 0x4009fd ./hello.c:20 $ addr2line -e hello 0x400a09 ./hello.c:25 $ addr2line -e hello 0x400a15 ./hello.c:30 쉽죠? ;)\nConclusion C 프로그램에서 backtrace 를 떠보는 방법을 알아보았습니다. 위의 내용을 여러분의 환경에서도 쉽게 테스트 해 볼 수 있게끔 제 [Github repo] (https://github.com/sjp38/backtrace_example) 에도 정리해 두었습니다. 클론하고, $ make run 해주시면 예제가 자동으로 빌드되고 돌아갈 겁니다.\n","permalink":"https://sjp38.github.io/posts/backtrace_c_language/","summary":"디버깅 과정에선 현재 어떤 코드가 어떤 함수를 거쳐 수행됐는지를 통한 컨텍스트 파악이 중요합니다. Java, Python, Go 등 대부분의 언어가 이를 위해 콜스택을 뽑을 수 있는 기능을 제공하죠. C 언어의 경우 gdb 등을 사용하면 쉽게 이를 볼 수 있지만 경우에 따라선 gdb 를 포기하고 printf() 등에만 의존해야 하기도 합니다. 이를 위한 기능이 c 라이브러리에도 있습니다, backtrace() 함수입니다. man 에도 이에 대한 설명이 있습니다만, 여기서도 간단히 소개해 봅니다.\nExample Source Code 예제로 설명하는게 가장 쉽죠.","title":"Backtrace on C language program"},{"content":"디버깅 과정에선 현재 어떤 코드가 어떤 함수를 거쳐 수행됐는지를 통한 컨텍스트 파악이 중요합니다. Java, Python, Go 등 대부분의 언어가 이를 위해 콜스택을 뽑을 수 있는 기능을 제공하죠. C 언어의 경우 gdb 등을 사용하면 쉽게 이를 볼 수 있지만 경우에 따라선 gdb 를 포기하고 printf() 등에만 의존해야 하기도 합니다. 이를 위한 기능이 c 라이브러리에도 있습니다, backtrace() 함수입니다. man 에도 이에 대한 설명이 있습니다만, 여기서도 간단히 소개해 봅니다.\nExample Source Code 예제로 설명하는게 가장 쉽죠. 간단한 사용법은 아래와 같습니다.\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;execinfo.h\u0026gt; void baz(void) { void *callstack[128]; int i, frames; char **strs; frames = backtrace(callstack, 128); strs = backtrace_symbols(callstack, frames); for (i = 0; i \u0026lt; frames; i++) printf(\u0026#34;%s\\n\u0026#34;, strs[i]); free(strs); } void bar(void) { baz(); } void foo(void) { bar(); } int main(void) { foo(); return 0; } Compile 아래와 같이 컴파일 합니다:\n$ gcc -rdynamic -g -o hello ./hello.c -rdynamic 과 -g 옵션을 잊지 맙시다.\n이제 프로그램을 실행해 보면:\n$ ./hello ./hello(baz+0x2e) [0x400964] ./hello(bar+0x9) [0x4009fd] ./hello(foo+0x9) [0x400a09] ./hello(main+0x9) [0x400a15] /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0) [0x7f87c51e6830] ./hello(_start+0x29) [0x400869] main(), foo(), bar(), 를 거쳐 baz() 가 수행되었음을 보입니다. 더 나아가서 어떤 소스파일의 몇번 라인인지를 보고 싶다면 addr2line 커맨드를 사용할 수 있습니다.\n$ addr2line -e hello 0x400964 ./hello.c:10 $ addr2line -e hello 0x4009fd ./hello.c:20 $ addr2line -e hello 0x400a09 ./hello.c:25 $ addr2line -e hello 0x400a15 ./hello.c:30 쉽죠? ;)\nConclusion C 프로그램에서 backtrace 를 떠보는 방법을 알아보았습니다. 위의 내용을 여러분의 환경에서도 쉽게 테스트 해 볼 수 있게끔 제 [Github repo] (https://github.com/sjp38/backtrace_example) 에도 정리해 두었습니다. 클론하고, $ make run 해주시면 예제가 자동으로 빌드되고 돌아갈 겁니다.\n","permalink":"https://sjp38.github.io/posts/ko/backtrace_c_language/","summary":"디버깅 과정에선 현재 어떤 코드가 어떤 함수를 거쳐 수행됐는지를 통한 컨텍스트 파악이 중요합니다. Java, Python, Go 등 대부분의 언어가 이를 위해 콜스택을 뽑을 수 있는 기능을 제공하죠. C 언어의 경우 gdb 등을 사용하면 쉽게 이를 볼 수 있지만 경우에 따라선 gdb 를 포기하고 printf() 등에만 의존해야 하기도 합니다. 이를 위한 기능이 c 라이브러리에도 있습니다, backtrace() 함수입니다. man 에도 이에 대한 설명이 있습니다만, 여기서도 간단히 소개해 봅니다.\nExample Source Code 예제로 설명하는게 가장 쉽죠.","title":"Backtrace on C language program"},{"content":"업데이트 (2020-01-01): KUnit 은 v5.5 머지 윈도우 사이 메인라인에 머지되었습니다. 이 포스트 작성 시점 이후로 많은 KUnit 에도 많은 변화가 있었고, 따라서 아래 내용 중 일부, 특히 테스트 셋업과 수행 부분은 좀 많이 달라졌습니다. 해당 내용을 위해선 공식 문서 를 참고하시길 권장합니다. 또한, 최신 버전은 파이썬 버전 종속성이 생겨서 우분투 16.04 위에서는 문제를 겪으실 수 있습니다. 최신버전의 파이썬을 쓰시거나 그냥 우분투 18.04 를 사용하시길 권장합니다.\n지난 2월 말에 FAST'19 학회를 다녀왔는데요, Ted Tso 도 왔더군요. 심지어 구글 부스를 지키고 계시더라구요. 어쩌다보니 식사자리에서 합석하고 잡담 나눈 레드햇 개발자 분들이랑 이야기를 하고 있길래 껴서 좀 이야기를 했는데, 이야기 중 테스트에 대한 이야기가 나왔고, 이에 Ted 가 KUnit 이라는 도구를 소개해 줬습니다. 잠깐 사용해 보니 매우 매력적인 것 같아서 이 블로그에서도 소개해 볼까 합니다.\nKUnit 은 이름에서 짐작했겠지만 리눅스 커널을 위한 유닛 테스트 프레임웍입니다. 구글의 Brendan Higgins 라는 분이 개발하고 있고, 커널 내에 머지되는 걸 목표로 해서 LKML 에도 RFC 패치를 보내고 있습니다. 구글러다 보니 구글에서 호스팅 되는 소스트리 위에서 개발을 하고 있고, 문서화 도 잘 해뒀군요.\n이 글은 이런 KUnit 을 사용하는 법을 간단히 정리해 봅니다. 글 내의 테스트에 사용된 환경은 Ubuntu 16.04 서버 버전입니다.\nInstall Kunit 개발 커널은 https://kunit.googlesource.com 에서 받을 수 있습니다. 간단히 아래 명령으로 커널 코드를 땡겨옵시다. 여기선 가장 최근에 RFC 패치를 보냈던 5.0-rc5 위의 버전으로 가져오겠습니다.\n$ git clone -b kunit/rfc/5.0-rc5/v4 https://kunit.googlesource.com/linux 물론, [Patchwork] (https://lore.kernel.org/patchwork/project/lkml/list/?series=383391) 을 통해 KUnit 패치만 직접 받아와 사용중인 커널에 적용하실 수도 있습니다. 전 v5.0 버전 위에도 적용해 봤는데 문제 없이 잘 적용되더군요.\n이어서 KUnit 을 위한 패키지를 깔아야 할텐데요, 커널 빌드에 필요한 패키지만 깔면 됩니다. 커널 빌드에 필요한 패키지에 대한 정보는 이 블로그의 커널 빌드 및 설치에 대한 포스트 를 참고해 주세요.\nTest 커널 빌드 종속성 패키지까지 다 설치했다면 준비가 거의 끝났습니다. 잘 돌아가는지 확인해 보기 위해 kunit 에서 제공하는 예제 테스트들을 돌려봅시다.\nKUnit 을 돌리기 위해선 configuration 을 커널 트리 루트에 kunitconfig 라는 이름의 파일로 써줘야 합니다. 이 설정은 어떤 테스트를 돌릴지 등을 지정합니다. 일단 아래 내용으로 해당 파일을 써줍시다:\n$ cd linux $ echo CONFIG_KUNIT=y \u0026gt; kunitconfig $ echo CONFIG_KUNIT_TEST=y \u0026gt;\u0026gt; kunitconfig $ echo CONFIG_KUNIT_EXAMPLE_TEST=y \u0026gt;\u0026gt; kunitconfig 이제 다음의 간단한 명령만으로 KUnit 예제 테스트를 돌릴 수 있습니다:\n$ ./tools/testing/kunit/kunit.py 아래와 같은 결과가 터미널에 뜰겁니다:\n[11:31:47] Building KUnit Kernel ... [11:32:12] Starting KUnit Kernel ... [11:32:12] ============================== [11:32:13] [PASSED] kunit-resource-test:kunit_resource_test_init_resources [11:32:13] [PASSED] kunit-resource-test:kunit_resource_test_alloc_resource [11:32:13] [PASSED] kunit-resource-test:kunit_resource_test_free_resource [11:32:13] [PASSED] kunit-resource-test:kunit_resource_test_cleanup_resources [11:32:13] ============================== [11:32:13] [PASSED] kunit-try-catch-test:kunit_test_try_catch_successful_try_no_catch [11:32:13] [PASSED] kunit-try-catch-test:kunit_test_try_catch_unsuccessful_try_does_catch [11:32:13] [PASSED] kunit-try-catch-test:kunit_test_generic_try_catch_successful_try_no_catch [11:32:13] [PASSED] kunit-try-catch-test:kunit_test_generic_try_catch_unsuccessful_try_does_catch [11:32:13] ============================== [11:32:13] [PASSED] string-stream-test:string_stream_test_get_string [11:32:13] [PASSED] string-stream-test:string_stream_test_add_and_clear [11:32:13] ============================== [11:32:13] [PASSED] example:example_simple_test [11:32:13] ============================== [11:32:13] Testing complete. 11 tests run. 0 failed. 0 crashed. [11:32:13] Elapsed time: 26.005s total, 0.000s configuring, 25.736s building, 0.268s running. kunit-resource-test, kunit-try-catch-test, string-stream-tets, example 등의 예제 테스트가 돌아갔고, 모두 테스트를 통과해서 문제가 없음을 보여줍니다.\nKUnit 은 테스트를 위해 커널도 빌드하기 때문에 빌드 시간이 조금 길긴 합니다. 이 경우엔 26초 정도 걸렸네요. 하지만 이건 처음 빌드라 그렇고, 기존에 빌드를 해두고 파일 하나만 수정하는 경우엔 약 10초 정도 걸리는 것 같습니다. 하지만 이후 실제 테스트를 돌리는건 매우 짧은 시간을 필요로 합니다. 이 경우 0.27초 가량 걸렸군요! 따라서 테스트가 늘어나도 많은 시간을 요하지 않습니다.\n스스로를 위한 유닛 테스트를 추가하는 법은 Kunit 공식 문서[1] 를 참고하시기 바랍니다. 어렵지 않습니다 :)\n[1] https://google.github.io/kunit-docs/third_party/kernel/docs/start.html#writing-your-first-test\nConclusion 리눅스 커널을 위한 Unit test framework 인 KUnit 에 대한 간단한 소개와 사용법을 설명했습니다. 저도 최근 개발에 활용하고 있는데, TDD 의 장점을 오랫만에 느낄 수 있었습니다. 하루 빨리 업스트림에도 머지되었으면 좋겠네요!\n","permalink":"https://sjp38.github.io/posts/ko/kunit_intro/","summary":"업데이트 (2020-01-01): KUnit 은 v5.5 머지 윈도우 사이 메인라인에 머지되었습니다. 이 포스트 작성 시점 이후로 많은 KUnit 에도 많은 변화가 있었고, 따라서 아래 내용 중 일부, 특히 테스트 셋업과 수행 부분은 좀 많이 달라졌습니다. 해당 내용을 위해선 공식 문서 를 참고하시길 권장합니다. 또한, 최신 버전은 파이썬 버전 종속성이 생겨서 우분투 16.04 위에서는 문제를 겪으실 수 있습니다. 최신버전의 파이썬을 쓰시거나 그냥 우분투 18.04 를 사용하시길 권장합니다.\n지난 2월 말에 FAST'19 학회를 다녀왔는데요, Ted Tso 도 왔더군요.","title":"Unit test for the Linux kernel using Kunit"},{"content":"Update (2020-01-01): KUnit has merged in v5.5 merge window. From the writing of this post, it had some changes, so below content, especially the test setup and running will not work. Recommend you to refer to the official document in the kernel for detailed tutorial. It also has a python version dependency now, so you would encounter a problem with Ubuntu 16.04. Recommend you to use later Python or Ubuntu 18.04 instead.\nI have attended FAST'19 last February. There was Ted Tso. I saw he hanging out with a few of Redhat people who I met during the lunch and tagged along with them. During the chat, we talked about test and Ted introduced us a testing framework called KUnit. I started using it after return from FAST'19 and felt it is amazing, so I would like to introduce it in this post.\nAs its name intimates, KUnit is a unit test framework for the Linux kernel. Google\u0026rsquo;s Brendan Higgins is developing it and he is also sending RFC patches to LKML so that it can be merged into the mainline. Because he is a Googler, he is hosting a source tree on a Google server and also made a well written Documentation.\nThis post will further briefly summarise how you can use KUnit. I tested this post on my Ubuntu 16.04 server.\nInstall You can receive Kunit development kernel from https://kunit.googlesource.com. Clone it with below simple command. I will use 5.0-rc5 based version which Brendan has recently sent the RFC patches.\n$ git clone -b kunit/rfc/5.0-rc5/v4 https://kunit.googlesource.com/linux Of course, you can get only patches via Patchwork and apply it on your kernel. I got it and applied it on my v5.0 kernel and it worked well.\nNow you should install some packages for KUnit. You need only the packages that required by kernel build. For the list of the packages, refer to the post describing it.\nTest It\u0026rsquo;s almost ready. Let\u0026rsquo;s run the example tests that kunit provides.\nFirst, you should write a file named kunitconfig under the kernel tree root directory. This file specifies what tests you want to run. Just write as below for now:\n$ cd linux $ echo CONFIG_KUNIT=y \u0026gt; kunitconfig $ echo CONFIG_KUNIT_TEST=y \u0026gt;\u0026gt; kunitconfig $ echo CONFIG_KUNIT_EXAMPLE_TEST=y \u0026gt;\u0026gt; kunitconfig Now you can run the KUnit example tests as below:\n$ ./tools/testing/kunit/kunit.py You will see results below on your terminal:\n[11:31:47] Building KUnit Kernel ... [11:32:12] Starting KUnit Kernel ... [11:32:12] ============================== [11:32:13] [PASSED] kunit-resource-test:kunit_resource_test_init_resources [11:32:13] [PASSED] kunit-resource-test:kunit_resource_test_alloc_resource [11:32:13] [PASSED] kunit-resource-test:kunit_resource_test_free_resource [11:32:13] [PASSED] kunit-resource-test:kunit_resource_test_cleanup_resources [11:32:13] ============================== [11:32:13] [PASSED] kunit-try-catch-test:kunit_test_try_catch_successful_try_no_catch [11:32:13] [PASSED] kunit-try-catch-test:kunit_test_try_catch_unsuccessful_try_does_catch [11:32:13] [PASSED] kunit-try-catch-test:kunit_test_generic_try_catch_successful_try_no_catch [11:32:13] [PASSED] kunit-try-catch-test:kunit_test_generic_try_catch_unsuccessful_try_does_catch [11:32:13] ============================== [11:32:13] [PASSED] string-stream-test:string_stream_test_get_string [11:32:13] [PASSED] string-stream-test:string_stream_test_add_and_clear [11:32:13] ============================== [11:32:13] [PASSED] example:example_simple_test [11:32:13] ============================== [11:32:13] Testing complete. 11 tests run. 0 failed. 0 crashed. [11:32:13] Elapsed time: 26.005s total, 0.000s configuring, 25.736s building, 0.268s running. It says example tests including kunit-resource-test, kunit-try-catch-test, string-stream-tets, example has ran, and all of those passed.\nKUnit should also build the kernel for the test, and the build takes a few of time. In this case, it took 26 seconds. That said, this was long because it\u0026rsquo;s first build. It took about only 10 seconds for me when I modified only one file after. Also, it takes very short time only for running actual test. In this case, it took only 0.27 seconds! Therefore, it will not take too huge time even though you have lots of tests.\nRefer to the Kunit official document to know how you can add your unit test. Not so hard :)\nConclusion Introduced the unit test framework for the Linux kernel, KUnit. I am also using it for my recent programming and could feel the advantage of TDD again. Hope this to be merged in the upstream soon!\n","permalink":"https://sjp38.github.io/posts/kunit_intro/","summary":"Update (2020-01-01): KUnit has merged in v5.5 merge window. From the writing of this post, it had some changes, so below content, especially the test setup and running will not work. Recommend you to refer to the official document in the kernel for detailed tutorial. It also has a python version dependency now, so you would encounter a problem with Ubuntu 16.04. Recommend you to use later Python or Ubuntu 18.","title":"Unit test for the Linux kernel using Kunit"},{"content":"연구실 내부 사용을 위한 Gitlab 을 Docker 를 사용해서 구축하고 사용하고 있습니다만, 하도 예전이라 Gitlab official docker image 가 아니었고, docker 버전도 2.x 대라서 최신 버전으로 바로 업그레이드가 불가능하군요.\n지금은 gitlab 에서 자체적으로 정식 docker 이미지를 제공합니다. 이 포스트에서는 Ubuntu 18.04 서버 위에 gitlab 정식 docker 이미지를 사용해 설치하는 방법을 기록합니다.\nDocker 설치 먼저 Docker 를 설치해야죠. 문서[1]를 참고해서 설치를 진행해 봅니다.\n먼저 apt 업데이트 후 종속 패키지들을 깔아줍니다:\nsudo apt update sudo apt install apt-transport-https ca-certificates curl software-properties-common 이제 최신 docker 를 깔기 위해 docker repository 를 apt 에 추가해 주고요:\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository \u0026#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable\u0026#34; sudo apt update 설치합시다:\nsudo apt install docker-ce 잘 깔렸는지 확인해 봅시다:\n$ sudo docker run hello-world Unable to find image \u0026#39;hello-world:latest\u0026#39; locally latest: Pulling from library/hello-world 1b930d010525: Pull complete Digest: sha256:2557e3c07ed1e38f26e389462d03ed943586f744621577a99efb77324b0fe535 Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \u0026#34;hello-world\u0026#34; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ 위와 같이 Hello from Docker! 가 나오면 된겁니다.\n[1] https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-18-04\nGitlab 설치 일단 시작 이제 Gitlab docker image 를 가져오고 돌려보죠. Gitlab 쪽 문서[1]를 참고합니다.\n$ cd $HOME; mkdir data $ sudo docker run --detach --hostname gitlab.example.com \\ --publish 30443:443 --publish 30480:80 --publish 30422:22 \\ --name gitlab --restart always \\ --volume $HOME/data/srv/gitlab/config:/etc/gitlab \\ --volume $HOME/data/srv/gitlab/logs:/var/log/gitlab \\ --volume $HOME/data/srv/gitlab/data:/var/opt/gitlab \\ gitlab/gitlab-ce:11.8.2-ce.0 이 글 작성 시점 기준으로 가장 마지막 정식 릴리즈가 11.8 이므로 11.8.2 버전을 골랐고, 기존에 웹서버와 ssh 가 깔려있는 관계로 별도의 포트를 사용하게 했습니다.\n조금 기다렸다가 http://gitlab.example.com:30480 으로 들어가면 로그인 됩니다. $ sudo docker ps -a 명령을 통해 만든 컨테이너의 status 가 starting 을 넘어갈 때까지만 기다리면 됩니다. 최초 로그인 시에는 관리자 패스워드를 바로 설정할 수 있습니다. 이후 root 계정에 지금 설정한 패스워드를 입력해 접속할 수 있습니다.\n설정 변경 몇가지 설정을 추가해야 합니다. 설정은 아래 명령으로 지금 띄운 컨테이너에 들어가 설정 파일을 수정하는 것으로 가능합니다:\n$ sudo docker exec -it gitlab /bin/bash # vi /etc/gitlab/gitlab.rb --volume 으로 $HOME/data/srv/gitlab/config 아래로 파일이 링크되어 있으므로 여기서 수정해도 괜찮습니다.\n해당 파일을 변경한 후에는 docker 를 재시작 해야 변경된 설정이 적용됩니다.\n$ sudo docker restart gitlab 포트 변경 적용 호스트의 80 포트, 22 포트, 443 포트를 점유할 수 없는 상황이므로 우린 30480, 30422, 30443 포트를 대신 사용하도록 했습니다. 이 경우 추가적인 설정이 필요합니다. gitlab.rb 파일에 아래 네줄을 추가합시다.\nexternal_url \u0026#39;http://gitlab.example.com:30480\u0026#39; nginx[\u0026#39;listen_port\u0026#39;] = 80 nginx[\u0026#39;listen_https\u0026#39;] = false gitlab_rails[\u0026#39;gitlab_shell_ssh_port\u0026#39;] = 30422 두번째, 세번째 줄을 추가 안해주면 동작 안합니다[3].\ngmail smtp 설정 이어서 smtp 설정을 해야 합니다.\n우린 gmail smtp 를 사용하겠습니다. 이 설정 파일에 다음과 같은 내용을 추가합니다. 이 내용은 공식 문서의 예제[2]에서 가져왔습니다.\ngitlab_rails[\u0026#39;smtp_enable\u0026#39;] = true gitlab_rails[\u0026#39;smtp_address\u0026#39;] = \u0026#34;smtp.gmail.com\u0026#34; gitlab_rails[\u0026#39;smtp_port\u0026#39;] = 587 gitlab_rails[\u0026#39;smtp_user_name\u0026#39;] = \u0026#34;my.email@gmail.com\u0026#34; gitlab_rails[\u0026#39;smtp_password\u0026#39;] = \u0026#34;my-gmail-password\u0026#34; gitlab_rails[\u0026#39;smtp_domain\u0026#39;] = \u0026#34;smtp.gmail.com\u0026#34; gitlab_rails[\u0026#39;smtp_authentication\u0026#39;] = \u0026#34;login\u0026#34; gitlab_rails[\u0026#39;smtp_enable_starttls_auto\u0026#39;] = true gitlab_rails[\u0026#39;smtp_tls\u0026#39;] = false gitlab_rails[\u0026#39;smtp_openssl_verify_mode\u0026#39;] = \u0026#39;peer\u0026#39; # Can be: \u0026#39;none\u0026#39;, \u0026#39;peer\u0026#39;, \u0026#39;client_once\u0026#39;, \u0026#39;fail_if_no_peer_cert\u0026#39;, see http://api.rubyonrails.org/classes/ActionMailer/Base.html 여기서 my.email 과 my-gmail-password 는 당연히 실제 gmail 계정으로 바꿔야겠죠? 해당 gmail 계정도 gmail 설정에서 smtp 를 사용할 수 있게 설정해 줘야 합니다.\n가입 기능 제거 gitlab 첫페이지는 sign in 과 register 기능이 있습니다. 처음 사용하는 유저는 register 를 사용하면 되는거죠.\n하지만 우린 폐쇄적으로 운영할 꺼라 계정을 관리자 통해서만 만들 수 있게 하고 싶습니다. Admin area -\u0026gt; Settings -\u0026gt; General -\u0026gt; Sign-up restrictions 메뉴에서 Sign-up enabled 를 비활성화 시키고 변경사항 저장 버튼을 누릅니다. 이제 gitlab 첫페이지에 register 기능이 사라져 있을 겁니다.\n[1] https://docs.gitlab.com/omnibus/docker/ [2] https://docs.gitlab.com/omnibus/settings/smtp.html [3] https://gitlab.com/gitlab-org/omnibus-gitlab/issues/3535\n","permalink":"https://sjp38.github.io/posts/ko/gitlab_docker_install/","summary":"연구실 내부 사용을 위한 Gitlab 을 Docker 를 사용해서 구축하고 사용하고 있습니다만, 하도 예전이라 Gitlab official docker image 가 아니었고, docker 버전도 2.x 대라서 최신 버전으로 바로 업그레이드가 불가능하군요.\n지금은 gitlab 에서 자체적으로 정식 docker 이미지를 제공합니다. 이 포스트에서는 Ubuntu 18.04 서버 위에 gitlab 정식 docker 이미지를 사용해 설치하는 방법을 기록합니다.\nDocker 설치 먼저 Docker 를 설치해야죠. 문서[1]를 참고해서 설치를 진행해 봅니다.\n먼저 apt 업데이트 후 종속 패키지들을 깔아줍니다:\nsudo apt update sudo apt install apt-transport-https ca-certificates curl software-properties-common 이제 최신 docker 를 깔기 위해 docker repository 를 apt 에 추가해 주고요:","title":"Gitlab docker install"},{"content":"FAST'19 Work-in-progress 세션 에서 현재 진행중인 연구에 대해 발표하게 되었습니다. 발표 제목은 \u0026ldquo;Automated Data Access Pattern Hint Instrumentation for System Performance and Durability of Swap Storage\u0026rdquo; 입니다.\n","permalink":"https://sjp38.github.io/posts/fast2019_talk/","summary":"FAST'19 Work-in-progress 세션 에서 현재 진행중인 연구에 대해 발표하게 되었습니다. 발표 제목은 \u0026ldquo;Automated Data Access Pattern Hint Instrumentation for System Performance and Durability of Swap Storage\u0026rdquo; 입니다.","title":"I will have a talk at the FAST'19"},{"content":"FAST'19 Work-in-progress 세션 에서 현재 진행중인 연구에 대해 발표하게 되었습니다. 발표 제목은 \u0026ldquo;Automated Data Access Pattern Hint Instrumentation for System Performance and Durability of Swap Storage\u0026rdquo; 입니다.\n","permalink":"https://sjp38.github.io/posts/ko/fast2019_talk/","summary":"FAST'19 Work-in-progress 세션 에서 현재 진행중인 연구에 대해 발표하게 되었습니다. 발표 제목은 \u0026ldquo;Automated Data Access Pattern Hint Instrumentation for System Performance and Durability of Swap Storage\u0026rdquo; 입니다.","title":"I will have a talk at the FAST'19"},{"content":"4.19 커널에서 오랫만에 perf 를 다시 빌드하고 써보려고 하니, perf report 가 아래와 같이 제대로 된 symbol name 을 찾질 못합니다.\n$ sudo perf record -g ls arch builtin-ftrace.c builtin-report.c Documentation perf.data.old bench builtin.h builtin-sched.c examples perf.h Build builtin-help.c builtin-script.c include perf-read-vdso.c builtin-annotate.c builtin-inject.c builtin-stat.c jvmti perf-sys.h builtin-bench.c builtin-kallsyms.c builtin-timechart.c Makefile perf-with-kcore.sh builtin-buildid-cache.c builtin-kmem.c builtin-top.c Makefile.config pmu-events builtin-buildid-list.c builtin-kvm.c builtin-trace.c Makefile.perf python builtin-c2c.c builtin-list.c builtin-version.c MANIFEST scripts builtin-config.c builtin-lock.c check-headers.sh perf-archive.sh tests builtin-data.c builtin-mem.c command-list.txt perf.c trace builtin-diff.c builtin-probe.c CREDITS perf-completion.sh ui builtin-evlist.c builtin-record.c design.txt perf.data util [ perf record: Woken up 1 times to write data ] [ perf record: Captured and wrote 0.025 MB perf.data (21 samples) ] sjpark@hydra:~/linux/tools/perf$ sudo perf report --stdio # To display the perf.data header info, please use --header/--header-only options. # # # Total Lost Samples: 0 # # Samples: 21 of event \u0026#39;cycles:ppp\u0026#39; # Event count (approx.): 2712237 # # Children Self Command Shared Object Symbol # ........ ........ ....... ................. ................................. # 59.39% 0.00% ls [unknown] [k] 0xffffffffa8a00088 | ---0xffffffffa8a00088 | |--51.91%--0xffffffffa8004185 | | | |--17.13%--0xffffffffa8212c8b | | 0xffffffffa8212afe | | 0xffffffffa821274a | | 0xffffffffa81bb3c5 왜이러지 하고 삽질하다가 알고보니 perf 쪽 최신 커밋인 edeb0c90df35 (\u0026ldquo;perf tools: Stop fallbacking to kallsyms for vdso symbols lookup\u0026rdquo;) 이 만든 버그군요. 해당 커밋만 revert 하고 perf 를 다시 빌드하면 다시 잘 됩니다.\n저만 겪는 문제는 아닌지 버그질라에도 이에 대한 이슈가 올라와 있네요: https://bugzilla.kernel.org/show_bug.cgi?id=201551\n","permalink":"https://sjp38.github.io/posts/ko/perf_symbol_problem_4.19/","summary":"4.19 커널에서 오랫만에 perf 를 다시 빌드하고 써보려고 하니, perf report 가 아래와 같이 제대로 된 symbol name 을 찾질 못합니다.\n$ sudo perf record -g ls arch builtin-ftrace.c builtin-report.c Documentation perf.data.old bench builtin.h builtin-sched.c examples perf.h Build builtin-help.c builtin-script.c include perf-read-vdso.c builtin-annotate.c builtin-inject.c builtin-stat.c jvmti perf-sys.h builtin-bench.c builtin-kallsyms.c builtin-timechart.c Makefile perf-with-kcore.sh builtin-buildid-cache.c builtin-kmem.c builtin-top.c Makefile.config pmu-events builtin-buildid-list.c builtin-kvm.c builtin-trace.c Makefile.perf python builtin-c2c.c builtin-list.c builtin-version.c MANIFEST scripts builtin-config.c builtin-lock.c check-headers.sh perf-archive.","title":"Perf symbol problem on Linux 4.19"},{"content":"지난 토요일, Theodore Ts\u0026rsquo;o 로부터 올해 Linux Plumbers Conference 의 한 트랙으로 열리는 커널 서밋에서 GCMA 발표를 해줄 수 있겠냐는 제의를 받았고 물론 그러겠노라고 했습니다. 발표 일정의 [첫번째 드래프트][1]가 올라왔군요. 화요일 아침에 발표하게 됐습니다.\n[1] https://lists.linuxfoundation.org/pipermail/ksummit-discuss/2018-November/006238.html\n","permalink":"https://sjp38.github.io/posts/ko/ksummit2018_talk/","summary":"지난 토요일, Theodore Ts\u0026rsquo;o 로부터 올해 Linux Plumbers Conference 의 한 트랙으로 열리는 커널 서밋에서 GCMA 발표를 해줄 수 있겠냐는 제의를 받았고 물론 그러겠노라고 했습니다. 발표 일정의 [첫번째 드래프트][1]가 올라왔군요. 화요일 아침에 발표하게 됐습니다.\n[1] https://lists.linuxfoundation.org/pipermail/ksummit-discuss/2018-November/006238.html","title":"I will have a talk at the kernel summit"},{"content":"지난 토요일, Theodore Ts\u0026rsquo;o 로부터 올해 Linux Plumbers Conference 의 한 트랙으로 열리는 커널 서밋에서 GCMA 발표를 해줄 수 있겠냐는 제의를 받았고 물론 그러겠노라고 했습니다. 발표 일정의 [첫번째 드래프트][1]가 올라왔군요. 화요일 아침에 발표하게 됐습니다.\n[1] https://lists.linuxfoundation.org/pipermail/ksummit-discuss/2018-November/006238.html\n","permalink":"https://sjp38.github.io/posts/ksummit2018_talk/","summary":"지난 토요일, Theodore Ts\u0026rsquo;o 로부터 올해 Linux Plumbers Conference 의 한 트랙으로 열리는 커널 서밋에서 GCMA 발표를 해줄 수 있겠냐는 제의를 받았고 물론 그러겠노라고 했습니다. 발표 일정의 [첫번째 드래프트][1]가 올라왔군요. 화요일 아침에 발표하게 됐습니다.\n[1] https://lists.linuxfoundation.org/pipermail/ksummit-discuss/2018-November/006238.html","title":"I will have a talk at the kernel summit"},{"content":"리눅스 커널은 Formalised and executable memory consistent model 을 제공합니다. 줄여서 linux kernel memory model (LKMM) 이라고 하죠. 이 글은 4.19 버전을 기준으로 LKMM 을 실제로 수행해 보기 위한 환경 셋업 과정과 간단한 실행 방법을 정리해 봅니다. 글 작성을 위한 테스트는 Ubuntu 16.04 서버가 설치된 가상머신에서 진행되었습니다.\nherd7 install LKMM 은 버전 7.49 의 \u0026ldquo;herd7\u0026rdquo; 과 \u0026ldquo;klitmus7\u0026rdquo; 을 필요로 합니다. 하지만 herd7 은 또 Ocaml 을 위한 패키지 매니저인 OPAM 을 설치할 것을 필요로 하죠. 우분투에선 패키지 시스템이 OPAM 을 지원하므로 아래와 같이 쉽게 설치할 수 있습니다:\n$ sudo apt install opam $ opam init $ sudo opam update $ sudo opam upgrade 두번째 커맨드 수행 중 다음과 같은 질문이 나오는데, 디폴트 선택을 주기 위해 그냥 엔터를 칩니다:\nDo you want OPAM to modify ~/.profile and ~/.ocamlinit? (default is \u0026#39;no\u0026#39;, use \u0026#39;f\u0026#39; to name a file other than ~/.profile) [N/y/f] 또한 update 와 upgrade 명령 시에 root 권한으로 이 커맨드를 수행하는 걸 권장하지 않는다고 하지만 정작 sudo 없이 하면 권한 없어서 실패합니다.\n이제 다음 명령을 통해 herdtools 의 빌드와 설치를 진행합니다.\n$ git clone https://github.com/herd/herdtools7 \u0026amp;\u0026amp; cd herdtools7 $ git checkout 7.49 $ make all $ make install 빌드에 약 3분 10여초가 소요됐습니다. 설치가 잘 되었는지 아래와 같이 확인해 봅니다:\n$ herd7 -version 7.49, Rev: 93dcbdd89086d5f3e981b280d437309fdeb8b427 LKMM Download LKMM 은 리눅스 소스 트리의 tools/memory-model/ 디렉토리에 있습니다. https://kernel.org 에서 다운받거나 해서 사용하면 됩니다.\n$ ls ~/linux/tools/memory-model/ Documentation linux-kernel.cat linux-kernel.def lock.cat scripts linux-kernel.bell linux-kernel.cfg litmus-tests README Herd7 Based Litmus Tests Execution $ herd7 -conf linux-kernel.cfg litmus-tests/SB+fencembonceonces.litmus Test SB+fencembonceonces Allowed States 3 0:r0=0; 1:r0=1; 0:r0=1; 1:r0=0; 0:r0=1; 1:r0=1; No Witnesses Positive: 0 Negative: 3 Condition exists (0:r0=0 /\\ 1:r0=0) Observation SB+fencembonceonces Never 0 3 Time SB+fencembonceonces 0.01 Hash=d66d99523e2cac6b06e66f4c995ebb48 Klistmus7 Based Litmus Tests Execution $ mkdir klitmus_test $ klitmus7 -o klitmus_test/ litmus-tests/SB+fencembonceonces.litmus $ cd klitmus_test/ $ ls $ make $ sudo sh run.sh $ sudo sh ./run.sh [sudo] password for sjpark: Thu Nov 8 04:55:44 KST 2018 Compilation command: klitmus7 -o klitmus_test/ litmus-tests/SB+fencembonceonces.litmus OPT= uname -r=4.19.0 Test SB+fencembonceonces Allowed Histogram (3 states) 16580117:\u0026gt;0:r0=1; 1:r0=0; 16402936:\u0026gt;0:r0=0; 1:r0=1; 3016947 :\u0026gt;0:r0=1; 1:r0=1; No Witnesses Positive: 0, Negative: 36000000 Condition exists (0:r0=0 /\\ 1:r0=0) is NOT validated Hash=d66d99523e2cac6b06e66f4c995ebb48 Observation SB+fencembonceonces Never 0 36000000 Time SB+fencembonceonces 1.40 Thu Nov 8 04:55:45 KST 2018 ","permalink":"https://sjp38.github.io/posts/ko/lkmm-install/","summary":"리눅스 커널은 Formalised and executable memory consistent model 을 제공합니다. 줄여서 linux kernel memory model (LKMM) 이라고 하죠. 이 글은 4.19 버전을 기준으로 LKMM 을 실제로 수행해 보기 위한 환경 셋업 과정과 간단한 실행 방법을 정리해 봅니다. 글 작성을 위한 테스트는 Ubuntu 16.04 서버가 설치된 가상머신에서 진행되었습니다.\nherd7 install LKMM 은 버전 7.49 의 \u0026ldquo;herd7\u0026rdquo; 과 \u0026ldquo;klitmus7\u0026rdquo; 을 필요로 합니다. 하지만 herd7 은 또 Ocaml 을 위한 패키지 매니저인 OPAM 을 설치할 것을 필요로 하죠.","title":"LKMM Setup and Usage"},{"content":"제가 새 기계에서 리눅스 커널 빌드 환경을 셋업하고 실제 빌드, 설치하는 과정을 정리해 봅니다. 글 작성 과정에서 실제 커맨드를 수행한 환경은 Ubuntu 16.04.3 Server OS 를 설치한 x86_64 가상머신입니다.\nInstall Dependent Packages $ sudo apt install build-essential libncurses5-dev libssl-dev bc bison flex \\ libelf-dev 커널을 빌드하려면 컴파일러와 라이브러리 등이 필요하겠죠. 위 커맨드는 우분투에서 커널 빌드에 필요한 패키지들을 깔아줍니다. 커널 트리의 Documentation/process/changes.rst 에도 커널 빌드에 필요한 패키지들이 나열되어 있으므로, 다른 환경이라면 이를 참고해 필요한 패키지를 설치합시다.\n페도라라면 아래와 같이 패키지를 깔면 됩니다:\n$ sudo dnf install ncurses-devel bison-devel bison flex-devel flex \\ elfutils-libelf-devel openssl-devel Fetch Linux Kernel Source Code $ git clone git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git 빌드를 하려면 소스코드를 가져와야죠. 위 커맨드를 통해 토발즈의 리눅스 소스코드를 가져올 수 있습니다. 네트워크를 통해 가져오는데, 소스코드는 물론이고 개발 이력 정보를 모두 담고 있으므로 많은 데이터를 가져와야해 시간이 상당히 걸립니다. 이 글을 쓰는 2018년 9월 초 기준, 버전정보만 약 1.2 GiB 군요.\n토발즈는 github 에 [미러] (https://github.com/torvalds/linux) 를 두고 있으므로, 여길 이용하는 것도 생각해 볼 수 있고, 굳이 버전 정보는 필요하지 않다면 [kernel.org] (https://kernel.org) 에서 tarball 로 소스코드만 받는것도 한 방법입니다.\n저는 아예 .git 디렉토리를 압축해서 별도 저장소에 보관하기도 합니다.\nMake Configuration File $ cd linux $ cp /boot/config-$(uname -r) ./.config $ make menuconfig 리눅스 빌드 설정 파일을 만들어야 합니다. 앞의 커맨드를 통해 배포판에서 제공한 커널을 빌드하는데 사용된 설정 파일을 기반으로 gui 환경에서 필요한 설정을 추가/제거 할 수 있습니다. 별달리 변경할 게 없다면 그냥 저장하고 나오면 됩니다.\n저는 빌드에 많은 시간이 걸리지 않고 저장 공간이 큰 시스템에서는 이 방법을 사용하고, 작은 가상머신 등의 환경에서는 localmodconfig 빌드 타겟을 사용해 가벼운 설정 파일을 만드는 편입니다.\nSeperated Build Directory 이렇게 빌드를 하면 컴파일된 파일들이 소스코드와 같은 디렉토리에 위치하게 되는데, grep 등을 할때 성가시고, 실수로 git 에 이렇게 만들어진 파일들을 추가하는 실수도 흔합니다. 리눅스 커널 빌드 시스템은 make 커맨드에 O 옵션을 제공하는데, 이 옵션의 인자로 빌드 디렉토리를 지정할 수 있습니다. 빌드 과정에서 만들어진 파일들은 이 디렉토리로 저장되므로, 소스코드 디렉토리를 깨끗하게 유지할 수 있습니다. 예를 들어 /foo 라는 디렉토리에 빌드 과정에서 만들어진 파일을 저장하고 싶다면 다음과 같습니다.\n$ make O=/foo menuconfig Build $ make -j $(grep \u0026#34;^processor\u0026#34; /proc/cpuinfo | wc -l) 이 커맨드는 리눅스 커널을 빌드합니다. 이 때 뒤의 -j 옵션을 통해 빌드 과정 작업을 한순간에 최대 몇개까지 수행해도 되는지 지정해주는데, 이 커맨드에선 빌드를 수행하는 시스템에 장착된 논리적 코어의 갯수를 줬습니다. 커널 빌드엔 긴 시간이 걸립니다. 프로세서 3개를 준 제 가상머신에서는 12분 30초 정도 걸렸군요. 이것도 localmodconfig 를 해줬기 때문이고, 이런저런 모듈 다 빌드하라고 했다면 훨씬 많이 걸렸을 겁니다.\nInstall $ sudo make modules_install install 이 커맨드는 빌드한 모듈들과 커널 자체를 설치합니다. 커널 빌드 시스템은 이 과정에서 가장 최신의 커널로 grub 의 디폴트 부트 대상도 바꿔줍니다. 이제 기계를 껐다 켜되, grub 등에서 부트할 커널 버전을 해당 버전으로 선택하면 빌드한 커널로 부팅됩니다. 현재 시스템이 사용중인 커널의 버전은 uname -r 로 알 수 있습니다.\nConclusion 이상으로 Ubuntu 16.04.3 을 기본으로 리눅스 커널을 빌드하고 설치하는 방법을 알아봤습니다. 총 일곱개의 커맨드 뿐. 쉽죠?\n","permalink":"https://sjp38.github.io/posts/ko/linux-kernel-build/","summary":"제가 새 기계에서 리눅스 커널 빌드 환경을 셋업하고 실제 빌드, 설치하는 과정을 정리해 봅니다. 글 작성 과정에서 실제 커맨드를 수행한 환경은 Ubuntu 16.04.3 Server OS 를 설치한 x86_64 가상머신입니다.\nInstall Dependent Packages $ sudo apt install build-essential libncurses5-dev libssl-dev bc bison flex \\ libelf-dev 커널을 빌드하려면 컴파일러와 라이브러리 등이 필요하겠죠. 위 커맨드는 우분투에서 커널 빌드에 필요한 패키지들을 깔아줍니다. 커널 트리의 Documentation/process/changes.rst 에도 커널 빌드에 필요한 패키지들이 나열되어 있으므로, 다른 환경이라면 이를 참고해 필요한 패키지를 설치합시다.","title":"Linux Kernel Build"},{"content":"크롬북을 구매했습니다. 구매 결정 과정부터 사용기까지 내용을 정리해볼까 합니다. 이번 글에서는 크롬북을 구매하기까지의 고민과 과정을 정리합니다.\n기본적으로 저는 글을 읽는걸 좋아하기도 하고 읽어야만 하기도 합니다. 그러다보니 여행을 가더라도 항상 어떤 책을 들고갈까 고르는게 설레기도 하지만 짜증나기도 하고, 마음만 앞서서 캐리어 무게를 책으로 꽉 채우기도 합니다. 그래서 예전부터 이북을 고려해 봤지만 너무 반응속도가 느리기도 하고 인쇄된 것에 비해선 가독성도 떨어지고 그 특유의 책을 넘겨가며 보는 반응은 아닌 것 같아 구매하지 않고 있었습니다. 하지만 슬슬 매번 책을 들고 다니는게 오히려 불편하다는 생각이 점점 늘어나고 있었습니다.\n한편으로는 랩톱만 들고 다니기에는 불편하다는 생각이 들었습니다. 저는 구글 핵페어에 출품을 하면서 넥서스7 1세대와 2세대를 얻게 되어 이 기기들을 사용해 왔습니다. 태블릿의 휴대성은 랩톱과 비교할 수 없는 것이었습니다. 특히 넥서스7 2세대는 해상도가 높아져 글을 읽기에도 편리했습니다. 다만, 7인치의 좁은, 특히 가로대비 세로가 매우 짧게 비디오에 특화된 화면비율은 많이 불편했습니다. 그래도 침대위 인터넷에는 쓸만했는데 작년 프라하에서 숙소에서 떨어뜨렸고, 디스플레이에 금이 가고 터치가 먹통이 되었습니다.\n있을 땐 그렇게 소중한지 몰랐지만 7인치짜리라도 태블릿이 없어지니 랩톱의 불편이 느껴졌습니다. 특히, 컨퍼런스 등에 가서 책상이 없는 자리에 앉을 때, 전원 플러그가 없을때 그렇습니다. 전력 등을 고려해 안쓰고 있을 때엔 랩톱을 닫고 있어야 하는데, 발표를 듣다가 뭔가 흥미로운 사이트 소개 등이 있어 잠시 인터넷을 하고 싶을때 랩톱을 열어야 합니다. 열고 나면 패스워드를 입력하거나 지문 인식을 해야 하는데, 이 짧은 인터럽트가 매우 불쾌하고 생각의 흐름을 끊어버립니다.\n한편, 최신 태블릿과 아이패드들을 만져보니 많이 발전되었다는 생각이 들었습니다. 그래서 하나 사는게 좋겠다 싶어 물건들을 알아보았습니다. 하지만 동시에 단점도 많이 눈에 띄더군요.\n요구사항 가격은 30만원선을 원합니다. 40을 넘어가면 지갑이 버티지 못합니다.\n랩톱과 함께 쓸만한 서브 디바이스를 원합니다. 따라서 커널을 빌드하거나 할 생각은 없으니 컴퓨팅 파워는 크게 중요하지 않습니다. 저장공간도 너무 클 필요 없습니다. 인터넷만 원활한 정도면 되겠습니다.\n책을 보고 싶고, 특히 논문도 볼 수 있길 바라기 때문에 화면이 크고 해상도가 높아야 합니다. 가로 비율이 너무 길어서 비디오에만 최적화 되어 있는 화면은 원치 않습니다. 적당한 pdf 뷰어도 지원이 되어야 합니다.\n오픈소스 운영체제로 돌아가는 기기면 좋겠습니다. 커널은 리눅스여야 합니다. 업스트림 커널을 설치할 수 있어 커널 테스트용으로 사용할 수 있다면 가산점이 크게 올라갑니다. 사실 가장 원하는건 데비안이나 우분투, 페도라 등이 깔린 리눅스 순정 태블릿이지만 적당한 기기가 없어 보입니다.\n리눅스 셸이 제공되면 좋겠습니다. 사실상 거의 모든 일을 거기서 할 수 있습니다.\n아이패드 결코 살 수 없습니다. 폐쇄성 때문입니다. 사용자 레벨에서도 폐쇄적이지만 독점 소프트웨어로 돌아가는 기기를 사고 싶지 않았습니다.\n안드로이드 태블릿 안드로이드 태블릿은 하이엔드 제품의 경우 아이패드와 비슷한 성능이고, 일단은 오픈소스인 안드로이드 운영체제를 사용하고 있습니다. 리눅스 커널 기반이고, 수많은 안드로이드 앱중에는 적절한 pdf 뷰어 앱도 있습니다. Termux 등을 사용하면 셸도 원활하게 사용할 수 있습니다. 업스트림 리눅스 커널을 직접 빌드해 설치하려면 까다롭긴 하지만 불가능한 것도 아니긴 합니다.\n한가지 치명적인 건 운영체제 업데이트가 원활치 않아 보이는군요. 가격을 생각해야 하니 나온지 오래된 모델들을 알아봤는데 하나같이 운영체제 업데이트가 되지 않고 있는 듯 했습니다.\n크롬북 그렇게 이번에도 아이쇼핑만 하고 그만두려던 차에 크롬북이 눈에 들어왔습니다. 크롬북은 안드로이드보다 훨씬 개방적인 정책을 취한 오픈소스 운영체제인 크롬 OS 를 사용하고 있습니다. 리눅스 커널 기반이고, 최근들어 안드로이드 앱과 리눅스 네이티브 앱을 공식 지원하고 있습니다. 구글 정책상 대부분의 크롬 OS 디바이스가 최신 OS로 업데이트 됩니다. 과거에 잠시 셋업만 해봤는데 crouton 등을 사용하면 Ubuntu 등의 리눅스 배포판을 설치할 수 있고 Chrome OS 와의 전환도 키 하나만 누르면 되어서 매우 간편했던 기억이 있습니다. 문제라면 폼팩터가 랩톱의 폼팩터라는 것인데, 요즘 나오는 크롬북은 디스플레이를 360도 전환할 수 있어 태블릿 모드와 텐트 모드를 사용할 수 있는 제품이 대부분입니다. 가격도 매우 저렵한게 특징입니다.\n이거다 싶었습니다!\n크롬북 플러스 그렇게 크롬북 모델들을 찾아보니 삼성 크롬북 플러스[1] 가 눈에 들어왔습니다. 12.3인치 화면에 2400x1600 해상도. 책 읽기에 딱 적절해 보입니다. 스타일러스 펜도 있고, 6코어 프로세서는 ARM 프로세서지만 제게는 차고 넘쳐 보이더군요. 한가지 걸리는건 브랜드와 가격. 삼성에 대해 안좋은 인식이 있습니다. 그리고 가격이 약 450 달러. 한국에서 사려면 대략 50만원을 넘습니다. 40만원 미만을 원하던 걸 생각하면 가격이 조금 셉니다.\n최종 구입 혹시나 하고 아마존에서 크롬북 프로 검색을 해봤습니다. 중고 모델은 350불 정도 하는군요. 어차피 보조 디바이스라 중고인건 괜찮은데 가격이 여전히 좀 그렇군요. 망설이며 며칠을 보내다가 새로고침을 해보니 가격이 250불이 되어 있었습니다. 아마존은 이런식으로 핫딜이 있다고 하는군요. 이때가 아니면 언제 지르랴, 하고 질렀습니다.\n[1] https://www.samsung.com/us/computing/chromebooks/12-14/xe513c24-k01us-xe513c24-k01us/\n","permalink":"https://sjp38.github.io/posts/ko/chromebook-plus-purchase/","summary":"크롬북을 구매했습니다. 구매 결정 과정부터 사용기까지 내용을 정리해볼까 합니다. 이번 글에서는 크롬북을 구매하기까지의 고민과 과정을 정리합니다.\n기본적으로 저는 글을 읽는걸 좋아하기도 하고 읽어야만 하기도 합니다. 그러다보니 여행을 가더라도 항상 어떤 책을 들고갈까 고르는게 설레기도 하지만 짜증나기도 하고, 마음만 앞서서 캐리어 무게를 책으로 꽉 채우기도 합니다. 그래서 예전부터 이북을 고려해 봤지만 너무 반응속도가 느리기도 하고 인쇄된 것에 비해선 가독성도 떨어지고 그 특유의 책을 넘겨가며 보는 반응은 아닌 것 같아 구매하지 않고 있었습니다.","title":"Chromebook Plus Purchase (크롬북 플러스 구매 결정기)"},{"content":"A paper about GCMA project has accepted to a top-level computer science journal, Transactions on Computers[1]. It will be published soon.\n[1] https://www.computer.org/web/tc\n","permalink":"https://sjp38.github.io/posts/gcma_accepted_to_tc/","summary":"A paper about GCMA project has accepted to a top-level computer science journal, Transactions on Computers[1]. It will be published soon.\n[1] https://www.computer.org/web/tc","title":"The Paper about GCMA Accepted to TC"},{"content":"GCMA 에 대한 논문이 컴퓨터 과학계의 최고 수준 저널인 Transactions on Computers[1] 에 Accept 되었습니다. 조만간 이를 통해 출간될 예정입니다.\n[1] https://www.computer.org/web/tc\n","permalink":"https://sjp38.github.io/posts/ko/gcma_accepted_to_tc/","summary":"GCMA 에 대한 논문이 컴퓨터 과학계의 최고 수준 저널인 Transactions on Computers[1] 에 Accept 되었습니다. 조만간 이를 통해 출간될 예정입니다.\n[1] https://www.computer.org/web/tc","title":"The Paper about GCMA Accepted to TC"},{"content":" 최근 흥미롭게 보았던 Git Origin Story 라는 제목의 LinuxJournal.com 기사를 번역해 봅니다. 원본 기사는 https://www.linuxjournal.com/content/git-origin-story 에서 보실 수 있습니다.\n수년간 리눅스 커널 개발자들이 사용해온 다양한 리비전 컨트롤 방법, Linus Torvalds가 Bit keeper 를 사용하기로 한 결정과 그에 뒤따른 논쟁, 그리고 어떻게 Git 이 만들어졌는가에 대한 글입니다.\n처음에, Linus Torvalds는 리비전 컨트롤을 아예 사용하지 않았습니다. 커널에 코드를 기여하고자 하는 사람은 Usenet 그룹에, 나중에는 메일링 리스트에 패치를 올렸고, Linus는 자신의 소스 트리에 그걸 적용했습니다. 나중에 Linus는 릴리즈를 통해 패치들 사이의 구분 없이 전체 소스 트리를 공개하는 식이었습니다. Torvalds의 작업 이력을 알아낼 수 있는 유일한 방법은 전체 릴리즈 버전 사이의 거대한 diff 를 통하는 것 뿐이었습니다.\n이는 오픈소스 리비전 컨트롤 시스템이 없기 때문은 아니었습니다. 1980년대부터 CVS 가 있었고, 그 당시에도 가장 유명한 시스템이었습니다. 그 핵심 기능을 사용해서 기여자들이 패치를 중앙 저장소에 보낼 수 있었고 그 저장소로 들어가는 패치의 기록을 조사할 수 있었습니다.\n하지만 CVS 에 대한 많은 불만이 있었습니다. 그 중 하나는 변경 사항을 파일별로 제공하고 커다란 패치는 하나의 버전으로 인식할 수 없어서, 다른 개발자들로부터의 과거의 기여를 해석하기가 어려웠습니다. 또한, 두개의 같은 파일을 수정하는 패치가 동시에 보내졌을 때 발생하는 레이스 컨디션 같은 고치기 어려운 버그들도 일부 있었습니다.\nLinus는 CVS 를 좋아하지 않았는데, 부분적으로는 다른 사람들의 불만과 같은 이유 때문이었고 부분적으로는 후에야 명확해진 그만의 이유 때문이었습니다. 그는 CVS 의 버그와 이상한 기능들을 해결하려는 목표를 가지고 2000년대 초부터 발전되어온 오픈소스 프로젝트인 SVN 도 좋아하지 않았습니다.\n많은 리눅스 커널 개발자들이 적당한 리비전 컨트롤의 부재에 불만족스러 했으며, 따라서 Linus가 사용 가능한 리비전 컨트롤 중에서 뭐든 하나를 고르길 바라는 커뮤니티로부터의 압력이 항상 있었습니다. 그리고, 2002년, Linus는 그렇게 했습니다. 충격적이고 당황스럽게도, Linus는 Larry McVoy 에 의해 운영되는 BitMover 라는 회사에 의해 개발된, 소스코드가 공개되어있지 않은 상업용 시스템인 BitKeeper 를 선택했습니다.\n리눅스 커널은 역사상 가장 중요한 오픈소스 프로젝트였고, Linus 그 스스로가 수십년간 다른 오픈소스 프로젝트들이 따라하게 되었고 지금까지도 그렇게 하고 있는 오픈소스 개발 방법을 처음으로 발견한 사람이었습니다. Linus가 무슨 생각을 하는 거지? 어떻게 그가 그의 커뮤니티와 오픈소스 세계를 이렇게 배신할수가 있지? 이게 Linus가 처음 커널 개발에 BitKeeper 를 사용했을 때 대부분의 반응이었습니다.\n또한, BitMover 는 돈을 받지 않고 BitKeeper 를 사용할 수 있는 라이센스를 제공하는데 대한 대가로 리눅스 커뮤니티에 제한을 걸었습니다. 첫째, 리눅스 개발자들은 BitKeeper 를 사용하는 동안 다른 경쟁 리비전 컨트롤 시스템 개발 프로젝트에 참여할 수 없었습니다. 둘째, BitMover 는 라이센스에 대한 악용을 막기 위해 커널 프로젝트에 관계된 일부 메타데이터를 제어할 수 있었습니다. 이 메타데이터에 대한 접근이 불가능하면, 커널 개발자들은 다른 리비전 컨트롤 시스템에서의 중요한 표준적 기능인, 과거의 커널 버전들 사이의 비교를 할 수 없었습니다.\nLinus가 BitKeeper 를 사용한지 수년이 지나도 논쟁은 줄어들지 않았습니다. 그의 기본적 주장은, 그는 프리 소프트웨어 (Free Software) 광신도가 아니라는 것이었습니다. 그는 오픈소스 도구들이 같은 일을 하는 상업용 도구들에 비해 낫다면 그걸 사용할 거라고 했습니다. 하지만 상업용 도구가 더 낫다면, 그는 다른 도구를 고려하지 않을 거라고요.\n하지만, 많은 커널 개발자들이 실제로 프리 소프트웨어 광신도였습니다. 커뮤니티에 손상을 입히고 리눅스 커널 프로젝트의 fork 를 일으킬 만큼은 아니지만 Linus와 다른 개발자들간의 분노와 긴장이 심해졌습니다. Alan Cox, Al Viro, David Miller, Andrea Arcangeli, Andrew Morton 과 많은 수의 다른 사람들이 경쟁 프로젝트를 이끌만한 기술력을 가지고 있음이 분명했고, 심지어 일부는 상당수 커널 개발자들을 그들 쪽으로 끌어갈 명성을 가지고 있었습니다. 하지만 아무도 그러지 않았습니다. 이 긴장과 적대는 계속 유지되었습니다.\nBitKeeper 의 무엇이 그리 대단했을까요? BitKeeper 에서 자랑한 건 분산시스템을 제공한다는 것으로, 모든 저장소가 쉽게 fork 되고 merge 될 수 있었습니다. 이게 핵심이었습니다. 이를 통해, 특정 하위 그룹의 커널 개발자들은 리비전 컨트롤의 이득을 얻으면서 그룹끼리 독자적으로 협업하고, 준비된 다음에 그들의 변경 사항을 Linus에게 전달할 수 있었습니다. 이를 통해, 전에는 Linus 한명의 어깨에 완전히 매여있던 수많은 작업이 Linus가 믿는 개발자들, 또는 그렇게 작업하기로 한 그룹들에게 분산될 수 있었습니다. 아키텍쳐별 코드, 드라이버, 그리고 커널의 하위 시스템들이 모두 어떻게든 독립적으로 개발되고, 이후 적절한 시점에 한번에 메인 커널에 병합될 수 있었습니다.\n슬슬 하는 이야기가 익숙하게 들릴 겁니다만, 2002년에 이건 새로운 아이디어였습니다. CVS 와 Subversion 같은 당시 존재하던 프로젝트들에서 fork 와 merge 는 주인만 할 수 있고, 죽고 싶도록 시간이 오래 걸리는 작업이었습니다. BitKeeper 를 통해, 이게 사소한 작업이 되었습니다.\n커널 개발 도구의 핵심부에 독점 소프트웨어를 사용하려는 Linus의 의지는 많은 사람들이 대안을 만드는데 더욱 노력하게 만들었습니다. CVS 와 Subversion 프로젝트는 너무 많은 기초적 설계 오류가 있었고, 이미 너무 많이 개발이 진행되어 변경하기가 쉽지 않았습니다. 다른 프로젝트들 모두 마찬가지였습니다. 하지만 이제 그들은 Linus가 정말 원하는걸 알거나 안다고 생각했으므로, 정말로 코딩을 시작할 수 있었습니다. 그 결과 분산 개발 기능을 제공하는 많은 수의 리비전 컨트롤 시스템이 나왔습니다.\n그런 시스템들 중에 arch, darcs, 그리고 monotone 등이 있었습니다. 그들은 Bitkeeper 를 경쟁 상대라고 함으로써, Linus가 Bitkeeper 에 대한 대안으로 그들을 선택하라고 설득했습니다.\n많은 사람들이 시도했지만, 아무도 성공하지 못했습니다. 이는 부분적으로는 Linus가 CVS 와 Subversion 에 뭐가 빠져있는지 모두 이야기 하지 않았듯, 그 프로젝트들에 Linus가 더 필요로 하는 것이 무엇인지 모두 말하지 않았기 때문입니다. 그리고, Linus가 소스가 폐쇄된 도구를 사용하는것도 개의치 않는 것 같았으므로, 어떤 대안이 그에게 받아들여질만 하려면 그 대안은 BitKeeper 보다 훨씬 기술적으로 향상되어 있어야만 할 것이었습니다. 따라서, BitKeeper 전에도 오픈소스 툴의 기능은 충분하지 않았지만, BitKeeper 가 나타남으로써 오픈소스 툴이 맞춰야 할 기능의 목표가 더욱 높아진 셈입니다.\n수년간의 많은 노력 후에도, 어떤 오픈소스 대안도 Linus의 필요를 맞추기엔 CVS 나 Subversion 보다도 크게 나아지지 못했습니다. 만약 Samba 를 만들었고 rsync 의 공동 창시자인 Andrew Tridgell 이 아니었더라면 이 상황은 훨씬 오래 지속될 수 있었을 겁니다. 2005년, Andrew는 프리 소프트웨어인 대안을 만들기 위해 BitKeeper 네트워킹 프로토콜을 리버스 엔지니어링 하려 했습니다. 그가 아니었더라도, 누군가는 시도했을 겁니다 - 그건 그저 시간 문제였습니다. Larry McVoy 는 누구든 이 시도를 했다면 당장 지원을 끊겠다고 리눅스 개발자들에게 경고했고, 실제로 그렇게 했습니다. 결국, 급작스럽게 BitKeeper 를 커널 개발에 사용될 수 없게 되었습니다. 전체 개발 도구와 분산 버전 컨트롤로부터 생겨난 개발 문화는 앞날을 알 수 없는 상황에 놓였습니다.\n이게 무슨 의미일까요? Linus는 그의 과거 방식의 개발로 돌아가서 모든 패치를 그 자신에게 보내라고 했을까요? 그렇지 않다면, BitKeeper 의 오픈소스 대안들 가운데 하나를 선택했을까요? 만약 그가 그랬다면, 어떤 대안을 골랐을까요?\n이 시점에서, 놀라운 일이 발생했습니다. Linus가 리눅스 커널 개발을 1991년 시작한 후 처음으로 작업을 완전히 멈췄습니다. 현존하는 어떤 도구도 그가 원하는 일을 해주지 못했으므로, 그는 자신의 것을 만들기로 결정했습니다.\nLinus의 주요 관심은, 사실 속도였습니다. 이것이 그가 기존에는 완전히, 적어도 현존하는 프로젝트들이 이해할 수 있는 방식으로는 이야기하지 않은 부분이었습니다. 전세계에서 전력을 다해 패치를 보내오는 수천명의 커널 개발자들을 위해, 그는 기존에는 상상할 수 없는 속도로 동작하는 무언가가 필요했습니다. 그는 가장 거대하고 가장 복잡한 작업이라 해도 완료하는데 몇초 이상 기다리는 걸 참을 수 없었습니다. Arch 도, darcs, monotone 도, 그리고 어떤 다른 프로젝트도 이 요구사항을 맞추지 못했습니다.\nLinus는 잠시 은둔한 채 코딩을 했고, 그 후에 그의 새로운 계획을 세상에 알렸습니다. 2005년 6월에 그 프로젝트를 시작한 이래 몇일만에, Linus의 git 리비전 컨트롤 시스템은 git 소스코드의 리비전 컨트롤을 완전히 할 수 있게 되었습니다. 몇주 후, git 은 리눅스 커널 개발의 리비전 컨트롤을 맡을 준비가 되었습니다. 몇달 후, 완전한 기능을 갖추었습니다. 이 시점에서, Linus는 이 프로젝트의 관리 권한을 해당 프로젝트의 가장 열정적인 기여자, Junio C. Hamano 에게 넘기고 리눅스 개발에 다시 전념했습니다.\n이 도구에 놀란 프리 소프트웨어 개발자 커뮤니티는 이 괴상한 작업물을 이해하려 노력했습니다. 이것은 리비전 컨트롤 소프트웨어의 어떤 것도 닮지 않았습니다. 사실, 이것은 리비전 컨트롤 시스템보다는 낮은 단계의 파일시스템 오퍼레이션들의 집합에 가까워 보였습니다. 그리고 다른 시스템들이 패치를 저장하는 것과 달리, 이것은 각각의 변경된 파일의 버전을 모두 저장했습니다. 어떻게 이런 방식이 괜찮을 수 있을까요? 하지만, 이 도구는 fork 와 merge 를 번개같은 속도로 처리할 수 있고, 패치를 요청하자마자 만들어낼 수 있었습니다.\n점진적으로, Junio는 CVS 와 Subversion 의 것들을 닮은 높은 수준의 커맨드 집합을 만들었습니다. Git 의 원래 커맨드들이 \u0026ldquo;배관\u0026rdquo; 이었다면, 새로운 커맨드들은 \u0026ldquo;도자기 제품\u0026rdquo; 이었습니다. 그리고, 결국 사용되게 되었습니다.\nBitKeeper 에 대한 논쟁과 분노가 있었던 만큼이나, git 의 계속된 개발을 향한 열망과 참여 의지가 많았습니다. 포팅, 확장 기능, 그리고 웹사이트들이 모든 것을 현재 상태로 끌어올렸습니다. 몇년만에, 거의 모든 사람들이 git 을 사용하게 되었습니다. 리눅스처럼, git 이 세상을 집어삼켰습니다.\n","permalink":"https://sjp38.github.io/posts/ko/git_origin_story_ko/","summary":"최근 흥미롭게 보았던 Git Origin Story 라는 제목의 LinuxJournal.com 기사를 번역해 봅니다. 원본 기사는 https://www.linuxjournal.com/content/git-origin-story 에서 보실 수 있습니다.\n수년간 리눅스 커널 개발자들이 사용해온 다양한 리비전 컨트롤 방법, Linus Torvalds가 Bit keeper 를 사용하기로 한 결정과 그에 뒤따른 논쟁, 그리고 어떻게 Git 이 만들어졌는가에 대한 글입니다.\n처음에, Linus Torvalds는 리비전 컨트롤을 아예 사용하지 않았습니다. 커널에 코드를 기여하고자 하는 사람은 Usenet 그룹에, 나중에는 메일링 리스트에 패치를 올렸고, Linus는 자신의 소스 트리에 그걸 적용했습니다.","title":"Git Origin Story in Korean"},{"content":"라즈베리 파이를 메인 컴퓨터로 사용하려는게 아니라면, 라즈베리 파이에 모니터와 키보드, 마우스를 연결하고 사용하는게 아무래도 번거롭습니다. ssh 로 붙어서 작업하는 것도 한 방법이지만, 그게 여의치 않은 상황도 있습니다. 그저 터미널만 연결되면 되는 상황이라면, 가장 간단한 건 UART Serial 통신을 사용하는 겁니다.\n라즈베리 파이는 UART 통신을 지원하고 있는데, GPIO 핀 중 14번과 15번이[2] 각각 TX, RX 입니다. 호스트 컴퓨터와 이 두개의 핀을 연결하면 UART 통신을 할 수 있어서 라즈베리 파이의 터미널에 바로 접근할 수 있습니다.\n호스트 머신에 핀을 연결하는게 번거로울 수 있는데, 시리얼-USB 젠더를 여기저기서 저렴한 가격에 팝니다[1]. 이걸 이용해 TX/RX 핀을 라즈베리 파이의 GPIO 14, 15번에 각각 연결하고 USB 를 호스트 머신에 연결합니다.\n이제 호스트 머신의 /dev/ 디렉토리에 ttyUSB 로 시작하는 파일이 생겼을 겁니다. 제 경우 ttyUSB0 라는 이름의 파일이 생겼군요. 이제, 시리얼 통신 프로그램인 minicom 을 사용해서 이 포트로 연결해서 UART 통신을 합시다:\n$ sudo minicom -D /dev/ttyUSB0 이제 라즈베리 파이를 부팅 시키면 부팅 로그부터 터미널에 나오고, 로그인 화면까지 뜹니다.\n라즈베리파이3 시리얼 문제와 해결법 하지만, 라즈베리 파이 3 에서는 내장으로 블루투스와 WiFi 가 들어가면서 GPIO 핀이 겹치게 되어 앞의 과정만으로는 시리얼 통신을 할 수 없습니다. 블루투스를 끄고 시리얼을 켜줘야 합니다.\n먼저, 다음과 같이 /boot/config.txt 파일에 다음 두줄을 추가합니다:\n$ sudo echo \u0026#34;enable_uart=1\u0026#34; \u0026gt;\u0026gt; /boot/config.txt $ sudo echo \u0026#34;dtoverlay=pi3-miniuart-bt\u0026#34; \u0026gt;\u0026gt; /boot/config.txt 그리고 /boot/cmdline.txt 를 열어서 console=tty1 이라는 내용을 추가해줍니다.\n준비가 끝났습니다. 재부팅 하면 minicom 에 라즈비안 콘솔이 연결됩니다.\n[1] https://www.devicemart.co.kr/29565\n[2] https://www.raspberrypi.org/documentation/usage/gpio/\n","permalink":"https://sjp38.github.io/posts/ko/rasp3-serial/","summary":"라즈베리 파이를 메인 컴퓨터로 사용하려는게 아니라면, 라즈베리 파이에 모니터와 키보드, 마우스를 연결하고 사용하는게 아무래도 번거롭습니다. ssh 로 붙어서 작업하는 것도 한 방법이지만, 그게 여의치 않은 상황도 있습니다. 그저 터미널만 연결되면 되는 상황이라면, 가장 간단한 건 UART Serial 통신을 사용하는 겁니다.\n라즈베리 파이는 UART 통신을 지원하고 있는데, GPIO 핀 중 14번과 15번이[2] 각각 TX, RX 입니다. 호스트 컴퓨터와 이 두개의 핀을 연결하면 UART 통신을 할 수 있어서 라즈베리 파이의 터미널에 바로 접근할 수 있습니다.","title":"Raspberry Pi 3 Serial Connection"},{"content":"OSSE 2016 에서 받아온 라즈베리 파이3 셋업을 해봅니다. 셋업에 사용된 호스트 환경은 Ubuntu 16.04 데스크탑입니다.\n라즈베리 파이는 SD 카드를 저장소로 사용합니다. 따라서 여기에 운영체제를 깔아야 합니다. 다만, 라즈베리 파이를 구매하면 SD 카드는 따라오지 않습니다. 각자 알아서 사야 합니다. 전 예전에 사둔 16 GiB 짜리 SD 카드를 사용하겠습니다.\n라즈베리 파이를 지원하는 운영체제는 여러가지 있는데, 데비안 계열의 Raspbian 이 공식 운영체제입니다. 다운로드 페이지 에서 Raspbian stretch lite 를 다운받고 압축을 풀어줍니다.\n$ ls 2018-06-27-raspbian-stretch-lite.zip $ unzip 2018-06-27-raspbian-stretch-lite.zip Archive: 2018-06-27-raspbian-stretch-lite.zip inflating: 2018-06-27-raspbian-stretch-lite.img $ ls 2018-06-27-raspbian-stretch-lite.img 2018-06-27-raspbian-stretch-lite.zip 압축 파일이 350 MiB, 압축 푼 이미지는 1.8 GiB 나 하는군요.\n이제 요걸 SD 카드에 써야하는데요, 일단 SD 카드를 데스크탑에 연결하고, df 명령을 이용해 이게 어떤 디바이스 파일로 인식되었는지 봅시다:\n$ df -h Filesystem Size Used Avail Use% Mounted on udev 7.8G 0 7.8G 0% /dev tmpfs 1.6G 174M 1.4G 11% /run /dev/sda1 222G 127G 84G 61% / tmpfs 7.8G 161M 7.7G 3% /dev/shm tmpfs 5.0M 4.0K 5.0M 1% /run/lock tmpfs 7.8G 0 7.8G 0% /sys/fs/cgroup tmpfs 1.6G 68K 1.6G 1% /run/user/1000 /dev/sdb 917G 541G 330G 63% /media/sjpark/47f422d0-445f-4dfc-86ca-559b801eb9d3 /dev/sdc2 15G 4.7G 9.3G 34% /media/sjpark/f24a4949-f4b2-4cad-a780-a138695079ec /dev/sdc1 56M 24M 33M 42% /media/sjpark/boot 제가 사용한 SD 카드는 기존에 라즈베리파이2 모델 B+ 운영체제가 설치되어 있었습니다. /dev/sdc 로 SD 카드가 잡혔고, /dev/sdc1 으로 부팅 파티션이, /dev/sdc2 로 데이터 파티션이 잡힌 것 같군요.\n이제 마운트된 파티션들을 언마운트하고, dd 명령으로 이미지를 덮어씌웁시다:\n$ sudo umount /media/sjpark/f24a4949-f4b2-4cad-a780-a138695079ec $ sudo umount /media/sjpark/boot $ sudo dd bs=4M if=./2018-06-27-raspbian-stretch-lite.img of=/dev/sdc 444+0 records in 444+0 records out 1862270976 bytes (1.9 GB, 1.7 GiB) copied, 199.44 s, 9.3 MB/s $ sync 처음 두개 커맨드가 언마운트를 하고, 세번째 커맨드가 이미지를 덮어씌우는 커맨드입니다. 혹시 모르니 네번째 커맨드에서 sync 해서 데이터가 확실히 씌워지게 했습니다.\n이제 라즈베리 파이의 HDMI 단자에 모니터를 연결하고 micro USB 포트에 스마트폰 충전하듯이 USB 를 연결해 전원을 인가해주면 라즈베리 파이가 라즈비안으로 부팅됩니다.\n","permalink":"https://sjp38.github.io/posts/ko/rasp3-modelb-setup/","summary":"OSSE 2016 에서 받아온 라즈베리 파이3 셋업을 해봅니다. 셋업에 사용된 호스트 환경은 Ubuntu 16.04 데스크탑입니다.\n라즈베리 파이는 SD 카드를 저장소로 사용합니다. 따라서 여기에 운영체제를 깔아야 합니다. 다만, 라즈베리 파이를 구매하면 SD 카드는 따라오지 않습니다. 각자 알아서 사야 합니다. 전 예전에 사둔 16 GiB 짜리 SD 카드를 사용하겠습니다.\n라즈베리 파이를 지원하는 운영체제는 여러가지 있는데, 데비안 계열의 Raspbian 이 공식 운영체제입니다. 다운로드 페이지 에서 Raspbian stretch lite 를 다운받고 압축을 풀어줍니다.\n$ ls 2018-06-27-raspbian-stretch-lite.","title":"Raspberry Pi 3 Model B Setup"},{"content":"리눅스 커널의 개발은 커뮤니티 주도입니다. 개발의 한 부분인 테스트 역시 커뮤니티 주도적입니다. 여러 개인 또는 단체가 커널을 각자의 방식으로 테스트 하고 그 결과를 공유합니다. 인텔에서는 0-day 서비스[1] 라는 서비스를 자체적으로 돌리는데, 이 서비스는 최신 리눅스 커널을 가져다가 빌드하고 다양한 기능 / 성능 테스트를 돌리고 그 결과 발견된 regression 을 LKML 에 메일로 보내주는 일을 합니다. 말하자면 Continuous Integration (CI) 이죠.\nLinux Kernel Performance (LKP) Tests[2] 는 0-day 서비스에서 기능 / 성능 테스트를 수행하는데 사용되는 도구입니다. 다양한 테스트를 돌리기 위한 시스템 환경 구성, 테스트 프로그램과 그 종속 프로그램 / 라이브러리의 설치와 환경 구성, 테스트 수행과 결과 정리, 그리고 테스트 진행 사이의 시스템 상태 프로파일링 및 프로파일링 결과 정리를 대신해 줍니다. 0-day 서비스에 연결되어 있지만 lkp-tests 와 0-day 서비스 사이의 종속성이 없으며, 오픈소스 프로젝트로 개발이 진행되고 있어 그 소스코드를 누구나 사용할 수 있으며 개인이 사용하기에도 편리하게 되어 있어서 개인 개발자가 자신의 패치를 테스트할 목적으로 사용하기에도 좋습니다. 이 글에서는 이러한 lkp-tests 의 구조와 사용법을 간단히 설명합니다. 전체적으로 인텔의 관련 블로그 글[3] 을 참고했습니다.\n설치 먼저 다음 커맨드로 lkp-tests 소스코드를 얻어옵니다:\n$ git clone https://github.com/intel/lkp-tests $ cd lkp-tests 그리고 lkp-tests 자체를 설치.\n$ sudo make install 이 커맨드는 단순히 지금 소스코드를 땡겨온 lkp-tests 소스코드 디렉토리의 bin/lkp 파일을 링크하는 /usr/local/bin/lkp 심볼릭 링크를 만들 뿐입니다. 따라서 셸에서 lkp 커맨드를 쓸 수 있게 해주죠. 이 lkp 파일이 결국 lkp-tests 의 대부분의 일을 해주는 핵심 커맨드입니다. 이 프로그램의 간단한 사용법은 다음과 같이 확인할 수 있습니다:\n$ lkp Usage: lkp \u0026lt;command\u0026gt; [options] INSTALLATION install JOB install binary dependencies for JOB JOB split JOB split JOB matrix compile JOB compile JOB into shell script TESTING run JOB run test JOB locally qemu JOB run test JOB in QEMU virtual machine RESULT result|rt|_rt|__rt PATTERNs show result dirs ls|ll PATTERNs ls result dirs rm-path result remove result dirs _rm PATTERNs remove _result dirs stat [options] show result stats compare [options] compare result stats DEBUG irb run irb with lib/*.rb loaded pry run pry with lib/*.rb loaded More commands can be found in /home/sjpark/lkp-tests/{bin,sbin,tools}/ 여기서 \u0026lt;command\u0026gt; 는 lkp-tests 소스코드 디렉토리 아래 bin/, sbin/, tools/, 또는 lkp-exec/ 아래 위치한 실행파일로, lkp 는 단순히 그 실행파일을 수행하면서 인자를 넘길 뿐입니다.\n테스트에 필요한 소프트웨어 설치 다음 커맨드는 lkp-tests 가 의존하고 있는 기본적 소프트웨어 패키지들을 모두 설치합니다:\n$ sudo lkp install Ubuntu 16.04 에서는 다음 패키지들을 까는군요:\nbc gawk gzip kmod time automake bison bsdtar build-essential bzip2 ca-certificates cpio fakeroot flex gcc git libc6-dev libc6-dev:i386 libklibc-dev libtool linux-libc-dev linux-libc-dev:i386 linux-tools-generic make openssl patch rsync ruby ruby-dev wget lkp-tests 내부 벤치마크 실행 이제 lkp-tests 에서 지원하는 벤치마크를 실제로 돌려봅시다.\n테스트 수행에 필요한 환경 설정 실제 테스트를 돌리기 위해선 벤치마크를 깔고, 그 벤치마크가 사용하는 패키지를 깔고, 테스트에 사용될 도구들을 깔고, 여러 설정을 하는등의 작업이 필요합니다.\n다음 명령은 lkp-tests 에서 ebizzy 라는 벤치마크를 사용하는 테스트를 위해 필요한 프로그램들을 설치하고 수행 환경을 준비합니다.\n$ sudo lkp install jobs/ebizzy.yaml job lkp-tests 에서 테스트 수행의 기본 단위는 job 이라고 이야기 하는데, jobs/ 디렉토리 아래에 각 job 을 설명한 yaml 파일이 있습니다. 위의 커맨드에서 인자로 넣은 ebizzy.yaml 은 ebizzy 를 사용한 테스트에 필요한 사항들이 들어있습니다. 이 커맨드는 내부적으로 이 테스트에 필요한 패키지를 설치하고 ebizzy 벤치마크도 소스코드를 인터넷에서 받아다가 컴파일해 설치합니다.\nJob 파일은 또한 해당 테스트가 어떤 시스템 환경들에서 어떤 벤치마크를 어떤 인자를 줘가며 수행해야할지 등에 대한 내용을 담고 있습니다. 예컨대 jobs/aim7-fs-1brd.yaml job 은 xfs, ext4, btrfs, f2fs 파일 시스템 각각에 대해 aim7 을 돌려보도록 되어 있습니다.\n테스트 수행 다음 명령은 ebizzy job 으로 기술된 테스트를 실제 수행시킵니다:\n$ sudo lkp run jobs/ebizzy.yaml job 쪼개기 ebizzy.yaml 은 시스템 소유 CPU 코어 갯수 2배 갯수의 쓰레드를 사용해 ebizzy 를 10초간 돌리는 실험을 100번 반복하도록 되어 있습니다. 즉, 실험의 경우의 수가 하나입니다. 그러나, 앞서 설명한 aim7-fs-1brd 와 같이 다양한 구성을 사용하게 되어 있는 경우, 한가지 구성에 대해서만 반복 실험을 하고 싶을 수 있을 겁니다. 이런 경우 다음 명령으로 job 을 쪼갤 수 있습니다:\n$ sudo lkp split jobs/ebizzy.yaml 이 커맨드는 인자로 넣은 job 파일을 쪼개서 현재 디렉토리에 쪼개진 job 파일들을 저장합니다. 어떤 구성이 쪼개졌는지는 파일 이름으로 볼 수 있습니다. ebizzy.yaml 을 쪼개면 ebizzy-200%-100x-10s.yaml 라는 이름의 한개의 job 파일이 생성됩니다. 앞서 이야기한 aim7-fs-1brd.yaml 을 쪼개면 다음과 같이 많은 수의 job 이 생성됩니다:\naim7-fs-1brd-1BRD_48G-btrfs-creat-clo-4.yaml aim7-fs-1brd-1BRD_48G-f2fs-creat-clo-1500.yaml aim7-fs-1brd-1BRD_48G-btrfs-disk_cp-1500.yaml aim7-fs-1brd-1BRD_48G-f2fs-disk_cp-3000.yaml aim7-fs-1brd-1BRD_48G-btrfs-disk_rd-9000.yaml aim7-fs-1brd-1BRD_48G-f2fs-disk_rd-9000.yaml aim7-fs-1brd-1BRD_48G-btrfs-disk_rr-1500.yaml aim7-fs-1brd-1BRD_48G-f2fs-disk_rr-3000.yaml aim7-fs-1brd-1BRD_48G-btrfs-disk_rw-1500.yaml aim7-fs-1brd-1BRD_48G-f2fs-disk_rw-3000.yaml aim7-fs-1brd-1BRD_48G-btrfs-disk_src-500.yaml aim7-fs-1brd-1BRD_48G-f2fs-disk_src-3000.yaml aim7-fs-1brd-1BRD_48G-btrfs-disk_wrt-1500.yaml aim7-fs-1brd-1BRD_48G-f2fs-disk_wrt-3000.yaml aim7-fs-1brd-1BRD_48G-btrfs-sync_disk_rw-10.yaml aim7-fs-1brd-1BRD_48G-f2fs-sync_disk_rw-600.yaml aim7-fs-1brd-1BRD_48G-ext4-creat-clo-1000.yaml aim7-fs-1brd-1BRD_48G-xfs-creat-clo-1500.yaml aim7-fs-1brd-1BRD_48G-ext4-disk_cp-3000.yaml aim7-fs-1brd-1BRD_48G-xfs-disk_cp-3000.yaml aim7-fs-1brd-1BRD_48G-ext4-disk_rd-9000.yaml aim7-fs-1brd-1BRD_48G-xfs-disk_rd-9000.yaml aim7-fs-1brd-1BRD_48G-ext4-disk_rr-3000.yaml aim7-fs-1brd-1BRD_48G-xfs-disk_rr-3000.yaml aim7-fs-1brd-1BRD_48G-ext4-disk_rw-3000.yaml aim7-fs-1brd-1BRD_48G-xfs-disk_rw-3000.yaml aim7-fs-1brd-1BRD_48G-ext4-disk_src-3000.yaml aim7-fs-1brd-1BRD_48G-xfs-disk_src-3000.yaml aim7-fs-1brd-1BRD_48G-ext4-disk_wrt-3000.yaml aim7-fs-1brd-1BRD_48G-xfs-disk_wrt-3000.yaml aim7-fs-1brd-1BRD_48G-ext4-sync_disk_rw-600.yaml aim7-fs-1brd-1BRD_48G-xfs-sync_disk_rw-600.yaml 테스트 결과 확인 테스트에 사용된 벤치마크 수행의 결과와 테스트 동안의 시스템 프로파일링 결과는 /lkp/result/ 디렉토리 밑에 \u0026lt;job name\u0026gt;/\u0026lt;configuration\u0026gt;/\u0026lt;host name\u0026gt;/\u0026lt;os distribution name\u0026gt;/\u0026lt;kernel config\u0026gt;/\u0026lt;gcc version\u0026gt;/\u0026lt;kernel version\u0026gt;/\u0026lt;unique id\u0026gt; 의 계층 구조로 저장됩니다. 또한, 이 실험 결과를 parsing 할 수 있는 경우엔 .json 파일을 만들어 줘서 parsing 된 결과 값도 보여줍니다.\n또한, 최근의 테스트 결과는 테스트 돌린 디렉토리에 result/ 라는 이름의, /lkp/result/ 아래 해당 디렉토리로의 심볼릭 링크를 만들어 줍니다.\nConclusion 이렇게 lkp-tests 가 무엇인지, 그리고 어떻게 사용할 수 있는지 알아봤습니다. 이제, 리눅스 커널 개발 커뮤니티에서 사용하는 리그레션 테스트를 여러분의 환경에서도 손쉽게 돌려볼 수 있습니다.\nReferences [1] https://01.org/lkp/documentation/0-day-test-service\n[2] https://github.com/intel/lkp-tests\n[3] https://01.org/blogs/jdu1/2017/lkp-tests-linux-kernel-performance-test-and-analysis-tool\n[4] https://wiki.archlinux.org/index.php/makepkg\n","permalink":"https://sjp38.github.io/posts/ko/lkp-tests/","summary":"리눅스 커널의 개발은 커뮤니티 주도입니다. 개발의 한 부분인 테스트 역시 커뮤니티 주도적입니다. 여러 개인 또는 단체가 커널을 각자의 방식으로 테스트 하고 그 결과를 공유합니다. 인텔에서는 0-day 서비스[1] 라는 서비스를 자체적으로 돌리는데, 이 서비스는 최신 리눅스 커널을 가져다가 빌드하고 다양한 기능 / 성능 테스트를 돌리고 그 결과 발견된 regression 을 LKML 에 메일로 보내주는 일을 합니다. 말하자면 Continuous Integration (CI) 이죠.\nLinux Kernel Performance (LKP) Tests[2] 는 0-day 서비스에서 기능 / 성능 테스트를 수행하는데 사용되는 도구입니다.","title":"Linux Kernel Performance (LKP) Tests"},{"content":"Linux 4.19-rc2 https://lkml.kernel.org/r/CA+55aFyG0GbDfoghEhAmKBPcZCiPu6CCpPRz9GwjCzLuP_Vv5Q@mail.gmail.com\n2018-09-02 14:45 PDT\nLinux 4.19-rc1 https://lkml.kernel.org/r/CA+55aFw9mxNPX6OtOp-aoUMdXSg=gBkQudGGamo__sh_ts_LdQ@mail.gmail.com\n2018-08-26 14:49 PDT\nLinux 4.18 https://lkml.kernel.org/r/CA+55aFzos7tr=OLju10Oe-z7r=eB2dSaFa7vwz2ApGO13B=z_g@mail.gmail.com\n2018-08-12 14:10:49 PDT\nLinux 4.18-rc8 https://lkml.kernel.org/r/CA+55aFw49Bh9u3KvGsMbnSLfHvevpWPuqgrWQT0tC0XCajNwzA@mail.gmail.com\n2018-08-05 12:58 PDT\nLinux 4.18-rc7 https://lkml.kernel.org/r/CA+55aFxpFefwVdTGVML99PSFUqwpJXPx5LVCA3D=g2t2_QLNsA@mail.gmail.com\n2018-07-29 22:09 UTC\nLinux 4.18-rc6 https://lkml.kernel.org/r/CA+55aFzMheDA-2z=MdGgJrz-REcrknb+4OEvRKaJipm+x6xEhw@mail.gmail.com\n2018-07-23 20:46 UTC\nLinux 4.18-rc5 https://lkml.kernel.org/r/CA+55aFwfMr2D2A_yesUyt_Lo3XMRk9epzgeBMt2HxMHiXMDYcg@mail.gmail.com\n2018-07-15 20:28 UTC\nLinux 4.18-rc4 https://lore.kernel.org/lkml/CA+55aFwXGyZ1Yx+Z8a93gpvb596ZRJ5ppiQL_+-k7gjeQLtcsQ@mail.gmail.com/T/#u\n2018-07-08 23:57 UTC\nLinux 4.18-rc3 https://lkml.kernel.org/r/CA+55aFwGk-pWKKCtp+kQUN_hov9tW+vUo6Wgob91bewwBL17fA@mail.gmail.com\n2018-07-01 23:46 UTC\n","permalink":"https://sjp38.github.io/posts/ko/linux_release_history/","summary":"Linux 4.19-rc2 https://lkml.kernel.org/r/CA+55aFyG0GbDfoghEhAmKBPcZCiPu6CCpPRz9GwjCzLuP_Vv5Q@mail.gmail.com\n2018-09-02 14:45 PDT\nLinux 4.19-rc1 https://lkml.kernel.org/r/CA+55aFw9mxNPX6OtOp-aoUMdXSg=gBkQudGGamo__sh_ts_LdQ@mail.gmail.com\n2018-08-26 14:49 PDT\nLinux 4.18 https://lkml.kernel.org/r/CA+55aFzos7tr=OLju10Oe-z7r=eB2dSaFa7vwz2ApGO13B=z_g@mail.gmail.com\n2018-08-12 14:10:49 PDT\nLinux 4.18-rc8 https://lkml.kernel.org/r/CA+55aFw49Bh9u3KvGsMbnSLfHvevpWPuqgrWQT0tC0XCajNwzA@mail.gmail.com\n2018-08-05 12:58 PDT\nLinux 4.18-rc7 https://lkml.kernel.org/r/CA+55aFxpFefwVdTGVML99PSFUqwpJXPx5LVCA3D=g2t2_QLNsA@mail.gmail.com\n2018-07-29 22:09 UTC\nLinux 4.18-rc6 https://lkml.kernel.org/r/CA+55aFzMheDA-2z=MdGgJrz-REcrknb+4OEvRKaJipm+x6xEhw@mail.gmail.com\n2018-07-23 20:46 UTC\nLinux 4.18-rc5 https://lkml.kernel.org/r/CA+55aFwfMr2D2A_yesUyt_Lo3XMRk9epzgeBMt2HxMHiXMDYcg@mail.gmail.com\n2018-07-15 20:28 UTC\nLinux 4.18-rc4 https://lore.kernel.org/lkml/CA+55aFwXGyZ1Yx+Z8a93gpvb596ZRJ5ppiQL_+-k7gjeQLtcsQ@mail.gmail.com/T/#u\n2018-07-08 23:57 UTC\nLinux 4.18-rc3 https://lkml.kernel.org/r/CA+55aFwGk-pWKKCtp+kQUN_hov9tW+vUo6Wgob91bewwBL17fA@mail.gmail.com\n2018-07-01 23:46 UTC","title":"Linux Release History"},{"content":"Linux 4.19-rc2 https://lkml.kernel.org/r/CA+55aFyG0GbDfoghEhAmKBPcZCiPu6CCpPRz9GwjCzLuP_Vv5Q@mail.gmail.com\n2018-09-02 14:45 PDT\nLinux 4.19-rc1 https://lkml.kernel.org/r/CA+55aFw9mxNPX6OtOp-aoUMdXSg=gBkQudGGamo__sh_ts_LdQ@mail.gmail.com\n2018-08-26 14:49 PDT\nLinux 4.18 https://lkml.kernel.org/r/CA+55aFzos7tr=OLju10Oe-z7r=eB2dSaFa7vwz2ApGO13B=z_g@mail.gmail.com\n2018-08-12 14:10:49 PDT\nLinux 4.18-rc8 https://lkml.kernel.org/r/CA+55aFw49Bh9u3KvGsMbnSLfHvevpWPuqgrWQT0tC0XCajNwzA@mail.gmail.com\n2018-08-05 12:58 PDT\nLinux 4.18-rc7 https://lkml.kernel.org/r/CA+55aFxpFefwVdTGVML99PSFUqwpJXPx5LVCA3D=g2t2_QLNsA@mail.gmail.com\n2018-07-29 22:09 UTC\nLinux 4.18-rc6 https://lkml.kernel.org/r/CA+55aFzMheDA-2z=MdGgJrz-REcrknb+4OEvRKaJipm+x6xEhw@mail.gmail.com\n2018-07-23 20:46 UTC\nLinux 4.18-rc5 https://lkml.kernel.org/r/CA+55aFwfMr2D2A_yesUyt_Lo3XMRk9epzgeBMt2HxMHiXMDYcg@mail.gmail.com\n2018-07-15 20:28 UTC\nLinux 4.18-rc4 https://lore.kernel.org/lkml/CA+55aFwXGyZ1Yx+Z8a93gpvb596ZRJ5ppiQL_+-k7gjeQLtcsQ@mail.gmail.com/T/#u\n2018-07-08 23:57 UTC\nLinux 4.18-rc3 https://lkml.kernel.org/r/CA+55aFwGk-pWKKCtp+kQUN_hov9tW+vUo6Wgob91bewwBL17fA@mail.gmail.com\n2018-07-01 23:46 UTC\n","permalink":"https://sjp38.github.io/posts/linux_release_history/","summary":"Linux 4.19-rc2 https://lkml.kernel.org/r/CA+55aFyG0GbDfoghEhAmKBPcZCiPu6CCpPRz9GwjCzLuP_Vv5Q@mail.gmail.com\n2018-09-02 14:45 PDT\nLinux 4.19-rc1 https://lkml.kernel.org/r/CA+55aFw9mxNPX6OtOp-aoUMdXSg=gBkQudGGamo__sh_ts_LdQ@mail.gmail.com\n2018-08-26 14:49 PDT\nLinux 4.18 https://lkml.kernel.org/r/CA+55aFzos7tr=OLju10Oe-z7r=eB2dSaFa7vwz2ApGO13B=z_g@mail.gmail.com\n2018-08-12 14:10:49 PDT\nLinux 4.18-rc8 https://lkml.kernel.org/r/CA+55aFw49Bh9u3KvGsMbnSLfHvevpWPuqgrWQT0tC0XCajNwzA@mail.gmail.com\n2018-08-05 12:58 PDT\nLinux 4.18-rc7 https://lkml.kernel.org/r/CA+55aFxpFefwVdTGVML99PSFUqwpJXPx5LVCA3D=g2t2_QLNsA@mail.gmail.com\n2018-07-29 22:09 UTC\nLinux 4.18-rc6 https://lkml.kernel.org/r/CA+55aFzMheDA-2z=MdGgJrz-REcrknb+4OEvRKaJipm+x6xEhw@mail.gmail.com\n2018-07-23 20:46 UTC\nLinux 4.18-rc5 https://lkml.kernel.org/r/CA+55aFwfMr2D2A_yesUyt_Lo3XMRk9epzgeBMt2HxMHiXMDYcg@mail.gmail.com\n2018-07-15 20:28 UTC\nLinux 4.18-rc4 https://lore.kernel.org/lkml/CA+55aFwXGyZ1Yx+Z8a93gpvb596ZRJ5ppiQL_+-k7gjeQLtcsQ@mail.gmail.com/T/#u\n2018-07-08 23:57 UTC\nLinux 4.18-rc3 https://lkml.kernel.org/r/CA+55aFwGk-pWKKCtp+kQUN_hov9tW+vUo6Wgob91bewwBL17fA@mail.gmail.com\n2018-07-01 23:46 UTC","title":"Linux Release History"},{"content":"리눅스 커널 커뮤니티는 버그 레포팅, 패치 업로드, 리뷰, 릴리즈, 토론 등등 모든 활동은 이메일을 통해 이루어집니다. 이 포스트에서는 리누스 토발즈도 쓰는 이메일 클라이언트인 Alpine 을 gmail 과 연동하는 방법을 알아봅니다.\n먼저 alpine 설치는 대부분 리눅스 배포판의 패키지 시스템에 등록되어 있으므로 해당 패키지 시스템을 사용해 쉽게 설치할 수 있습니다. 데비안 계열이면 apt install alpine, 페도라 계열이면 dnf install alpine 이죠.\ngmail imap 정보 입력 S (Settings) -\u0026gt; L (collectionLists) -\u0026gt; A (Add Cltn)\nNickname: gmail or anything Server: imap.gmail.com/ssl/user=sj@gmail.com\n^X (Commit change) E (Exit Setup)\nSMTP 서버 설정 S (Setup) -\u0026gt; C (config)\nSMTP server: smtp.gmail.com/tls/user=sj@gmail.com\n쓰레드 기반 소팅 [Sort key]: tHread (enter)\n리눅스 커널 커뮤니티에서 요구하는 설정 [Sending Preferences]: Do Not Send Flowed Text, Strip Whitespace Before Sending\nReferences https://harbhag.wordpress.com/2010/07/14/configure-alpine-to-sendreceive-emails-from-gmail/\n","permalink":"https://sjp38.github.io/posts/alpine-for-lkml/","summary":"리눅스 커널 커뮤니티는 버그 레포팅, 패치 업로드, 리뷰, 릴리즈, 토론 등등 모든 활동은 이메일을 통해 이루어집니다. 이 포스트에서는 리누스 토발즈도 쓰는 이메일 클라이언트인 Alpine 을 gmail 과 연동하는 방법을 알아봅니다.\n먼저 alpine 설치는 대부분 리눅스 배포판의 패키지 시스템에 등록되어 있으므로 해당 패키지 시스템을 사용해 쉽게 설치할 수 있습니다. 데비안 계열이면 apt install alpine, 페도라 계열이면 dnf install alpine 이죠.\ngmail imap 정보 입력 S (Settings) -\u0026gt; L (collectionLists) -\u0026gt; A (Add Cltn)","title":"Alpine for LKML"},{"content":"리눅스 커널 커뮤니티는 버그 레포팅, 패치 업로드, 리뷰, 릴리즈, 토론 등등 모든 활동은 이메일을 통해 이루어집니다. 이 포스트에서는 리누스 토발즈도 쓰는 이메일 클라이언트인 Alpine 을 gmail 과 연동하는 방법을 알아봅니다.\n먼저 alpine 설치는 대부분 리눅스 배포판의 패키지 시스템에 등록되어 있으므로 해당 패키지 시스템을 사용해 쉽게 설치할 수 있습니다. 데비안 계열이면 apt install alpine, 페도라 계열이면 dnf install alpine 이죠.\ngmail imap 정보 입력 S (Settings) -\u0026gt; L (collectionLists) -\u0026gt; A (Add Cltn)\nNickname: gmail or anything Server: imap.gmail.com/ssl/user=sj@gmail.com\n^X (Commit change) E (Exit Setup)\nSMTP 서버 설정 S (Setup) -\u0026gt; C (config)\nSMTP server: smtp.gmail.com/tls/user=sj@gmail.com\n쓰레드 기반 소팅 [Sort key]: tHread (enter)\n리눅스 커널 커뮤니티에서 요구하는 설정 [Sending Preferences]: Do Not Send Flowed Text, Strip Whitespace Before Sending\nReferences https://harbhag.wordpress.com/2010/07/14/configure-alpine-to-sendreceive-emails-from-gmail/\n","permalink":"https://sjp38.github.io/posts/ko/alpine-for-lkml/","summary":"리눅스 커널 커뮤니티는 버그 레포팅, 패치 업로드, 리뷰, 릴리즈, 토론 등등 모든 활동은 이메일을 통해 이루어집니다. 이 포스트에서는 리누스 토발즈도 쓰는 이메일 클라이언트인 Alpine 을 gmail 과 연동하는 방법을 알아봅니다.\n먼저 alpine 설치는 대부분 리눅스 배포판의 패키지 시스템에 등록되어 있으므로 해당 패키지 시스템을 사용해 쉽게 설치할 수 있습니다. 데비안 계열이면 apt install alpine, 페도라 계열이면 dnf install alpine 이죠.\ngmail imap 정보 입력 S (Settings) -\u0026gt; L (collectionLists) -\u0026gt; A (Add Cltn)","title":"Alpine for LKML"},{"content":"이 글은 머신러닝 학습 환경으로도 널리 사용되는 Jupyter Notebook 과 Google Colab 에 대해 간단히 설명합니다.\nJupyter Notebook Jupyter Notebook [1] 은 대화형으로 프로그래밍 언어를 공부하고 실습해 볼 수 있도록 만들어진 개발 / 학습 환경입니다. 이 환경은 크게 노트북 문서, Jupyter Notebook App, Notebook kernel, 그리고 Notebook Dashboard 로 구성됩니다.\n노트북 문서 노트북 문서는 프로그램 코드 조각들과 Rich text (이걸 한글로 뭐라 해야 할지\u0026hellip;), 그리고 각 코드 조각의 수행 결과 로 구성됩니다. 백문이 불여일견, 이 링크 를 따라가 보시기 바랍니다. 링크는 간단한 파이썬 교육을 위해 만들어진 노트북 문서로, 코드를 수정하고 수행해 볼 수 있습니다. 텍스트도 수정할 수 있습니다. 문서에 코드 또는 텍스트 셀을 추가해 코드 셀에는 코드를, 텍스트 셀에는 텍스트를 작성할 수 있으며, 텍스트 셀에 작성할 수 있는 텍스트는 단순한 평문이 아니라 강조, 이탤릭 등의 효과를 포함할 수 있습니다. Jupyter Notebook 환경은 노트북 문서들을 읽어들여 Rich Text 를 저자가 의도한 모습대로 렌더링 해주고, 코드 셀을 사용자가 원하면 셀별로 수행시켜줍니다. 코드 셀의 좌측에 수행 버튼이 떠서, 이를 클릭하면 해당 셀을 수행하는 형태입니다. 문서 상의 모든 코드 셀의 일괄 수행 역시 가능합니다. 이 때, 앞서 수행된 코드 셀의 수행 결과는 다음에 수행되는 코드 셀에 영향을 끼칩니다. 예를 들어 특정 셀에서 전역 변수의 값을 변경했다면 다음에 수행하는 셀에 변경된 전역 변수의 값이 보입니다.\n이를 통해 Jupyter Notebook 사용자는 노트북 문서를 사용해 타인에게 학습시킬 문서를 작성하고 학습자가 곧바로 하나씩 수행해 볼 수 있게 해줄 수 있으며, 스스로 공부하는 사람도 자신이 공부한 내용을 쉽게 정리할 수 있게 해줍니다.\nJupyter Notebook App Jupyter Notebook App 은 Jupyter 노트북 문서를 읽어들여 작성자가 원한 모습으로 보여주고 코드의 수행 등을 대신해 주고, 또한 노트북 문서를 새로 작성할 수 있는 에디터 역할을 합니다. 서버-클라이언트 구조로 되어 있어 로컬 컴퓨터에 서버를 띄우고 웹브라우저로 접속해서 작업할 수도, 다른 컴퓨터에 띄워진 서버에 웹브라우저로 접속해 작업할 수도 있습니다. 일부 공개 Jupyter Notebook 서버도 서비스 되고 있습니다. Google Colab 역시 그런 형태입니다.\nGithub 은 웹인터페이스 상에서 Notebook 문서를 렌더링 해 보여주는 기능을 제공하고 있습니다.\nNotebook kernel 과 Notebook Dashboard 실제 코드의 수행을 담당하는게 Notebook kernel, 각 노트북 문서의 관리를 담당해 주는 인터페이스가 Dashboard 입니다. 커널은 프로그램이 언어별로 존재하며, Jupyter Notebook 에서는 다양한 언어의 커널을 지원하고 있습니다.\nGoogle Colab Jupyter Notebook 은 앞서 설명했듯 자신의 컴퓨터에 설치하고 서버를 띄울수도, 다른 컴퓨터에 설치하고 서버를 띄울 수도 있습니다. ... as a Service 의 시대인 만큼, Jupyter Notebook Server 를 서비스하는 회사들이 많습니다. Google Colab[2] 은 그런 서비스 중 하나입니다. 이 프로젝트는 머신러닝 교육과 연구를 돕기 위해 만들어진 Google 의 연구 프로젝트로, 결국은 하나의 Jupyter notebook 환경일 뿐인데, 어떠한 셋업도 필요 없고 구글 클라우드 위에서 동작합니다.\n노트북 문서는 구글 드라이브에 저장하고 불러올 수 있으며, Github 에 있는 노트북 문서도 읽어올 수 있습니다. 참고로 노트북 문서는 .ipynb 라는 확장자를 사용하는 텍스트 파일입니다. Colab 에서 작성한 노트북 문서를 .ipynb 확장자 파일로 곧바로 다운받을 수 있으므로 구글 드라이브로 공유하기 부담스러운 경우는 github 을 통해 공유해도 좋겠습니다. 뿐만 아니라 읽기만 하므로 다른 사람의 Jupyter Notebook 문서도 공개되어 있다면 얼마든지 불러올 수 있습니다.\nGithub 의 노트북 문서 불러오기 Github 의 노트북 파일을 불러오는 방법은 간단합니다. 먼저 Github 웹 인터페이스에 들어가 Google Colab 에서 읽고자 하는 문서의 github 상에서의 주소를 파악합니다. 대략 https://github.com/sjp38/jupyternb_hello/blob/master/jupyternb_hello.ipynb 와 같은 형태가 될겁니다. 여기서 https:// 를 제거하고 github.com 에서 ./com 을 제거한 후, https://colab.research.google.com/ 뒤에 붙여줍니다. 그러면 대략 https://colab.research.google.com/github/sjp38/jupyternb_hello/blob/master/jupyternb_hello.ipynb 같은 모습이 되겠죠. 이 주소를 웹브라우저에 입력하면, Colab 에 해당 노트북이 열리고 수행도 해볼 수 있습니다.\nSummary 머신러닝 학습에 많이 사용되는 Jupyter Notebook 과 머신러닝을 위한 Jupyter Notebook 서비스 중 하나인 Google Colab 에 대해 알아봤습니다. 저도 최근에야 알게 된 프로젝트인데, 코드와 그에 대한 설명을 정말 쉽고 효과적으로 공유할 수 있는 획기적 방법 같습니다. 다른 분야에도 널리 퍼지면 좋겠군요.\n[1] http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html\n[2] https://colab.research.google.com/notebooks/welcome.ipynb\n","permalink":"https://sjp38.github.io/posts/ko/ml-study-env/","summary":"이 글은 머신러닝 학습 환경으로도 널리 사용되는 Jupyter Notebook 과 Google Colab 에 대해 간단히 설명합니다.\nJupyter Notebook Jupyter Notebook [1] 은 대화형으로 프로그래밍 언어를 공부하고 실습해 볼 수 있도록 만들어진 개발 / 학습 환경입니다. 이 환경은 크게 노트북 문서, Jupyter Notebook App, Notebook kernel, 그리고 Notebook Dashboard 로 구성됩니다.\n노트북 문서 노트북 문서는 프로그램 코드 조각들과 Rich text (이걸 한글로 뭐라 해야 할지\u0026hellip;), 그리고 각 코드 조각의 수행 결과 로 구성됩니다.","title":"머신러닝 학습/실습 환경 (Jupyter Notebook \u0026 Google Colab)"},{"content":"You can use classical debugger for your Linux kernel programming, though Torvalds doesn\u0026rsquo;t like it. I also do not prefer such use of debuggers, but admit that sometimes debuggers are quite useful. ;)\nThere are several ways to debug Linux kernel, but one of above is to set up a Linux virtual machine using QEMU and debugging the Linux kernel of the virtual machine from the host machine. This post summarises how to debug the Linux kernel in this way.\nTest Environment The versions and names of the software I used for test of this post are as below.\nUbuntu 16.04.3 Server gdb 7.11.1 QEMU v2.11.0-dirty Linux v4.16 Kernel Build First, build the kernel you want to debug. You should turn CONFIG_GDB_SCRIPTS on, turn CONFIG_DEBUG_INFO_REDUCED off, and turn CONFIG_FRAME_POINTER on if your target architecture supports it.\nBoot The Virtual Machine If your kernel is ready, boot a QEMU vertual machine with it. You could do it in several ways. For example, you could install the kernel on the virtual machine disk. Or, you could use -kernel, -append and -initrd QEMU option to boot the virtual machine with your kernel image in host machine directly, or some other ways. One thing you should keep in your mind is that you should turn kaslr off. Just giving nokaslr in the kernel parameter doesn\u0026rsquo;t works well.\nPass -s option to QEMU when you start up the QEMU virtual machine, or enter gdbserver in the QEMU monitor console command line. This make the virtual machine to start gdbserver and wait on tcp::1234 for some accesses. If you have given -nographic QEMU option and set the kernel parameter so that the virtual machine\u0026rsquo;s console is connected to your terminal, you could not see the QEMU monitor console directly. In this case, you can go back to QEMU monitor console by entering Ctrl+a c. If you want to go back to the virtual machine\u0026rsquo;s console again, Ctrl+a c \u0026lt;enter\u0026gt;.\nStart gdb Move to the build directory of the kernel to debug, enter gdb vmlinux. This will start up gdb using the symbol and debuggin information of the kernel. Ubuntu or some distributions might fail to read vmlinux-gdb.py. The error message also show you how you can fix it, but in summary, you should append below one line at the end of the .gdbinit file and start the gdb again with the above command:\nadd-auto-load-state-path /path/to/linux-build Now, connect to the QEMU virtual machine by entering below command from the gdb session:\n(gdb) target remote :1234 Remote debugging using :1234 0xffffffff818cce92 in native_safe_halt () at /home/sjpark/linux/arch/x86/include/asm/irqflags.h:54 54 asm volatile(\u0026#34;sti; hlt\u0026#34;: : :\u0026#34;memory\u0026#34;); Just after you entering this command, QEMU virtual machine will be frozen. From now, you can see the variables of the kernel, set the breakpoint, execute the code step by step, as you normally did with gdb and user space programs. For example, you can set breakpoint to specific function as below:\n(gdb) b cma_alloc Breakpoint 1 at 0xffffffff81240f10: file /home/hacklog/linux/mm/cma.c, line 399. If you want your virtual machine to run again, you can enter c. This will resume the execution of the kernel. If you set a breakpoint as described above and if the code is be executed, the execution will be started on the breakpoint.\n(gdb) c Continuing. If you want the kernel to stop again, enter Ctrl+C in the gdb.\n^C Thread 1 received signal SIGINT, Interrupt. 0xffffffff818cce92 in native_safe_halt () at /home/sjpark/linux/arch/x86/include/asm/irqflags.h:54 54 asm volatile(\u0026#34;sti; hlt\u0026#34;: : :\u0026#34;memory\u0026#34;); (gdb) Use Linux gdb helper Actually, you can normally use gdb even though it failed to load vmlinux-gdb.py. The python script contains some helper scripts for more convenient kernel debugging on the gdb. You can do kernel debugging a little bit more conveniently if you use it.\nList of the helper scripts The helper scripts have lx prefix. You can list up their names and brief descriptions as below:\n(gdb) apropos lx function lx_current -- Return current task function lx_module -- Find module by name and return the module variable function lx_per_cpu -- Return per-cpu variable function lx_task_by_pid -- Find Linux task by PID and return the task_struct variable function lx_thread_info -- Calculate Linux thread_info from task variable function lx_thread_info_by_pid -- Calculate Linux thread_info from task variable found by pid lx-cmdline -- Report the Linux Commandline used in the current kernel lx-cpus -- List CPU status arrays lx-dmesg -- Print Linux kernel log buffer lx-fdtdump -- Output Flattened Device Tree header and dump FDT blob to the filename lx-iomem -- Identify the IO memory resource locations defined by the kernel lx-ioports -- Identify the IO port resource locations defined by the kernel lx-list-check -- Verify a list consistency lx-lsmod -- List currently loaded modules lx-mounts -- Report the VFS mounts of the current process namespace lx-ps -- Dump Linux tasks lx-symbols -- (Re-)load symbols of Linux kernel and currently loaded modules lx-version -- Report the Linux Version of the current kernel So easy, huh? ;)\nReferences The Kernel Official Document for the Kernel Debugging A blog article The gdbserver official document ","permalink":"https://sjp38.github.io/posts/qemu_kernel_debugging/","summary":"You can use classical debugger for your Linux kernel programming, though Torvalds doesn\u0026rsquo;t like it. I also do not prefer such use of debuggers, but admit that sometimes debuggers are quite useful. ;)\nThere are several ways to debug Linux kernel, but one of above is to set up a Linux virtual machine using QEMU and debugging the Linux kernel of the virtual machine from the host machine. This post summarises how to debug the Linux kernel in this way.","title":"Linux Kernel Debugging Using QEMU"},{"content":"토발즈는 좋아하지 않지만, 리눅스 커널 프로그래밍에도 디버거를 사용할 수 있습니다. 저도 디버거 사용을 좋아하지는 않는 편이지만, 경우에 따라선 디버거를 사용하는게 좋을 때도 있고 취향은 존중되어야죠. ;)\n커널 디버깅 방법은 여러가지가 있는데, 그 중 하나는 QEMU 등을 이용한 리눅스 가상 머신을 띄워 두고, 호스트 머신에서 해당 가상 머신의 리눅스 커널을 디버깅 하는 방법입니다. 이 글에선 이렇게 디버깅 하는 방법을 간단히 정리해 봅니다.\n테스트 환경 글 작성 과정에서 테스트에 사용한 주요 소프트웨어들과 버전은 다음과 같습니다.\nUbuntu 16.04.3 Server gdb 7.11.1 QEMU v2.11.0-dirty Linux v4.16 커널 빌드 디버깅할 커널을 빌드합니다. 이 때 CONFIG_GDB_SCRIPTS 는 켜고 CONFIG_DEBUG_INFO_REDUCED 는 끄고, 타겟 아키텍쳐가 CONFIG_FRAME_POINTER 를 지원한다면 켜야 합니다.\n가상 머신 부팅 빌드가 완료되면 해당 커널을 사용해 QEMU 가상 머신을 부팅시킵니다. 가상 머신 위에 커널을 설치하는 방법도 있겠고, QEMU 에 -kernel 과 -append, -initrd 등을 사용해서 호스트에서 빌드한 리눅스 커널로 부팅시키는 방법도 있을 겁니다. 이 때, kaslr 을 꺼야 합니다. 커널 패러미터에 nokaslr 을 추가하는 걸로 끌 수 있습니다. kaslr 이 켜진 채로 디버깅 해야 한다면 다른 방법이 있는데, 여기선 다루지 않겠습니다.\nQEMU 가상 머신을 시작할 때 QEMU 에 -s 옵션을 주거나 QEMU monitor console 에서 gdbserver 라고 명령을 입력해 줍니다. 이 명령은 가상머신에서 gdbserver 를 시작시켜서 gdbserver 가 tcp::1234 에서 접속을 기다리게 함으로써 QEMU 의 gdb 기능을 활성화 시켜줍니다. -nographic 옵션을 주거나 해서 QEMU 를 수행시켰다면 화면에 QEMU monitor console 이 아니라 가상머신의 console 로 연결되었을 텐데, Ctrl+a c 키 조합으로 QEMU monitor console 로 이동할 수 있습니다. 여기서 가상머신 콘솔로 돌아가려면 Ctrl+a c \u0026lt;enter\u0026gt; 를 입력해 줍니다.\ngdb 시작 호스트 머신에서 디버깅할 커널의 빌드 디렉토리로 이동해서 gdb vmlinux 명령어를 입력해 빌드된 리눅스 심볼과 디버깅 정보를 사용해 gdb 가 켜지도록 합니다. 우분투나 일부 배포본에서는 이 때 vmlinux-gdb.py 를 읽어들이는데 실패할 수 있을 겁니다. gdb 에서도 에러메세지를 띄워 주겠지만, 홈디렉토리의 .gdbinit 파일에 다음 한줄을 추가해 주고 앞서 설명한 커맨드로 gdb 를 다시 시작합니다:\nadd-auto-load-state-path /path/to/linux-build 이후, gdb 세션에서 다음과 같은 명령어를 입력해 QEMU 가상머신에 연결합니다:\n(gdb) target remote :1234 Remote debugging using :1234 0xffffffff818cce92 in native_safe_halt () at /home/sjpark/linux/arch/x86/include/asm/irqflags.h:54 54 asm volatile(\u0026#34;sti; hlt\u0026#34;: : :\u0026#34;memory\u0026#34;); 이와 함께 QEMU 가상 머신은 동작이 멈출 겁니다. 여기서부터 gdb 를 평소에 사용하듯이 사용해 리눅스 커널의 변수를 보거나 중단점 (breakpoint) 를 설정하거나 한단계씩 코드를 수행시키거나 할 수 있습니다. 예를 들어 다음과 같이 특정 함수에 breakpoint 를 설정할 수 있습니다:\n(gdb) b cma_alloc Breakpoint 1 at 0xffffffff81240f10: file /home/sjpark/linux/mm/cma.c, line 399. 예를 들어 수행이 멈춰 있는 가상머신의 수행을 다시 가능하게 하려면 다음과 같이 c 를 입력해 줍니다. 가상머신의 커널 수행이 재개되며, Breakpoint 가 설정되어 있고 해당 위치 코드가 수행되면 다시 수행이 멈출 겁니다.\n(gdb) c Continuing. 다시 멈추려면 gdb 에서 Ctrl+C 를 누릅시다:\n^C Thread 1 received signal SIGINT, Interrupt. 0xffffffff818cce92 in native_safe_halt () at /home/sjpark/linux/arch/x86/include/asm/irqflags.h:54 54 asm volatile(\u0026#34;sti; hlt\u0026#34;: : :\u0026#34;memory\u0026#34;); (gdb) 리눅스 gdb helper 사용하기 사실은 앞 단계에서 .gdbinit 를 굳이 수정하지 않아서 gdb가 vmlinux-gdb.py 를 읽어들이는데 실패하더라도 gdb 를 평범하게 사용할 수 있습니다. vmlinux-gdb.py 는 사실 gdb 위에서 리눅스 커널을 디버깅하는걸 편리하게 해줄 수 있는 일부 스크립트, 즉 gdb helper 를 담고 있습니다. 이걸 사용하면 보다 쉽게 커널 디버깅을 할 수 있습니다.\nhelper 스크립트 리스트업 사용 가능한 helper 스크립트는 lx로 시작하는 규칙을 갖고 있습니다. 다음 명령으로 사용 가능한 스크립트 목록과 간단한 설명을 볼 수 있습니다:\n(gdb) apropos lx function lx_current -- Return current task function lx_module -- Find module by name and return the module variable function lx_per_cpu -- Return per-cpu variable function lx_task_by_pid -- Find Linux task by PID and return the task_struct variable function lx_thread_info -- Calculate Linux thread_info from task variable function lx_thread_info_by_pid -- Calculate Linux thread_info from task variable found by pid lx-cmdline -- Report the Linux Commandline used in the current kernel lx-cpus -- List CPU status arrays lx-dmesg -- Print Linux kernel log buffer lx-fdtdump -- Output Flattened Device Tree header and dump FDT blob to the filename lx-iomem -- Identify the IO memory resource locations defined by the kernel lx-ioports -- Identify the IO port resource locations defined by the kernel lx-list-check -- Verify a list consistency lx-lsmod -- List currently loaded modules lx-mounts -- Report the VFS mounts of the current process namespace lx-ps -- Dump Linux tasks lx-symbols -- (Re-)load symbols of Linux kernel and currently loaded modules lx-version -- Report the Linux Version of the current kernel 참 쉽죠? ;)\n참고 자료 커널 디버깅 공식 문서 참고할만한 영문 블로그 글 gdbserver 공식 문서 ","permalink":"https://sjp38.github.io/posts/ko/qemu_kernel_debugging/","summary":"토발즈는 좋아하지 않지만, 리눅스 커널 프로그래밍에도 디버거를 사용할 수 있습니다. 저도 디버거 사용을 좋아하지는 않는 편이지만, 경우에 따라선 디버거를 사용하는게 좋을 때도 있고 취향은 존중되어야죠. ;)\n커널 디버깅 방법은 여러가지가 있는데, 그 중 하나는 QEMU 등을 이용한 리눅스 가상 머신을 띄워 두고, 호스트 머신에서 해당 가상 머신의 리눅스 커널을 디버깅 하는 방법입니다. 이 글에선 이렇게 디버깅 하는 방법을 간단히 정리해 봅니다.\n테스트 환경 글 작성 과정에서 테스트에 사용한 주요 소프트웨어들과 버전은 다음과 같습니다.","title":"QEMU 를 사용한 리눅스 커널 디버깅"},{"content":"경우에 따라서 SPEC CPU2006 의 벤치마크 중 일부의 소스코드를 수정하고 싶을 수 있습니다. 예를 들어 특정 벤치마크가 구체적으로 어떻게 동작하는지 알아보기 위해 디버깅 메세지를 추가하고자 할수도 있고, 코드 변경을 통해 성능을 높인다거나 해볼 수도 있겠죠. 그러나, SPEC CPU2006 은 엄정한 벤치마크 수트이기 때문에 소스코드는 물론, 소스코드를 사용하는 도구가 변경된 경우 에러 메세지를 내고 수행을 거부합니다. 수정된 소스코드로 얻어진 결과는 벤치마크 결과로 적합하지 않기 때문이죠.\n때문에, 어쩔 수 없이 수정이 필요하면서도 기존의 수행 방법을 따르려면 이 에러를 내는 곳을 없애는 게 한가지 방법이 될 수 있습니다. 다음의 패치를 적용하면 이 검증 코드가 사라져서 수정된 코드로도 벤치마크를 돌릴 수 있게 됩니다.\ndiff --git a/bin/formatter/setup_common.pl b/bin/formatter/setup_common.pl index 36170cda1649..b21890972dbd 100755 --- a/bin/formatter/setup_common.pl +++ b/bin/formatter/setup_common.pl @@ -278,13 +278,13 @@ sub check_important_files { return if ( $::suite_version \u0026gt; 4 \u0026amp;\u0026amp; !$ENV{\u0026#39;SPEC_CHECK\u0026#39;}); $::check_integrity = 1; - foreach my $important_file (jp(\u0026#39;bin\u0026#39;, basename($0)), - grep { m/$re/ } keys %::file_md5) { - if (!check_files(\\%::file_md5, $important_file)) { - print STDERR \u0026#34;\\n\\nPart of the tools ($important_file) is corrupt!\\nAborting...\\n\\n\u0026#34;; - exit 1; - } - } +# foreach my $important_file (jp(\u0026#39;bin\u0026#39;, basename($0)), +# grep { m/$re/ } keys %::file_md5) { +# if (!check_files(\\%::file_md5, $important_file)) { +# print STDERR \u0026#34;\\n\\n Part of the tools ($important_file) is corrupt!\\nAborting...\\n\\n\u0026#34;; +# exit 1; +# } +# } } 1; diff --git a/bin/setup_common.pl b/bin/setup_common.pl index 36170cda1649..d9dbe214d498 100755 --- a/bin/setup_common.pl +++ b/bin/setup_common.pl @@ -219,9 +219,9 @@ sub md5filedigest { sub load_module { my ($module, $quiet) = @_; - if ($::check_integrity \u0026amp;\u0026amp; !check_files(\\%::file_md5, jp(\u0026#39;bin\u0026#39;, $module))) { -\tdie \u0026#34;\\n\\nPart of the tools ($module) is corrupt! Aborting...\\n\\n\u0026#34;; - } +# if ($::check_integrity \u0026amp;\u0026amp; !check_files(\\%::file_md5, jp(\u0026#39;bin\u0026#39;, $module))) { +#\tdie \u0026#34;\\n\\nPart of the tools ($module) is corrupt! Aborting...\\n\\n\u0026#34;; +# } eval \u0026#34;require \\\u0026#34;$module\\\u0026#34;;\u0026#34;; print \u0026#39;.\u0026#39; unless ($quiet); if ($@) { @@ -278,13 +278,13 @@ sub check_important_files { return if ( $::suite_version \u0026gt; 4 \u0026amp;\u0026amp; !$ENV{\u0026#39;SPEC_CHECK\u0026#39;}); $::check_integrity = 1; - foreach my $important_file (jp(\u0026#39;bin\u0026#39;, basename($0)), - grep { m/$re/ } keys %::file_md5) { - if (!check_files(\\%::file_md5, $important_file)) { - print STDERR \u0026#34;\\n\\nPart of the tools ($important_file) is corrupt!\\nAborting...\\n\\n\u0026#34;; - exit 1; - } - } +# foreach my $important_file (jp(\u0026#39;bin\u0026#39;, basename($0)), +# grep { m/$re/ } keys %::file_md5) { +# if (!check_files(\\%::file_md5, $important_file)) { +# print STDERR \u0026#34;\\n\\nPart of the tools ($important_file) is corrupt!\\nAborting...\\n\\n\u0026#34;; +# exit 1; +# } +# } } 1; diff --git a/bin/util.pl b/bin/util.pl index ccf4a72477c0..c8c0cd786522 100755 --- a/bin/util.pl +++ b/bin/util.pl @@ -211,11 +211,11 @@ sub copy_tree { offer_verify_advice(); return 0; } -\tif ($sumhash-\u0026gt;{$sf} ne md5filedigest($sf)) { -\tLog(0, \u0026#34;\\n$sf is corrupt!\\n\u0026#34;); - offer_verify_advice(); -\treturn 0; -\t} +#\tif ($sumhash-\u0026gt;{$sf} ne md5filedigest($sf)) { +#\tLog(0, \u0026#34;\\n$sf is corrupt!\\n\u0026#34;); +# offer_verify_advice(); +#\treturn 0; +#\t} } if ($sf =~ /\\.bz2$/) { copy_bz2_file($sf, $file, [$target], 0); ","permalink":"https://sjp38.github.io/posts/ko/spec_cpu2006_modification/","summary":"경우에 따라서 SPEC CPU2006 의 벤치마크 중 일부의 소스코드를 수정하고 싶을 수 있습니다. 예를 들어 특정 벤치마크가 구체적으로 어떻게 동작하는지 알아보기 위해 디버깅 메세지를 추가하고자 할수도 있고, 코드 변경을 통해 성능을 높인다거나 해볼 수도 있겠죠. 그러나, SPEC CPU2006 은 엄정한 벤치마크 수트이기 때문에 소스코드는 물론, 소스코드를 사용하는 도구가 변경된 경우 에러 메세지를 내고 수행을 거부합니다. 수정된 소스코드로 얻어진 결과는 벤치마크 결과로 적합하지 않기 때문이죠.\n때문에, 어쩔 수 없이 수정이 필요하면서도 기존의 수행 방법을 따르려면 이 에러를 내는 곳을 없애는 게 한가지 방법이 될 수 있습니다.","title":"spec cpu2006 벤치마크 수정하기"},{"content":"컨퍼런스 둘째날부터는 kernel summit track 이 시작됩니다. 이번 컨퍼런스 참가는 아무래도 kernel summit 에서의 시끄럽고 정신없는 토론에 참여하고 싶기 때문이었기에 오늘부터가 제게는 가장 재밌는 시간입니다.\n![foo] (/img/osse_05/1.jpg)\n아침 일찍 일어나 컨퍼런스 장소로 출발합니다. 10명이 함께 묵는 방을 사용하고 있기에 일찍 일어나지 않으면 샤워를 제시간에 하기 어려우므로 조금 일찍 일어났습니다.\n![foo] (/img/osse_05/2.jpg)\n![foo] (/img/osse_05/3.jpg)\n![foo] (/img/osse_05/4.jpg)\n일찍 출발한 만큼 일찍 도착. 아직 부스에 사람도 없고 조용하네요. 한동안 부스 한켠에 준비된 휴식 공간에 앉아 커널 메일링 리스트도 읽고 코드도 보고 했습니다.\n![foo] (/img/osse_05/5.jpg)\n아침식사가 차려졌습니다. 간단하게 커피에 빵. 저 호밀빵이 담백하고 맛있더군요.\n![foo] (/img/osse_05/6.jpg)\n키노트. 키노트에 나선 분들이 속한 회사나 단체의 미래에 대한 전망과 상황을 알 수 있어 재밌습니다.\n![foo] (/img/osse_05/7.jpg)\n키노트 끝나고 커피타임. 샌드위치류가 나왔는데 역시 호텔 음식은 맛있습니다.\n![foo] (/img/osse_05/8.jpg)\n오늘 오후부터 kernel summit track 이 진행되었습니다. kernel summit track 은 다른 세션들처럼 친절한 발표 형태가 아니라 한명이 앞에서 토론을 진행하고 중간중간 나머지 개발자들이 끼어들어 질문하고 토론합니다. 딸랑 한두장 슬라이드만 들고 나오는 발표자도 많습니다. 참여한 사람들이 초대받은 커널 메인테이너기 때문이죠. 다만 2015년부터는 kernel summit 을 다른 이벤트와 함께 열고, 함께 열린 이벤트의 참가자들이 참여할 수 있게 하고 있습니다. 덕분에 더 많은 토론이 가능해졌죠.\n근데 또 덕분에 너무 많은 사람들이 참여하다보니 좀 토론의 질이 떨어진다고 생각했는지, 올해부터는 kernel summit 이 technical summit 과 maintainer summit 으로 나뉘었습니다. technical summit 은 기존의 kernel summit 처럼 개방 형태로 진행하고 maintainer summit 은 메인테이너 중에도 메인테이너만 모아서 기존처럼 폐쇄된 초대 형식으로 진행합니다. 누굴 초대해야 하나 기준에 대해서도 많은 토론이 있었습니다. 최종적으로는 약 30명만 초대해서 진행했다더군요. maintainer summit 은 마지막날에 진행되었습니다.\n![foo] (/img/osse_05/9.jpg)\n한 세션이 끝나고 정리중인 모습. 유명한 메인테이너들이 많이 보입니다.\n![foo] (/img/osse_05/10.jpg)\n차려진 스폰서들의 부스를 돌아다니며 각 부스에서 사인을 받아 빙고를 두개 이상 만들어 제출한 사람들에 대해 추첨을 통해 선물을 주는 이벤트가 진행되고 있었습니다. 그렇잖아도 부스 방문하는거 좋아하는 제게는 아주 제격인 이벤트죠! 사정이 있는건지 열리지 않은 부스도 있었기에 모두 사인을 채우지는 못했지만 열린 부스는 하나도 빼놓지 않고 모두 돌아다니며 사인을 받았습니다.\n![foo] (/img/osse_05/11.jpg)\n오후에 있던 세션 중 하나로 John Corbet 의 주최로 커널 개발자들과의 토론 시간이 있었습니다. 메일링 리스트에서 보던 이름의 주인들을 이렇게 직접 보니 반갑더군요. 말미에 테스트 어떻게 하느냐고 질문도 던졌는데, 다들 다양한 방법으로 테스트를 하고 계시더군요. 특히 인텔의 자동 테스트 bot 이 유용하게 사용되고 있는 것 같더군요. 커뮤니티를 위한 큰 기여인 것 같습니다.\n![foo] (/img/osse_05/12.jpg)\n어제는 이브닝 이벤트인 career fair 에서 술이 무제한으로 계속 나오기에 한잔씩 마시며 회사에서 오신 분들이랑 농담 따먹기 하고 기술적 이야기도 하면서 두시간이 넘게 놀았는데, 오늘의 이브닝 이벤트는 좀 애매합니다. 술도 맥주 한잔밖에 안줘요! :\u0026rsquo;( 그래서 그런지 좀 일찍 이브닝 이벤트가 끝났습니다. 덕분에 어제보다 꽤 일찍 숙소에 돌아와 버리게 되었습니다. 이 기회에 첫날 아쉬웠던 프라하 구경을 밤중에 다시 나와봤습니다.\n![foo] (/img/osse_05/13.jpg)\n한결 여유가 생겨서 그런지 이런저런 이국적 느낌 나는 가게들도 둘러볼 수 있어 좋았습니다. 여기는 뭔가 나무로 만든 물건들을 전문으로 판매하는 것 같던데 신기한 물건들이 많더군요.\n![foo] (/img/osse_05/14.jpg)\n체코는 꼭두각시 인형이 유명하다죠? 하나 기념으로 사고 싶었고 가격도 꽤 저렴했지만 사면 둘곳도 없어서 그냥 나왔습니다.\n![foo] (/img/osse_05/15.jpg)\n그렇다 해도 멀리까지 걸어갈 시간도 안되고 해서 그냥 카를교[1]에 다시 왔습니다. 다시 봐도 아름답네요.\n![foo] (/img/osse_05/16.jpg)\n![foo] (/img/osse_05/17.jpg)\n오늘의 마무으리는 마트에서 산 소세지와 Kozel 맥주로. 소세지 가격이 한국 돈으로 단돈 5백원. 우리나라면 천하장사 얇은거 하나 먹을까 말까한 가격인데 실하고 뽀드득거리는 식감에 육즙도 많더군요. 프라하 물가 아주 칭찬합니다.\nReferences [1] https://en.wikipedia.org/wiki/Charles_Bridge\n","permalink":"https://sjp38.github.io/posts/ko/osse2017_05/","summary":"컨퍼런스 둘째날부터는 kernel summit track 이 시작됩니다. 이번 컨퍼런스 참가는 아무래도 kernel summit 에서의 시끄럽고 정신없는 토론에 참여하고 싶기 때문이었기에 오늘부터가 제게는 가장 재밌는 시간입니다.\n![foo] (/img/osse_05/1.jpg)\n아침 일찍 일어나 컨퍼런스 장소로 출발합니다. 10명이 함께 묵는 방을 사용하고 있기에 일찍 일어나지 않으면 샤워를 제시간에 하기 어려우므로 조금 일찍 일어났습니다.\n![foo] (/img/osse_05/2.jpg)\n![foo] (/img/osse_05/3.jpg)\n![foo] (/img/osse_05/4.jpg)\n일찍 출발한 만큼 일찍 도착. 아직 부스에 사람도 없고 조용하네요. 한동안 부스 한켠에 준비된 휴식 공간에 앉아 커널 메일링 리스트도 읽고 코드도 보고 했습니다.","title":"OSSummit 2017 Attendence - 05"},{"content":"드디어 컨퍼런스 첫날입니다. 아침 8시부터 아침식사와 등록이 시작되므로, 7시에 숙소에서 나왔습니다.\n![foo] (/img/osse_04/1.jpg)\n어제는 날이 흐리더니, 오늘은 비도 옵니다. 우산을 챙겨 나옵니다. 그래도 어제 미리 학회장에 들렀던 덕에 길을 헤매지 않고 찾아갈 수 있었습니다.\n![foo] (/img/osse_04/2.jpg)\n빗길을 따라 한참을 걸어서 도착했습니다.\n![foo] (/img/osse_04/3.jpg)\n![foo] (/img/osse_04/4.jpg)\n도착하니 7시 반 정도. 공식 스케쥴은 8시부터 시작이라 아직 한산합니다. 스폰서 부스도 아직 준비중인 곳이 많고, 아직 준비가 덜된 곳도 많습니다. 돌아다니며 인사도 하고 간단한 스몰토크도 하면서 시간을 보냈습니다. 만나면 \u0026ldquo;how are you?\u0026rdquo; 하고 간단한 이야기를 시작할 수 있는 서구문화는 개인적으로 참 맘에 드는 문화입니다.\n![foo] (/img/osse_04/5.jpg)\n아침식사입니다. 체제비는 지원받지 못하기에 이런걸로 끼니를 잘 때워야 합니다.\n![foo] (/img/osse_04/6.jpg)\n키노트가 시작되었습니다. 오랜만의 리눅스 파운데이션 행사라 짐 젬린의 반가운 얼굴도 보고 좋았네요.\n![foo] (/img/osse_04/7.jpg)\n키노트가 끝나고 커피 타임에 나온 간식. 믿고 먹는 연어가 올라간 샌드위치입니다. 요런게 가볍게 먹기 좋죠. 먹는중에 샌프란시스코에서 온 흑인 시스어드민 분께서 먼저 말을 걸어 주셔서 대화를 했는데 매우 즐거운 대화였습니다. 사진도 찍혔더군요. 하하.\n![foo] (/img/osse_04/8.jpg)\n세션은 CloudOpen Track, ContainerCon Track, Embedded Linux Conference, LinuxCon Track 등등으로 나뉘어 동시진행되었는데요. 아무래도 커널 프로그래밍을 하는 위주의 이야기는 LinuxCon 에 모여있더군요. 흥미로운 발표가 많았습니다.\n![foo] (/img/osse_04/9.jpg)\n오후 휴식시간. 사람이 정말 많더군요. 참고로 컨퍼런스는 지하부터 2층까지, 3층을 모두 빌려서 진행되었습니다.\n![foo] (/img/osse_04/10.jpg)\n오후 휴식시간엔 고기가 나왔습니다. 이걸로 오늘의 저녁을 때운다는 각오로 열심히 먹습니다\u0026hellip; 만, 사람이 원체 많아서 음식이 빨리 동납니다. 그래도 그간 컨퍼런스 다니면서 획득한 눈치밥으로 어떻게든 남은 음식을 찾아서 배를 채웠습니다.\n![foo] (/img/osse_04/11.jpg)\n![foo] (/img/osse_04/12.jpg)\n원래 저녁은 먹지 않으려 했는데, perf 등의 프로파일러를 개발하고 계신 송태웅님을 만나서 함께 저녁을 먹게 되었습니다. 배가 불러서 전 간단히 수프 한접시만. 타지에서 만난 한국 사람과 즐겁게 이야기 나누면서 맥주도 한잔 기울였습니다.\n식사 후에는 Career fair 이브닝 이벤트가 있어 또 가봤는데, 사진이 없네요. 아직 취업 준비중이 아니라 그냥 흥미로 들어가봤는데 유익한 정보가 많았습니다. 맥주 한잔 하면서 이야기 나누는 형태였는데, 덕분에 적당한 취기와 함께 농담 따먹기도 많이 하고 기술적인 이야기도 많이 나눴습니다.\n![foo] (/img/osse_04/13.jpg)\n이브닝 이벤트가 너무 즐거웠기에 돌아가는 길이 아쉬울 정도.\n![foo] (/img/osse_04/14.jpg)\n![foo] (/img/osse_04/15.jpg)\n그냥 돌아가기엔 시간이 좀 있기에 시내를 조금 둘러보면서 좀 걸었습니다. 프라하 역사도 복잡하고 해서 뭔가 와닿지는 않은 도시인데, 그래도 아름다움 하나는 인정할만 한 것 같습니다.\n","permalink":"https://sjp38.github.io/posts/ko/osse2017_04/","summary":"드디어 컨퍼런스 첫날입니다. 아침 8시부터 아침식사와 등록이 시작되므로, 7시에 숙소에서 나왔습니다.\n![foo] (/img/osse_04/1.jpg)\n어제는 날이 흐리더니, 오늘은 비도 옵니다. 우산을 챙겨 나옵니다. 그래도 어제 미리 학회장에 들렀던 덕에 길을 헤매지 않고 찾아갈 수 있었습니다.\n![foo] (/img/osse_04/2.jpg)\n빗길을 따라 한참을 걸어서 도착했습니다.\n![foo] (/img/osse_04/3.jpg)\n![foo] (/img/osse_04/4.jpg)\n도착하니 7시 반 정도. 공식 스케쥴은 8시부터 시작이라 아직 한산합니다. 스폰서 부스도 아직 준비중인 곳이 많고, 아직 준비가 덜된 곳도 많습니다. 돌아다니며 인사도 하고 간단한 스몰토크도 하면서 시간을 보냈습니다.","title":"OSSummit 2017 Attendence - 04"},{"content":"OSSummit 등록도 마쳤고, 남은 하루는 프라하 성 쪽을 둘러보기로 했습니다. 내일부터는 OSSummit 발표를 아침부터 오후까지 들어야 하므로, 프라하 관광을 해가 떠있을 때 하는건 오늘이 마지막이니 부지런히 걸어야 합니다. 어떻게 생각해 보면 꽤 강행군이기도 하고, 아침 일찍 도착하길 다행이다 싶습니다.\nVltava[1] ![foo] (/img/osse_03/4.jpg)\nOSSummit 컨퍼런스 회장인 힐튼 프라하 호텔은 프라하 시내의 동북쪽에 위치해 있어서 조금만 걸으면 아침에 심카드 사고 나서 걸었던 블타바 강이 나옵니다. 아까 지나갔던 코스지만 한번 더 걸어가기로 합니다.\n![foo] (/img/osse_03/5.jpg)\n프라하에 있는 동안 날씨가 계속 흐렸습니다. 해가 뜬걸 본적이 많지 않군요. 햇빛에 약한 편이라 다행이기도 하지만 맑은 날씨면 더 멋진 모습을 볼 수 있을 것 같아 아쉬웠습니다.\n![foo] (/img/osse_03/6.jpg)\n블타바 강에는 백조 등의 새가 꽤 많습니다. 암스테르담에서도 느낀거지만 백조는 크기가 참 큽니다. 백조 왕자 이야기에서 왕자들이 백조가 된다는 상상은 그 크기에서 비롯된 거 아닐까 하는 실없는 생각도 해봅니다.\n![foo] (/img/osse_03/7.jpg)\n블타바 강에는 유람선도 많이 다닙니다. 강 건너편의 풍경과 잘 어울립니다.\n![foo] (/img/osse_03/8.jpg)\n아침에는 여기서 블타바 강을 떠났지만, 이번엔 유명한 다리인 카를교를 지나 프라하 성까지 갈 계획이므로 강변을 따라 더 걸어갑니다.\n![foo] (/img/osse_03/9.jpg)\n뭔지 모를 조형물도 있는데 가이드가 사람들 모아놓고 설명하고 있는걸 보면 뭔가가 있나봅니다.\nCharles Bridge[2] ![foo] (/img/osse_03/10.jpg)\n저멀리 카를교가 보이기 시작합니다.\n![foo] (/img/osse_03/11.jpg)\n![foo] (/img/osse_03/12.jpg)\n드디어 카를교에 다왔습니다. 카를교는 1357년 카를 5세의 명령으로 착공, 15세기 초에 완성된 블타바강의 다리입니다. 다리의 길이는 총 520m 로, 프라하 성과 구시가지를 연결하고 있으며, 여러 아름다운 동상들이 다리 위에 있어서 동상들의 다리라고 부르는 사람들도 있는 것 같습니다. 동상들은 원본은 박물관에 모셔다 두었다고 하고, 현재 다리 위에 있는 건 모조품이라고 하는 것 같더군요. 프라하에서 가장 유명한 관광지 중 하나라고 할 수 있는 것 같습니다.\n![foo] (/img/osse_03/13.jpg)\n이런 느낌의 동상들이 있습니다. 종교가 있으면 좀 더 다른 느낌으로 프라하를 즐길 수 있었을지도 모르겠습니다. 실제로 프라하는 종교적 의미가 많이 있는 도시 같더군요. 하지만 저랑 종교는 별로 연이 없어서\u0026hellip;\n![foo] (/img/osse_03/14.jpg)\n이 동상은 어떤 규칙을 따라 만지면 어떤 소원을 이뤄준다고 적혀 있더군요. 프라하에 한번 더 올 수 있게 해준댔다\u0026hellip; 아직 프라하에 그정도 감정까진 싹트지 않았기도 하고 해서 딱히 만지진 않았습니다.\n![foo] (/img/osse_03/15.jpg)\n다리 위 곳곳에는 미술품, 기념품 등을 파는 노점들이 많이 있습니다. 가장 유명한 관광지 중 하나인 만큼 관광객들도 매우 많습니다.\n![foo] (/img/osse_03/16.jpg)\n긴 다리를 건너길 마무리 할쯤 보이는 모습입니다. 저기엔 어떤 사람들이 살까요? 여기 사는 사람들은 어떤 기분일까요?\n![foo] (/img/osse_03/17.jpg)\n다리를 건너오고나선 주욱 오르막길입니다. 오르막길을 따라 한참을 올라가면 프라하 성이 있습니다.\n![foo] (/img/osse_03/18.jpg)\n중간중간 아름다운 건축물이 계속 나옵니다. 걸그룹 보고 \u0026lsquo;예쁜애 옆에 예쁜애 옆에 예쁜애\u0026rsquo; 뭐 이런식으로 수식하는 것 같은데, 프라하는 \u0026lsquo;예쁜 건축물 옆에 예쁜 건축물 옆에 예쁜 건축물\u0026rsquo; 이라 해도 과언이 아닐 것 같습니다. 어디든 조금만 걷다보면 사진찍고 싶은 건축물이 나옵니다.\nPrague Castle[3] ![foo] (/img/osse_03/19.jpg)\n프라하 성으로 들어가기 직전 오르막길의 끝에서 걸어온 길을 바라보고 찍은 사진입니다. 올라오면서 크게 느끼지 못했는데 이렇게 보니 꽤 올라왔구나 싶더군요.\n![foo] (/img/osse_03/20.jpg)\n높은 지대인만큼 프라하 성에서는 프라하 시내를 바라볼 수 있습니다. 당연하게도 쌍안경도 있구요. 적당히 찍었더니 구글 포토가 이어붙여서 파노라마 사진을 만들어줬습니다. 날씨가 맑았다면 더 멋졌을텐데, 조금 아쉽기도 하지만, 전망이 멋졌습니다.\n![foo] (/img/osse_03/21.jpg)\n프라하 성은 매우 넓습니다. 일부 정원과 공간들은 입장권을 구매해야 들어갈 수 있습니다. 하지만 이번 프라하 여행의 주 목적은 관광이 아니기도 하고, 시간도 많지 않으므로 그런 곳은 스킵합니다.\nStrahov Monastic Brewery[4] ![foo] (/img/osse_03/22.jpg)\n제 목표는 어디까지나 스트라호프 수도원 맥주 양조장입니다. 스트라호프 수도원은 1142년에 건립된 수도원으로, 1628년엔 여기 양조장이 생겼습니다. 한동안 폐업한 적도 있다지만 지금은 다시 부활되어 긴 역사를 자랑하는 맥주 양조장이 지금까지도 영업을 하고 있게 된겁니다. 솔직히 프라하의 역사와 문화가 좀 생경했는데, 이것만큼은 친숙하죠. 놓칠 수 없습니다.\n벌써 해가 지기 시작했습니다. 스트라호프 수도원 표지판을 따라 계속해서 걸어갑니다. 한참을 더 걸어야 합니다.\n![foo] (/img/osse_03/23.jpg)\n어김없이 오는길에 길을 잃고 헤맸습니다. 하마터면 전혀 다른 음식점에 들어갈 뻔 했습니다. 하지만, 드디어 스트라호프 수도원에 도착했습니다.\n![foo] (/img/osse_03/24.jpg)\n그리고, 양조장을 가리키는 표지판이 보입니다.\n![foo] (/img/osse_03/25.jpg)\n기다리고 기다리던 양조장입니다. 실내는 물론이고 실외에도 사람이 가득했습니다. 잠깐의 웨이팅을 거쳐 다른 테이블에 합석했습니다.\n![foo] (/img/osse_03/2.jpg)\n양조장에서 직접 만든 맥주가 3종이 있는 것 같습니다. Amber, Dark, 그리고 IPA. 호박은 좋아하지 않으므로 Dark 와 IPA 를 한잔씩, 그리고 안주로 야채 샐러드를 주문했습니다. 가장 싼 안주이긴 하지만, 맥주 포함해서 가격은 한국돈으로 2만원이 안됩니다. 프라하의 물가에 건배하며 맥주를 마셔봅니다.\n하지만 10월 말인데다 해가 이미 졌고 산위라 그런지 찬바람이 마구 들어옵니다. 오들오들 떨면서도 천천히 다 마셨습니다. 다 마시고 계산하려 하는데 맥주 더 마시겠냐고 하더군요. 맘같아서야 그러고 싶지만 추워서 \u0026ldquo;no thanks\u0026rdquo; 이야기 하고 나왔습니다.\nBack to Old Town of Prague ![foo] (/img/osse_03/26.jpg)\n![foo] (/img/osse_03/27.jpg)\n![foo] (/img/osse_03/1.jpg)\n해가 완전히 져서 돌아오는 길은 완전히 밤입니다. 프라하는 야경도 유명합니다. 돌아오는 길에 프라하 성에 다시 올라가 야경을 감상했습니다. 특히 블타바 강에 비치는 불빛이 멋지더군요.\n![foo] (/img/osse_03/28.jpg)\n곧바로 숙소로 돌아가기도 그러니 밤중의 프라하도 즐겨보기로 하고 구시가 거리를 천천히 거닐어 봅니다.\nFinish of the Day ![foo] (/img/osse_03/29.jpg)\n아쉽지만 숙소 도착. 낮에 봤던 노점들도 이제 영업을 종료하고 있습니다.\n![foo] (/img/osse_03/3.jpg)\n맥주가 유명한 곳인만큼 (호스텔 벽에도 써있습니다. 프라하는 맥주가 물보다 싸니까 맥주 많이 마시라고. 전 지역 주민의 충고를 잘 받아들입니다 하하), 체코에서의 매일밤 마무리는 맥주와 함께 해야겠다고 생각했습니다. 그래서 점심에 심카드 사면서 봐두었던 마트에 가서 소세지와 맥주를 사왔습니다. 소세지는 앞의 포스트에서 사진으로도 올려뒀던 소세지 진열대에서 사왔는데, 무게를 재고 가격표를 붙여야 하는데 이걸 해주는 여성분은 영어를 못하시는 것 같더군요. 바디랭귀지로 주문하는데 뭔가 짜증을\u0026hellip; 가장 저렴한 편인 소세지를 샀습니다. 한 조각에 한국돈으로 오백원 정도밖에 안합니다. 우리나라에서 오백원이면 천하장사 소세지 젓가락굵기만한거나 살텐데, 역시 체코 물가 리스펙트합니다. 소세지 맛은 좀 짠 편인데 전 짠걸 잘 먹기도 하거니와, 짠만큼 맥주를 더 마시면 덜 짭니다.\n체코하면 필스너라는 인식이 있는 것 같은데 저 염소 맥주라고도 불리는 Kozel 맥주도 유명하다고 하더군요. 왠지 염소가 맘에 들어 샀는데, 한국돈으로 천원이 안됩니다. 맛은 탁월.\n이렇게 호스텔 휴게공간에서 맥주에 소세지를 함께 하며 하루를 마무리 합니다.\n하루동안 새삼 느낀게, 한국인 여행객이 정말 많더군요. 한시간 이상 한국말 못들은 경우가 많지 않은 거 같습니다. 호스텔에서도 꽤 많은 한국인이 있어서 휴게 공간에서 맥주 마시는 사이에도 앞자리에 한국인 커플과 모녀가 이야기를 나누더군요.\n이제 내일부터 OSSummit 이 시작됩니다. 어떤 흥미진진한 세션들이 있을지, 어떤 재밌는 이벤트가 준비되어 있을지, 커널 커뮤니티에서 메일로만 만났던 커널 개발자들과 만나서 어떤 이야기를 나눌지 기대하며 잠자리에 들었습니다.\n[*] 이 다음 글부터는 OSSummit 이야기가 본격적으로 시작됩니다. 거꾸로, 프라하 여행 정보는 거의 없을 겁니다.\nReferences [1] https://ko.wikipedia.org/wiki/%EB%B8%94%ED%83%80%EB%B0%94_%EA%B0%95\n[2] https://en.wikipedia.org/wiki/Charles_Bridge\n[3] https://en.wikipedia.org/wiki/Prague_Castle\n[4] https://www.tripadvisor.com/Attraction_Review-g274707-d634219-Reviews-The_Strahov_Monastic_Brewery-Prague_Bohemia.html\n","permalink":"https://sjp38.github.io/posts/ko/osse2017_03/","summary":"OSSummit 등록도 마쳤고, 남은 하루는 프라하 성 쪽을 둘러보기로 했습니다. 내일부터는 OSSummit 발표를 아침부터 오후까지 들어야 하므로, 프라하 관광을 해가 떠있을 때 하는건 오늘이 마지막이니 부지런히 걸어야 합니다. 어떻게 생각해 보면 꽤 강행군이기도 하고, 아침 일찍 도착하길 다행이다 싶습니다.\nVltava[1] ![foo] (/img/osse_03/4.jpg)\nOSSummit 컨퍼런스 회장인 힐튼 프라하 호텔은 프라하 시내의 동북쪽에 위치해 있어서 조금만 걸으면 아침에 심카드 사고 나서 걸었던 블타바 강이 나옵니다. 아까 지나갔던 코스지만 한번 더 걸어가기로 합니다.","title":"OSSummit 2017 Attendence - 03"},{"content":"Immigration ![immigration] (/img/osse_02/14.jpg)\n먼저 공항에서 입국심사를 거쳐야 합니다. 한글 표지판이 많이 있어서 영어에 익숙지 않은 분들도 비교적 쉽게 적응할 수 있겠다 싶었습니다.\n제가 가장 많이 다녀온 외국은 미국인데요. 대한민국 여권 소지자는 미국에 갈 때 비자가 필요없지만 E-SATA 로 등록을 해야 하고, 언젠가부터 E-SATA 등록비도 몇만원 정도 생겼죠. 또, 미국은 입국심사가 왠지 날카롭다는 인상입니다. 입국할 때 입국심사 카드도 써야하고 여기 숙소 주소 등도 적어야 하고, 지문도 찍어야 하죠. 공항 보안검색대에선 투시카메라로 사진도 찍고. 그래도 뭐 간편하게 가는 편이라 생각했었습니다만 프라하 공항에서 생각이 바뀌었습니다. 대한민국 여권 소지자는 프라하에 갈때에도 비자가 필요없습니다. 입국심사를 위한 카드 작성도 없습니다. 입국심사관은 거의 아무것도 묻질 않습니다. 숙소가 어딘지도 알릴 필요 없고, 뭐하러 왔는지 꼬치꼬치 묻지도 않습니다. 지문도 찍지 않는군요. 정말 편하다는 인상을 받았습니다.\n![foo] (/img/osse_02/18.jpg)\n공항 사진입니다. 그렇게 크진 않네요. 아담한 크기의 공항입니다. 그래도 무료 와이파이도 잘 됩니다.\n프라하는 코룬이라는 단위의 통화를 사용합니다. 유로를 받는 곳도 있다고 하지만 왠만하면 코룬을 쓰는게 좋은 것 같습니다. 한국에서도 코룬 환전이 된다고 하는데, 급하게 오느라 미리 하지 못했습니다. 다른 여행객들도 프라하에서 직접 환전하는 경우가 많다고 하는군요. 공항 환전소는 환율이 좋지 않고 시내의 일부 환전소가 괜찮으므로, 공항에서는 시내 가는 교통비 정도만 환전하고, 시내의 추천 환전소에 가서 나머지를 환전하는게 좋다는 이야기가 많더군요. 일단 교통비와 심카드 살 돈을 생각해서 3만원 정도를 환전했습니다. 코룬 환율은 당시 1 코룬당 50원 정도. 수수료를 떼고 약 540 코룬이 제게 떨어졌습니다. 역시 공항 환전은 가성비가 좋지 않네요.\nTo The Hostel 이제 환전도 했으니 숙소로 이동을 해야겠습니다. 컨퍼런스 참가 지원 여부가 늦게 발표된 만큼 숙소도 늦게 잡았습니다. 하지만 특가로 나온 방이 있어 매우 저렴하게 구할 수 있었습니다. 외국에 혼자 나가면 호스텔을 예약하는 편입니다. 저렴한 가격에 각지의 여행객과 만날 수 있어 이득보는 느낌이거든요.\n사실 호스텔에 대한 처음 인상은 별로 좋지 않았습니다. 유럽 여행 가서 호스텔에서 변태 만나고 벼룩에 고생했다는 친구의 이야기도 있었고, 처음 이용했던 호스텔은 2014년에 Google I/O 가서 이용해 봤는데, 방도 엄청 좁고 시설이 열악했거든요. 하지만 두번째로 암스테르담에서 이용했던 호스텔 이후 인식이 완전 바뀌었습니다. 넓고 인테리어도 좋고 함께 방을 썼던 친구들도 유쾌해서 매우 즐거웠던 경험이었습니다.\n어쨌든 이번에 구한 숙소는 프라하 중심가에 위치한 호스텔. 그 가격에 이런 위치라니 시설이 얼마나 안좋길래 이렇게 나머지 조건이 좋은 걸까 걱정이 되기도 했습니다.\n![foo] (/img/osse_02/19.jpg)\n프라하에서는 버스, 지하철, 트램 등이 모두 하나의 교통권을 사용합니다. 교통권은 사용 시간대별로 가격이 매겨지며, 그 시간 내에는 환승이 모두 무료. 즉, 30분짜리 교통권을 사면 버스를 한대 타든 두대 타든 지하철을 갈아타든 30분 내에는 추가로 돈을 지불할 일이 없습니다. 전 119번 버스를 타고 나가서 지하철을 타고 시내로 이동할 계획입니다. 구글맵이 그렇게 추천했거든요. 구글맵은 약 40분 걸린다고 이야기 하는군요. 교통권 자판기에서 90분짜리를 뽑습니다. 32 코룬입니다. 한국돈으로 약 1,600원이군요.\n![foo] (/img/osse_02/20.jpg)\n뽑은 교통권입니다. 유효 시간이 90분이라고 적혀 있습니다.\n공항을 나서기전 마지막으로 무료 와이파이를 이용해 필요한 정보를 최대한 미리 검색해두고 폰에 다운로드 받아둡니다. 여길 나서면 숙소에 도착하기 전까지는 인터넷이 불가능하니까요. 심각한 길치인 저로썬 큰 모험입니다.\n![foo] (/img/osse_02/21.jpg)\n여행자들 가는길이 다 거기서 거기인지 여행자인 분들이 함께 움직입니다. 제가 프라하에 도착한 시각은 아침 9시 무렵. 전날 비가 왔는지 땅이 젖어있습니다. 일기예보로는 제가 머무르는 동안 계속 흐리고 때때로 비가 올 예정이더군요.\n프라하 버스 정류장은 모니터로 버스가 어디쯤 오고 있는지 자세히 표시됩니다. 한국 대중교통이 이런 시스템이 잘되어있기로 유명하다고 들었는데, 여긴 더 자세한 것 같다는 인상을 받았습니다.\n![foo] (/img/osse_02/22.jpg)\n도착한 버스를 탔습니다. 버스에 타면 승차권을 넣는 기계가 있는데, 거기 집어넣으면 위 사진처럼 집어넣은 시간이 찍힙니다. 표는 중간중간 검표원이 검사를 하게 되는데, 이 때 여기 찍힌 시간과 검사 시각 사이의 시간이 표에 적힌 유효시간 내인지를 보게 된다고 합니다. 버스기사는 딱히 표를 보거나 하지 않습니다. 신뢰를 기반으로 운영되는 시스템인거죠. 검표원을 만나진 못했습니다만, 무임승차 같은 짓은 하지 않기로 합시다.\n![foo] (/img/osse_02/23.jpg)\n![foo] (/img/osse_02/24.jpg)\n버스에서 내리고 지하철 타는 길도 여행객들이 다들 우루루 움직여서 그냥 따라가도 되었습니다. 지하철도 상당히 노선이 간단해서 큰 어려움 없이 승차할 수 있었습니다.\n![foo] (/img/osse_02/25.jpg)\n지하철에서 내려 땅위로 나왔습니다. 길치가 인터넷으로부터의 실시간 도움 없이 숙소를 찾아야 하는 시간이 왔습니다. 숙소까지는 걸어서 3분 거리인데 역시 헤맸습니다.\n![foo] (/img/osse_02/26.jpg)\n길을 헤매는 와중에도 신기한 구경거리는 있습니다. 역시 프라하, 역시 시내 중심지입니다. 지나가는 관광객도 무척 많습니다. 단체 관광객, 가이드를 따라 투어중인 관광객도 많더군요.\n![foo] (/img/osse_02/27.jpg)\n그래도 어찌어찌 숙소를 찾았습니다. 호스텔이 쇼핑몰처럼 생긴 건물 안에 있더군요. 의외의 위치선정이라 많이 헤맸습니다. 체크인 수속은 먼저 밟을 수 있지만, 방 청소 시간이 남아있어서 실질 체크인은 오후 두시부터 가능합니다. 등록데스크에 짐을 맡길 수 있으므로, 짐을 맡겨두고 체크인 시간까지 좀 돌아다니기로 합니다. 하지만 먼저 등록데스크의 무료 와이파이에 붙어 최대한 주변 정보를 받아둡니다. 일단 다음 목표는 시내 통신사 대리점에 가서 심카드를 구매하는 겁니다.\nSIM Card for the Internet ![foo] (/img/osse_02/28.jpg)\n거리에선 인터넷이 안되지만 숙소 위치는 파악했고 숙소까지 가면 인터넷이 됩니다. 조금 마음이 편안해지니 주변 경치도 눈에 들어옵니다. 프라하에서 심카드를 구매할 수 있는 통신사로 보다폰, O2, 그리고 T-mobile 이 있습니다만, T-mobile 을 많이들 추천하더군요. 미국 여행 시에도 T-mobile 에서 구매해서 나름 편하게 사용했으므로 T-mobile 대리점을 찾아갔습니다. 그런데, 아뿔싸. 일요일이라 쉬는 날이네요. 숙소로 돌아가 다시 인터넷 검색을 하니 좀 떨어진 위치에 큰 쇼핑몰이 있고 거기에 T-mobile 대리점이 있습니다. 조금 먼 길이라 인터넷 없이 찾아가려니 걱정되지만 일단 출발합니다.\n![foo] (/img/osse_02/29.jpg)\n![foo] (/img/osse_02/30.jpg)\n그래도 다운받아진 구글 지도가 있고 GPS 가 있으니 생각보다 어렵지 않게 길을 찾아갈 수 있었습니다. 점원 분께 여행자고 심카드를 구매하고자 한다고 하니 능숙하게 안내를 해주시는군요.\n\u0026ldquo;데이터가 필요한가요? 문자는 필요한가요?\u0026rdquo; \u0026ldquo;전 데이터만 있으면 되요!\u0026rdquo;\n통화, 문자 없이 1 GB 데이터를 LTE 속도로 30일간 사용할 수 있는 심카드를 약 200 코룬에 구매했습니다. 1 GB 데이터가 너무 많은거 아닌가 싶고 국내에서도 3G 쓰는데 LTE 가 필요한가 싶지만 이게 가장 저렴한 버전이라고 하시는군요. 생각해보면 제가 쓰는 폰인 넥서스5 는 LTE 지원함에도 국내에선 3G 데이터를 썼는데, 외국에서 오히려 LTE 써보네요. 아이러니\u0026hellip;\n개인적으로 외국 나갈때 자주 사용하는 선불심 판매소에서 파는 데이터 유심은 무제한 데이터에 대략 만원 후반대 가격인데, 200 코룬이면 약 만원이니 가성비도 나쁘지 않습니다. 심카드를 꽂고 폰을 재부팅 합니다. 도브리덴! 하는 안내문자가 날아오고 (도브리덴은 체코어로 인사말이라고 합니다), 인터넷이 됩니다. 할렐루야!\nLocal Foods of Prague 대리점을 나오니 바로 앞에 식료품 마트가 있습니다. 많은 외국은 인건비가 비싸서 그런지 음식점에서 사먹는 비용은 비싸지만 식재료는 무척 저렴해서, 직접 요리해 먹으면 우리나라보다도 훨씬 싸게 식사를 해결할 수 있는 경우가 많습니다. 때문에 저는 외국에 나오면 식료품 마트에서 먹을거리를 자주 사먹습니다. 여기가 제 식사의 대부분을 충당할 가능성이 큰 곳이므로 한번 둘러봤습니다.\n![foo] (/img/osse_02/2.jpg)\n체코하면 맥주입니다. 체코는 독일을 제치고 일인당 맥주 소비량이 가장 많은 나라입니다. 필스너 우르켈을 만든 나라이기도 하구요. 물보다도 맥주가 싼 가격인 것도 특징입니다. 정말 쌉니다. 대부분의 맥주가 한병에 한국돈으로 천원을 넘지 않습니다.\n![foo] (/img/osse_02/1.jpg)\n맥주하면 또 소세지죠! 소세지도 저렴합니다. 여행중 매일밤 여기서 맥주와 소세지를 사서 맥주 한잔씩 하며 하루를 마무리 했습니다.\nSightseeing before Check-in 이제 급한 불은 모두 껐습니다. 숙소도 찾았고, 인터넷도 되고. 하지만 아직도 오후 12시를 조금 넘긴 시간. 체크인도 오후 두시부터이고, OSSummit pre-registration 도 오후 세시부터 시작입니다. 일단 무작정 시내를 돌아다녀 보기로 하고 걸었습니다.\n![foo] (/img/osse_02/3.jpg)\n걷다보니 블타바강이 나왔습니다. 강 건너편으로 프라하 성이 아름답게 보입니다. 강변으로 산책로도 조성되어 있고, 강에 선박 레스토랑도 많습니다. 일단 강변을 따라 걸어봅니다.\n![foo] (/img/osse_02/4.jpg)\n천천히 걷다보니 좀 시간이 흐릅니다. 슬슬 체크인 시간이 다가옵니다. 강변에서 빠져나와 숙소쪽으로 천천히 걸어갔습니다. 어디로 걷는지도 모르고 그냥 걸었는데 여기저기 멋진 게 많습니다. 알고보니 여기가 중심지더군요.\n![foo] (/img/osse_02/5.jpg)\n![foo] (/img/osse_02/6.jpg)\n광장입니다. 암스테르담에 갔을때 봤던 중앙 광장이 떠올랐습니다. 사람도 많고 관광객도 많고 볼거리도 많습니다.\n![foo] (/img/osse_02/7.jpg)\n나름 유명한 시계 같더군요. 정각엔 인형들이 튀어나와서 뭔가 하고 들어간다는데 이게 몇백년된 시계라고 했던 것 같습니다. 정각에 여기 있질 않아서 인형들이 움직이는건 보지 못했습니다.ㅜㅜ\n![foo] (/img/osse_02/8.jpg)\n길치의 특성 중 하나는 자꾸 샛길로 빠지려는 본능이 있다는 점 아닐까 싶습니다. 반듯이 숙소로 가다가도 자꾸 옆길이 보이니 들어가보고 싶습니다. 장점은 그렇게 발견하는 재미진 곳이 많다는 거죠. 그렇게 발가는대로 걸어보니 재래시장 같은 곳이 나타났습니다. 먹을거리도 팔고, 꼭두각시 인형도 팔고, 기념품도 많이 있습니다.\n![foo] (/img/osse_02/9.jpg)\n기내식을 많이 먹었지만 맛깔나게 담아둔 과일이 맛있어 보이더군요. 그래도 돈이 별로 없어서 그냥 참고 지나갑니다.\nBack to the Hostel ![foo] (/img/osse_02/10.jpg)\n드디어 숙소 근처에 도착. 곧 체크인 시간입니다. 잠깐 숙소 근처 거리를 천천히 둘러봤습니다. 이제야 정신차리고 보니 숙소는 바츨라프 광장의 아래쪽에 있었더군요. 그래서인지 숙소 건물 앞 길거리에는 노점이 여럿 있고 관광객들이 거기서 먹을거리와 맥주를 즐기고 있었습니다. 시선과 후각을 강렬하게 끌어당긴 것 중 하나는 이 장작불에 빙글빙글 돌아가며 구워지는 고기! 체코 전통 요리 중 하나인 것 같은데, 주문하면 곧바로 칼로 고기를 일부분 썰어서 빵과 함께 주는 시스템 같습니다. 여기다 맥주까지 함께 판매하니, 안먹고 버티기 힘들정도로 침이 줄줄 흐르더군요. 그래도 전 환전한 돈도 얼마 안되고 해서 참았습니다.\n![foo] (/img/osse_02/11.jpg)\n어쨌든 드디어 체크인 시간이 되었으니 숙소로 들어갑니다. 제가 예약한 방은 10인 혼성 도미토리 (dormitory) 룸. 위 사진처럼 다섯개의 이층침대가 있습니다. 일찍 체크인한 덕인지 제가 첫번째인가봅니다. 창가 1층 자리를 선점했습니다. 어쩌면 이 넓은 방을 혼자 쓸수도\u0026hellip;? 했는데 밤에 다들 체크인 하더군요. 하하. 어쨌든 아주 넓진 않지만 좁지 않고 깨끗했습니다. 대만족! 잠깐 인터넷도 하고 간단히 세수도 하고, 이제 뭐할지 계획을 짜봅니다.\n내일부터 OSSummit 시작이니, 낮에 관광을 하는건 오늘이 마지막입니다. 일단 나가서 좀 돌아다녀보고, 컨퍼런스 회장으로 이동해 pre-registration 도 하고, 이어서 프라하 성을 돌아보기로 계획했습니다.\nJourney to OSSummit Pre-registration ![foo] (/img/osse_02/12.jpg)\n![foo] (/img/osse_02/13.jpg)\n가장 먼저 숙소 바로 앞의 바츨라프 광장을 둘러봤습니다. 약간 경사가 져 있어서 바츨라프 광장 끝의 동상 앞에서 뒤를 돌아보면 프라하 시내가 보이는 경치가 좋더군요. 바츨라프 광장은 서울 광화문 광장과 비슷한데, 민주화 관련 운동도 있었다고 하니 촛불이 가득 채웠던 광화문과 더욱 비슷한 느낌이 들었습니다.\n근데 프라하랑은 개인적으로 딱히 접점이 없어서일까요, 역사라던지가 머리에 잘 들어오지 않습니다. 암스테르담 같은 경우 민주화, 다양성 존중 등이 발전되어 있고 파이썬 창시자인 귀도 반 로썸 아저씨의 고향이라 그런지 꽤 하나하나가 와닿았는데 말이죠. 그래선지 어디가 어딘지도 잘 모르겠고 그냥 헤매듯이 정처없이 거닐었습니다. 그래도 어딜 가든 다 아름답고 멋집니다. 건축물들이 예술입니다. 근데 그래서 더 특색을 모르겠더군요. 저랑 프라하는 잘 안맞나봐요.\n![foo] (/img/osse_02/31.jpg)\n그렇게 걷다보니 만난 작은 공원. 공원을 원래 좋아하는터라 반가웠습니다. 공원의 반대편은 프라하 중앙역에 연결되어 있더군요.\n![foo] (/img/osse_02/32.jpg)\n컨퍼런스 회장으로 이동 중 만난. 뭔지 모를 곳. 낡은 건물이었는데 그 안은 천장이 뚫려있고 기차같은게 운행되고 있더군요. 뭔지 모르겠는데 멋졌습니다.\n![foo] (/img/osse_02/17.jpg)\n마침내 도착한 컨퍼런스 회장! 힐트 프라하입니다. 정식 일정은 내일부터지만 오늘도 미리 등록을 할 수 있습니다. 내일 와서 줄서긴 싫기도 하고, 미리 준비중인 회장을 구경하고 싶어서 왔습니다.\n![foo] (/img/osse_02/33.jpg)\n등록 부스입니다. 아주 한산할 줄 알았는데 생각보다 사람이 있더군요.\n![foo] (/img/osse_02/15.jpg)\n등록 완료했습니다. 이 네임택 하나가, 그렇게 갖고 싶었습니다. 크흑.\n빨간 딱지는 선물 증정 부스에 제출해서 티셔츠 하나, 그리고 리셉션 때 맥주와 바꿀 수 있는 쿠폰을 받을 수 있게 되어 있더군요.\n![foo] (/img/osse_02/16.jpg)\n스폰서 기업들이 부스를 차리고 있는 분주한 모습도 볼 수 있었습니다. 내일은 이곳이 어떻게 꾸며질까 미리 어느정도 예상도 할 수 있었습니다.\n이제 어느덧 오후 4시가 되어갑니다만, 아침 9시부터 움직였으니 꽤 많은 일이 있었습니다. 일단 여기서 여행기의 두번째 포스트를 마무리 합니다.\n","permalink":"https://sjp38.github.io/posts/ko/osse2017_02/","summary":"Immigration ![immigration] (/img/osse_02/14.jpg)\n먼저 공항에서 입국심사를 거쳐야 합니다. 한글 표지판이 많이 있어서 영어에 익숙지 않은 분들도 비교적 쉽게 적응할 수 있겠다 싶었습니다.\n제가 가장 많이 다녀온 외국은 미국인데요. 대한민국 여권 소지자는 미국에 갈 때 비자가 필요없지만 E-SATA 로 등록을 해야 하고, 언젠가부터 E-SATA 등록비도 몇만원 정도 생겼죠. 또, 미국은 입국심사가 왠지 날카롭다는 인상입니다. 입국할 때 입국심사 카드도 써야하고 여기 숙소 주소 등도 적어야 하고, 지문도 찍어야 하죠. 공항 보안검색대에선 투시카메라로 사진도 찍고.","title":"OSSummit 2017 Attendence - 02"},{"content":"![pargue!] (/img/osse_01/8.jpg)\nOpen Source Summit Europe 과 Embedded Linux Conference Europe, 그리고 Annual Kernel Summit 이 합동으로 열린 프라하에 다녀왔습니다. 이에 대한 기록을 남겨봅니다.\nThe Event 리눅스 재단에서는 다양한 컨퍼런스를 개최합니다. 2015년까지는 한국에서도 Korea Linux Forum 이라는 행사를 매년 열었죠. 특히 2015년에는 커널 서밋도 함께해서 특히 특별했던 기억입니다. 이런 이벤트들 중에서도 가장 큰 이벤트는 오픈소스 서밋이 아닐까 싶습니다. 이 이벤트는 기존의 리눅스콘 등 행사들이 합쳐진 행사입니다. 가장 큰 이벤트가 오픈소스 서밋이라면 가장 중요한 행사는 커널 서밋이라 할 수 있지 않을까 싶습니다. 커널 서밋은 커널 개발에 중요한 역할을 하는 메인테이너들이 모여 현재 개발 상의 이슈를 공유, 해결책을 토론하고 차후 개발을 위한 회의를 하는 자리입니다. 당연하지만 토발즈도 이 자리에 함께 합니다. 중요 개발자들끼리만 모이는 자리인 만큼 초대 형식으로만 참가할 수 있었는데, 2015년부터는 다른 이벤트와 함께 개최되어서 초반 몇일은 함께 열린 이벤트의 참가자들도 토의에 참여할 수 있게 되었습니다.\n올해는 프라하에서 오픈소스 서밋 유럽지역 행사와 임베디드 리눅스 컨퍼런스 유럽지역 행사, 그리고 커널 서밋이 함께 열렸습니다. 당연히 최신 정보를 얻고 다른 개발자들과 네트워킹을 할 수도 있고, 제 프로젝트인 GCMA 를 홍보할 수도 있는 기회이기에 꼭 참여해야겠다 싶었습니다.\nKOSSLAB 에서는 오픈소스 개발자들의 해외 컨퍼런스 참여를 지원합니다. 자원이 한정되어 있는 만큼 지원이 좀 까다롭습니다. 지원 신청은 발표자 또는 초대장을 받은 사람에 한정되며, 지원은 비행기표 비용이며, 발표자의 경우 호텔비 이틀치를 추가로 지원합니다. 즉, 컨퍼런스 등록비, 숙식을 위한 비용은 각자 부담해야 합니다. 지원한 모두를 지원하는 것도 아니고 내부 심사가 있습니다. 그래도 지원을 받는데 성공하면 매우 큰 도움이 되죠.\n저는 초대장을 받아 신청하게 되었는데, 지원 여부 결과가 꽤 늦게까지 발표되지 않았습니다. 초조하게 기다리고 있다가 어차피 각자 결제 후 차후 영수증을 통한 증빙을 통한 지원이라 전해듣고, 에라 모르겠다 하고 자비로 비행기표 등을 모두 구매했는데 다음날 아침, 지원을 해주기로 결정했다는 전화를 받았습니다. 다시 한번 KOSSLAB 에 감사한 마음을 전합니다 :D\nTo Incheon Airport ![Incheon Airport] (/img/osse_01/1.jpg)\n토요일 밤 인천 공항에서 출발해 이스탄불에서 한번 환승하고 프라하로 가는 터키항공 편을 구매했습니다. 빨래를 하고 짐을 싸며 낮시간을 보냈습니다. 인터넷 연결이 어려울 테니 볼만한 영화도 다운받고, 읽을거리도 인쇄해두고, 참여/관리중인 프로젝트들의 소스코드도 랩톱 안에 최신으로 땡겨둡니다. 해가 질 무렵, 공항으로 출발했습니다. 인천공항 가는길은 지하철을 사용합니다.\nTo Istanbul 알고보니 터키항공은 서비스가 좋기로 유명한 모양입니다. 상도 받았다는 것 같더군요.\n출발한 후에 승객들에게 파우치를 하나씩 주는데, 열어보면 안대와 슬리퍼, 귀마개, 칫솔, 립밤 등이 들어있습니다.\n![to_istanbul] (/img/osse_01/2.jpg)\n좌석에 제공되는 서비스도 좋은 편입니다. 의자에 USB 가 있어 핸드폰과 태블릿 등을 충전할 수 있고고, 좌석마다 달린 디스플레이를 통해 영화, 뉴스, 기내정보, 음악 등을 즐길 수 있습니다. 한글 자막이 제공되진 않지만 한국어 더빙 영화는 일부 있는 것 같습니다. 영어 자막은 대부분의 영화가 제공하므로 대충 누가 나쁜놈이고 착한놈인지 정도는 알아들을 수 있었습니다.\n요즘 비행기는 다들 이정도는 제공하는 것 같기도 하지만, 제 경우는 출장 때 외에는 비행기 타는 일이 거의 없고, 출장갈 때마다 가능한 저렴한 표를 구하는 편이다보니 (내가 힘들게 가는만큼 다른 친구들이 이득보겠거니 해서 그러는데, 굳이 그럴 필요는 없나 싶기도 하군요.) 좋은 비행기 타본 적이 없어서 디스플레이가 있는 비행기는 대략 3년만에 처음입니다. 감동의 눈물이 흘렀습니다.ㅜㅜ 근데 디스플레이 없는 비행기에 이미 너무 익숙해졌는지 영화를 잘 안보게 되는군요.\n![to_istanbul_first_food] (/img/osse_01/3.jpg)\n첫번째 기내식은 비빔밥과 파스타가 제공되었습니다. 한국에서 출발하는 만큼 비빔밥을 준비한 준비성은 좋지만 개인적으로 외국 여행중에는 외국 음식을 먹자는 편이고 고기류를 좋아하는 편이라 파스타를 먹으며 눈물을 흘렸습니다. 신기한건 와인을 주문하면 병째로 줍니다. 하지만 작은 병이라 컵 하나에 가득 따른 정도의 양과 비슷합니다. 한국계 항공사에서 주는것보단 많은 양이지만 델타 등의 미국계 항공사에서 주는 것과 비슷한 정도 같습니다.\n![to_istanbul_second_food] (/img/osse_01/4.jpg)\n내리기 전 제공되는 기내식은 오므라이스와 샌드위치입니다. 가볍게 먹기 좋았습니다.\n![istanbul_airport] (/img/osse_01/5.jpg)\n이스탄불 공항은 화려한 편이었습니다. 화장실은 좀 더러웠지만\u0026hellip; 특히 중간에 터키 아이스크림을 파는 가게가 있었는데, 고객을 놀려대며 즐거움을 주는 모습을 오프라인으로는처음 봤습니다. 신기하더군요. 아쉬운건 무료 와이파이가 없습니다. 정확히는, 있긴 한데 사용을 위해선 패스워드를 SMS 를 통해 받아야 합니다. 로밍을 켤 돈이 없어 그냥 버텼습니다. 환승 시간이 길지 않아 다행이었습니다.\n환승을 위해 게이트에 도착해 기다리는데 함께 기다리는 사람들 중 일부 한국 사람들이 게이트가 바뀌었다며 갑자기 뛰어갑니다. 확인해보니 정말로 바뀌어 있더군요. 이동하는 중에 이에 대한 내용이 뒤늦게 방송으로 나왔습니다. 외국인 분들은 뒤늦게 헐레벌떡 오시더군요. 저도 헐레벌떡이었지만.\n신기한게 게이트에서 여권 검사를 합니다. 덕분에 게이트에 들어가는데에도 줄이 생겼습니다. 머리가 길어 눈이 가려서 그런지 검사하는 분이 같은 사람 맞냐며 생일 등을 물어보는데 좀 긴장되더군요. 그래도 큰 문제 없이 통과. 비행기는 출발합니다.\nTo Prague ![to_prague] (/img/osse_01/6.jpg)\n환승 비행기도 터키항공. 이번 여행은 계속 터키항공만 이용합니다.\n![to_pargue_food] (/img/osse_01/7.jpg)\n두시간 가량의 짧은 비행이지만 기내식이 나옵니다. 이번에도 오므라이스와 샌드위치.\n![pargue!] (/img/osse_01/8.jpg)\n먹고 놀고 책도 읽고 하다보니 프라하에 도착합니다.\n","permalink":"https://sjp38.github.io/posts/ko/osse2017_01/","summary":"![pargue!] (/img/osse_01/8.jpg)\nOpen Source Summit Europe 과 Embedded Linux Conference Europe, 그리고 Annual Kernel Summit 이 합동으로 열린 프라하에 다녀왔습니다. 이에 대한 기록을 남겨봅니다.\nThe Event 리눅스 재단에서는 다양한 컨퍼런스를 개최합니다. 2015년까지는 한국에서도 Korea Linux Forum 이라는 행사를 매년 열었죠. 특히 2015년에는 커널 서밋도 함께해서 특히 특별했던 기억입니다. 이런 이벤트들 중에서도 가장 큰 이벤트는 오픈소스 서밋이 아닐까 싶습니다. 이 이벤트는 기존의 리눅스콘 등 행사들이 합쳐진 행사입니다. 가장 큰 이벤트가 오픈소스 서밋이라면 가장 중요한 행사는 커널 서밋이라 할 수 있지 않을까 싶습니다.","title":"OSSummit 2017 Attendence - 01"},{"content":"idle_page_tracking[1] is a simple, stupid toolbox for idle pages tracking. It can be used to get real working set size of a process.\nTools This section describes two tools in the box though more tools exists. You can get more description about each tool from the README in the repository[1].\nuserprog userprog is a sample synthetic workload for test of other tools. It interactively allocates and access specified pages in the allocated pages. After execution, it first asks how many pages to allocates. Once you type in how many pages to allocate, the program will repeatedly asks how many pages in the allocated pages you want to do access.\nwspages.sh Now you can calculate working set size of a process using the tools. To simplify the life even more, wspages.sh helps the complicated works. It requires pid, time interval, and target memory mapped regions as argument. The third argument can be ignored. In the case, it uses heap, stack, and anonymous pages as target memory region by default. If you give the arguments well, this tool will prints out number of pages accessed between the time interval. Simple example of usage and output is as below:\n$ sudo ./wspages.sh `pidof userprog` 1 [heap] 3 wspgstat.sh Like *stat programs (such as vmstat, iostat, \u0026hellip;), wspgstat.sh monitors and print out number of pages in working set of specific process repeatedly. It requires pid of target program, delay between idleness check, and target memory mapped regions as arguments. The third argument is optional and has default value as same as wspages.sh\u0026rsquo;s same argument. Simple example usage is as below:\n$ ./wspgstat.sh `pidof mysqld` 5 1 17448 9 21536 18 21659 Limitations The tools use idle page tracking feature of the Linux kernel[2] internally. It means that the tools work on Linux systems that idle page tracking feature is turned on. You can check whether your system turned on or off the feature by simply running the command below:\n$ if [ -d /sys/kernel/mm/page_idle ]; \\ then echo \u0026#34;ON\u0026#34;; else echo \u0026#34;OFF\u0026#34;; fi It also shares limitation of idle page tracking feature of the Linux kernel. It tracks only userspace pages on LRU list of the kernel.\nLicense GPL v3\nReferences [1] https://github.com/sjp38/idle_page_tracking\n[2] https://www.kernel.org/doc/Documentation/vm/idle_page_tracking.txt\n","permalink":"https://sjp38.github.io/posts/idle_page_tracking/","summary":"idle_page_tracking[1] is a simple, stupid toolbox for idle pages tracking. It can be used to get real working set size of a process.\nTools This section describes two tools in the box though more tools exists. You can get more description about each tool from the README in the repository[1].\nuserprog userprog is a sample synthetic workload for test of other tools. It interactively allocates and access specified pages in the allocated pages.","title":"Idle Page Tracking Tools"},{"content":"idle_page_tracking[1] is a simple, stupid toolbox for idle pages tracking. It can be used to get real working set size of a process.\nTools This section describes two tools in the box though more tools exists. You can get more description about each tool from the README in the repository[1].\nuserprog userprog is a sample synthetic workload for test of other tools. It interactively allocates and access specified pages in the allocated pages. After execution, it first asks how many pages to allocates. Once you type in how many pages to allocate, the program will repeatedly asks how many pages in the allocated pages you want to do access.\nwspages.sh Now you can calculate working set size of a process using the tools. To simplify the life even more, wspages.sh helps the complicated works. It requires pid, time interval, and target memory mapped regions as argument. The third argument can be ignored. In the case, it uses heap, stack, and anonymous pages as target memory region by default. If you give the arguments well, this tool will prints out number of pages accessed between the time interval. Simple example of usage and output is as below:\n$ sudo ./wspages.sh `pidof userprog` 1 [heap] 3 wspgstat.sh Like *stat programs (such as vmstat, iostat, \u0026hellip;), wspgstat.sh monitors and print out number of pages in working set of specific process repeatedly. It requires pid of target program, delay between idleness check, and target memory mapped regions as arguments. The third argument is optional and has default value as same as wspages.sh\u0026rsquo;s same argument. Simple example usage is as below:\n$ ./wspgstat.sh `pidof mysqld` 5 1 17448 9 21536 18 21659 Limitations The tools use idle page tracking feature of the Linux kernel[2] internally. It means that the tools work on Linux systems that idle page tracking feature is turned on. You can check whether your system turned on or off the feature by simply running the command below:\n$ if [ -d /sys/kernel/mm/page_idle ]; \\ then echo \u0026#34;ON\u0026#34;; else echo \u0026#34;OFF\u0026#34;; fi It also shares limitation of idle page tracking feature of the Linux kernel. It tracks only userspace pages on LRU list of the kernel.\nLicense GPL v3\nReferences [1] https://github.com/sjp38/idle_page_tracking\n[2] https://www.kernel.org/doc/Documentation/vm/idle_page_tracking.txt\n","permalink":"https://sjp38.github.io/posts/ko/idle_page_tracking/","summary":"idle_page_tracking[1] is a simple, stupid toolbox for idle pages tracking. It can be used to get real working set size of a process.\nTools This section describes two tools in the box though more tools exists. You can get more description about each tool from the README in the repository[1].\nuserprog userprog is a sample synthetic workload for test of other tools. It interactively allocates and access specified pages in the allocated pages.","title":"Idle Page Tracking Tools"},{"content":"Database 를 위해 사용되는 벤치마크는 크게 OLTP vs OLAP 로 나뉩니다[1]. OLTP 계열의 대표주자는 TPC-C 이고, OLAP 계열의 대표주자 중 하나로 TPC-H[2] 가 있습니다. 이 글에서는 TPC-H 를 MariaDB 에서 돌리는 방법에 대해 설명합니다.\nEnvironment Setup 이 글을 작성하면서 사용한 운영체제와 소프트웨어들의 버전은 다음과 같습니다.\nUbuntu 16.04.2 Server MariaDB 10.2.8 TPC-H toolkit 2.17.2 Automated Scripts 아래 설명할 모든 내용을 자동화 해서 손쉽게 TPC-H 를 돌릴 수 있도록 소스코드 변경부터 빌드, 수행까지 정리한 스크립트들을 github 에 올려 두었습니다: https://github.com/sjp38/tpch-mariadb\n시간이 없다면 해당 스크립트를 사용하실 것을 권장합니다.\nTPC-H Spec TPC-H 벤치마크 스펙은 TPC 웹사이트에서 얻을 수 있습니다[3]. 하지만 여기서는 간단히 설명을 해봅니다. 간단한 설명인 만큼 내용이 엄밀히 말해서 맞다고 할수는 없으므로 엄밀한 내용은 정식 스펙 또는 다른 문서를 확인해 보시기 바랍니다. TPC-H 는 8개의 테이블에 많은 데이터를 쌓아놓고, 이 데이터의 분석을 위한 22개의 쿼리를 수행하며 그 성능을 측정하는 형태로 구성되어 있습니다. 성능은 테이블에 데이터를 로드하는데 걸리는 시간, 22개의 쿼리 각각의 수행 시간, 그리고 여러 세션을 열어놓고 22개 쿼리를 각 세션에서 수행하면서 파악되는 처리량 (초당 처리된 쿼리의 갯수)으로 측정됩니다.\nGet TPC-H Toolkit TPC-H 라는 이름으로 벤치마크를 행하려면 테이블을 어떻게 만들고 거기에 데이터는 어떻게 넣어야 하며, 쿼리는 어떤 것들로 이루어져야 하는지에 대한 명세서를 TPC 에서 제공합니다. 이를 바탕으로 각자 TPC-H 를 구성해서 돌릴 수 있습니다. 하지만 이걸 각자 하는건 귀찮고 힘들기 때문에, 테이블과 테이블의 데이터, 그리고 쿼리들을 생성하는 도구를 TPC 에서 TPC-H Toolkit 이라는 이름으로 그 소스코드를 공식적으로 제공하고 있습니다. TPC 의 해당 사이트[4]를 찾아가 개인정보를 입력하고 license 에 동의를 하면 다운로드 받을 수 있는 링크를 메일로 보내줍니다.\n이렇게 받은 파일은 zip 파일입니다. 압축을 풀어보면 아래와 같이 해당 버전명의 디렉토리가 나오고, 그 아래에 실제 소스 코드와 라이센스 파일이 있습니다. 여기서 우린 dbgen/ 디렉토리를 사용할 겁니다.\n$ tree 2.17.2 -L 1 2.17.2 ├── dbgen ├── dev-tools ├── EULA.txt └── ref_data Build Source Code dbgen 디렉토리 아래 dbgen 과 qgen 이라는, 우리가 사용하게 될 프로그램을 위한 소스코드가 있습니다. 여기 있는 makefile.suite 라는 파일은 make 를 사용해 이 코드를 빌드하기 위한 규칙의 기본 골조를 담고 있습니다. 이 파일을 `makefile' 이라는 이름으로 복사하고 내용을 다음과 같이 수정합니다.\n$ diff -u makefile.suite makefile --- makefile.suite 2017-04-21 06:01:08.000000000 +0900 +++ makefile 2017-09-10 11:10:12.563384756 +0900 @@ -100,15 +100,15 @@ ################ ## CHANGE NAME OF ANSI COMPILER HERE ################ -CC = +CC = gcc # Current values for DATABASE are: INFORMIX, DB2, TDAT (Teradata) # SQLSERVER, SYBASE, ORACLE, VECTORWISE # Current values for MACHINE are: ATT, DOS, HP, IBM, ICL, MVS, # SGI, SUN, U2200, VMS, LINUX, WIN32 # Current values for WORKLOAD are: TPCH -DATABASE= -MACHINE = -WORKLOAD = +DATABASE= SQLSERVER +MACHINE = LINUX +WORKLOAD = TPCH # CFLAGS = -g -DDBNAME=\\\u0026#34;dss\\\u0026#34; -D$(MACHINE) -D$(DATABASE) -D$(WORKLOAD) -DRNG_TEST -D_FILE_OFFSET_BITS=64 LDFLAGS = -O 이후, $ make 명령으로 dbgen 과 qgen 이라는 프로그램이 빌드됩니다.\n$ make ... bm_utils.o qgen.o rnd.o varsub.o text.o bcd2.o permute.o speed_seed.o rng64.o -lm $ file dbgen dbgen: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.32, BuildID[sha1]=d0bca1a18c33947d85f5943c8325837faec7c95d, not stripped $ file qgen qgen: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.32, BuildID[sha1]=79a6216e04c446715b0e55f9c804586887b698c8, not stripped TPC-H Toolkit Usage MariaDB 에 TPC-H 를 돌리기 위해선 여기서 몇가지 추가 수정을 해야합니다. 하지만 그에 앞서 dbgen/ 디렉토리 내의 파일들을 어떻게 사용해서 TPC-H 를 수행하는지 알아봅시다.\nData Preparation 먼저 dss.ddl 파일은 8개의 테이블 생성에 사용되는 sql 문을 담고 있습니다. DB 에서 이 파일 내에 적힌 sql 문들을 그대로 수행하라고 하면 8개의 테이블이 생성됩니다.\ndbgen 은 테이블에 데이터를 로드하는 sql 문을 생성합니다. dbgen 에 scale factor 등의 인자를 줘서 수행시키면 8개의 .tbl suffix 를 갖는 파일이 생성됩니다. 이 파일들은 각각 파일명에 일치하는 이름의 테이블에 데이터를 insert 하는 query 문들로 구성되어 있습니다. DB 에 이 파일 내의 sql 명령들을 수행하라고 하면 데이터가 로드되는 것입니다.\ndss.ri 는 테이블 인덱스 생성에 필요한 sql 문을 담고 있습니다. DB 에 이 파일 내의 sql 명령들을 수행하라고 함으로써 테이블 인덱스 생성이 완료되어 TPC-H 의 쿼리들을 수행할 준비가 마쳐집니다.\nQuery Creation and Execution qgen 은 TPC-H 의 분석 작업을 대표하는 22개의 쿼리를 생성해 줍니다. 22개의 쿼리라고 표현했지만 22 종류의 쿼리라고 하는게 옳을 겁니다. 동일한 쿼리의 경우 반복 수행되면 DB 에서 앞 쿼리의 결과를 캐시해 뒀다가 곧바로 리턴하기 때문에 인자 등은 달라야 하기 때문입니다. 이를 위해 dbgen/queries/ 디렉토리 아래에는 생성되어야 하는 22 종류 쿼리의 템플릿을 담고 있습니다. qgen 은 이 템플릿을 참고하고 랜덤하게 인자를 생성해 최종적으로 DB 에서 수행될 수 있는 쿼리문을 생성합니다. 이 때 랜덤 시드는 dists.dss 라는 파일을 참고해 만들어집니다.\nModify TPC-H Toolkit for MariaDB DBMS 마다 query syntax 가 조금씩 다릅니다. 때문에 TPC-H Toolkit 은 지원하는 DBMS 마다 다르게 테이블 생성, 쿼리 생성을 하도록 짜여져 있습니다만, 지원하는 DBMS 목록에 MariaDB 는 포함되어 있지 않습니다. 따라서 MariaDB 에 TPC-H 를 돌리기 위해선 TPC-H Toolkit 의 일부분을 수정해야 합니다.\n수정해야 하는 파일은 dss.ddl, dss.ri, 그리고 queries/ 디렉토리 아래의 템플릿 등입니다. 하나하나 설명하는 것은 너무 내용이 길어지므로, 수정 내용을 patch 형태로 만들어 github 에 올려두었습니다[5]. 이 패치 파일을 가져와서 다음과 같이 적용할 수 있습니다. 명령을 수행하는 디렉토리는 TPC-H Toolkit 소스코드 디렉토리 여야 합니다.\n$ wget https://raw.githubusercontent.com/sjp38/tpch-mariadb/07fdcbfa9ba1be26f437ff130338a223d0dbfecd/0001-Modify-for-MariaDB.patch $ patch -p1 \u0026lt; 0001-Modify-for-MariaDB.patch 위 변경 사항은 makefile 의 수정도 포함되어 있습니다. 적용 후 dbgen, qgen 을 빌드해 줍시다.\nData Creation dbgen/ 디렉토리로 들어가 dbgen 을 수행해 줍니다. 인자로 scale factor 등을 줄 수 있습니다. -h 인자를 줘서 dbgen 의 수행 방법을 알 수 있으니 참고합시다. 수행이 마무리 되면 다음과 같이 8개의 .tbl suffix 를 갖는 파일들이 생성됩니다.\ndbgen$ ls -ahl *.tbl -rw-rw-r-- 1 sjpark sjpark 187M Sep 9 10:48 customer.tbl -rw-rw-r-- 1 sjpark sjpark 5.8G Sep 9 10:48 lineitem.tbl -rw-rw-r-- 1 sjpark sjpark 2.2K Sep 9 10:48 nation.tbl -rw-rw-r-- 1 sjpark sjpark 1.4G Sep 9 10:48 orders.tbl -rw-rw-r-- 1 sjpark sjpark 919M Sep 9 10:48 partsupp.tbl -rw-rw-r-- 1 sjpark sjpark 186M Sep 9 10:48 part.tbl -rw-rw-r-- 1 sjpark sjpark 389 Sep 9 10:48 region.tbl -rw-rw-r-- 1 sjpark sjpark 11M Sep 9 10:48 supplier.tbl 참고로, 위 수행결과는 scale factor 값을 8로 준 결과입니다.\nLoad Data 이제 MariaDB 를 사용해 tpch 라는 이름의 데이터베이스를 생성하고 (line 1) 그 아래 테이블을 생성하고 (line 2) 각 테이블에 데이터를 로드한 후 (line 3-5) 각 테이블의 인덱스까지 만들어 줍시다 (line 6).\n$ mysql -u root -p password -e \u0026#34;create database tpch;\u0026#34; $ mysql -u root -p password \u0026lt; dss.ddl $ for table in customer lineitem nation orders partsupp part region supplier \\ do mysql -u root -p -e \\ \u0026#34;LOAD DATA LOCAL INFILE \u0026#39;$table.tbl\u0026#39; FIELDS TERMINATED BY \u0026#39;|\u0026#39;;\u0026#34; done $ mysql -u root -p password \u0026lt; ./dss.ri Create Queries 이제 쿼리를 만들어 봅시다. qgen 은 인자로 생성할 쿼리의 타입을 1-22 사이 숫자로 받아서 쿼리문을 생성, 화면에 뿌려줍니다. 다음과 같은 커맨드로 이를 따로 저장합니다. 아래 커맨드는 dbgen/ 디렉토리 아래에서 수행됨을 가정합니다.\n$ cd queries/ $ for i in {1..22}; do ../qgen $i \u0026gt; query-$i.sql; done 이제 dbgen/queries/ 디렉토리 아래에 query- 라는 prefix 의 쿼리문을 담는 파일 22개가 생성되어 있습니다.\nExecute Queries 앞서 생성한 쿼리문 파일은 MariaDB 에 호환되는 sql 문으로 구성되어 있으므로, 아래와 같이 간단히 실행시키면 됩니다.\n$ for i in {1..22}; do mysql -u root -p password \u0026lt; dbgen/queries/query-$i.sql 일부 쿼리는 수십초, 일부 쿼리는 1초도 걸리지 않아 수행되는 걸 확인할 수 있습니다.\nConclusion TPC-H 가 어떻게 구성되어 있고 어떻게 수행시키며, MariaDB 에서의 수행을 위해서는 어떤 수정이 필요한지 설명했습니다. github 에 있는 자동화 스크립트[6]를 이용하면 이 과정을 손쉽게 한번에 해결할 수 있습니다.\nReferences [1] http://datawarehouse4u.info/OLTP-vs-OLAP.html\n[2] http://www.tpc.org/tpch/\n[3] http://www.tpc.org/tpc_documents_current_versions/pdf/tpc-h_v2.17.2.pdf\n[4] http://www.tpc.org/tpc_documents_current_versions/download_programs/tools-download-request.asp?bm_type=TPC-H\u0026amp;bm_vers=2.17.2\u0026amp;mode=CURRENT-ONLY\n[5] https://raw.githubusercontent.com/sjp38/tpch-mariadb/07fdcbfa9ba1be26f437ff130338a223d0dbfecd/0001-Modify-for-MariaDB.patch\n[6] https://github.com/sjp38/tpch-mariadb\n","permalink":"https://sjp38.github.io/posts/ko/tpch-on-mariadb/","summary":"Database 를 위해 사용되는 벤치마크는 크게 OLTP vs OLAP 로 나뉩니다[1]. OLTP 계열의 대표주자는 TPC-C 이고, OLAP 계열의 대표주자 중 하나로 TPC-H[2] 가 있습니다. 이 글에서는 TPC-H 를 MariaDB 에서 돌리는 방법에 대해 설명합니다.\nEnvironment Setup 이 글을 작성하면서 사용한 운영체제와 소프트웨어들의 버전은 다음과 같습니다.\nUbuntu 16.04.2 Server MariaDB 10.2.8 TPC-H toolkit 2.17.2 Automated Scripts 아래 설명할 모든 내용을 자동화 해서 손쉽게 TPC-H 를 돌릴 수 있도록 소스코드 변경부터 빌드, 수행까지 정리한 스크립트들을 github 에 올려 두었습니다: https://github.","title":"MariaDB (MySQL) 위에서 TPC-H 벤치마크 돌리기"},{"content":"Benchmarks for Database can be roughly divided into two kinds, OLTP and OLAP[1]. One of the most popular OLTP benchamrks is TPC-C, while that of OLAP is TPC-H[2]. This post describes how you can run TPC-H against MariaDB.\nEnvironment Setup The versions of the OS and programs I used for writeup of this post are as below.\nUbuntu 16.04.2 Server MariaDB 10.2.8 TPC-H toolkit 2.17.2 Automated Scripts I automated whole things I will describe below using scripts and uploaded the scripts to the Github: https://github.com/sjp38/tpch-mariadb\nIf you hano no time, just go to the link and use the script.\nTPC-H Spec You can ge TPC-H benchmark specification from TPC website[3]. Refer to it if you need strict specification of the benchmark. Nonetheless, I give you a rough description of the benchmark here, though. TPC-H stores a huge data into 8 tables and run 22 queries analysing this data. To measure the performance, we can measure the time to store/load the data, runtime of each of the 22 queries, and the throughput (number of processed queries per second) of multiple sessions.\nGet TPC-H Toolkit TPC provides the specification says how the tables should be constructed, what data should be stored in the tables, and what kind of queries should be issued. So, anyone can implement their TPC-H based on this specification. Nonetheless, as manual read of the specification and manual implementation can be boring and exhaustive to someone. For the reason, TPC officially provides a tool, namely TPC-H Toolkit, that helps creation of the tables, the data, and the queries. If you go to the site[4], enter your personal information, and agree to the license, they will send you a link to download the TPC-H Toolkit by mail.\nThe file is in zip format. After extracting the file, you can get the directory named by the version of the toolkit. The source code and license file is under the directory. We will use dbgen/ directory here.\n$ tree 2.17.2 -L 1 2.17.2 ├── dbgen ├── dev-tools ├── EULA.txt └── ref_data Build Source Code Under the dbgen/, there are source code of the programs that we will use, dbgen and qgen. Copy makefile.suite to makefile and edit the content as below.\n$ diff -u makefile.suite makefile --- makefile.suite 2017-04-21 06:01:08.000000000 +0900 +++ makefile 2017-09-10 11:10:12.563384756 +0900 @@ -100,15 +100,15 @@ ################ ## CHANGE NAME OF ANSI COMPILER HERE ################ -CC = +CC = gcc # Current values for DATABASE are: INFORMIX, DB2, TDAT (Teradata) # SQLSERVER, SYBASE, ORACLE, VECTORWISE # Current values for MACHINE are: ATT, DOS, HP, IBM, ICL, MVS, # SGI, SUN, U2200, VMS, LINUX, WIN32 # Current values for WORKLOAD are: TPCH -DATABASE= -MACHINE = -WORKLOAD = +DATABASE= SQLSERVER +MACHINE = LINUX +WORKLOAD = TPCH # CFLAGS = -g -DDBNAME=\\\u0026#34;dss\\\u0026#34; -D$(MACHINE) -D$(DATABASE) -D$(WORKLOAD) -DRNG_TEST -D_FILE_OFFSET_BITS=64 LDFLAGS = -O Now, $ make command will build dbgen and qgen.\n$ make ... bm_utils.o qgen.o rnd.o varsub.o text.o bcd2.o permute.o speed_seed.o rng64.o -lm $ file dbgen dbgen: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.32, BuildID[sha1]=d0bca1a18c33947d85f5943c8325837faec7c95d, not stripped $ file qgen qgen: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.32, BuildID[sha1]=79a6216e04c446715b0e55f9c804586887b698c8, not stripped TPC-H Toolkit Usage To run TPC-H on MariaDB, we need several more modification. Before that, let\u0026rsquo;s see how we run TPC-H using the files under dbgen/ directory.\nData Preparation dss.ddl file has the sql statements be used for the creation of the 8 tables. If you command your DB to execute the sql statements in this file, the 8 tables will be created.\ndbgen creates the sql statements that stores the data to the table. If you run the dbgen with optional arguments including scale factor, 8 files having .tbl suffix will be created. Each of these files has query statements inserting the data to the table having same name with the file. You can store the data to the tables by making your DB to run the sql statements.\ndss.ri has a sql statement creating the table index. Once your DB runs these sql statements, the table index will be generated and you will be ready to run the TPC-H queries.\nQuery Creation and Execution qgen creates the queries doing the TPC-H\u0026rsquo;s analysis tasks. We simply said 22 queries, but it would be better to say 22 kinds of queries. If a query is repeatedly issued with same arguments, DB server can cache the results and simply return it to the client. As this can distort the results, TPC-H Toolkit has the template of the 22 queries under dbgen/queries/ directory and let qgen to create query statements using random arguments, based on this templates. The seed for the random number generation is created based on dists.dss file.\nModify TPC-H Toolkit for MariaDB Each DBMS has a little bit different query syntax. Thus, TPC-H Toolkit is made to support multiple DBMSes, but the MariaDB is not in the supported DBMSes. Therefore, you should modify a part of the TPC-H Toolkit to run TPC-H on the MariaDB.\nThe files need modifications are dss.ddl, dss.ri, and the templates under the queries/ directory. As the description of the each of the modifications will be too long, I simply made patches for the modifications and uploaded on Github[5]. You can apply the patch files to your TPC-H Toolkit as below. You should be on the TPC-H Toolkit source code directory while running below command.\n$ wget https://raw.githubusercontent.com/sjp38/tpch-mariadb/07fdcbfa9ba1be26f437ff130338a223d0dbfecd/0001-Modify-for-MariaDB.patch $ patch -p1 \u0026lt; 0001-Modify-for-MariaDB.patch The changes above includes the modification of the makefile. After applying, build dbgen and qgen.\nData Creation Now, move to dbgen/ directory and run dbgen. You can give scale factor using its argument. Refer to the usage of dbgen using -h option. After its execution, you can see below 8 .tbl files.\ndbgen$ ls -ahl *.tbl -rw-rw-r-- 1 sjpark sjpark 187M Sep 9 10:48 customer.tbl -rw-rw-r-- 1 sjpark sjpark 5.8G Sep 9 10:48 lineitem.tbl -rw-rw-r-- 1 sjpark sjpark 2.2K Sep 9 10:48 nation.tbl -rw-rw-r-- 1 sjpark sjpark 1.4G Sep 9 10:48 orders.tbl -rw-rw-r-- 1 sjpark sjpark 919M Sep 9 10:48 partsupp.tbl -rw-rw-r-- 1 sjpark sjpark 186M Sep 9 10:48 part.tbl -rw-rw-r-- 1 sjpark sjpark 389 Sep 9 10:48 region.tbl -rw-rw-r-- 1 sjpark sjpark 11M Sep 9 10:48 supplier.tbl The above results used scale factor value as 8.\nLoad Data Now, with your MariaDB, create a database named tpch (line 1), create tables under the database (line 2), load the data to the tables (lines 3-5), and make index for each of the tables (line 6).\n$ mysql -u root -p password -e \u0026#34;create database tpch;\u0026#34; $ mysql -u root -p password \u0026lt; dss.ddl $ for table in customer lineitem nation orders partsupp part region supplier \\ do mysql -u root -p -e \\ \u0026#34;LOAD DATA LOCAL INFILE \u0026#39;$table.tbl\u0026#39; FIELDS TERMINATED BY \u0026#39;|\u0026#39;;\u0026#34; done $ mysql -u root -p password \u0026lt; ./dss.ri Create Queries Now, create the queries. qgen receives a number from 1 to 22 which means the type of the queries to create, generate the query statement, and print on the screen. You can save the queries with below commands. This example assumes it is executed on the dbgen/ directory.\n$ cd queries/ $ for i in {1..22}; do ../qgen $i \u0026gt; query-$i.sql; done Now, you have 22 query- prefixed files containing each type of queries under the dbgen/queries/ directory.\nExecute Queries As the query files have sql statement compatible with MariaDB, you can simply run them as below.\n$ for i in {1..22}; do mysql -u root -p password \u0026lt; dbgen/queries/query-$i.sql Few queries will take few of tens of seconds to complete while another queries take less than 1 second.\nConclusion This post summarised how TPC-H is constructed, how you can run it, and what modifications are required to run it on MariaDB. You can do this with only few lines of command based on the automated scripts on my Github repo[6].\nReferences [1] http://datawarehouse4u.info/OLTP-vs-OLAP.html\n[2] http://www.tpc.org/tpch/\n[3] http://www.tpc.org/tpc_documents_current_versions/pdf/tpc-h_v2.17.2.pdf\n[4] http://www.tpc.org/tpc_documents_current_versions/download_programs/tools-download-request.asp?bm_type=TPC-H\u0026amp;bm_vers=2.17.2\u0026amp;mode=CURRENT-ONLY\n[5] https://raw.githubusercontent.com/sjp38/tpch-mariadb/07fdcbfa9ba1be26f437ff130338a223d0dbfecd/0001-Modify-for-MariaDB.patch\n[6] https://github.com/sjp38/tpch-mariadb\n","permalink":"https://sjp38.github.io/posts/tpch-on-mariadb/","summary":"Benchmarks for Database can be roughly divided into two kinds, OLTP and OLAP[1]. One of the most popular OLTP benchamrks is TPC-C, while that of OLAP is TPC-H[2]. This post describes how you can run TPC-H against MariaDB.\nEnvironment Setup The versions of the OS and programs I used for writeup of this post are as below.\nUbuntu 16.04.2 Server MariaDB 10.2.8 TPC-H toolkit 2.17.2 Automated Scripts I automated whole things I will describe below using scripts and uploaded the scripts to the Github: https://github.","title":"TPC-H on MariaDB (MySQL)"},{"content":"악의 조직 Oracle 에서 Sun 을 인수한 후 이어진 반 open source 적 행보에 MySQL 개발자는 MySQL 을 fork 해서 MariaDB 를 개발하고 있습니다. 저작권을 악용해 중요한 기능은 천천히 릴리즈 하거나 유료 라이센스로만 공개하기도 하는 Oracle 의 MySQL 과 달리 MariaDB 는 예전 MySQL 처럼 공개적으로 개발되고 있어 새롭고 진보적인 기능도 많이 있는 편인 것 같습니다.\n이 글에서는 Ubuntu 16.04 서버에 MariaDB 를 소스코드부터 가져와서 설치하고 사용하는 간단한 사용법을 정리해 봅니다.\nEnvironment 이 글에서는 Ubuntu 16.04.2 server 버전을 사용합니다.\nBuild and Install MariaDB 는 대부분의 리눅스 배포본을 위한 패키징이 잘 되어 있어서 각 배포본의 패키징 시스템을 사용하면 한두줄의 커맨드로 쉽게 설치할 수 있습니다. 하지만 여기선 문서[1] 를 참고해 가며 소스 코드부터 가져와서 바닥부터 가장 최신 버전을 설치해 보기로 합시다.\n소스코드는 github 에 git repository 의 형태로 공개되어 있습니다. 아래의 명령어로 코드를 mariadb/ 디렉토리 아래에 가져올 수 있습니다.\n$ git clone https://github.com/MariaDB/server.git mariadb $ cd mariadb git repository 인만큼 버전은 git 을 통해 tag 로 관리되고 있습니다. 이 글을 작성 중인 시점에서 가장 최신 stable 릴리즈는 10.2.8[2] 로, 2017년 8월 18일 자로 릴리즈 되었습니다. 다음 커맨드로 해당 버전의 코드를 checkout 할 수 있습니다:\n$ git checkout mariadb-10.2.8 이제 소스코드는 준비되었고, 빌드할 차례입니다. cmake 를 사용해 어떻게 빌드할지 등을 설정할 수 있는데, 여기선 release 할때 사용하는 설정을 사용해 보겠습니다. cmake 가 실패하는 경우는 대부분 필요 패키지가 설치되지 않은 경우입니다. libaio-dev, libjemalloc-dev, libgnutls-dev 등의 패키지가 설치되어 있어야 합니다.\n해당 패키지 설치 후에도 같은 에러 메세지가 나올 수 있는데, cmake 의 기존 결과가 캐싱되어 재사용되기 때문입니다. CMakeCache.txt 와 CMakeFiles/ 디렉토리를 제거해주면 캐싱된 내용은 사라집니다.\n이어서 간단히 make 를 사용해 빌드하고 설치를 할 수 있습니다. 설치는 super user 권한이 필요하기 때문에 sudo 를 사용해야 합니다.\n$ cmake . -DBUILD_CONFIG=mysql_release $ make $ sudo make install 어떤 사양의 머신에서 빌드하느냐에 따라 다르겠지만 빌드하는데 꽤 긴 시간이 걸립니다. 이 글을 작성하며 사용한 72 코어 / 144 쓰레드 머신에서는 -j144 옵션을 줘서 빌드할 경우 1분 5초 걸렸습니다. 별다른 에러 메세지가 없다면 빌드에 성공한 것입니다.\nInitialize MariaDB Server 이제 MariaDB 의 기본 설치는 마무리 되었지만, 아직 MariaDB 구동을 위한 준비가 모두 끝나진 않았습니다. MariaDB 가 제대로 동작하기 위해서는 test database, default user 등등의 최소 데이터를 생성하는 초기화 작업을 진행해야 합니다. 앞의 설치는 MariaDB 실행파일을 만들어 시스템에 설치한 것이고, 이 초기화 작업은 MariaDB 서비스의 설치라고 생각하면 이해가 조금 편할 수도 있겠습니다.\nsuper user 권한의 남용은 보안적으로 위험할 수 있으므로, MariaDB 는 기본적으로 별개의 사용자 계정을 사용할 것을 권장합니다. 다음 예에서는 mysql 이라는 이름의 user 를 생성하고 이 사용자 계정을 사용하도록 해서 초기화를 진행합니다.\n$ sudo adduser mysql $ sudo chown -R mysql /usr/local/mysql/ $ cd /usr/local/mysql/ $ sudo -u mysql ./scripts/mysql_install_db --user=mysql 순조롭게 진행되었다면 다음과 같은 메세지를 볼 수 있을 겁니다:\nInstalling MariaDB/MySQL system tables in \u0026#39;./data\u0026#39; ... OK To start mysqld at boot time you have to copy support-files/mysql.server to the right place for your system PLEASE REMEMBER TO SET A PASSWORD FOR THE MariaDB root USER ! To do so, start the server, then issue the following commands: \u0026#39;./bin/mysqladmin\u0026#39; -u root password \u0026#39;new-password\u0026#39; \u0026#39;./bin/mysqladmin\u0026#39; -u root -h hydra password \u0026#39;new-password\u0026#39; Alternatively you can run: \u0026#39;./bin/mysql_secure_installation\u0026#39; which will also give you the option of removing the test databases and anonymous user created by default. This is strongly recommended for production servers. See the MariaDB Knowledgebase at http://mariadb.com/kb or the MySQL manual for more instructions. You can start the MariaDB daemon with: cd \u0026#39;.\u0026#39; ; ./bin/mysqld_safe --datadir=\u0026#39;./data\u0026#39; You can test the MariaDB daemon with mysql-test-run.pl cd \u0026#39;./mysql-test\u0026#39; ; perl mysql-test-run.pl Please report any problems at http://mariadb.org/jira The latest information about MariaDB is available at http://mariadb.org/. You can find additional information about the MySQL part at: http://dev.mysql.com Consider joining MariaDB\u0026#39;s strong and vibrant community: https://mariadb.org/get-involved/ Starting MariaDB 이제 준비가 끝났습니다. 앞의 초기화 과정 이후 나온 메세지에서도 알 수 있듯이, 다음 커맨드로 MariaDB 서버를 시작할 수 있습니다:\n$ sudo -u mysql /usr/local/mysql/bin/mysqld_safe --datadir=\u0026#39;./data\u0026#39; Connect to Local MariaDB Server MariaDB 는 여러가지 방법으로 접근해 사용할 수 있는데, 관리 목적 등으로는 local shell 을 사용하는게 가장 간단합니다. 다음 커맨드로 local shell 을 열 수 있습니다. 이 커맨드는 같은 기계 위에 띄워져 있는 MariaDB 서버 프로세스에 접속해 해당 서버에 sql 쿼리를 날릴 수 있는 프롬프트를 띄워 줍니다.\n$ /usr/local/mysql/bin/mysql 위 커맨드에 \u0026ndash;version 인자를 주면 현재 mariadb 의 버전도 볼 수 있습니다:\n$ /usr/local/mysql/bin/mysql --version /usr/local/mysql/bin/mysql Ver 15.1 Distrib 10.2.8-MariaDB, for Linux (x86_64) using readline 5.1 s Kill MariaDB Server 서버를 끝낼 수도 있어야겠죠. 다음의 커맨드로 mysql 서버 프로세스에게 SIGTERM 시그널을 날려서 서버 프로세스를 종료시킬 수 있습니다.\n$ sudo -u mysql kill -SIGTERM `pidof mysqld` Basical Usage 프롬프트에서 다음과 같이 기본적인 sql 쿼리를 날릴 수 있습니다.\n$ sudo /usr/local/mysql/bin/mysql \u0026gt; create database sj_db; \u0026gt; create table sjtable ( id INT PRIMARY KEY, name VARCHAR(20) ); \u0026gt; insert into sjtable values ( 1, \u0026#39;Will\u0026#39; ); \u0026gt; select * from sjtable; 그 외의 MariaDB sql 문법을 위해서는 MariaDB basic sql statement 문서[3] 를 참고합시다.\nmy.cnf configuration mysql 과 마찬가지로 MariaDB 역시 my.cnf 파일을 사용해[1] 대부분의 설정을 구성합니다. 기본적으로 /etc/my.cnf, /etc/mysql/my.cnf \u0026hellip; 순으로 설정 파일을 찾게 되며, mysqld_safe 실행파일 실행 시에 \u0026ndash;defaults-file 인자로 파일 경로를 줄수도 있습니다. 소스 코드 디렉토리의 support-files/ 디렉토리 아래에 my-huge.cnf, my-large.cnf, my-medium.cnf 등의 예제 설정도 있습니다.\n앞의 과정을 따라서 설치하면 /etc/ 아래에 my.cnf 파일이 없을 겁니다. 이 때의 기본 설정은 어떻게 되는지는 다음 커맨드를 통해 알 수 있습니다.\n$ /usr/local/mysql/bin/mysql -NBe \u0026#39;SHOW VARIABLES\u0026#39; askapache.com 에서는[5] 이를 이용해 기본 my.cnf 를 추출하는 커맨드도 소개하고 있으니 필요하면 참고하시기 바랍니다.\nData Directory Specification 실험용으로 MariaDB 를 사용하는 경우라면 MariaDB 데이터를 최초 상태로 백업해 두거나 서로 다른 설정의 데이터를 유지해야 할 수도 있습니다.\nMariaDB 의 default data directory 는 /usr/local/mysql/data/ 로, 프롬프트에서\n\u0026gt; select @@datadir; 명령으로 현재 띄워진 MariaDB 서버 프로세스가 사용중인 data directory 의 경로를 볼 수 있습니다. 이 경로는 my.cnf 상에서 수정할 수도 있고, mysqld_safe 실행 시 \u0026ndash;datadir 옵션으로 지정할 수도 있습니다. 주의할 점은, 이때 \u0026ndash;datadir 인자로 주는 데이터 디렉토리는 한번은 scripts/mysql_install_db 를 실행해준 디렉토리여야 한다는 것입니다. mysql_install_db 명령에도 \u0026ndash;datadir 인자를 줄수 있습니다.\nConclusion MariaDB 최신 버전의 소스코드를 가져와 빌드하고 설치해서 사용하는 방법을 알아봤습니다. 하나의 예제로 정리해 보자면 다음과 같습니다.\n$ git clone https://github.com/MariaDB/server.git mariadb $ cd mariadb $ git checkout mariadb-10.2.8 $ cmake . -DBUILD_CONFIG=mysql_release $ make $ sudo make install $ sudo adduser mysql $ sudo chown -R mysql /usr/local/mysql/ $ cd /usr/local/mysql/ $ sudo -u mysql ./scripts/mysql_install_db --datadirr=\u0026#39;./data\u0026#39; \u0026amp; $ /usr/local/mysql/bin/mysql References [1] https://mariadb.com/kb/en/mariadb/generic-build-instructions/\n[2] https://downloads.mariadb.org/mariadb/+releases/\n[3] https://mariadb.com/kb/en/mariadb/basic-sql-statements/\n[4] https://mariadb.com/kb/en/mariadb/configuring-mariadb-with-mycnf/\n[5] https://www.askapache.com/mysql/view-mysql-variables-my-cnf/\n","permalink":"https://sjp38.github.io/posts/ko/mariadb_setup/","summary":"악의 조직 Oracle 에서 Sun 을 인수한 후 이어진 반 open source 적 행보에 MySQL 개발자는 MySQL 을 fork 해서 MariaDB 를 개발하고 있습니다. 저작권을 악용해 중요한 기능은 천천히 릴리즈 하거나 유료 라이센스로만 공개하기도 하는 Oracle 의 MySQL 과 달리 MariaDB 는 예전 MySQL 처럼 공개적으로 개발되고 있어 새롭고 진보적인 기능도 많이 있는 편인 것 같습니다.\n이 글에서는 Ubuntu 16.04 서버에 MariaDB 를 소스코드부터 가져와서 설치하고 사용하는 간단한 사용법을 정리해 봅니다.","title":"Ubuntu 16.04 Server 위에 MariaDB 설치/사용하기"},{"content":"현재 사용중인 랩탑에 설치한 OS 는 Fedora 24 였는데, 너무 오래되었고 지원도 얼마전 끝났기에[0] 이번에 Fedora 26 으로 새로 설치했습니다. 마침 go 언어도 1.9 가 최근에 릴리즈 되었기에 개인적으로 go 언어를 설치하는 방법을 기록해 둡니다.\n여기선 소스 코드만 가지고 빌드, 설치하는 방법을 기록합니다.\nGet Source Code go 언어는 오픈소스입니다. 다음 커맨드를 통해 구글로부터 소스코드를 받아올 수 있습니다.\n$ git clone https://go.googlesource.com/go 기다리면 go/ 디렉토리에 소스코드가 딸려옵니다.\ngolang 1.4 Build \u0026amp; Install go 언어를 빌드한다는 건 go 언어 컴파일러와 기본 라이브러리 등과 같은, go 언어로 짠 프로그램을 빌드하고 수행하는데 필요한 도구들을 빌드한다는 이야기입니다. 이런 기본 도구는 go 언어로 짜여져 있기 때문에 go 언어를 소스코드로부터 빌드하려면 go 언어가 미리 설치되어 있어야 합니다. 따라서 1.4 버전의 go 언어를 먼저 빌드, 설치합니다.\n$ cp -R go go1.4 $ cd go1.4/src $ git checkout go1.4.3 $ CGO_ENABLED=0 ./all.bash 앞서 받아온 소스코드를 go1.4/ 디렉토리로 복사하고 (line 1) 그리로 이동해서 (line 2) git 을 사용해 1.4 버전들 중 가장 마지막 버전인 1.4.3 버전의 코드를 꺼낸 후 (line 3) 마지막 줄에서 빌드를 하는 명령들입니다.\n참고로 CGO_ENABLED=0 를 빼먹으면 빌드에 실패합니다[1]. go 개발팀에선 그냥 바이너리로 최신 go 를 짜기 위한 go 를 설치하길 권장하지만[2], 전 소스 코드만으로 설치를 하고 싶으므로 이렇게 합니다.\ngolang 1.9 Build \u0026amp; Install 역시 간단합니다.\ncd ../go/src git checkout go1.9 ./all.bash 앞서 받아둔 go 소스 코드로 돌아가서 (line 1), 1.9 버전의 소스코드를 꺼내고 (line 2), 마지막으로 빌드 / 설치를 진행합니다 (line 3).\n다음과 같은 메세지를 보게 되면 빌드 / 설치에 성공한 겁니다.\nALL TESTS PASSED --- Installed Go for linux/amd64 in /home/sjpark/go Installed commands in /home/sjpark/go/bin *** You need to add /home/sjpark/go/bin to your PATH. Test Installation 설치가 잘 되었는지 마지막으로 테스트 해봅시다.\n$ go version go version devel +bad6b6fa91 Fri Aug 25 23:29:55 2017 +0000 linux/amd64 위와 같이 결과가 나오면 잘 설치된 것입니다.\nAdditional Configuration 추가적으로 go 바이너리의 위치를 PATH 에 넣어주고, 사용할 GOPATH 를 지정해 줍니다. golang 은 개발 코드의 위치와 go 언어로 짜여진 프로그램의 설치 위치 규칙을 기본적으로 권장하는 규칙이 있는데, 이를 위해 사용되는 디렉토리의 꼭대기가 GOPATH 입니다. 나만의 방식으로 go 언어를 다루겠다면 굳이 지정할 필요 없지만, 전 그정도 규칙은 따르는 편이므로 다음 내용을 홈 디렉토리의 .bashrc 에 추가해 이를 지정해 줍니다.\nexport GOPATH=$HOME/gopath export PATH=$PATH:$HOME/go/bin export PATH=$PATH:$GOPATH/bin GOPATH 아래 bin/ 디렉토리는 일반적으로 설치한 go 언어 프로그램의 실행파일을 위치시키는 곳이므로 역시 PATH 에 추가해줬습니다 (line 3).\n이 규칙을 이해하기 쉽게 다음과 같이 제가 만든 hn 이라는 프로그램을 설치해 보고, 이 명령이 GOPATH 를 어떻게 사용하는지 보면 다음과 같습니다.\n$ go get github.com/sjp38/hn $ tree gopath/ gopath/ ├── bin │ └── hn └── src └── github.com └── sjp38 └── hn ├── hn.go ├── LICENSE └── README.md 5 directories, 4 files References [0] https://fedoramagazine.org/fedora-24-eol/\n[1] https://github.com/golang/go/issues/18156#issuecomment-264389887\n[2] https://github.com/golang/go/issues/18156#issuecomment-264492152\n","permalink":"https://sjp38.github.io/posts/ko/golang1.9_fedora26/","summary":"현재 사용중인 랩탑에 설치한 OS 는 Fedora 24 였는데, 너무 오래되었고 지원도 얼마전 끝났기에[0] 이번에 Fedora 26 으로 새로 설치했습니다. 마침 go 언어도 1.9 가 최근에 릴리즈 되었기에 개인적으로 go 언어를 설치하는 방법을 기록해 둡니다.\n여기선 소스 코드만 가지고 빌드, 설치하는 방법을 기록합니다.\nGet Source Code go 언어는 오픈소스입니다. 다음 커맨드를 통해 구글로부터 소스코드를 받아올 수 있습니다.\n$ git clone https://go.googlesource.com/go 기다리면 go/ 디렉토리에 소스코드가 딸려옵니다.\ngolang 1.4 Build \u0026amp; Install go 언어를 빌드한다는 건 go 언어 컴파일러와 기본 라이브러리 등과 같은, go 언어로 짠 프로그램을 빌드하고 수행하는데 필요한 도구들을 빌드한다는 이야기입니다.","title":"Golang 1.9 install on Fedora 26"},{"content":"최근 커널은 stakc dump 에서 콜 트레이스(Call Trace) 에 각 코드의 메모리 어드레스를 찍어주지 않습니다. 이에 대해 포스팅을 해봅니다.\nCall Trace 커널은 문제가 발생하거나 하면 문제의 원인을 찾을 수 있는 다양한 정보를 담고 있는 stack dump 를 로그로 뿌려 줍니다. 문제의 원인을 찾는데 매우 소중한 정보입니다. 그 정보 중에서도 중요한 것 중 하나가 콜 트레이스로, 이 문제의 순간에 오기까지 어느 함수의 어느 지점에서 어느 함수를 호출해서 여기까지 왔는가를 담는 정보입니다.\n디버깅 정보를 담아 빌드된 커널이라면 다음과 같이 사람 눈으로 곧바로 어느정도 알 수 있는 수준의 콜 트레이스가 나옵니다:\nCall Trace: [\u0026lt;c12ba080\u0026gt;] ? dump_stack+0x44/0x64 [\u0026lt;c103ed6a\u0026gt;] ? __warn+0xfa/0x120 [\u0026lt;c109e8a7\u0026gt;] ? module_put+0x57/0x70 [\u0026lt;c109e8a7\u0026gt;] ? module_put+0x57/0x70 [\u0026lt;c103ee33\u0026gt;] ? warn_slowpath_null+0x23/0x30 [\u0026lt;c109e8a7\u0026gt;] ? module_put+0x57/0x70 [\u0026lt;f80ca4d0\u0026gt;] ? gp8psk_fe_set_frontend+0x460/0x460 [dvb_usb_gp8psk] [\u0026lt;c109f617\u0026gt;] ? symbol_put_addr+0x27/0x50 [\u0026lt;f80bc9ca\u0026gt;] ? dvb_usb_adapter_frontend_exit+0x3a/0x70 [dvb_usb] 콜 트레이스는 어떻게 이 순간에 이르게 되었는가를 역순으로 보여줍니다. 즉, dvd_usb_adapter_frontend_exit() 에서 symbol_put_addr() 를 호출했고, 여기서 gp8psk_fe_set_frontend() 를 호출했고, \u0026hellip; 반복되어 dump_stack() 함수에 의해 이 메세지가 뜬 것이죠. 함수 이름 옆의 0xaa/0xbb 와 같은 숫자들은 각각 함수 내에서 해당 순간 코드까지의 오프셋, 그리고 해당 함수의 전체 크기를 나타냅니다.\n이것만으로도 많은 정보를 알 수 있지만 해당 함수의 정확히 몇번째 라인에서 문제가 났는지는 이것만으로 알수가 없습니다. 코드를 한줄한줄 눈으로 보고 로그를 추가해보고 하면서 찾을 수도 있겠지만 복장이 터지겠죠. 가장 왼쪽 [\u0026lt; 와 \u0026gt;] 사이의 16진수는 메모리 상에서 해당 코드의 주소를 의미합니다. 따라서 디버깅 정보가 있다면 이 주소를 가지고 해당 코드가 어느 파일의 몇번째 라인인지 파악할 수 있습니다.\n이 작업을 위한 도구가 여럿 있는데, addr2line[1] 도 많이 사용되는 도구 중 하나입니다.\n$ addr2line -e ../linux.out/vmlinux 0xffffffff810e91f0 linux/arch/x86/include/asm/rwsem.h:83 -e 옵션을 통해 커널 디버깅 정보를 담고 있는 커널 이미지가 위치한 경로를 넘겨주고 마지막 인자로 앞의 콜 트레이스에서 얻어온 주소를 주면 어느 파일의 몇번째 라인을 가리키는지 쉽게 알 수 있습니다.\nText Address Removed from Stack Dump 그런데, 2016년 말 후에 릴리즈된 x86 용 커널은 콜 트레이스에서 위의 addr2line 에 넘겨줘야 할, 어드레스 정보가 더이상 콜 트레이스에 없습니다. 해당되는 커널에서는 다음과 같은 콜 트레이스가 나올 겁니다:\nCall Trace: dump_stack+0x85/0xc2 bad_page+0xc1/0x120 free_pages_check_bad+0x7a/0x80 __free_pages_ok+0x32a/0x3e0 __free_pages+0x19/0x30 shrink_huge_zero_page_scan+0x50/0x60 이는 2016년 10월 25일자로 Josh Poimboeuf 에 의해 만들어진 커밋[2] 에 의한 겁니다. 코드의 메모리상 어드레스가 추측 가능할 경우엔 해당 영역에 코드를 바꾼다거나 하는 여러 공격이 들어올 수 있어 보안상 좋지 않습니다. 때문에 최근 시스템은 동일한 프로그램이라 하더라도 메모리에 적재될 때마다 코드의 위치가 바뀌거나 하도록 하는 기능을 갖추고 있습니다. Address randomization[3] 이 한 예입니다. 따라서 Address randomization 이 가줘져 있다고는 하지만 해당 어드레스를 누구나 볼 수 있는 커널 로그에 뿌리는 것도 좋은 행위는 아닐 뿐더러, 이렇게 나온 정보는 시스템에 따라 무효할 것이기 때문에 적어도 커밋 메세지에는 존재할 필요가 없는데 버그 레포팅 할때 사람들이 뿌려대서 귀찮기만 하다는 것이죠.\nHow to find out the Line, now? 문제는, 이렇게 되니 기존의 addr2line 을 이용해 한방에 해결되던 위치 찾기가 좀 복잡해진다는 겁니다. 먼저 해당 함수의 메모리 상 위치를 찾아내고, 그 다음 오프셋을 더해서 해당 코드의 메모리 상 주소를 찾아내어서 다시 addr2line 등을 사용해야 하는 것이죠.\n이게 귀찮다면 만능 도구 gdb 를 사용할 수 있습니다:\n$ gdb ../linux.out/vmlinux ... (gdb) list *(free_pages_check_bad+0x7a) 0xffffffff811daf1a is in free_pages_check_bad (/home/sjpark/linux/mm/page_alloc.c:941). 936 #ifdef CONFIG_MEMCG 937 if (unlikely(page-\u0026gt;mem_cgroup)) 938 bad_reason = \u0026#34;page still charged to cgroup\u0026#34;; 939 #endif 940 bad_page(page, bad_reason, bad_flags); 941 } 942 943 static inline int free_pages_check(struct page *page) 944 { 945 if (likely(page_expected_state(page, PAGE_FLAGS_CHECK_AT_FREE))) 하지만 이 방법은 동일한 이름의 심볼이 두개 존재하는 경우 첫번째 심볼에 대해서만 보여줍니다. 따라서 사려 깊은 Josh Poimboeuf 는 저처럼 addr2line 을 좋아하는 사람들을 위해 대체할 도구를 만들었습니다. 그 이름은 faddr2line 으로, 커널 소스의 scripts/ 디렉토리 아래에 있습니다. 다음과 같이 사용할 수 있습니다:\n$ ./scripts/faddr2line ../linux.out/vmlinux free_pages_check_bad+0x7a free_pages_check_bad+0x7a/0x80: free_pages_check_bad at mm/page_alloc.c:941 두번째 인자로 디버깅 정보 담긴 이미지파일 경로, 그 뒤로 찾고자 하는 코드의 함수와 함수로부터 해당 코드까지의 오프셋을 주면 됩니다.\nConclusion 보안적 이유와 쓸모없음으로 인해 2016년 말 후의 커널은 콜 트레이스에서 각 코드의 메모리 어드레스를 제거하고 func_name+0x123/0x456 포맷으로만 코드 위치를 제공하게 되었습니다. 이로 인해 해당 코드의 파일 내에서의 위치를 찾는데에 예전처럼 addr2line 을 더 사용할 수는 없게 되었지만 커널 모드의 scripts/faddr2line 도구를 사용해 예전처럼 쉽게 콜 트레이스의 각 위치의 파일 내에서의 위치를 파악할 수 있습니다.\nReferences [1] http://www.skrenta.com/rt/man/addr2line.1.html\n[2] http://lkml.kernel.org/r/69329cb29b8f324bb5fcea14d61d224807fb6488.1477405374.git.jpoimboe@redhat.com\n[3] https://en.wikipedia.org/wiki/Address_space_layout_randomization\n","permalink":"https://sjp38.github.io/posts/kernel-text-addresses-removed-from-calltrace/","summary":"최근 커널은 stakc dump 에서 콜 트레이스(Call Trace) 에 각 코드의 메모리 어드레스를 찍어주지 않습니다. 이에 대해 포스팅을 해봅니다.\nCall Trace 커널은 문제가 발생하거나 하면 문제의 원인을 찾을 수 있는 다양한 정보를 담고 있는 stack dump 를 로그로 뿌려 줍니다. 문제의 원인을 찾는데 매우 소중한 정보입니다. 그 정보 중에서도 중요한 것 중 하나가 콜 트레이스로, 이 문제의 순간에 오기까지 어느 함수의 어느 지점에서 어느 함수를 호출해서 여기까지 왔는가를 담는 정보입니다.","title":"Kernel text addresses removed from calltrace"},{"content":"최근 커널은 stakc dump 에서 콜 트레이스(Call Trace) 에 각 코드의 메모리 어드레스를 찍어주지 않습니다. 이에 대해 포스팅을 해봅니다.\nCall Trace 커널은 문제가 발생하거나 하면 문제의 원인을 찾을 수 있는 다양한 정보를 담고 있는 stack dump 를 로그로 뿌려 줍니다. 문제의 원인을 찾는데 매우 소중한 정보입니다. 그 정보 중에서도 중요한 것 중 하나가 콜 트레이스로, 이 문제의 순간에 오기까지 어느 함수의 어느 지점에서 어느 함수를 호출해서 여기까지 왔는가를 담는 정보입니다.\n디버깅 정보를 담아 빌드된 커널이라면 다음과 같이 사람 눈으로 곧바로 어느정도 알 수 있는 수준의 콜 트레이스가 나옵니다:\nCall Trace: [\u0026lt;c12ba080\u0026gt;] ? dump_stack+0x44/0x64 [\u0026lt;c103ed6a\u0026gt;] ? __warn+0xfa/0x120 [\u0026lt;c109e8a7\u0026gt;] ? module_put+0x57/0x70 [\u0026lt;c109e8a7\u0026gt;] ? module_put+0x57/0x70 [\u0026lt;c103ee33\u0026gt;] ? warn_slowpath_null+0x23/0x30 [\u0026lt;c109e8a7\u0026gt;] ? module_put+0x57/0x70 [\u0026lt;f80ca4d0\u0026gt;] ? gp8psk_fe_set_frontend+0x460/0x460 [dvb_usb_gp8psk] [\u0026lt;c109f617\u0026gt;] ? symbol_put_addr+0x27/0x50 [\u0026lt;f80bc9ca\u0026gt;] ? dvb_usb_adapter_frontend_exit+0x3a/0x70 [dvb_usb] 콜 트레이스는 어떻게 이 순간에 이르게 되었는가를 역순으로 보여줍니다. 즉, dvd_usb_adapter_frontend_exit() 에서 symbol_put_addr() 를 호출했고, 여기서 gp8psk_fe_set_frontend() 를 호출했고, \u0026hellip; 반복되어 dump_stack() 함수에 의해 이 메세지가 뜬 것이죠. 함수 이름 옆의 0xaa/0xbb 와 같은 숫자들은 각각 함수 내에서 해당 순간 코드까지의 오프셋, 그리고 해당 함수의 전체 크기를 나타냅니다.\n이것만으로도 많은 정보를 알 수 있지만 해당 함수의 정확히 몇번째 라인에서 문제가 났는지는 이것만으로 알수가 없습니다. 코드를 한줄한줄 눈으로 보고 로그를 추가해보고 하면서 찾을 수도 있겠지만 복장이 터지겠죠. 가장 왼쪽 [\u0026lt; 와 \u0026gt;] 사이의 16진수는 메모리 상에서 해당 코드의 주소를 의미합니다. 따라서 디버깅 정보가 있다면 이 주소를 가지고 해당 코드가 어느 파일의 몇번째 라인인지 파악할 수 있습니다.\n이 작업을 위한 도구가 여럿 있는데, addr2line[1] 도 많이 사용되는 도구 중 하나입니다.\n$ addr2line -e ../linux.out/vmlinux 0xffffffff810e91f0 linux/arch/x86/include/asm/rwsem.h:83 -e 옵션을 통해 커널 디버깅 정보를 담고 있는 커널 이미지가 위치한 경로를 넘겨주고 마지막 인자로 앞의 콜 트레이스에서 얻어온 주소를 주면 어느 파일의 몇번째 라인을 가리키는지 쉽게 알 수 있습니다.\nText Address Removed from Stack Dump 그런데, 2016년 말 후에 릴리즈된 x86 용 커널은 콜 트레이스에서 위의 addr2line 에 넘겨줘야 할, 어드레스 정보가 더이상 콜 트레이스에 없습니다. 해당되는 커널에서는 다음과 같은 콜 트레이스가 나올 겁니다:\nCall Trace: dump_stack+0x85/0xc2 bad_page+0xc1/0x120 free_pages_check_bad+0x7a/0x80 __free_pages_ok+0x32a/0x3e0 __free_pages+0x19/0x30 shrink_huge_zero_page_scan+0x50/0x60 이는 2016년 10월 25일자로 Josh Poimboeuf 에 의해 만들어진 커밋[2] 에 의한 겁니다. 코드의 메모리상 어드레스가 추측 가능할 경우엔 해당 영역에 코드를 바꾼다거나 하는 여러 공격이 들어올 수 있어 보안상 좋지 않습니다. 때문에 최근 시스템은 동일한 프로그램이라 하더라도 메모리에 적재될 때마다 코드의 위치가 바뀌거나 하도록 하는 기능을 갖추고 있습니다. Address randomization[3] 이 한 예입니다. 따라서 Address randomization 이 가줘져 있다고는 하지만 해당 어드레스를 누구나 볼 수 있는 커널 로그에 뿌리는 것도 좋은 행위는 아닐 뿐더러, 이렇게 나온 정보는 시스템에 따라 무효할 것이기 때문에 적어도 커밋 메세지에는 존재할 필요가 없는데 버그 레포팅 할때 사람들이 뿌려대서 귀찮기만 하다는 것이죠.\nHow to find out the Line, now? 문제는, 이렇게 되니 기존의 addr2line 을 이용해 한방에 해결되던 위치 찾기가 좀 복잡해진다는 겁니다. 먼저 해당 함수의 메모리 상 위치를 찾아내고, 그 다음 오프셋을 더해서 해당 코드의 메모리 상 주소를 찾아내어서 다시 addr2line 등을 사용해야 하는 것이죠.\n이게 귀찮다면 만능 도구 gdb 를 사용할 수 있습니다:\n$ gdb ../linux.out/vmlinux ... (gdb) list *(free_pages_check_bad+0x7a) 0xffffffff811daf1a is in free_pages_check_bad (/home/sjpark/linux/mm/page_alloc.c:941). 936 #ifdef CONFIG_MEMCG 937 if (unlikely(page-\u0026gt;mem_cgroup)) 938 bad_reason = \u0026#34;page still charged to cgroup\u0026#34;; 939 #endif 940 bad_page(page, bad_reason, bad_flags); 941 } 942 943 static inline int free_pages_check(struct page *page) 944 { 945 if (likely(page_expected_state(page, PAGE_FLAGS_CHECK_AT_FREE))) 하지만 이 방법은 동일한 이름의 심볼이 두개 존재하는 경우 첫번째 심볼에 대해서만 보여줍니다. 따라서 사려 깊은 Josh Poimboeuf 는 저처럼 addr2line 을 좋아하는 사람들을 위해 대체할 도구를 만들었습니다. 그 이름은 faddr2line 으로, 커널 소스의 scripts/ 디렉토리 아래에 있습니다. 다음과 같이 사용할 수 있습니다:\n$ ./scripts/faddr2line ../linux.out/vmlinux free_pages_check_bad+0x7a free_pages_check_bad+0x7a/0x80: free_pages_check_bad at mm/page_alloc.c:941 두번째 인자로 디버깅 정보 담긴 이미지파일 경로, 그 뒤로 찾고자 하는 코드의 함수와 함수로부터 해당 코드까지의 오프셋을 주면 됩니다.\nConclusion 보안적 이유와 쓸모없음으로 인해 2016년 말 후의 커널은 콜 트레이스에서 각 코드의 메모리 어드레스를 제거하고 func_name+0x123/0x456 포맷으로만 코드 위치를 제공하게 되었습니다. 이로 인해 해당 코드의 파일 내에서의 위치를 찾는데에 예전처럼 addr2line 을 더 사용할 수는 없게 되었지만 커널 모드의 scripts/faddr2line 도구를 사용해 예전처럼 쉽게 콜 트레이스의 각 위치의 파일 내에서의 위치를 파악할 수 있습니다.\nReferences [1] http://www.skrenta.com/rt/man/addr2line.1.html\n[2] http://lkml.kernel.org/r/69329cb29b8f324bb5fcea14d61d224807fb6488.1477405374.git.jpoimboe@redhat.com\n[3] https://en.wikipedia.org/wiki/Address_space_layout_randomization\n","permalink":"https://sjp38.github.io/posts/ko/kernel-text-addresses-removed-from-calltrace/","summary":"최근 커널은 stakc dump 에서 콜 트레이스(Call Trace) 에 각 코드의 메모리 어드레스를 찍어주지 않습니다. 이에 대해 포스팅을 해봅니다.\nCall Trace 커널은 문제가 발생하거나 하면 문제의 원인을 찾을 수 있는 다양한 정보를 담고 있는 stack dump 를 로그로 뿌려 줍니다. 문제의 원인을 찾는데 매우 소중한 정보입니다. 그 정보 중에서도 중요한 것 중 하나가 콜 트레이스로, 이 문제의 순간에 오기까지 어느 함수의 어느 지점에서 어느 함수를 호출해서 여기까지 왔는가를 담는 정보입니다.","title":"Kernel text addresses removed from calltrace"},{"content":"쏟아지는 LKML[2] 의 메일들을 트위터 라이브스트림처럼 터미널에 보여주는 간단한 프로그램[1] 을 go 언어로 만들어 봤습니다. 아직 보완할 점 투성이지만 이제 최초의 목적대로는 동작하는군요.\nReferences [1] https://github.com/sjp38/lkml\n[2] https://en.wikipedia.org/wiki/Linux_kernel_mailing_list\n","permalink":"https://sjp38.github.io/posts/ko/lkml_go/","summary":"쏟아지는 LKML[2] 의 메일들을 트위터 라이브스트림처럼 터미널에 보여주는 간단한 프로그램[1] 을 go 언어로 만들어 봤습니다. 아직 보완할 점 투성이지만 이제 최초의 목적대로는 동작하는군요.\nReferences [1] https://github.com/sjp38/lkml\n[2] https://en.wikipedia.org/wiki/Linux_kernel_mailing_list","title":"lkml livestream"},{"content":"I wrote a simple, stupid program[1] that showing LKML[2] mails in terminal briefly like twitter livestream in Go language. It is just an early version and so many things to be complemented exists, though. Nevertheless, now it just works as I wanted at first.\nReferences [1] https://github.com/sjp38/lkml\n[2] https://en.wikipedia.org/wiki/Linux_kernel_mailing_list\n","permalink":"https://sjp38.github.io/posts/lkml_go/","summary":"I wrote a simple, stupid program[1] that showing LKML[2] mails in terminal briefly like twitter livestream in Go language. It is just an early version and so many things to be complemented exists, though. Nevertheless, now it just works as I wanted at first.\nReferences [1] https://github.com/sjp38/lkml\n[2] https://en.wikipedia.org/wiki/Linux_kernel_mailing_list","title":"lkml livestream"},{"content":"PARSEC 은 멀티쓰레드 프로그램들로 구성된 benchmark suite 입니다. 멀티쓰레드로 구성되어 있기 때문에 멀티코어 시스템에서의 multi core scalability 를 테스트 하기에도 적합합니다. 이 글에선 현재 최신 버전인 3.0 버전의 PARSEC 을 Ubuntu 16.04 server 에 설치하면서 겪는 문제의 해결법과 간단한 사용법을 정리해 봅니다.\nToolbox for PARSEC 3.0 on Ubuntu Xenial 아래의 내용을 하나하나 읽어가면서 따라하는 것도 귀찮은 일입니다. 그래서 아래에서 설명하는, Ubuntu Xenial 에서 PARSEC 3.0 을 돌리기 위해 필요한 작업을 대부분 자동으로 해주는 도구들을 만들어 두었습니다. 오픈소스로 공개되어 있으니[1], 아래의 머리 아픈 내용을 읽기 귀찮다면 해당 도구들을 사용하시기 바랍니다. 해당 도구들의 사용법은 README 에 간략히 설명되어 있습니다.\n[1] https://github.com/sjp38/parsec_on_ubuntu_xenial\nPARSEC 3.0 Download 공식 홈페이지[1] 에 들어가면 PARSEC 3.0 다운로드 링크가 첫페이지부터 있습니다. 해당 링크를 사용하면 tar.gz 포맷의 tarball 로 정리된 PARSEC 3.0 을 다운받을 수 있습니다. 웹브라우저로 들어가서 다운로드를 받는 방법도 있겠고, curl 이나 wget 등의 command line tool 을 사용해 다운받을 수도 있겠습니다. 다음 커맨드는 PARSEC 3.0 을 다운받아 parsec-3.0/ 디렉토리 아래 압축을 풀고 압축을 푼 디렉토리로 이동합니다.\n$ wget http://parsec.cs.princeton.edu/download/3.0/parsec-3.0.tar.gz $ tar zxvf parsec-3.0.tar.gz $ cd parsec-3.0 Build 이제 PARSEC 3.0 을 빌드해야 합니다. PARSEC 은 여러 벤치마크를 포함하고 있으므로 개별적 벤치마크를 하나하나 직접적으로 다루기보다는 suite 내의 각 벤치마크를 통합적으로 관리할 수 있는 parsecmgmt 라는 관리 프로그램을 사용하도록 되어 있습니다. 빌드 역시 마찬가지입니다. 참고로, parsecmgmt 는 bash script 입니다.\n기본적인 PARSEC 3.0 빌드 방법은 다음과 같이 간단합니다:\n$ source ./env.sh $ parsecmgmt -a build 첫번째 커맨드는 parsecmgmt 의 경로를 PATH 에 추가하는 등, 환경 변수 설정 등의 일을 처리해 주며, 두번째의 간단한 커맨드가 전체 PARSEC 3.0 빌드 프로세스를 수행하게 됩니다.\nPerl Version Problem 하지만 Ubuntu 16.04 server 에서는 다음과 같은 에러 메세지를 내뱉으며 빌드에 실패합니다:\nsmime.pod around line 272: Expected text after =item, not a number smime.pod around line 276: Expected text after =item, not a number smime.pod around line 280: Expected text after =item, not a number smime.pod around line 285: Expected text after =item, not a number smime.pod around line 289: Expected text after =item, not a number POD document had syntax errors at /usr/bin/pod2man line 68. make: *** [install_docs] Error 1 Makefile:680: recipe for target \u0026#39;install_docs\u0026#39; failed [PARSEC] Error: \u0026#39;env PATH=/usr/local/sbin:...\u0026#39; failed. 에러 메세지에서 유추할 수 있듯 PARSEC 3.0 의 소스 코드 중 smime.pod 파일이 문법에 맞지 않아 생긴 문제입니다. 참고로 pod 는 perl 프로그램 문서화에 사용되는 간단한 markup language 입니다[2]. Ubuntu 16.04 는 perl 5.22.1 버전을 기본으로 사용하고 있는데, PARSEC 3.0 에 있는 코드는 perl 5.14.2 버전에 맞춰져 있으며 최신 버전으로 오는 사이 문법이 바뀐 것으로 인한 문제로 보입니다. 해결책은 두가지가 있습니다.\n방법 1: perl 5.14.2 설치\nGoogle groups 의 관련 쓰레드[3] 를 참고한 방법입니다. 5.14.2 버전의 perl 소스코드를 받아와 이를 설치하고 PARSEC 빌드에 이 버전의 perl 을 사용하는 방법입니다. 다음의 커맨드로 ~/localperl/ 디렉토리 아래 5.14.2 버전 perl 을 설치하고 사용할 수 있습니다.\nwget http://www.cpan.org/src/5.0/perl-5.14.2.tar.gz $ tar zxvf perl-5.14.2.tar.gz $ cd perl-5.14.2/ $ mkdir ~/localperl $ ./Configure -des -Dprefix=$HOME/localperl $ time make -j $ make test $ make install $ ~/localperl/bin/perl -v 방법 2: pod 파일 문법 오류 수정\n좀 더 정공법에 가까운 방법으로, 다음 글을 참고한 해결책입니다: https://yulistic.gitlab.io/2016/05/parsec-3.0-installation-issues/\n최신 버전의 문법에 맞게 pod 파일의 문제시 되는 부분들을 고쳐주는 것으로, 문제되는 모든 pod 파일의 =item [0-9] 을 =item C\u0026lt;[0-9]\u0026gt; 으로 바꿔줍니다. diff 로 표현하면 다음과 같은 수정을 가하게 되겠습니다:\n--- a/pkgs/libs/ssl/src/doc/apps/smime.pod +++ b/pkgs/libs/ssl/src/doc/apps/smime.pod @@ -265,28 +265,28 @@ encrypted data is used for other purposes. =over 4 -=item 0 +=item C\u0026lt;0\u0026gt; the operation was completely successfully. -=item 1 +=item C\u0026lt;1\u0026gt; an error occurred parsing the command options. -=item 2 +=item C\u0026lt;2\u0026gt; one of the input files could not be read. -=item 3 +=item C\u0026lt;3\u0026gt; an error occurred creating the PKCS#7 file or when reading the MIME message. -=item 4 +=item C\u0026lt;4\u0026gt; an error occurred decrypting or verifying the message. -=item 5 +=item C\u0026lt;5\u0026gt; the message was verified correctly but an error occurred writing out the signers certificates. 이렇게 파일 하나하나 수정하면 이 에러 메세지는 사라집니다. 참고한 링크에서는 하나하나 손으로 수정하기보다는 다음과 같이 간단한 bash shell script 를 짜서 일괄적으로 수정하는 걸 추천합니다:\n#! /bin/bash for i in 0 1 2 3 4 5 6 7 8 9 do echo \u0026#34;Replacing \u0026#39;=item $i\u0026#39; to \u0026#39;=item C\u0026lt;$i\u0026gt;\u0026#39;\u0026#34; grep -rl \u0026#34;=item $i\u0026#34; * | xargs sed -i \u0026#34;s/=item $i/=item C\u0026lt;$i\u0026gt;/g\u0026#34; done 이어서 설명할 문제들과 해결책도 해당 링크를 참고한 것임을 밝혀둡니다.\n__mbstate_t Conflict 앞의 에러 메세지는 사라지지만 이제 다음과 같은 에러 메세지가 나올 겁니다:\n/usr/include/wchar.h:94:3: error: conflicting types for ‘__mbstate_t’ } __mbstate_t; ^ In file included from ../include/machine/bsd_endian.h:37:0, from ../include/sys/bsd_types.h:44, from ../include/sys/bsd_param.h:64, from if_host.c:48: ../include/sys/bsd__types.h:105:3: note: previous declaration of ‘__mbstate_t’ was here } __mbstate_t; ^ In file included from ../include/net/bsd_if_var.h:82:0, from ../include/net/bsd_if.h:459, from if_host.c:57: ../include/sys/bsd_buf_ring.h: In function ‘buf_ring_dequeue_sc’: ../include/sys/bsd_buf_ring.h:200:33: warning: variable ‘cons_next_next’ set but not used [-Wunused-but-set-variable] uint32_t cons_head, cons_next, cons_next_next; ^ make[1]: *** [if_host.o] Error 1 basd__types.h 파일에 __mbstate_t 타입을 중복 정의했기 때문에 발생한 문제입니다. 해당 파일에서 해당 정의 부분을 다음과 같이 주석 처리하면 이 문제는 사라집니다.\ndiff --git a/pkgs/libs/uptcpip/src/include/sys/bsd__types.h b/pkgs/libs/uptcpip/src/include/sys/bsd__types.h index fa1b0f0f26d9..bd7e6a97f4c8 100644 --- a/pkgs/libs/uptcpip/src/include/sys/bsd__types.h +++ b/pkgs/libs/uptcpip/src/include/sys/bsd__types.h @@ -93,6 +93,7 @@ typedef __ct_rune_t __wint_t; /* wint_t (see above) */ typedef __uint32_t __fixpt_t; /* fixed point number */ +#if 0 /* Skip conflicting __mbstate_t definition */ /* * mbstate_t is an opaque object to keep conversion state during multibyte * stream conversions. @@ -104,5 +105,6 @@ typedef union { __int64_t _mbstateL; /* for alignment */ } __mbstate_t; #endif +#endif /* Skip conflicting __mbstate_t definition */ #endif /* !_BSD_SYS__TYPES_H_ */ pkg-config Package Not Found 성공적인 빌드를 위해선 당연하지만 PARSEC 3.0 이 의존성을 가진 패키지가 모두 설치되어 있어야 합니다. 이를 주의 깊게 미리 설치해 두지 않았다면 다음과 같은 에러 메세지를 만날 수도 있습니다:\nconfigure: error: *** pkg-config not found. See http://www.freedesktop.org/software/pkgconfig/ [PARSEC] Error: ... 위 메세지는 pkg-config 프로그램이 설치되어 있지 않아서 발생한 문제임을 알 수 있습니다. 간단히 Ubuntu 의 package 시스템인 apt 를 사용해 다음과 같이 해당 프로그램을 설치해 주면 문제는 사라집니다.\n$ sudo apt install pkg-config Build Success 이 정도까지가 나타날 수 있는 대부분의 문제입니다. 위 해결책들을 모두 적용했다면 아마 빌드에 성공할 겁니다. 빌드에 성공하면 다음과 같이 성공했다는 메세지를 볼 수 있을 겁니다:\n[PARSEC] [PARSEC] BIBLIOGRAPHY [PARSEC] [PARSEC] [1] Bienia. Benchmarking Modern Multiprocessors. Ph.D. Thesis, 2011. [PARSEC] [2] Woo et al. The SPLASH-2 Programs: Characterization and Methodological Considerations. ISCA, 1995. [PARSEC] [PARSEC] Done. 참고로 빌드에 꽤 긴 시간이 소모됩니다. 제가 사용한 72 코어 / 144 쓰레드 머신에서도 약 10분이 걸렸습니다.\nSimple Usage 이제 빌드가 잘 되었는지 돌려봐야 할 차례입니다. 다음 커맨드는 각 벤치마크를 가장 작은 크기의 데이터셋을 가지고 실행해 보기 때문에 각 벤치마크가 돌아가긴 하는지만 보는데 적격입니다:\nparsecmgmt -a run 가장 작은 크기의 데이터셋을 사용하기 때문에 모든 벤치마크를 수행하지만 빠르게 종료됩니다.\nparsecmgmt Options -a 옵션은 action 을 의미합니다. 앞의 섹션에서는 빌드를 위해 여기에 build 값을 주었고, 여기선 벤치마크 수행을 위해 run 값을 준 것입니다.\n-i 옵션을 통해 벤치마크들은 워크로드에서 사용할 데이터 크기를 지정할 수 있습니다. 이 인자의 값으로 test, simdev, simsmall, simmedium, simlarge, native 를 줄 수 있습니다. Test 는 정확성 테스트만을 위한, 빨리 끝나는 데이터로 이 인자를 주지 않으면 default 로 이 값이 취해집니다. native 는 가장 realworld workload 에 가까운 벤치마크를 위한 데이터라 볼 수 있습니다.\n-p 옵션을 통해 어떤 sub benchmark 를 돌릴지 정할 수 있습니다. 이 옵션을 별도로 주지 않으면 모든 benchmark 를 돌리게 됩니다.\n-n 옵션은 number of threads to use 입니다.\n예를 들어 parsecmgmt -p canneal -a run -i native -n 1 은 canneal sub benchmark 하나만을 쓰레드 한개 써서 native 데이터셋으로 실행합니다.\nReferences [1] http://parsec.cs.princeton.edu\n[2] https://en.wikipedia.org/wiki/Plain_Old_Documentation\n[3] https://groups.google.com/forum/#!topic/snipersim/_1qpbmpPRtg\n","permalink":"https://sjp38.github.io/posts/ko/parsec_3_howto/","summary":"PARSEC 은 멀티쓰레드 프로그램들로 구성된 benchmark suite 입니다. 멀티쓰레드로 구성되어 있기 때문에 멀티코어 시스템에서의 multi core scalability 를 테스트 하기에도 적합합니다. 이 글에선 현재 최신 버전인 3.0 버전의 PARSEC 을 Ubuntu 16.04 server 에 설치하면서 겪는 문제의 해결법과 간단한 사용법을 정리해 봅니다.\nToolbox for PARSEC 3.0 on Ubuntu Xenial 아래의 내용을 하나하나 읽어가면서 따라하는 것도 귀찮은 일입니다. 그래서 아래에서 설명하는, Ubuntu Xenial 에서 PARSEC 3.0 을 돌리기 위해 필요한 작업을 대부분 자동으로 해주는 도구들을 만들어 두었습니다.","title":"Parsec 3.0 설치 / 사용법"},{"content":"여러개의 리눅스 데스크탑 PC 를 한 책상 위에서 사용하는 경우가 있다. 이 때, 한 PC 에서 Ctrl-C 해서 clipboard 에 복사한 내용을 다른쪽 PC 에서 Ctrl-V 로 붙여넣고 싶은 경우가 있다. 여러가지 해결책이 있겠으나, 다음과 같이 ssh 와 xclip 을 사용해서 해결할 수도 있다:\n$ ssh \u0026lt;username\u0026gt;@\u0026lt;remote host\u0026gt; \u0026#39;DISPLAY=:0 xclip -o -selection clipboard\u0026#39; | \\ xclip -i -selection clipboard 참고: http://askubuntu.com/questions/513442/can-two-pcs-with-ubuntu-share-the-clipboard-buffer\n","permalink":"https://sjp38.github.io/posts/ko/xclip_copy_remote_clipboard/","summary":"여러개의 리눅스 데스크탑 PC 를 한 책상 위에서 사용하는 경우가 있다. 이 때, 한 PC 에서 Ctrl-C 해서 clipboard 에 복사한 내용을 다른쪽 PC 에서 Ctrl-V 로 붙여넣고 싶은 경우가 있다. 여러가지 해결책이 있겠으나, 다음과 같이 ssh 와 xclip 을 사용해서 해결할 수도 있다:\n$ ssh \u0026lt;username\u0026gt;@\u0026lt;remote host\u0026gt; \u0026#39;DISPLAY=:0 xclip -o -selection clipboard\u0026#39; | \\ xclip -i -selection clipboard 참고: http://askubuntu.com/questions/513442/can-two-pcs-with-ubuntu-share-the-clipboard-buffer","title":"원격 데스크탑의 clipboard 를 ssh 와 xclip 으로 복사해오기"},{"content":"SPEC, which is a standard corporation for the benchmark[1], makes and shares various benchmark suites. SPEC CPU 2006[1] is one of those benchmark suites. It has made to measure performance of computation intensive workload and widely being used now. It has released v1.0 in 2006, 1.1 in 2008, and 1.2 in 2011. This post briefly describes the way to install and execute the SPEC CPU 2006 v1.1 on Ubuntu 16.04 servers.\nAutomated Toolbox For those who might say TL; DR, I wrote a script that can install and execute the SPEC CPU 2006 with one command[1]. If you have no time to read further, just use it, please.\n[1] https://github.com/sjp38/spec_on_ubuntu_xenial\nTest Environment The test machine I used for this post has:\nIntel Xeon E7-8870 v3 Linux 4.10 kernel Ubuntu 16.04.1 Server version Get The Source Code You should get the source code first. You can buy SPEC CPU 2006 in DVD or .iso file format (As of March 2017, the cost of the SPEC CPU 2006 v1.2 is $800). There are source code of the benchmarks, source code of tool programs that helps compile, execution, and verification of the benchmarks, pre-compiled tool programs, rule files for the execution of the benchmarks, and documents. This post is written basedon SPEC CPU 2006 v1.1. If you got the .iso file, you can access to the files in it by mounting it as below:\n$ mkdir tmnt $ sudo mount -o loop SPEC_CPU2006v1.1.iso ./tmnt $ ls tmnt It is ok to directly install and execute the benchmarks, but I prefer to first copy the files outside of the mounted dir. The owner of the files is root, as the above command mounted the file via the sudo command. Change the owner to you as below:\n$ mkdir SPEC_CPU2006v1.1 $ cp -R ./tmnt/* SPEC_CPU2006v1.1/ $ sudo umount ./tmnt \u0026amp;\u0026amp; rm -fr ./tmnt $ sudo chown -R \u0026lt;username\u0026gt; SPEC_CPU2006v1.1 $ sudo chmod -R 755 SPEC_CPU2006v1.1 $ cd SPEC_CPU2006v1.1 Build The Tools The .iso file has executable binaries for the tools, which is built for various platforms such as redhat and suse. But, there is no binary for Ubuntu. Therefore, you should build the tools from the source code as below:\n$ cd tools/src $ ./buildtools buildtools is a shell script which builds tools under tools/src. But, you may encounter some errors. Following sections describe the errors and how you can solve it.\nConflicting types for \u0026lsquo;getline\u0026rsquo; Build of md5sum will show you following error message:\ngcc -DHAVE_CONFIG_H -I/home/sjpark/SPEC_CPU2006v1.1/tools/output/include -I. -Ilib -c -o md5sum.o md5sum.c In file included from md5sum.c:38:0: lib/getline.h:31:1: error: conflicting types for \u0026#39;getline\u0026#39; getline PARAMS ((char **_lineptr, size_t *_n, FILE *_stream)); ^ Type conflict is occurred because getline() and getdelim() functions are declared in stdio.h, but those are declared again in getline.h file. You can fix this as below, by checking GLIBC version.\n--- a/tools/src/specmd5sum/lib/getline.h +++ b/tools/src/specmd5sum/lib/getline.h @@ -27,10 +27,14 @@ Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA. */ # endif # endif +# if __GLIBC__ \u0026lt; 2 + int getline PARAMS ((char **_lineptr, size_t *_n, FILE *_stream)); int getdelim PARAMS ((char **_lineptr, size_t *_n, int _delimiter, FILE *_stream)); +#endif + #endif /* not GETLINE_H_ */ Undefined reference to pow I referenced an internet post[3] to solve this and following two problems.\nNow, you will see below error message while building perl.\ncc -L/home/sjpark/SPEC_CPU2006v1.1/tools/output/lib -L/usr/local/lib -o miniperl \\ miniperlmain.o opmini.o libperl.a libperl.a(pp.o): In function `Perl_pp_pow\u0026#39;: pp.c:(.text+0x2a76): undefined reference to `pow\u0026#39; It failed to find pow functiona. You should modify it to link libm library. You can solve this problem by setting PERLFLAGS env variable and executing buildtools again:\n$ PERLFLAGS=\u0026quot;-A libs=-lm -A libs=-ldl\u0026quot; ./buildtools\nYou haven\u0026rsquo;t done a \u0026ldquo;make depend\u0026rdquo; yet! Now, you see below error message.\nYou haven\u0026#39;t done a \u0026#34;make depend\u0026#34; yet! make[1]: *** [hash.o] Error 1 The bin/sh which is used while building perl directs to /bin/dash. This problem made by dash. Simply modify the symbolic link so that it can use bash instead.\n$ sudo rm /bin/sh $ sudo ln -s /bin/bash /bin/sh If you want it to revert this change, simply restore the symbolic link again.\nasm/page.h file not found tools/src/perl-5.8.8/ext/IPC/SysV/SysV.xs is including a kernel header file, asm/page.h.\ncc -c -I/home/sjpark/SPEC_CPU2006v1.1/tools/output/include -fno-strict-aliasing -pipe -Wdeclaration-after-statement -I/usr/local/include -D_LARGEFILE_SOURCE -D_FILE_OFFSET_BITS=64 -O2 -DVERSION=\\\u0026#34;1.04\\\u0026#34; -DXS_VERSION=\\\u0026#34;1.04\\\u0026#34; -fpic \u0026#34;-I../../..\u0026#34; SysV.c SysV.xs:7:25: fatal error: asm/page.h: No such file or directory Block the include statement in the SysV.xs file and define PAGE_SIZE as below.\n--- a/tools/src/perl-5.8.8/ext/IPC/SysV/SysV.xs +++ b/tools/src/perl-5.8.8/ext/IPC/SysV/SysV.xs @@ -4,7 +4,7 @@ #include \u0026lt;sys/types.h\u0026gt; #ifdef __linux__ -# include \u0026lt;asm/page.h\u0026gt; +#define PAGE_SIZE 4096 #endif perl test fail If you apply every solution above and run $ PERLFLAGS=\u0026quot;-A libs=-lm -A libs=-ldl\u0026quot; ./buildtools, about 9 of 900 tests for the perl fails. Because those tests are ignorable, just answer to ignore (Simply enter y as the prompt explains).\nFailed 9 test scripts out of 907, 99.01% okay. ### Since not all tests were successful, you may want to run some of ### them individually and examine any diagnostic messages they produce. ### See the INSTALL document\u0026#39;s section on \u0026#34;make test\u0026#34;. ### You have a good chance to get more information by running ### ./perl harness ### in the \u0026#39;t\u0026#39; directory since most (\u0026gt;=80%) of the tests succeeded. ### You may have to set your dynamic library search path, ### LD_LIBRARY_PATH, to point to the build directory: ### setenv LD_LIBRARY_PATH `pwd`:$LD_LIBRARY_PATH; cd t; ./perl harness ### LD_LIBRARY_PATH=`pwd`:$LD_LIBRARY_PATH; export LD_LIBRARY_PATH; cd t; ./perl harness ### export LD_LIBRARY_PATH=`pwd`:$LD_LIBRARY_PATH; cd t; ./perl harness ### for csh-style shells, like tcsh; or for traditional/modern ### Bourne-style shells, like bash, ksh, and zsh, respectively. u=0.92 s=0.69 cu=89.23 cs=5.47 scripts=907 tests=112394 make[2]: *** [_test_tty] Error 1 make[2]: Leaving directory `/home/sjpark/SPEC_CPU2006v1.1/tools/src/perl-5.8.8\u0026#39; make[1]: *** [_test] Error 2 make[1]: Leaving directory `/home/sjpark/SPEC_CPU2006v1.1/tools/src/perl-5.8.8\u0026#39; make: *** [test] Error 2 + \u0026#39;[\u0026#39; 2 -ne 0 \u0026#39;]\u0026#39; + set +x Hey! Some of the Perl tests failed! If you think this is okay, enter y now: Build success Finally, the build step completes.\nTools built successfully. Go to the top of the tree and source the shrc file. Then you should be ready. $ Execution Configuration File Now you can execute the benchmarks. For this, you should configure the execution environemnts of the benchmarks. There are example configuration files under config/ dir.\nExample-linux64-amd64-gcc43.cfg would be appropriate for the test system I use for this post. You can modify this file as you want. In my test, I just copied the file to config/config.cfg file.\nEnvironment Setup For execution of SPEC CPU benchmarks, you should set various environemnt variables. Below simple one command do that for you.\n$ source ./shrc Running Workload runspec program is used for the execution of each benchmark. This program is located under bin/ dir of the SPEC CPU source code, but you can use it directly without entering path, as the above envrionment variables setting has registered it as $PATH. For example, if you want to execute mcf benchmark, you can use below command:\n$ runspec --iterations 1 --size ref --action onlyrun --config config.cfg --noreportable mcf This command executes mcf benchmark and prints the path to the log file describing the execution results.\n... Run Complete The log for this run is in /home/username/spec/spec_src/result/CPU2006.003.log runspec finished at Sun Sep 24 13:55:14 2017; 290 total seconds elapsed To do some experiments for your particular use case, you should understand the usage of runspec. Because it is an out of scope of this post, reference to other documents, please.\nConclusion This post described the way to run SPEC CPU 2006 on an Ubuntu 16.04 system.\nReferences [0] http://spec.org/\n[1] http://spec.org/benchmarks.html#cpu\n[2] http://spec.org/order.html\n[3] https://wiki.linaro.org/MichaelHope/Sandbox/BuildingSPECTools\n","permalink":"https://sjp38.github.io/posts/spec_cpu2006_install/","summary":"SPEC, which is a standard corporation for the benchmark[1], makes and shares various benchmark suites. SPEC CPU 2006[1] is one of those benchmark suites. It has made to measure performance of computation intensive workload and widely being used now. It has released v1.0 in 2006, 1.1 in 2008, and 1.2 in 2011. This post briefly describes the way to install and execute the SPEC CPU 2006 v1.1 on Ubuntu 16.04 servers.","title":"Install / execute spec cpu2006 benchmark"},{"content":"SPEC 은 벤치마크를 위한 협력기구 [0] 로, 다양한 벤치마크 suite 들을 만들고 공유합니다. SPEC CPU 2006 은 여기서 만든 벤치마크 도구집합 중 하나 [1] 로 계산 작업 집중적인 워크로드에 대한 성능을 측정을 목표로 만들어졌으며, 많은 곳에서 사용되고 있습니다. 2006년 1.0 버전이, 2008년에 1.1 버전이, 그리고 2011년에 1.2 버전이 나왔습니다. 본 글은 Ubuntu 16.04 서버 위에서의 SPEC CPU 2006 v1.1 의 설치와 실행 방법에 대해 간단히 설명합니다.\nAutomated Toolbox 아래 내용들을 하나하나 읽고 따라하기엔 시간이 부족할 분들을 위해, 한방에 설치 / 수행이 가능하도록 스크립트를 짜서 Github 에 올려뒀습니다[1]. 시간이 없는 분들은 이쪽을 사용 바랍니다.\n[1] https://github.com/sjp38/spec_on_ubuntu_xenial\n설치 환경 본 글에서 설명하는 내용은 다음과 같은 환경의 머신 위에서 수행되었습니다:\nIntel Xeon E7-8870 v3 Linux 4.10 kernel Ubuntu 16.04.1 Server version 소스 코드 구하기 먼저 소스 코드가 있어야겠죠. SPEC CPU 2006 은 DVD 또는 .iso 파일의 형태로 구매 [2] 될 수 있습니다 (작성 시점에서 SPEC CPU 2006 v1.2 의 가격은 $800 군요). 이렇게 구매된 DVD 안에는 벤치마크 소스코드와 벤치마크의 컴파일과 수행, 검증을 위한 tool 프로그램들의 소스코드, 미리 컴파일된 tool 프로그램들, 벤치마크 실행을 위한 규칙 파일, 그리고 문서등이 들어있습니다. 이 글에선 SPEC CPU 2006 v1.1 을 바탕으로 설명합니다. .iso 파일을 구했다면 다음과 같은 명령으로 mount 해서 그 안의 파일들을 보고 사용할 수 있습니다:\n$ mkdir tmnt $ sudo mount -o loop SPEC_CPU2006v1.1.iso ./tmnt $ ls tmnt 마운트한 위치에서 곧바로 설치 / 실행을 수행해도 좋지만 파일을 복사해두고 사용하겠습니다. mount 를 sudo 로 해야하는 관계로 이 파일들의 owner 는 root 이며 쓰기권한도 없습니다. 굳이 root 가 되지 않고도 벤치마크를 설치하고 돌릴 수 있으므로 파일의 owner 와 권한을 바꿔줍니다:\n$ mkdir SPEC_CPU2006v1.1 $ cp -R ./tmnt/* SPEC_CPU2006v1.1/ $ sudo umount ./tmnt \u0026amp;\u0026amp; rm -fr ./tmnt $ sudo chown -R \u0026lt;username\u0026gt; SPEC_CPU2006v1.1 $ sudo chmod -R 755 SPEC_CPU2006v1.1 $ cd SPEC_CPU2006v1.1 툴 빌드 SPEC 에서 사용되는 도구들은 앞서 가져온 .iso 파일 안에 redhat, suse 등 여러 플랫폼 용으로 미리 빌드되어 있습니다. 하지만 Ubuntu 를 위한 버전은 없습니다. 따라서 다음과 같이 소스코드로부터 직접 빌드를 해야 합니다:\n$ cd tools/src $ ./buildtools buildtools 는 셸 스크립트로, tools/src 아래 있는 각 툴들을 빌드합니다. 곧바로 진행되면 좋겠지만, 다음과 같은 에러들이 발생합니다.\nConflicting types for \u0026lsquo;getline\u0026rsquo; md5sum 빌드 중 다음과 같은 에러 메세지가 나옵니다:\ngcc -DHAVE_CONFIG_H -I/home/sjpark/SPEC_CPU2006v1.1/tools/output/include -I. -Ilib -c -o md5sum.o md5sum.c In file included from md5sum.c:38:0: lib/getline.h:31:1: error: conflicting types for \u0026#39;getline\u0026#39; getline PARAMS ((char **_lineptr, size_t *_n, FILE *_stream)); ^ md5sum 빌드 중 getline(), getdelim() 함수가 stdio.h 에서 선언되어 있는데도 getline.h 파일에 또 선언되어서 conflicting type 으로 나는 문제입니다. 역시 툴 중 하나인 tar 의 경우엔 GLIBC 버전을 체크해 2 이상일 경우엔 해당 declaration 을 제거해 두었는데, md5sum 아래의 getline.h 엔 이 체크가 없기 때문에 문제가 됩니다. 다음과 같이 GLIBC 버전 체크를 추가해 중복선언이 없도록 수정해 줍니다:\n--- a/tools/src/specmd5sum/lib/getline.h +++ b/tools/src/specmd5sum/lib/getline.h @@ -27,10 +27,14 @@ Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA. */ # endif # endif +# if __GLIBC__ \u0026lt; 2 + int getline PARAMS ((char **_lineptr, size_t *_n, FILE *_stream)); int getdelim PARAMS ((char **_lineptr, size_t *_n, int _delimiter, FILE *_stream)); +#endif + #endif /* not GETLINE_H_ */ Undefined reference to pow 이 문제와 아래의 두개의 문제는 인터넷 상의 SPEC CPU 2000 에 대한 비슷한 문제의 해결책[3] 을 참고했습니다.\n이제 perl 빌드 중 다음과 같은 에러 메세지가 발생합니다:\ncc -L/home/sjpark/SPEC_CPU2006v1.1/tools/output/lib -L/usr/local/lib -o miniperl \\ miniperlmain.o opmini.o libperl.a libperl.a(pp.o): In function `Perl_pp_pow\u0026#39;: pp.c:(.text+0x2a76): undefined reference to `pow\u0026#39; pow 함수를 찾지 못하는 문제로, libm 라이브러리를 링크 시점에 링크하도록 알려줘야 합니다. 다음과 같이 PERLFLAGS 환경변수를 설정하고 buildtools 를 실행하는 것으로 해결할 수 있습니다:\n$ PERLFLAGS=\u0026quot;-A libs=-lm -A libs=-ldl\u0026quot; ./buildtools\nYou haven\u0026rsquo;t done a \u0026ldquo;make depend\u0026rdquo; yet! 이어서 다음 에러 메세지가 나옵니다.\nYou haven\u0026#39;t done a \u0026#34;make depend\u0026#34; yet! make[1]: *** [hash.o] Error 1 perl 빌드 중 사용되는 /bin/sh 은 /bin/dash 를 가리키고 있는데, dash 에서 생기는 문제입니다. 다음과 같이 심볼릭 링크를 수정해 bin/sh 이 bash 를 가리키도록 하면 문제는 해결됩니다.\n$ sudo rm /bin/sh $ sudo ln -s /bin/bash /bin/sh 시스템을 원래대로 돌리고 싶다면 빌드 끝나고 나중에 심볼릭 링크를 되돌리면 됩니다.\nasm/page.h file not found 커널 헤더파일인 asm/page.h 파일을 tools/src/perl-5.8.8/ext/IPC/SysV/SysV.xs 파일에서 include 하고 있어 발생하는 문제가 다음과 같이 발생합니다:\ncc -c -I/home/sjpark/SPEC_CPU2006v1.1/tools/output/include -fno-strict-aliasing -pipe -Wdeclaration-after-statement -I/usr/local/include -D_LARGEFILE_SOURCE -D_FILE_OFFSET_BITS=64 -O2 -DVERSION=\\\u0026#34;1.04\\\u0026#34; -DXS_VERSION=\\\u0026#34;1.04\\\u0026#34; -fpic \u0026#34;-I../../..\u0026#34; SysV.c SysV.xs:7:25: fatal error: asm/page.h: No such file or directory SysV.xs 파일의 해당 include 문을 다음과 같이 막고 PAGE_SIZE 를 정의해 줍니다.\n--- a/tools/src/perl-5.8.8/ext/IPC/SysV/SysV.xs +++ b/tools/src/perl-5.8.8/ext/IPC/SysV/SysV.xs @@ -4,7 +4,7 @@ #include \u0026lt;sys/types.h\u0026gt; #ifdef __linux__ -# include \u0026lt;asm/page.h\u0026gt; +#define PAGE_SIZE 4096 #endif perl test fail 위의 해결책을 모두 적용하고 $ PERLFLAGS=\u0026quot;-A libs=-lm -A libs=-ldl\u0026quot; ./buildtools 를 수행하면 perl 쪽의 테스트 약 900개 가운데 9개 정도 fail 나는 문제가 있긴 하지만 이건 무시하겠다고 하면 무시가 되고 빌드 진행이 됩니다. 테스트 9개가 fail 났는데 무시하겠냐는 질문이 아래와 같이 뜨는데, 무시하겠다고 답해줍시다 (해당 프롬프트에서 설명하는대로, y 를 입력하면 됩니다).\nFailed 9 test scripts out of 907, 99.01% okay. ### Since not all tests were successful, you may want to run some of ### them individually and examine any diagnostic messages they produce. ### See the INSTALL document\u0026#39;s section on \u0026#34;make test\u0026#34;. ### You have a good chance to get more information by running ### ./perl harness ### in the \u0026#39;t\u0026#39; directory since most (\u0026gt;=80%) of the tests succeeded. ### You may have to set your dynamic library search path, ### LD_LIBRARY_PATH, to point to the build directory: ### setenv LD_LIBRARY_PATH `pwd`:$LD_LIBRARY_PATH; cd t; ./perl harness ### LD_LIBRARY_PATH=`pwd`:$LD_LIBRARY_PATH; export LD_LIBRARY_PATH; cd t; ./perl harness ### export LD_LIBRARY_PATH=`pwd`:$LD_LIBRARY_PATH; cd t; ./perl harness ### for csh-style shells, like tcsh; or for traditional/modern ### Bourne-style shells, like bash, ksh, and zsh, respectively. u=0.92 s=0.69 cu=89.23 cs=5.47 scripts=907 tests=112394 make[2]: *** [_test_tty] Error 1 make[2]: Leaving directory `/home/sjpark/SPEC_CPU2006v1.1/tools/src/perl-5.8.8\u0026#39; make[1]: *** [_test] Error 2 make[1]: Leaving directory `/home/sjpark/SPEC_CPU2006v1.1/tools/src/perl-5.8.8\u0026#39; make: *** [test] Error 2 + \u0026#39;[\u0026#39; 2 -ne 0 \u0026#39;]\u0026#39; + set +x Hey! Some of the Perl tests failed! If you think this is okay, enter y now: Build success 여기까지 오면 이제 빌드가 완료됩니다.\nTools built successfully. Go to the top of the tree and source the shrc file. Then you should be ready. $ 실행 Configuration File 빌드가 완료되었다면 이제 실행을 해야겠죠. 벤치마크의 실행 환경을 구성해야 하는데, config/ 디렉토리 밑에 예제 구성 파일들이 있습니다. 이 가운데, Example-linux64-amd64-gcc43.cfg 정도가 이 글을 작성하며 사용한 시스템에는 적당할 겁니다. 해당 파일을 바탕으로 자신만의 구성 파일을 만들어 config/ 디렉토리 아래 저장합니다. 이 글에서는 config/config.cfg 라는 이름의 파일로 Example-linux64-amd64-gcc43.cfg 파일을 단순히 복사했습니다.\nEnvironment Setup SPEC CPU 벤치마크를 수행하기 위한 환경변수 등을 설정해야 합니다. 다음 명령으로 간단히 이를 수행할 수 있습니다.\n$ source ./shrc Running Workload 최종적인 워크로드의 수행은 runspec 이라는 프로그램을 사용해 이루어집니다. 이 프로그램은 SPEC CPU 소스코드의 bin/ 디렉토리 아래 위치해 있지만 앞서 행한 환경변수 설정으로 인해 커맨드라인에 경로를 직접 입력하지 않고도 수행할 수 있습니다. 예컨대 mcf 워크로드를 수행하고자 한다면 다음과 같은 커맨드를 사용할 수 있습니다:\n$ runspec --iterations 1 --size ref --action onlyrun --config config.cfg --noreportable mcf 위 커맨드를 수행하면 mcf 워크로드가 수행되며, 수행 결과를 요약한 로그 파일의 경로를 다음과 같이 화면에 뿌려줍니다.\n... Run Complete The log for this run is in /home/username/spec/spec_src/result/CPU2006.003.log runspec finished at Sun Sep 24 13:55:14 2017; 290 total seconds elapsed 더 자신의 목적에 맞는 실험을 위해선 runspec 의 사용법을 파악해야 합니다. 이 글에서의 범위는 벗어나므로, 이에 대해서는 다른 문서들을 참고하시기 바랍니다.\nConclusion SPEC CPU 2006 을 Ubuntu 16.04 에 설치하는 과정을 알아봤습니다. 다음 글에서는 SPEC CPU 벤치마크를 실행해 보는 방법을 설명합니다.\nReferences [0] http://spec.org/\n[1] http://spec.org/benchmarks.html#cpu\n[2] http://spec.org/order.html\n[3] https://wiki.linaro.org/MichaelHope/Sandbox/BuildingSPECTools\n","permalink":"https://sjp38.github.io/posts/ko/spec_cpu2006_install/","summary":"SPEC 은 벤치마크를 위한 협력기구 [0] 로, 다양한 벤치마크 suite 들을 만들고 공유합니다. SPEC CPU 2006 은 여기서 만든 벤치마크 도구집합 중 하나 [1] 로 계산 작업 집중적인 워크로드에 대한 성능을 측정을 목표로 만들어졌으며, 많은 곳에서 사용되고 있습니다. 2006년 1.0 버전이, 2008년에 1.1 버전이, 그리고 2011년에 1.2 버전이 나왔습니다. 본 글은 Ubuntu 16.04 서버 위에서의 SPEC CPU 2006 v1.1 의 설치와 실행 방법에 대해 간단히 설명합니다.\nAutomated Toolbox 아래 내용들을 하나하나 읽고 따라하기엔 시간이 부족할 분들을 위해, 한방에 설치 / 수행이 가능하도록 스크립트를 짜서 Github 에 올려뒀습니다[1].","title":"spec cpu2006 벤치마크 설치 / 실행하기"},{"content":"리눅스 커널은 오픈 소스 소프트웨어이므로 그 소스코드가 공개되어 있어 누구나 인터넷을 통해 쉽게 얻을 수 있습니다. 이 글에서는 리눅스 커널 소스코드를 받아올 수 있는 몇가지 방법을 설명합니다.\nkernel.org 리눅스 커널 소스 코드를 받아오기 위한 기본적 공식 사이트는 [kernel.org] (https://www.kernel.org) 라 할 수 있겠는데, 이 사이트에는 소스 코드를 포함해 리눅스 커널을 위한 다양한 리소스가 정리되어 있습니다. 이 사이트에 웹브라우저를 통해 들어가보면 첫페이지에서부터 가장 최근에 릴리즈된 버전의 소스코드, 가장 최근의 안정화된 버전의 소스코드 등을 tar.xz 포맷의 압축 파일 또는 patch 등 다양한 형태로 다운받을 수 있는 링크가 있습니다.\n한가지 유의할 것은 kernel.org 는 공식적 사이트일 뿐으로 비슷하게 소스코드를 호스팅 하는 사이트는 github 을 포함해 여럿 있을 수 있다는 점입니다. 또한, 특정한 회사나 개인이 수정한 버전의 커널의 소스코드는 kernel.org 에서 받을 수 없을 수 있습니다. 하지만, 리눅스 커널의 라이센스가 GPL 인만큼, 그들도 자신이 수정한 버전을 상품 등으로 배포하고 있다면 소스코드를 공개해야 하므로, 해당 버전을 만든 사람 또는 회사에 문의해 보면 그 소스코드를 받을 수 있을 겁니다. 예를 들어 안드로이드의 경우 자신들이 수정한 커널을 사용하며, 그렇게 수정된 커널의 소스코드를 자신들의 소스코드 [호스팅 사이트] (https://android.googlesource.com/) 에 공개하고 있습니다.\nSpecific Version kernel.org 첫 페이지에는 몇가지 버전의 소스코드만 존재하므로 찾고 있는 버전은 해당 페이지에 링크가 존재하지 않을 수 있습니다. 특정 버전을 찾기 위한 페이지 역시 kernel.org 는 제공하는데, https://www.kernel.org/pub/linux/kernel/ 주소로 들어가면 특정 버전의 커널 소스코드를 받을 수 있습니다.\n예를 들어 4.2.1 버전을 받고 싶다면, 다음 커맨드를 셸에서 수행해 받아올 수 있습니다:\n$ wget https://www.kernel.org/pub/linux/kernel/v4.x/linux-4.2.1.tar.xz $ tar xvf linux-4.2.1.tar.xz $ ls linux-4.2.1 Git Repository Cloning 주요 리눅스 개발자들은 각자의 git repository 로 자신이 개발중인 버전의 리눅스 커널 소스코드를 관리하는데, 이 역시 남들이 볼 수 있게 공유해 두고 있습니다. 따라서, 원한다면 특정 리눅스 개발자의 개발중인 리눅스 커널 소스코드를 git 으로 clone 해올 수 있습니다. 많은 주요 개발자들이 kernel.org 위에 자신의 git repository 를 호스팅 하고 있으며, github 을 사용하는 사람들도 많습니다. 예를 들어 리누스 토발즈는 kernel.org 위에 자신의 git repository 를 호스팅 하면서 github 에 미러링도 하고 있습니다. 각각의 repository 의 주소는 다음과 같습니다:\nhttps://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git https://github.com/torvalds/linux.git 다음과 같은 명령을 통해 리누스 토발즈의 개발중인 리눅스 커널 소스코드를 clone 해올 수 있습니다:\n$ git clone https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git $ ls linux 개발자의 repository 를 클론해 오는 방식의 장점은, 일단 아직 릴리즈 되지 않은 따끈따끈한 버전의 소스코드를 그 commit history 와 함께 볼 수 있다는 점일 겁니다. 리눅스 커널 개발에 참여하고 싶다면 현재 어떤 기능이 구현되고 있고 어떤 버그가 아직 고쳐지지 않았는지 등을 알 수 있으므로 필수적입니다. 또하나의 장점은 git repository 에는 그동안 해당 repository 에서 릴리즈한 버전들이 모두 포함되어 있어, 해당 버전을 언제든지 checkout 할 수 있다는 점입니다.\n단점은, commit history 와 개발중인 코드를 원하는게 아니라면 불필요하게 많은 용량의 데이터를 다운로드 받아야 한다는 것입니다. 현재 소스코드를 필요로 하는 목적에 맞춰, 특정 버전의 코드가 필요할 뿐이라면 압축 파일을, 그렇지 않다면 git repository 를 사용한 접근을 하는 편이 옳을 겁니다.\nConclusion 리눅스 커널의 소스코드를 얻어오는 몇가지 방법을 알아봤습니다. 리눅스 커널은 오픈소스 형태라 그 소스코드를 쉽게 구할 수 있으며, kernel.org 또는 github 등의 호스팅 사이트에서 압축 파일, 패치, 또는 git repository 의 형태로 얻을 수 있습니다. 개발중인 repository 의 clone 을 통한 형태는 commit history 와 개발중인 코드의 정보를 알 수 있다는 장점이 있지만 그만큼 다운로드 받아야 하는 데이터의 양이 크다는 단점도 존재합니다. 자신이 현재 소스코드를 얻고자 하는 목적에 맞춰 적합한 방법으로 소스코드를 얻어오는 것이 좋을 겁니다.\n","permalink":"https://sjp38.github.io/posts/fetching-linux-source-code/","summary":"리눅스 커널은 오픈 소스 소프트웨어이므로 그 소스코드가 공개되어 있어 누구나 인터넷을 통해 쉽게 얻을 수 있습니다. 이 글에서는 리눅스 커널 소스코드를 받아올 수 있는 몇가지 방법을 설명합니다.\nkernel.org 리눅스 커널 소스 코드를 받아오기 위한 기본적 공식 사이트는 [kernel.org] (https://www.kernel.org) 라 할 수 있겠는데, 이 사이트에는 소스 코드를 포함해 리눅스 커널을 위한 다양한 리소스가 정리되어 있습니다. 이 사이트에 웹브라우저를 통해 들어가보면 첫페이지에서부터 가장 최근에 릴리즈된 버전의 소스코드, 가장 최근의 안정화된 버전의 소스코드 등을 tar.","title":"Fetching linux kernel source code"},{"content":"리눅스 커널은 오픈 소스 소프트웨어이므로 그 소스코드가 공개되어 있어 누구나 인터넷을 통해 쉽게 얻을 수 있습니다. 이 글에서는 리눅스 커널 소스코드를 받아올 수 있는 몇가지 방법을 설명합니다.\nkernel.org 리눅스 커널 소스 코드를 받아오기 위한 기본적 공식 사이트는 [kernel.org] (https://www.kernel.org) 라 할 수 있겠는데, 이 사이트에는 소스 코드를 포함해 리눅스 커널을 위한 다양한 리소스가 정리되어 있습니다. 이 사이트에 웹브라우저를 통해 들어가보면 첫페이지에서부터 가장 최근에 릴리즈된 버전의 소스코드, 가장 최근의 안정화된 버전의 소스코드 등을 tar.xz 포맷의 압축 파일 또는 patch 등 다양한 형태로 다운받을 수 있는 링크가 있습니다.\n한가지 유의할 것은 kernel.org 는 공식적 사이트일 뿐으로 비슷하게 소스코드를 호스팅 하는 사이트는 github 을 포함해 여럿 있을 수 있다는 점입니다. 또한, 특정한 회사나 개인이 수정한 버전의 커널의 소스코드는 kernel.org 에서 받을 수 없을 수 있습니다. 하지만, 리눅스 커널의 라이센스가 GPL 인만큼, 그들도 자신이 수정한 버전을 상품 등으로 배포하고 있다면 소스코드를 공개해야 하므로, 해당 버전을 만든 사람 또는 회사에 문의해 보면 그 소스코드를 받을 수 있을 겁니다. 예를 들어 안드로이드의 경우 자신들이 수정한 커널을 사용하며, 그렇게 수정된 커널의 소스코드를 자신들의 소스코드 [호스팅 사이트] (https://android.googlesource.com/) 에 공개하고 있습니다.\nSpecific Version kernel.org 첫 페이지에는 몇가지 버전의 소스코드만 존재하므로 찾고 있는 버전은 해당 페이지에 링크가 존재하지 않을 수 있습니다. 특정 버전을 찾기 위한 페이지 역시 kernel.org 는 제공하는데, https://www.kernel.org/pub/linux/kernel/ 주소로 들어가면 특정 버전의 커널 소스코드를 받을 수 있습니다.\n예를 들어 4.2.1 버전을 받고 싶다면, 다음 커맨드를 셸에서 수행해 받아올 수 있습니다:\n$ wget https://www.kernel.org/pub/linux/kernel/v4.x/linux-4.2.1.tar.xz $ tar xvf linux-4.2.1.tar.xz $ ls linux-4.2.1 Git Repository Cloning 주요 리눅스 개발자들은 각자의 git repository 로 자신이 개발중인 버전의 리눅스 커널 소스코드를 관리하는데, 이 역시 남들이 볼 수 있게 공유해 두고 있습니다. 따라서, 원한다면 특정 리눅스 개발자의 개발중인 리눅스 커널 소스코드를 git 으로 clone 해올 수 있습니다. 많은 주요 개발자들이 kernel.org 위에 자신의 git repository 를 호스팅 하고 있으며, github 을 사용하는 사람들도 많습니다. 예를 들어 리누스 토발즈는 kernel.org 위에 자신의 git repository 를 호스팅 하면서 github 에 미러링도 하고 있습니다. 각각의 repository 의 주소는 다음과 같습니다:\nhttps://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git https://github.com/torvalds/linux.git 다음과 같은 명령을 통해 리누스 토발즈의 개발중인 리눅스 커널 소스코드를 clone 해올 수 있습니다:\n$ git clone https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git $ ls linux 개발자의 repository 를 클론해 오는 방식의 장점은, 일단 아직 릴리즈 되지 않은 따끈따끈한 버전의 소스코드를 그 commit history 와 함께 볼 수 있다는 점일 겁니다. 리눅스 커널 개발에 참여하고 싶다면 현재 어떤 기능이 구현되고 있고 어떤 버그가 아직 고쳐지지 않았는지 등을 알 수 있으므로 필수적입니다. 또하나의 장점은 git repository 에는 그동안 해당 repository 에서 릴리즈한 버전들이 모두 포함되어 있어, 해당 버전을 언제든지 checkout 할 수 있다는 점입니다.\n단점은, commit history 와 개발중인 코드를 원하는게 아니라면 불필요하게 많은 용량의 데이터를 다운로드 받아야 한다는 것입니다. 현재 소스코드를 필요로 하는 목적에 맞춰, 특정 버전의 코드가 필요할 뿐이라면 압축 파일을, 그렇지 않다면 git repository 를 사용한 접근을 하는 편이 옳을 겁니다.\nConclusion 리눅스 커널의 소스코드를 얻어오는 몇가지 방법을 알아봤습니다. 리눅스 커널은 오픈소스 형태라 그 소스코드를 쉽게 구할 수 있으며, kernel.org 또는 github 등의 호스팅 사이트에서 압축 파일, 패치, 또는 git repository 의 형태로 얻을 수 있습니다. 개발중인 repository 의 clone 을 통한 형태는 commit history 와 개발중인 코드의 정보를 알 수 있다는 장점이 있지만 그만큼 다운로드 받아야 하는 데이터의 양이 크다는 단점도 존재합니다. 자신이 현재 소스코드를 얻고자 하는 목적에 맞춰 적합한 방법으로 소스코드를 얻어오는 것이 좋을 겁니다.\n","permalink":"https://sjp38.github.io/posts/ko/fetching-linux-source-code/","summary":"리눅스 커널은 오픈 소스 소프트웨어이므로 그 소스코드가 공개되어 있어 누구나 인터넷을 통해 쉽게 얻을 수 있습니다. 이 글에서는 리눅스 커널 소스코드를 받아올 수 있는 몇가지 방법을 설명합니다.\nkernel.org 리눅스 커널 소스 코드를 받아오기 위한 기본적 공식 사이트는 [kernel.org] (https://www.kernel.org) 라 할 수 있겠는데, 이 사이트에는 소스 코드를 포함해 리눅스 커널을 위한 다양한 리소스가 정리되어 있습니다. 이 사이트에 웹브라우저를 통해 들어가보면 첫페이지에서부터 가장 최근에 릴리즈된 버전의 소스코드, 가장 최근의 안정화된 버전의 소스코드 등을 tar.","title":"Fetching linux kernel source code"},{"content":"I am using Fedora 23 laptop and installed stable version Google Chrome from its official website [0]. In this case, just using Updates of Fedora Software program doesn\u0026rsquo;t update Chrome automatically. For the case, follow below commands to update your Chrome:\n$ sudo dnf update google-chrome-stable ... $ sudo killall chrome $ google-chrome-stable The second killall command is necessary because Chrome doesn\u0026rsquo;t kill its process by just cliking Close button. Or, you may reboot your computer but you wouldn\u0026rsquo;t like that.\n[0] https://www.google.com/chrome/browser/desktop/index.html?brand=CHBD\u0026amp;gclid=CKiMjdqX5dICFYcGKgodqZIM2Q\n","permalink":"https://sjp38.github.io/posts/fedora-chrome-update/","summary":"I am using Fedora 23 laptop and installed stable version Google Chrome from its official website [0]. In this case, just using Updates of Fedora Software program doesn\u0026rsquo;t update Chrome automatically. For the case, follow below commands to update your Chrome:\n$ sudo dnf update google-chrome-stable ... $ sudo killall chrome $ google-chrome-stable The second killall command is necessary because Chrome doesn\u0026rsquo;t kill its process by just cliking Close button. Or, you may reboot your computer but you wouldn\u0026rsquo;t like that.","title":"Updating Google Chrome on Fedora 23"},{"content":"랩톱에 Fedora 23 을 깔고 크롬을 공식 홈페이지 [0] 에서 다운받아 메인 브라우저로 사용하고 있습니다. 그런데 이렇게 설치한 경우에는 단순히 Fedora Software 프로그램의 Updates 기능을 통해 업데이트가 되지 않더군요. 이런 경우에는 다음의 커맨드를 통해 직접 업데이트를 할 수 있습니다:\n$ sudo dnf update google-chrome-stable ... $ sudo killall chrome $ google-chrome-stable 두번째의 killall 커맨드는 Chrome 프로세스들이 닫기 버튼을 누르는 것만으로는 모두 종료되지 않기 때문에 명시적으로 종료시키기 위해 필요합니다. 컴퓨터를 아예 리붓 하는 방법도 있겠지만 별로 그러고 싶지는 않을테지요. 이후에 크롬을 다시 시작하면 업데이트된 버전으로 시작됩니다.\n[0] https://www.google.com/chrome/browser/desktop/index.html?brand=CHBD\u0026amp;gclid=CKiMjdqX5dICFYcGKgodqZIM2Q\n","permalink":"https://sjp38.github.io/posts/ko/fedora-chrome-update/","summary":"랩톱에 Fedora 23 을 깔고 크롬을 공식 홈페이지 [0] 에서 다운받아 메인 브라우저로 사용하고 있습니다. 그런데 이렇게 설치한 경우에는 단순히 Fedora Software 프로그램의 Updates 기능을 통해 업데이트가 되지 않더군요. 이런 경우에는 다음의 커맨드를 통해 직접 업데이트를 할 수 있습니다:\n$ sudo dnf update google-chrome-stable ... $ sudo killall chrome $ google-chrome-stable 두번째의 killall 커맨드는 Chrome 프로세스들이 닫기 버튼을 누르는 것만으로는 모두 종료되지 않기 때문에 명시적으로 종료시키기 위해 필요합니다. 컴퓨터를 아예 리붓 하는 방법도 있겠지만 별로 그러고 싶지는 않을테지요.","title":"Updating Google Chrome on Fedora 23"},{"content":"I have developed a chat bot [1] for Kakaotalk [2] using Go language because I have been curious about the process of Kakaotalk chat bot development process. Implementation to major version has consumed only two hours owing to power of Go language, simpleness of Kakaotalk auto-reply API, and simple simple functionality requirement of my bot. It has coded really simply and in brute-force manner, do only simple echoing. However, for the reason, the code could be helpful for beginner of Kakaotalk chat bot or Go language Restful API server programmer. That\u0026rsquo;s why I am introducing it here. You can get the code from below link:\nhttps://github.com/sjp38/kakaobot\nReferences [1] https://en.wikipedia.org/wiki/Chatbot\n[2] http://www.kakao.com/services/8\n","permalink":"https://sjp38.github.io/posts/kakaobot/","summary":"I have developed a chat bot [1] for Kakaotalk [2] using Go language because I have been curious about the process of Kakaotalk chat bot development process. Implementation to major version has consumed only two hours owing to power of Go language, simpleness of Kakaotalk auto-reply API, and simple simple functionality requirement of my bot. It has coded really simply and in brute-force manner, do only simple echoing. However, for the reason, the code could be helpful for beginner of Kakaotalk chat bot or Go language Restful API server programmer.","title":"Golang kakaotalk chat bot making"},{"content":"Kakaotalk [1] chat bot [2] 은 어떻게 만드는지 궁금해져서 Go 언어로 간단한 Kakaotalk chat bot 을 만들어 봤습니다. Go 언어의 강력함과 Kakaotalk auto-reply API 의 단순성, 그리고 echo 서버 역할 정도만 하자는 심플하다 못해 썰렁한 기능 목표 덕에 최초 목표한 데까지는 두시간 만에 만들어졌습니다. 매우 단순히 echo 서버 정도의 역할만 하고 있지만, 매우 단순하게 짜여져 있기 때문에 Kakaotalk chat bot 을 만들고자 할 때, 또는 Restful API 를 사용하는 서버를 Go 언어로 짜고자 할 때 시작용으로 참고할 만 하지 않을까 싶어 소개합니다. 아래 링크를 통해 코드를 얻을 수 있습니다:\nhttps://github.com/sjp38/kakaobot\nReferences [1] https://en.wikipedia.org/wiki/Chatbot\n[2] http://www.kakao.com/services/8\n","permalink":"https://sjp38.github.io/posts/ko/kakaobot/","summary":"Kakaotalk [1] chat bot [2] 은 어떻게 만드는지 궁금해져서 Go 언어로 간단한 Kakaotalk chat bot 을 만들어 봤습니다. Go 언어의 강력함과 Kakaotalk auto-reply API 의 단순성, 그리고 echo 서버 역할 정도만 하자는 심플하다 못해 썰렁한 기능 목표 덕에 최초 목표한 데까지는 두시간 만에 만들어졌습니다. 매우 단순히 echo 서버 정도의 역할만 하고 있지만, 매우 단순하게 짜여져 있기 때문에 Kakaotalk chat bot 을 만들고자 할 때, 또는 Restful API 를 사용하는 서버를 Go 언어로 짜고자 할 때 시작용으로 참고할 만 하지 않을까 싶어 소개합니다.","title":"Golang kakaotalk chat bot making"},{"content":"You can use arping to know IP address to MAC address mapping of your local network. Usage is simple:\narping [-AbDfhqUV] [-c count] [-w deadline] [-s source] -I interface destination For example, you may use the command as below:\n$ arping -I eth0 10.0.0.1 ARPING 10.0.0.1 from 10.0.0.2 eth0 Unicast reply from 10.0.0.1 [11:22:33:44:55:66] 0.123ms Unicast reply from 10.0.0.1 [11:22:33:44:55:66] 0.251ms ... Secret of the tool is ARP protocol [1]. To know the MAC address of the machine that has a specific IP address, IP protocol layer uses the protocol. MAC address that found in this way can be used to communicate with Ethernet protocol layer. arping just sends the ARP REQUEST to local network neighbour.\nIt could be useful in case of internet connection problem if IP duplication is suspicious.\n[1] http://www.erg.abdn.ac.uk/users/gorry/course/inet-pages/arp.html\n","permalink":"https://sjp38.github.io/posts/arping-howto/","summary":"You can use arping to know IP address to MAC address mapping of your local network. Usage is simple:\narping [-AbDfhqUV] [-c count] [-w deadline] [-s source] -I interface destination For example, you may use the command as below:\n$ arping -I eth0 10.0.0.1 ARPING 10.0.0.1 from 10.0.0.2 eth0 Unicast reply from 10.0.0.1 [11:22:33:44:55:66] 0.123ms Unicast reply from 10.0.0.1 [11:22:33:44:55:66] 0.251ms ... Secret of the tool is ARP protocol [1]. To know the MAC address of the machine that has a specific IP address, IP protocol layer uses the protocol.","title":"Using arping to know ip-MAC mapping"},{"content":"로컬 네트워크에서 어떤 IP 주소가 어떤 MAC 어드레스에 매핑되는지 알기 위해 arping 을 사용할 수 있습니다. 사용법은 간단합니다:\narping [-AbDfhqUV] [-c count] [-w deadline] [-s source] -I interface destination 예를 들면, 다음과 같습니다:\n$ arping -I eth0 10.0.0.1 ARPING 10.0.0.1 from 10.0.0.2 eth0 Unicast reply from 10.0.0.1 [11:22:33:44:55:66] 0.123ms Unicast reply from 10.0.0.1 [11:22:33:44:55:66] 0.251ms ... 이 툴의 동작 원리는 ARP 프로토콜 [1] 입니다. IP 프로토콜 레이어는 이 프로토콜을 사용해 특정 IP 주소를 사용하는 기계의 MAC 어드레스를 파악하고 이 주소를 아랫단의 Ethernet 레이어에 보냅니다. arping 은 단지 ARP REQUEST 를 로컬 네트워크의 컴퓨터들에게 보내는 일을 합니다.\n인터넷 연결 문제가 발생했을 때, IP 중복이 의심된다면 유용하게 사용될 수 있습니다.\n[1] http://www.erg.abdn.ac.uk/users/gorry/course/inet-pages/arp.html\n","permalink":"https://sjp38.github.io/posts/ko/arping-howto/","summary":"로컬 네트워크에서 어떤 IP 주소가 어떤 MAC 어드레스에 매핑되는지 알기 위해 arping 을 사용할 수 있습니다. 사용법은 간단합니다:\narping [-AbDfhqUV] [-c count] [-w deadline] [-s source] -I interface destination 예를 들면, 다음과 같습니다:\n$ arping -I eth0 10.0.0.1 ARPING 10.0.0.1 from 10.0.0.2 eth0 Unicast reply from 10.0.0.1 [11:22:33:44:55:66] 0.123ms Unicast reply from 10.0.0.1 [11:22:33:44:55:66] 0.251ms ... 이 툴의 동작 원리는 ARP 프로토콜 [1] 입니다. IP 프로토콜 레이어는 이 프로토콜을 사용해 특정 IP 주소를 사용하는 기계의 MAC 어드레스를 파악하고 이 주소를 아랫단의 Ethernet 레이어에 보냅니다.","title":"Using arping to know ip-MAC mapping"},{"content":"꽤 맘에 드는 hugo 테마[1]를 찾았다. 하지만 tag 기능이 빠져있어 너무 아쉬워하다가 이대로 포기하기엔 너무 맘에 들어 이래저래 찾아보니 과거에 tag 기능 관련 이슈가 올라왔지만 close 처리된 상태. 이대로는 암만 기다려도 tag 기능을 구현해주진 않겠구나 싶어서 이것저것 보고 낑낑대며 서툴고 간단하게나마 tag 기능을 구현[2]. Pull request[3] 도 보냈는데 과연 받아들여줄런지.\n업데이트: 별다른 discussion 없이 머지됐다 ;)\n[1] http://themes.gohugo.io/beautifulhugo/\n[2] https://github.com/sjp38/beautifulhugo-sj\n[3] https://github.com/halogenica/beautifulhugo/pull/15\n","permalink":"https://sjp38.github.io/posts/ko/beautifulhugo_contribute/","summary":"꽤 맘에 드는 hugo 테마[1]를 찾았다. 하지만 tag 기능이 빠져있어 너무 아쉬워하다가 이대로 포기하기엔 너무 맘에 들어 이래저래 찾아보니 과거에 tag 기능 관련 이슈가 올라왔지만 close 처리된 상태. 이대로는 암만 기다려도 tag 기능을 구현해주진 않겠구나 싶어서 이것저것 보고 낑낑대며 서툴고 간단하게나마 tag 기능을 구현[2]. Pull request[3] 도 보냈는데 과연 받아들여줄런지.\n업데이트: 별다른 discussion 없이 머지됐다 ;)\n[1] http://themes.gohugo.io/beautifulhugo/\n[2] https://github.com/sjp38/beautifulhugo-sj\n[3] https://github.com/halogenica/beautifulhugo/pull/15","title":"beautifulhugo 테마 tags 기능 구현"},{"content":"이사로 생긴 쓰레기 정리를 돕다가 보니 한 물건이 유난히 눈에 띄었다. 자그마한 크기에 왠지 모르게 90년대 감성. 자세히 살펴 보니 전자사전 같이 생겼는데 왠지 옛날에 유행하던 palmtop[1] 같은 느낌. 어차피 버릴 물건이기에 따로 챙겨두고 컴퓨터로 검색을 해보았다.\n![HP 95LX] (/img/hp95lx/1.jpg)\n모델명인 HP 95LX 로 검색해보니[2] 한때 스프레드시트 프로그램의 대명사였던 Lotus 123 을 탑재한 것으로 유명한 palmtop PC 로, MS-DOS 를 장착한 모델이다. 당연하게도 바로는 안켜지지만 잘 살펴보니 전용 배터리가 아니라 2A 건전지를 사용하고 있기에 건전지를 끼고 파워 버튼을 눌러봤지만 역시 잠잠. 시무룩. 하지만 또 여기저기 살펴보니 충전지 비슷한 물건이 있다. 배터리 교체 시에 in-memory 데이터가 날아가지 않도록 해당 충전지를 충전 후 동작하는 형태가 아닐까 싶어 잠시 동안 놔두었다 켜봤더니, 켜진다!\n![HP 95LX boot] (/img/hp95lx/2.jpg)\n몇가지 주요 어플리케이션을 통해 주요 기능들을 제공한다. 파일 탐색, 약속 관리, 전화번호부 관리, 메모, 계산기, 그리고 Lotus 123 을 통한 스프레드 시트 관리가 가능하다.3\n파일 탐색 기능. 실행 파일의 실행도 가능한 듯 하다. ![HP 95LX filer] (/img/hp95lx/4.jpg)\n약속 관리 기능. 2017년 달력도 존재. ![HP 95LX appointment book] (/img/hp95lx/5.jpg)\n전화번호부. ![HP 95LX phone book] (/img/hp95lx/6.jpg)\n메모. ![HP 95LX memo] (/img/hp95lx/7.jpg)\n그리고, 시대를 풍미한 스프레드시트, Lotus 123. ![HP 95LX lotus 123] (/img/hp95lx/8.jpg)\n한참 가지고 놀다가 뒤늦게야 시간과 사용자를 설정. 연도 설정이 두자리라 혹시나 Y2K 문제가 있진 않을까 걱정했지만 2017 년으로 잘 인식한다. 잘 짜여진 프로그램이란 이리도 멋지다. ![HP 95LX boot] (/img/hp95lx/9.jpg)\n요즘 나오는 스마트폰에 비교하자면 보잘것없지만 그 시절에도 이만한 휴대성과 완성도의 물건을 아직도 동작할 만큼 튼튼하게 제품으로 만들어냈다는 사실에 경외로움을 숨길 수 없거니와, 여전히 텍스트 기반 UI 를 즐겨 사용하는 내 입장에서는 이 UI 도 여전히 멋지다. 물론 Unix 계열 셸을 제공했다면 완벽했겠지만\u0026hellip; 과거의 물건이 유난한 감동을 준 하루였다.\nReferences [1] https://en.wikipedia.org/wiki/Palmtop_PC\n[2] https://en.wikipedia.org/wiki/HP_95LX\n","permalink":"https://sjp38.github.io/posts/ko/hp_95lx/","summary":"이사로 생긴 쓰레기 정리를 돕다가 보니 한 물건이 유난히 눈에 띄었다. 자그마한 크기에 왠지 모르게 90년대 감성. 자세히 살펴 보니 전자사전 같이 생겼는데 왠지 옛날에 유행하던 palmtop[1] 같은 느낌. 어차피 버릴 물건이기에 따로 챙겨두고 컴퓨터로 검색을 해보았다.\n![HP 95LX] (/img/hp95lx/1.jpg)\n모델명인 HP 95LX 로 검색해보니[2] 한때 스프레드시트 프로그램의 대명사였던 Lotus 123 을 탑재한 것으로 유명한 palmtop PC 로, MS-DOS 를 장착한 모델이다. 당연하게도 바로는 안켜지지만 잘 살펴보니 전용 배터리가 아니라 2A 건전지를 사용하고 있기에 건전지를 끼고 파워 버튼을 눌러봤지만 역시 잠잠.","title":"1990년대의 palmtop, HP 95LX 를 득템"},{"content":"테스트 등을 위해 소스코드로부터 커널을 직접 빌드, 설치하기 시작하면 어느새 수많은 커널이 설치되어 있는 것을 확인할 수 있다. 삭제를 위해선 make install 로 만들어진 파일들을 직접 제거하고 grub 을 업데이트 해줘야 한다.\n예를 들어 시스템이 현재 부팅되어 있는 버전의 커널을 언인스톨하고자 한다면 다음의 일련의 커맨드를 입력하면 된다:\n# rm /boot/vmlinuz-$(uname -r) # rm /boot/initrd.img-$(uname -r) # rm /boot/System.map-$(uname -r) # rm /boot/config-$(uname -r) # rm -fr /lib/modules/$(uname -r) # rm /var/lib/initramfs-tools/$(uname -r) # update-grub2 다른 버전의 설치되어있는 커널을 제거하고 싶다면 위의 $(uname -r) 부분을 제거하고자 하는 커널 버전으로 대체하면 된다.\n참고 문서 http://askubuntu.com/questions/594443/how-can-i-remove-compiled-kernel ","permalink":"https://sjp38.github.io/posts/ko/uninstall-kernel/","summary":"테스트 등을 위해 소스코드로부터 커널을 직접 빌드, 설치하기 시작하면 어느새 수많은 커널이 설치되어 있는 것을 확인할 수 있다. 삭제를 위해선 make install 로 만들어진 파일들을 직접 제거하고 grub 을 업데이트 해줘야 한다.\n예를 들어 시스템이 현재 부팅되어 있는 버전의 커널을 언인스톨하고자 한다면 다음의 일련의 커맨드를 입력하면 된다:\n# rm /boot/vmlinuz-$(uname -r) # rm /boot/initrd.img-$(uname -r) # rm /boot/System.map-$(uname -r) # rm /boot/config-$(uname -r) # rm -fr /lib/modules/$(uname -r) # rm /var/lib/initramfs-tools/$(uname -r) # update-grub2 다른 버전의 설치되어있는 커널을 제거하고 싶다면 위의 $(uname -r) 부분을 제거하고자 하는 커널 버전으로 대체하면 된다.","title":"uninstall kernel"},{"content":"나는 보통의 경우 크롬으로 웹브라우징을 한다. 하지만 몇달 전부터 몇가지 예외에 대해서는 파이어폭스를 함께 쓰고 있다.\n부족한 하드웨어 스펙 나의 데스크탑 환경은 모니터 세대를 연결한 PC 하나로 구성되어 있었는데, FHD 모니터 세대를 돌리기는 벅찼는지 간헐적 입력 랙이 자주 발생했다. 또, 모니터를 한대 정도 더 늘리고 싶었다. 해서 집에서 놀고있던 5년된 HP 랩탑에 모니터 하나를 연결시키고 이 랩탑과 PC 를 키보드/마우스 하나로 제어하는 환경을 구축했다. PC 에 연결되는 모니터는 두대로 줄어드니까 입력 랙도 줄어들 것이라 생각한것. 여기까지는 계산대로였는데, HP 랩탑이 5년전 모델이라 램이 2 GB. 난 크롬에서 탭 10여개를 띄워두는데, 가뜩이나 메모리 많이 먹는 크롬이라 도무지 무리. 램 2 GB 를 사서 추가로 달아줬지만 그래도 영 버벅였다. 기존 환경으로 돌아가긴 싫은데\u0026hellip; 싶던 와중 파이어폭스를 떠올렸고, 파이어폭스는 역시 적당한 메모리 사용량으로 내 워크로드를 충족해 주었다.\n일부 성급한 최적화가 이루어진 사이트 리눅스용 크롬에서의 페이스북은 한글 입력 문제가 있다. 뭐라 설명하기도 짜증나는데 한마디로 한글로 글을 입력하려 하면 사람을 짱나게 만드는 문제가 존재한다. 모바일 페이지에선 안그러는 것 같은데, 암튼 짜증난다. 크롬 문제인지 페이스북 문제인지 리눅스 문제인지 모르겠지만 암튼 이불킥할 글을 좀 덜 쓰게 해주는 장점도 있지만 여간 불편한게 아니다. 파이어폭스에서는 문제가 없다.\n모질라에 감사의 마음을 금전으로 파이어폭스를 만들고 있는 모질라는 세상에 많은 것을 기여하는 훌륭한 곳인데 돈이 항상 부족하다. 대안적 도구의 중요성을 되새기고 감사의 마음을 담아 소액이나마 기부해 보았다. 기부를 하고 싶다면 다음 링크를 사용하면 된다: https://donate.mozilla.org/ko/\n뱀발 w3m 같은 CLI 웹브라우저들도 훌륭한 대안 웹브라우저다 ;)\n","permalink":"https://sjp38.github.io/posts/ko/donate-mozilla/","summary":"나는 보통의 경우 크롬으로 웹브라우징을 한다. 하지만 몇달 전부터 몇가지 예외에 대해서는 파이어폭스를 함께 쓰고 있다.\n부족한 하드웨어 스펙 나의 데스크탑 환경은 모니터 세대를 연결한 PC 하나로 구성되어 있었는데, FHD 모니터 세대를 돌리기는 벅찼는지 간헐적 입력 랙이 자주 발생했다. 또, 모니터를 한대 정도 더 늘리고 싶었다. 해서 집에서 놀고있던 5년된 HP 랩탑에 모니터 하나를 연결시키고 이 랩탑과 PC 를 키보드/마우스 하나로 제어하는 환경을 구축했다. PC 에 연결되는 모니터는 두대로 줄어드니까 입력 랙도 줄어들 것이라 생각한것.","title":"donate mozilla"},{"content":"오라클이 백인 남성에게 더 많은 월급을 지불하고 아시아인, 그중에서도 인도 사람을 많이 개발직에 채용했다는 이유로 미국 정부가 오라클을 고소.\nhttp://www.reuters.com/article/us-oracle-usa-labor-idUSKBN1522O6?il=0\n","permalink":"https://sjp38.github.io/posts/ko/us-sues-oracle/","summary":"오라클이 백인 남성에게 더 많은 월급을 지불하고 아시아인, 그중에서도 인도 사람을 많이 개발직에 채용했다는 이유로 미국 정부가 오라클을 고소.\nhttp://www.reuters.com/article/us-oracle-usa-labor-idUSKBN1522O6?il=0","title":"us sues oracle"},{"content":"The importance of physically contiguous memory has increased in modern computing environments, including both low- and high-end systems. Existing physically contiguous memory allocators generally have critical limitations. For example, the most commonly adopted solution, the memory reservation technique, wastes a significant amount of memory space. Scatter/Gather direct memory access (DMA) and input-output memory management units (IOMMUs) avoid this problem by utilizing additional hardware for address space virtualization. However, additional hardware means an increase in costs and power consumption, which is especially disadvantageous for small systems and they do not provide real contiguous memory. Linux Contiguous Memory Allocator (CMA) aims to provide both contiguous memory allocation and to maximize memory utilization based on page migration, but they suffer from unpredictably long latency and a high probability of allocation failure. Therefore, we introduce a new solution to this problem, the guaranteed contiguous memory allocator (GCMA). This guarantees efficient memory space utilization, short latency, and successful allocation. The GCMA uses a reservation scheme and increases memory utilization by sharing the memory with immediately discardable data. Our evaluation of a GCMA on a Raspberry Pi 2 finds a latency that is 15-130 times lower compared to a CMA, and a latency that is up to 10 times lower when taking a photo. Using a large working set in a memory-fragmented high-end system, the GCMA is able to produce a 2.27× speedup.\nSource Code The source code for this version has been submitted to LKML for discussion. A complete git tree is also available at Github.\nPublications and Presentations SeongJae Park, Minchan Kim, Heon Y. Yeom, GCMA: Guaranteed Contiguous Memory Allocator. In Transactions on Computers, March 2019. Link SeongJae Park, GCMA: Guaranteed Contiguous Memory Allocator. In The Linux Kernel Summit, November 2018. Slides, Video, Link SeongJae Park, Minchan Kim, Heon Y. Yeom, GCMA: Guaranteed Contiguous Memory Allocator. In 45th issue of ACM SIGBED Review, January 2016. Paper, Link SeongJae Park, Minchan Kim, Heon Y. Yeom, GCMA: Guaranteed Contiguous Memory Allocator. In Embedded Operating Systems Workshop (EWiLi), October 2015. Paper, Slides SeongJae Park, Minchan Kim, GCMA: Guaranteed Contiguous Memory Allocator. In Linux Foundation Korea Linux Forum (LFKLF), October 2014. Slides ","permalink":"https://sjp38.github.io/posts/gcma/","summary":"The importance of physically contiguous memory has increased in modern computing environments, including both low- and high-end systems. Existing physically contiguous memory allocators generally have critical limitations. For example, the most commonly adopted solution, the memory reservation technique, wastes a significant amount of memory space. Scatter/Gather direct memory access (DMA) and input-output memory management units (IOMMUs) avoid this problem by utilizing additional hardware for address space virtualization. However, additional hardware means an increase in costs and power consumption, which is especially disadvantageous for small systems and they do not provide real contiguous memory.","title":"GCMA: Guaranteed Contiguous Memory Allocator"},{"content":"The importance of physically contiguous memory has increased in modern computing environments, including both low- and high-end systems. Existing physically contiguous memory allocators generally have critical limitations. For example, the most commonly adopted solution, the memory reservation technique, wastes a significant amount of memory space. Scatter/Gather direct memory access (DMA) and input-output memory management units (IOMMUs) avoid this problem by utilizing additional hardware for address space virtualization. However, additional hardware means an increase in costs and power consumption, which is especially disadvantageous for small systems and they do not provide real contiguous memory. Linux Contiguous Memory Allocator (CMA) aims to provide both contiguous memory allocation and to maximize memory utilization based on page migration, but they suffer from unpredictably long latency and a high probability of allocation failure. Therefore, we introduce a new solution to this problem, the guaranteed contiguous memory allocator (GCMA). This guarantees efficient memory space utilization, short latency, and successful allocation. The GCMA uses a reservation scheme and increases memory utilization by sharing the memory with immediately discardable data. Our evaluation of a GCMA on a Raspberry Pi 2 finds a latency that is 15-130 times lower compared to a CMA, and a latency that is up to 10 times lower when taking a photo. Using a large working set in a memory-fragmented high-end system, the GCMA is able to produce a 2.27× speedup.\nSource Code The source code for this version has been submitted to LKML for discussion. A complete git tree is also available at Github.\nPublications and Presentations SeongJae Park, Minchan Kim, Heon Y. Yeom, GCMA: Guaranteed Contiguous Memory Allocator. In Transactions on Computers, March 2019. Link SeongJae Park, GCMA: Guaranteed Contiguous Memory Allocator. In The Linux Kernel Summit, November 2018. Slides, Video, Link SeongJae Park, Minchan Kim, Heon Y. Yeom, GCMA: Guaranteed Contiguous Memory Allocator. In 45th issue of ACM SIGBED Review, January 2016. Paper, Link SeongJae Park, Minchan Kim, Heon Y. Yeom, GCMA: Guaranteed Contiguous Memory Allocator. In Embedded Operating Systems Workshop (EWiLi), October 2015. Paper, Slides SeongJae Park, Minchan Kim, GCMA: Guaranteed Contiguous Memory Allocator. In Linux Foundation Korea Linux Forum (LFKLF), October 2014. Slides ","permalink":"https://sjp38.github.io/posts/ko/gcma/","summary":"The importance of physically contiguous memory has increased in modern computing environments, including both low- and high-end systems. Existing physically contiguous memory allocators generally have critical limitations. For example, the most commonly adopted solution, the memory reservation technique, wastes a significant amount of memory space. Scatter/Gather direct memory access (DMA) and input-output memory management units (IOMMUs) avoid this problem by utilizing additional hardware for address space virtualization. However, additional hardware means an increase in costs and power consumption, which is especially disadvantageous for small systems and they do not provide real contiguous memory.","title":"GCMA: Guaranteed Contiguous Memory Allocator"},{"content":"\u0026ldquo;Is Parallel Programming is Hard, And, If So, What Can You Do About It?\u0026quot;[1] 은 parallel programming 분야에서 대가라 불릴만한 분으로, 이쪽 분야에서 매우 중요한 동기화 메커니즘인 RCU[2] 를 개발했으며 리눅스 커널의 RCU 메인테이너로 활동하고 있는 Paul E. McKenney[3] 가 오픈소스 방식으로 저술하고 있는, parallel programming 에 대한 책입니다.\n개인적으로 이 책의 한국어 번역을 오픈소스[4]로 진행하고 있습니다. 이 프로젝트는 원저작자인 Paul 에게 공식 한국어 번역으로 인증받았습니다[5].\n컨트리뷰션에 대해서도 열려 있으니, 이에 관심 있는 분은 repository 내의 README 문서의 Contribution 섹션[6] 을 참고 바랍니다.\nReferences [1] https://www.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html\n[2] https://en.wikipedia.org/wiki/Read-copy-update\n[3] http://www.rdrop.com/~paulmck/\n[4] https://github.com/sjp38/perfbook-ko_KR\n[5] https://git.kernel.org/pub/scm/linux/kernel/git/paulmck/perfbook.git/commit/?id=edbfcdee046026d3f98592c411a20219b96c8e50\n[6] https://github.com/sjp38/perfbook-ko_KR#contribution\n","permalink":"https://sjp38.github.io/posts/ko/perfbook-kokr/","summary":"\u0026ldquo;Is Parallel Programming is Hard, And, If So, What Can You Do About It?\u0026quot;[1] 은 parallel programming 분야에서 대가라 불릴만한 분으로, 이쪽 분야에서 매우 중요한 동기화 메커니즘인 RCU[2] 를 개발했으며 리눅스 커널의 RCU 메인테이너로 활동하고 있는 Paul E. McKenney[3] 가 오픈소스 방식으로 저술하고 있는, parallel programming 에 대한 책입니다.\n개인적으로 이 책의 한국어 번역을 오픈소스[4]로 진행하고 있습니다. 이 프로젝트는 원저작자인 Paul 에게 공식 한국어 번역으로 인증받았습니다[5].\n컨트리뷰션에 대해서도 열려 있으니, 이에 관심 있는 분은 repository 내의 README 문서의 Contribution 섹션[6] 을 참고 바랍니다.","title":"\"Is Parallel Programming Hard, And, If So, What Can You Do About It?\" Translation"},{"content":"\u0026ldquo;Is Parallel Programming is Hard, And, If So, What Can You Do About It?\u0026quot;[1] 은 parallel programming 분야에서 대가라 불릴만한 분으로, 이쪽 분야에서 매우 중요한 동기화 메커니즘인 RCU[2] 를 개발했으며 리눅스 커널의 RCU 메인테이너로 활동하고 있는 Paul E. McKenney[3] 가 오픈소스 방식으로 저술하고 있는, parallel programming 에 대한 책입니다.\n개인적으로 이 책의 한국어 번역을 오픈소스[4]로 진행하고 있습니다. 이 프로젝트는 원저작자인 Paul 에게 공식 한국어 번역으로 인증받았습니다[5].\n컨트리뷰션에 대해서도 열려 있으니, 이에 관심 있는 분은 repository 내의 README 문서의 Contribution 섹션[6] 을 참고 바랍니다.\nReferences [1] https://www.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html\n[2] https://en.wikipedia.org/wiki/Read-copy-update\n[3] http://www.rdrop.com/~paulmck/\n[4] https://github.com/sjp38/perfbook-ko_KR\n[5] https://git.kernel.org/pub/scm/linux/kernel/git/paulmck/perfbook.git/commit/?id=edbfcdee046026d3f98592c411a20219b96c8e50\n[6] https://github.com/sjp38/perfbook-ko_KR#contribution\n","permalink":"https://sjp38.github.io/posts/perfbook-kokr/","summary":"\u0026ldquo;Is Parallel Programming is Hard, And, If So, What Can You Do About It?\u0026quot;[1] 은 parallel programming 분야에서 대가라 불릴만한 분으로, 이쪽 분야에서 매우 중요한 동기화 메커니즘인 RCU[2] 를 개발했으며 리눅스 커널의 RCU 메인테이너로 활동하고 있는 Paul E. McKenney[3] 가 오픈소스 방식으로 저술하고 있는, parallel programming 에 대한 책입니다.\n개인적으로 이 책의 한국어 번역을 오픈소스[4]로 진행하고 있습니다. 이 프로젝트는 원저작자인 Paul 에게 공식 한국어 번역으로 인증받았습니다[5].\n컨트리뷰션에 대해서도 열려 있으니, 이에 관심 있는 분은 repository 내의 README 문서의 Contribution 섹션[6] 을 참고 바랍니다.","title":"\"Is Parallel Programming Hard, And, If So, What Can You Do About It?\" Translation"},{"content":" Recent \u0026amp; Upcoming Talks Recent Publications Ongoing \u0026amp; Past Projects CV ","permalink":"https://sjp38.github.io/about/","summary":" Recent \u0026amp; Upcoming Talks Recent Publications Ongoing \u0026amp; Past Projects CV ","title":"About"},{"content":" DAMON: Data Access Monitor damo hackermail stream-track RCX: Read-Copy Transact GCMA: Guaranteed Contiguous Memory Allocator DAPHICX: Data Access Pattern Hint Injecting Compiler Extension Translation of \u0026ldquo;Is Parallel Programming Hard, And, If So, What Can You Do About It?\u0026rdquo; Lazybox ","permalink":"https://sjp38.github.io/projects/","summary":" DAMON: Data Access Monitor damo hackermail stream-track RCX: Read-Copy Transact GCMA: Guaranteed Contiguous Memory Allocator DAPHICX: Data Access Pattern Hint Injecting Compiler Extension Translation of \u0026ldquo;Is Parallel Programming Hard, And, If So, What Can You Do About It?\u0026rdquo; Lazybox ","title":"Projects"},{"content":" SeongJae Park, Page-level and Fleet-wide Data Access Monitoring for Meta. In Linux Plumbers Refereed Track, Dec 2025. Link SeongJae Park, Actionable Data Access Monitoring Output Data and Format. In Linux System Monitoring and Observability MC at Linux Plumbers, Dec 2025. Link SeongJae Park, DAMON-based Pages Migration for {C,G,X}PU [un]attached NUMA nodes. In Device and Specific PurposeMemory MC at Linux Plumbers, Dec 2025. Link SeongJae Park, hkml: Mailing Tool for Simple Linux Kernel Development. In Open Source Summit Japan, Dec 2025. Link SeongJae Park, Overcoming Observer Effects in Memory Management with DAMON. In Kernel Recipes, Sep 2025. Slides, Video, Link SeongJae Park, Self-Driving DAMON/S: Controlled and Automated Access-aware Efficient Systems. In Open Source Summit North America, Jun 2025. Slides, Video, Link SeongJae Park, DAMON Requirements for Access-aware MM of Future. In Linux Storage | Filesystem | MM \u0026amp; BPF Summit, Mar 2025. Slides, Link SeongJae Park, DAMON Updates and Plans: Monitoring Parameters Auot-tuning and Memory Tiering. In Linux Storage | Filesystem | MM \u0026amp; BPF Summit, Mar 2025. Slides, Link SeongJae Park, DAMON: Kernel Subsystem for Data Access Monitoring and Access-aware System Operations. In Fosdem, Feb 2025. Slides, Video, Link SeongJae Park, hkml: A tool for working on mailing lists-driven projects without subscribing. In FOSDEM, Feb 2025. Slides, Video, Link SeongJae Park, DAMON: Long-term Plans for Kernel That {Just Works,Extensible}. In Linux Kernel Memory Management Microconferenct at Linux Plumbers, Sep 2024. Slides, Video, Link SeongJae Park, DAMON Recipes: Ways to Save Memory Using a Linux Kernel Subsystem in the Real World. In Open Source Summit Europe, Sep 2024. Slides 1, Slides 2, Video, Link SeongJae Park, DAMON Updates and Plans: Automation of DAMON tuning, tiering, and VM guest scaling. In Linux Storage | Filesystem | MM \u0026amp; BPF Summit, May 2024. Slides, Video, Link SeongJae Park, DAMO[N,S]?: Implementing Self-Driven Data Access-Aware Efficient Linux System. In Open Source Summit North America, Apr 2024. Slides, Video, Link SeongJae Park, DAMON: Current Status and Future Plans. In Kernel Summit, Nov 2023. Slides, Video, Link SeongJae Park, Data Access Monitoring Operator (DAMO): User-Space Tool/Python Library for Access-Aware Profiling and Optimization of Your Linux Systems. In Open Source Summit Europe, Sep 2023. Slides, Video, Link SeongJae Park, DAMON, DAMOS, and DAMO: Kernel Subsystems and User-Space Tools for Data Access-Aware System Analysis/Optimizations. In Open Source Summit North America, May 2023. Slides, Video, Link SeongJae Park, DAMON updates and future plans. In Linux Storage | Filesystem | MM \u0026amp; BPF Summit, May 2023. Slides, Video, Link SeongJae Park, Current Status and Future Plans of DAMON. In The Linux Kernel Summit, September 2022. Slides, Video, Link SeongJae Park, Writing a fine-grained access pattern oriented lightweight kernel module using DAMON/DAMOS in 10 minutes. In The Linux Kernel Summit, September 2021. Slides, Video, Link SeongJae Park, DAMON: Data Access Monitoring Framework for Fun and Memory Management Optimizations, In The Linux Kernel Summit, August 2020. Slides, Video, Link SeongJae Park, Tracing Data Access Pattern with Bounded Overhead and Best-effort Accuracy. In The Linux Kernel Summit, September 2019. Slides, Link SeongJae Park, Biscuit: an operating system written in Go. In 1st GDG Golang Korea meetup, May 2019. Slides, Video SeongJae Park, Yunjae Lee, Moonsub Kim, Heon Y. Yeom, Automated Data Access Pattern Hint Instrumentation for System Performance and Durability of Swap Storages. (WiP) In 17th USENIX Conference on File and Storage Technologies (FAST), February 2019. Link SeongJae Park, GCMA: Guaranteed Contiguous Memory Allocator. In The Linux Kernel Summit, November 2018. Slides, Video, Link SeongJae Park, Linux Kernel Memory Model. In 4th Korea Linux Kernel Conference, November 2018. Slides SeongJae Park, An Introduction to the Formalised Memory Model for Linux Kernel. In Korea Open Source Software Conference (KOSSCON), August 2018. Slides SeongJae Park, Design Choices of Golang for High Scalability. In GDG Korea Meeup, September 2017. Slides SeongJae Park, Brief Introduction to Kselftest. In 2nd Korea Linux Kernel Conference, July 2017. Slides SeongJae Park, Understanding of Linux Kernel Memory Model. In Korea Open Source Software Conference (KOSSCON), November 2016. Slides SeongJae Park, Develop Android/iOS app using golang. In Gophercon Korea, August 2015. Slides SeongJae Park, Hello Android.go In GDG Android Korea Conference (GKAC), April 2015. Slides, Video SeongJae Park, Minchan Kim, GCMA: Guaranteed Contiguous Memory Allocator. In Linux Foundation Korea Linux Forum (LFKLF), October 2014. Slides SeongJae Park, How GIT Works Internally. In Samsung Open-source Software Conference (SOSCON), September 2014. Slides SeongJae Park, Let The Contribution Begin. In Google Developers Group DevFest W, March 2013. Slides ","permalink":"https://sjp38.github.io/talks/","summary":"SeongJae Park, Page-level and Fleet-wide Data Access Monitoring for Meta. In Linux Plumbers Refereed Track, Dec 2025. Link SeongJae Park, Actionable Data Access Monitoring Output Data and Format. In Linux System Monitoring and Observability MC at Linux Plumbers, Dec 2025. Link SeongJae Park, DAMON-based Pages Migration for {C,G,X}PU [un]attached NUMA nodes. In Device and Specific PurposeMemory MC at Linux Plumbers, Dec 2025. Link SeongJae Park, hkml: Mailing Tool for Simple Linux Kernel Development.","title":"Recent \u0026 Upcoming Talks"},{"content":" SeongJae Park, Madhuparna Bhowmik, Alexandru Uta, DAOS: Data Access-aware Operating System. In The 31st International ACM Symposium on High-Performance Parallel and Distributed Computing (HPDC'22), June 2022. Paper, Slides, Poster SeongJae Park, Paul E. McKenney, Laurent Dufour, Heon Y. Yeom, An HTM-Based Update-side Synchronization for RCU on NUMA systems. In 15th ACM European Conference on Computer Systems (EuroSys), April 2020. Paper, Video (5min, 12min), Slides SeongJae Park, Yunjae Lee, Heon Y. Yeom, Profiling Dynamic Data Access Patterns with Controlled Overhead and Quality. In 20th ACM/IFIP International Middleware Conference (MIDDLEWARE) Industry, December 2019. Paper SeongJae Park, Yunjae Lee, Moonsub Kim, Heon Y. Yeom, Automating Context Based Access Pattern Hint Injection for System Performance and Swap Storage Durability. In 11th USENIX Workshop on Hot Topics in Storage and File Systems (HotStorage), July 2019. Paper, Slides SeongJae Park, Yunjae Lee, Yunhee Kim, Heon Y. Yeom, Profiling Dynamic Data Access Patterns with Bounded Overhead and Accuracy. In IEEE International Workshop on Foundations and Applications of Self-* Systems (FAS*), June 2019. Paper SeongJae Park, Minchan Kim, Heon Y. Yeom, GCMA: Guaranteed Contiguous Memory Allocator. In Transactions on Computers, March 2019. Paper SeongJae Park, Hyuck Han, Heon Y. Yeom, Knowing the Cost of Synchronization Primitives on Modern Hardware. In Journal of Korea, November 2018. Paper SeongJae Park, Minchan Kim, Heon Y. Yeom, GCMA: Guaranteed Contiguous Memory Allocator. In Embedded Operating Systems Workshop (EWiLi), October 2015. Paper, Slides Hyuck Han, SeongJae Park, Hyungsoo Jung, Alan Fekete, Uwe Rohm, Heon Y. Yeom, Scalable Serializable Snapshot Isolation for Multicore Systems. In IEEE 30th International Conference on Data Engineering (ICDE), March 2014. Paper ","permalink":"https://sjp38.github.io/publications/","summary":"SeongJae Park, Madhuparna Bhowmik, Alexandru Uta, DAOS: Data Access-aware Operating System. In The 31st International ACM Symposium on High-Performance Parallel and Distributed Computing (HPDC'22), June 2022. Paper, Slides, Poster SeongJae Park, Paul E. McKenney, Laurent Dufour, Heon Y. Yeom, An HTM-Based Update-side Synchronization for RCU on NUMA systems. In 15th ACM European Conference on Computer Systems (EuroSys), April 2020. Paper, Video (5min, 12min), Slides SeongJae Park, Yunjae Lee, Heon Y.","title":"Recent Publications"}]