<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>projects | hacklog</title>
    <link>/tags/projects/</link>
      <atom:link href="/tags/projects/index.xml" rel="self" type="application/rss+xml" />
    <description>projects</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Sat, 15 Feb 2020 09:11:55 +0100</lastBuildDate>
    <image>
      <url>/img/tux.png</url>
      <title>projects</title>
      <link>/tags/projects/</link>
    </image>
    
    <item>
      <title>RCX: Read-Copy Transact</title>
      <link>/post/rcx/</link>
      <pubDate>Sat, 15 Feb 2020 09:11:55 +0100</pubDate>
      <guid>/post/rcx/</guid>
      <description>&lt;p&gt;Read-copy update (RCU) can provide ideal scalability for read-mostly workloads,
but some believe that it provides only poor performance for updates. This
belief is due to the lack of RCU-centric update synchronization mechanisms. RCU
instead works with a range of update-side mechanisms, such as locking. In fact,
many developers embrace simplicity by using global locking. Logging, hardware
transactional memory, or fine-grained locking can provide better scalability,
but each of these approaches has limitations, such as imposing overhead on
readers or poor scalability on non-uniform memory access (NUMA) systems, mainly
due to their lack of NUMA-aware design principles.&lt;/p&gt;
&lt;p&gt;This project introduces an RCU extension (RCX) that provides highly scalable
RCU updates on NUMA systems while retaining RCU’s read-side benefits. RCX
combines hardware transactional memory (HTM) and traditional locking based on
our NUMA-aware design principles for RCU. Micro-benchmarks on a NUMA system
having 144 hardware threads show RCX has up to 22.61 times better performance
and up to 145.00 times lower HTM abort rates compared to a state-of-the-art
RCU/HTM combination. To demonstrate the effectiveness and applicability of RCX,
we have applied RCX to parallelize some of the Linux kernel memory management
system and an in-memory database system. The optimized kernel and the database
show up to 24 and 17 times better performance compared to the original version,
respectively.&lt;/p&gt;
&lt;h2 id=&#34;news&#34;&gt;News&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;2020-04-19&lt;/em&gt;: The EuroSys&#39;20 paper is uploaded at
&lt;a href=&#34;https://dl.acm.org/doi/abs/10.1145/3342195.3387527&#34;&gt;ACM DL&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;2020-04-04&lt;/em&gt;: The accepted papers list of EuroSys&#39;20 has
&lt;a href=&#34;https://www.eurosys2020.org/program/accepted-papers/&#34;&gt;uploaded&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;2020-02-14&lt;/em&gt;: The paper introducing RCX has accepted to be presented by
&lt;a href=&#34;https://www.eurosys2020.org/&#34;&gt;EuroSys&#39;20&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;source-code&#34;&gt;Source Code&lt;/h2&gt;
&lt;p&gt;The source code of RCX is available at: &lt;a href=&#34;https://github.com/rcx-sync&#34;&gt;https://github.com/rcx-sync&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;publications-and-presentations&#34;&gt;Publications and Presentations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;SeongJae Park, Paul E. McKenney, Laurent Dufour, Heon Y. Yeom, &lt;strong&gt;An HTM-Based
Update-side Synchronization for RCU on NUMA systems.&lt;/strong&gt; In &lt;em&gt;15th ACM European
Conference on Computer Systems (EuroSys)&lt;/em&gt;, April 2020 (Accepted).
&lt;a href=&#34;https://dl.acm.org/doi/abs/10.1145/3342195.3387527&#34;&gt;Paper&lt;/a&gt;,
&lt;a href=&#34;https://www.youtube.com/watch?v=QydRe1z5uYk&amp;amp;feature=youtu.be&#34;&gt;Video (Short)&lt;/a&gt;,
&lt;a href=&#34;https://www.youtube.com/watch?v=h7RzyhR_lPQ&amp;amp;feature=youtu.be&#34;&gt;Video (Long)&lt;/a&gt;,
&lt;a href=&#34;https://www.eurosys2020.org/wp-content/uploads/2020/04/slides/166_seongjae_slides.pdf&#34;&gt;Slides&lt;/a&gt;,
&lt;a href=&#34;https://www.eurosys2020.org/program/&#34;&gt;Link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>DAMON: Data Access Monitor</title>
      <link>/post/damon/</link>
      <pubDate>Fri, 27 Dec 2019 18:21:07 +0100</pubDate>
      <guid>/post/damon/</guid>
      <description>&lt;p&gt;Modern workloads tend to have huge working sets and low locality.  Despite this
trend, the capacity of DRAM has not been increased enough to accommodate such
huge working sets. Therefore, memory management mechanisms optimized for such
modern workloads are widely required today. For such optimizations, knowing the
data access pattern of given workloads is essential. However, manually
extracting such patterns from huge and complex workloads is exhaustive. Worse
yet, existing memory access analysis tools incur unacceptably high overheads
for unnecessarily detailed analysis results.&lt;/p&gt;
&lt;p&gt;To mitigate this situation, we introduce a tool that is designed for data
access pattern tracing. Two core mechanisms in this tool, a region-based
sampling and an adaptive region adjustment, allow users to limit the tracing
overhead in a bounded range regardless of the size and complexity of target
workloads, while preserving the quality of results. Our empirical evaluations
that conducted with 20 realistic workloads show the high quality, low overhead,
and a potential use case of this tool.&lt;/p&gt;
&lt;h2 id=&#34;source-code&#34;&gt;Source Code&lt;/h2&gt;
&lt;p&gt;The source code of DAMON for the
&lt;a href=&#34;https://github.com/sjp38/linux/tree/damon/next&#34;&gt;next&lt;/a&gt;
and the
&lt;a href=&#34;https://github.com/sjp38/linux/tree/damon/master&#34;&gt;latest&lt;/a&gt;
releases are available.
Note that the source trees are frequently rebased.  The tree for the next
release can be rebased several times per day, while the tree for the latest
release can be rebased for each release of DAMON patchset setries.&lt;/p&gt;
&lt;p&gt;The source code of DAPTRACE, which is a prototype of DAMON, is also
&lt;a href=&#34;https://github.com/daptrace&#34;&gt;available&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;official-document&#34;&gt;Official Document&lt;/h2&gt;
&lt;p&gt;The DAMON official document for the
&lt;a href=&#34;https://damonitor.github.io/doc/html/next/&#34;&gt;next&lt;/a&gt;
and the
&lt;a href=&#34;https://damonitor.github.io/doc/html/latest/&#34;&gt;latest&lt;/a&gt;
releases are available online.&lt;/p&gt;
&lt;h2 id=&#34;showcase-website&#34;&gt;Showcase Website&lt;/h2&gt;
&lt;p&gt;There is a showcase web site[1] that you can get more information of DAMON.
The site hosts&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the official documentation of DAMON[2],&lt;/li&gt;
&lt;li&gt;the heatmap format dynamic access pattern of various realistic workloads for
heap area[3], mmap()-ed area[4], and stack[5] area,&lt;/li&gt;
&lt;li&gt;the dynamic working set size distribution[6] and chronological working set
size changes[7], and&lt;/li&gt;
&lt;li&gt;the latest performance test results[8].&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://damonitor.github.io/_index&#34;&gt;https://damonitor.github.io/_index&lt;/a&gt;&lt;br&gt;
[2] &lt;a href=&#34;https://damonitor.github.io/doc/html/latest&#34;&gt;https://damonitor.github.io/doc/html/latest&lt;/a&gt;&lt;br&gt;
[3] &lt;a href=&#34;https://damonitor.github.io/test/result/visual/latest/rec.heatmap.0.html&#34;&gt;https://damonitor.github.io/test/result/visual/latest/rec.heatmap.0.html&lt;/a&gt;&lt;br&gt;
[4] &lt;a href=&#34;https://damonitor.github.io/test/result/visual/latest/rec.heatmap.1.html&#34;&gt;https://damonitor.github.io/test/result/visual/latest/rec.heatmap.1.html&lt;/a&gt;&lt;br&gt;
[5] &lt;a href=&#34;https://damonitor.github.io/test/result/visual/latest/rec.heatmap.2.html&#34;&gt;https://damonitor.github.io/test/result/visual/latest/rec.heatmap.2.html&lt;/a&gt;&lt;br&gt;
[6] &lt;a href=&#34;https://damonitor.github.io/test/result/visual/latest/rec.wss_sz.html&#34;&gt;https://damonitor.github.io/test/result/visual/latest/rec.wss_sz.html&lt;/a&gt;&lt;br&gt;
[7] &lt;a href=&#34;https://damonitor.github.io/test/result/visual/latest/rec.wss_time.html&#34;&gt;https://damonitor.github.io/test/result/visual/latest/rec.wss_time.html&lt;/a&gt;&lt;br&gt;
[8] &lt;a href=&#34;https://damonitor.github.io/test/result/perf/latest/html/index.html&#34;&gt;https://damonitor.github.io/test/result/perf/latest/html/index.html&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;publications-and-presentations&#34;&gt;Publications and Presentations&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Yunjae Lee, Yunhee Kim, and Heon. Y. Yeom, &lt;strong&gt;Lightweight Memory Tracing for
Hot Data Identification,&lt;/strong&gt; In &lt;em&gt;Cluster computing&lt;/em&gt;, 2020.
&lt;a href=&#34;https://link.springer.com/article/10.1007/s10586-020-03130-1&#34;&gt;Paper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Jonathan Corbet, &lt;strong&gt;Memory-management optimization with DAMON.&lt;/strong&gt; In Linux
Weekly News, February 2020.
&lt;a href=&#34;https://lwn.net/Articles/812707/&#34;&gt;Article&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SeongJae Park, Yunjae Lee, Heon Y. Yeom, &lt;strong&gt;Profiling Dynamic Data Access
Patterns with Controlled Overhead and Quality.&lt;/strong&gt; In 20th ACM/IFIP
International Middleware Conference Industry, December 2019.
&lt;a href=&#34;https://dl.acm.org/citation.cfm?id=3368125&#34;&gt;Paper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SeongJae Park, &lt;strong&gt;Tracing Data Access Pattern with Bounded Overhead and
Best-effort Accuracy.&lt;/strong&gt; In &lt;em&gt;The Linux Kernel Summit&lt;/em&gt;, September 2019.
&lt;a href=&#34;https://linuxplumbersconf.org/event/4/contributions/548/attachments/311/590/damon_ksummit19.pdf&#34;&gt;Slides&lt;/a&gt;,
&lt;a href=&#34;https://linuxplumbersconf.org/event/4/contributions/548/&#34;&gt;Link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SeongJae Park, Yunjae Lee, Yunhee Kim, Heon Y. Yeom, &lt;strong&gt;Profiling Dynamic Data
Access Patterns with Bounded Overhead and Accuracy.&lt;/strong&gt; In IEEE International
Workshop on Foundations and Applications of Self-* Systems (FAS* 2019),
June 2019.
&lt;a href=&#34;https://ieeexplore.ieee.org/abstract/document/8791992&#34;&gt;Paper&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;news&#34;&gt;News&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;2020-06-04&lt;/em&gt;: Physical Memory Monitoring is now
&lt;a href=&#34;https://lore.kernel.org/linux-mm/20200603141135.10575-1-sjpark@amazon.com/&#34;&gt;available&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;2020-05-18&lt;/em&gt;: DAMON showcase website is announced&lt;/p&gt;
&lt;p&gt;&lt;em&gt;2020-05-13&lt;/em&gt;: DAMON official document is uploaded
&lt;a href=&#34;https://damonitor.github.io/doc/html/latest/admin-guide/mm/damon/&#34;&gt;online&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;2020-02-20&lt;/em&gt;: DAMON has introduced by an LWN
&lt;a href=&#34;https://lwn.net/Articles/812707/&#34;&gt;article&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;2020-02-10&lt;/em&gt;: The first RFC of Data Access Monitoring-based Operating Schemes
(DAMOS) has posted to
&lt;a href=&#34;https://lore.kernel.org/linux-mm/20200210150921.32482-1-sjpark@amazon.com/&#34;&gt;LKML&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;2020-01-23&lt;/em&gt;: The RFC of DAMON has introduced by LWN&amp;rsquo;s &lt;a href=&#34;https://lwn.net/Articles/809100/&#34;&gt;&amp;lsquo;Kernel patches of
interest&amp;rsquo;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;2020-01-20&lt;/em&gt;: The first RFC patchset of DAMON has posted to
&lt;a href=&#34;https://lore.kernel.org/linux-mm/20200110131522.29964-1-sjpark@amazon.com/&#34;&gt;LKML&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;changes&#34;&gt;Changes&lt;/h2&gt;
&lt;p&gt;Changes made for each version of the patchsets are as below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    damon/patches/v1 (2020-01-20):         59 files,       9771 inserts,          0 deletes
    damon/patches/v2 (2020-01-28):      11688 files,     585615 inserts,     275931 deletes
    damon/patches/v3 (2020-02-04):          7 files,        599 inserts,        341 deletes
    damon/patches/v4 (2020-02-08):          3 files,         26 inserts,         25 deletes
    damon/patches/v5 (2020-02-17):          9 files,        388 inserts,         94 deletes
    damon/patches/v6 (2020-02-24):          6 files,         70 inserts,         39 deletes
    damon/patches/v7 (2020-03-18):          7 files,        324 inserts,        278 deletes
    damon/patches/v8 (2020-04-06):      11536 files,     600681 inserts,     285609 deletes
    damon/patches/v9 (2020-04-24):         13 files,        220 inserts,        123 deletes
   damon/patches/v10 (2020-05-05):          2 files,         34 inserts,         17 deletes
   damon/patches/v11 (2020-05-11):          0 files,          0 inserts,          0 deletes
   damon/patches/v12 (2020-05-18):         22 files,        906 inserts,        616 deletes
   damon/patches/v13 (2020-05-25):          5 files,        300 inserts,          9 deletes
   damon/patches/v14 (2020-06-02):      11557 files,     558546 inserts,     285921 deletes
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The numbers are made by &lt;a href=&#34;https://github.com/sjp38/relstat&#34;&gt;https://github.com/sjp38/relstat&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DAPHICX: Data Access Pattern Hint Injecting Compiler Extension</title>
      <link>/post/daphicx/</link>
      <pubDate>Thu, 30 May 2019 18:59:53 +0900</pubDate>
      <guid>/post/daphicx/</guid>
      <description>&lt;p&gt;Memory pressure is inevitable as the size of working sets is rapidly growing
while the capacity of dynamic random access memory (DRAM) is not. Meanwhile,
storage devices have evolved so that their speed is comparable to the speed of
DRAM while their capacity scales are comparable to that of hard disk drives
(HDD). Thus, hierarchial memory systems configuring DRAM as the main memory and
high-end storages as swap devices will be common.&lt;/p&gt;
&lt;p&gt;Due to the unique characteristics of these modern storage devices, the swap
target decision should be optimal. It is essential to know the exact data
access patterns of workloads for such an optimal decision, although underlying
systems cannot accurately estimate such complex and dynamic patterns. For this
reason, memory systems allow programs to voluntarily hint their data access
pattern. Nevertheless, it is exhausting for a human to manually figure out the
patterns and embed optimal hints if the workloads are huge and complex.&lt;/p&gt;
&lt;p&gt;This project introduces a compiler extension that automatically optimizes a
program to voluntarily hint its dynamic data access patterns to the underlying
swap system using a static/dynamic analysis based profiling result. To our best
knowledge, this is the first profile-guided optimization (PGO) for modern swap
devices. Our empirical evaluation of the scheme using realistic workloads shows
consistent improvement in performance and swap device lifetime up to 2.65 times
and 2.98 times, respectively.&lt;/p&gt;
&lt;h1 id=&#34;publications-and-presentations&#34;&gt;Publications And Presentations&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;SeongJae Park, Yunjae Lee, Moonsub Kim Heon Y. Yeom, &lt;strong&gt;Automating Context
Based Access Pattern Hint Injection for System Performance and Swap Storage
Durability.&lt;/strong&gt; In 11th USENIX Workshop on Hot Topics in Storage and File
Systems (HotStorage), July 2019.
&lt;a href=&#34;https://www.usenix.org/system/files/hotstorage19-paper-park.pdf&#34;&gt;Paper&lt;/a&gt;,
&lt;a href=&#34;https://www.usenix.org/sites/default/files/conference/protected-files/hotstorage19_slides_park.pdf&#34;&gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SeongJae Park, Yunjae Lee, Moonsub Kim, Heon Y. Yeom, &lt;strong&gt;Automated Data Access
Pattern Hint Instrumentation for System Performance and Durability of Swap
Storages.&lt;/strong&gt; (WiP) In 17th USENIX Conference on File and Storage Technologies
(FAST), February 2019.
&lt;a href=&#34;https://www.usenix.org/conference/fast19/wips&#34;&gt;Link&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Idle Page Tracking Tools</title>
      <link>/post/idle_page_tracking/</link>
      <pubDate>Wed, 13 Sep 2017 13:46:00 +0900</pubDate>
      <guid>/post/idle_page_tracking/</guid>
      <description>&lt;p&gt;&lt;code&gt;idle_page_tracking&lt;/code&gt;[1] is a simple, stupid toolbox for idle pages tracking.
It can be used to get real working set size of a process.&lt;/p&gt;
&lt;h1 id=&#34;tools&#34;&gt;Tools&lt;/h1&gt;
&lt;p&gt;This section describes two tools in the box though more tools exists.  You can
get more description about each tool from the README in the repository[1].&lt;/p&gt;
&lt;h2 id=&#34;userprog&#34;&gt;userprog&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;userprog&lt;/code&gt; is a sample synthetic workload for test of other tools.  It
interactively allocates and access specified pages in the allocated pages.
After execution, it first asks how many pages to allocates.  Once you type in
how many pages to allocate, the program will repeatedly asks how many pages in
the allocated pages you want to do access.&lt;/p&gt;
&lt;h2 id=&#34;wspagessh&#34;&gt;wspages.sh&lt;/h2&gt;
&lt;p&gt;Now you can calculate working set size of a process using the tools.  To
simplify the life even more, &lt;code&gt;wspages.sh&lt;/code&gt; helps the complicated works.  It
requires pid, time interval, and target memory mapped regions as argument.  The
third argument can be ignored.  In the case, it uses heap, stack, and anonymous
pages as target memory region by default.  If you give the arguments well, this
tool will prints out number of pages accessed between the time interval.
Simple example of usage and output is as below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo ./wspages.sh `pidof userprog` 1 [heap]
3
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;wspgstatsh&#34;&gt;wspgstat.sh&lt;/h2&gt;
&lt;p&gt;Like &lt;code&gt;*stat&lt;/code&gt; programs (such as vmstat, iostat, &amp;hellip;), wspgstat.sh monitors and
print out number of pages in working set of specific process repeatedly.  It
requires pid of target program, delay between idleness check, and target memory
mapped regions as arguments.  The third argument is optional and has default
value as same as wspages.sh&amp;rsquo;s same argument.  Simple example usage is as below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ./wspgstat.sh `pidof mysqld` 5
1 17448
9 21536
18 21659
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;limitations&#34;&gt;Limitations&lt;/h1&gt;
&lt;p&gt;The tools use idle page tracking feature of the Linux kernel[2] internally.  It
means that the tools work on Linux systems that idle page tracking feature is
turned on.  You can check whether your system turned on or off the feature by
simply running the command below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ if [ -d /sys/kernel/mm/page_idle ]; \
        then echo &amp;quot;ON&amp;quot;; else echo &amp;quot;OFF&amp;quot;; fi
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It also shares limitation of idle page tracking feature of the Linux kernel.
It tracks only userspace pages on LRU list of the kernel.&lt;/p&gt;
&lt;h1 id=&#34;license&#34;&gt;License&lt;/h1&gt;
&lt;p&gt;GPL v3&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://github.com/sjp38/idle_page_tracking&#34;&gt;https://github.com/sjp38/idle_page_tracking&lt;/a&gt;&lt;br&gt;
[2] &lt;a href=&#34;https://www.kernel.org/doc/Documentation/vm/idle_page_tracking.txt&#34;&gt;https://www.kernel.org/doc/Documentation/vm/idle_page_tracking.txt&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>lkml livestream</title>
      <link>/post/lkml_go/</link>
      <pubDate>Sun, 28 May 2017 17:51:43 +0900</pubDate>
      <guid>/post/lkml_go/</guid>
      <description>&lt;p&gt;I wrote a simple, stupid program[1] that showing LKML[2] mails in terminal
briefly like twitter livestream in Go language.  It is just an early version
and so many things to be complemented exists, though.  Nevertheless, now it
just works as I wanted at first.&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://github.com/sjp38/lkml&#34;&gt;https://github.com/sjp38/lkml&lt;/a&gt;&lt;br&gt;
[2] &lt;a href=&#34;https://en.wikipedia.org/wiki/Linux_kernel_mailing_list&#34;&gt;https://en.wikipedia.org/wiki/Linux_kernel_mailing_list&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GCMA: Guaranteed Contiguous Memory Allocator</title>
      <link>/post/gcma/</link>
      <pubDate>Sat, 14 Jan 2017 23:11:23 +0900</pubDate>
      <guid>/post/gcma/</guid>
      <description>&lt;p&gt;The importance of physically contiguous memory has increased in modern
computing environments, including both low- and high-end systems. Existing
physically contiguous memory allocators generally have critical limitations.
For example, the most commonly adopted solution, the memory reservation
technique, wastes a significant amount of memory space. Scatter/Gather direct
memory access (DMA) and input-output memory management units (IOMMUs) avoid
this problem by utilizing additional hardware for address space virtualization.
However, additional hardware means an increase in costs and power consumption,
which is especially disadvantageous for small systems and they do not provide
real contiguous memory. Linux Contiguous Memory Allocator (CMA) aims to provide
both contiguous memory allocation and to maximize memory utilization based on
page migration, but they suffer from unpredictably long latency and a high
probability of allocation failure. Therefore, we introduce a new solution to
this problem, the guaranteed contiguous memory allocator (GCMA). This
guarantees efficient memory space utilization, short latency, and successful
allocation. The GCMA uses a reservation scheme and increases memory utilization
by sharing the memory with immediately discardable data. Our evaluation of a
GCMA on a Raspberry Pi 2 finds a latency that is 15-130 times lower compared to
a CMA, and a latency that is up to 10 times lower when taking a photo. Using a
large working set in a memory-fragmented high-end system, the GCMA is able to
produce a 2.27× speedup.&lt;/p&gt;
&lt;h1 id=&#34;source-code&#34;&gt;Source Code&lt;/h1&gt;
&lt;p&gt;The source code for this version has been submitted to &lt;a href=&#34;https://lkml.org/lkml/2015/2/23/480&#34;&gt;LKML&lt;/a&gt; for discussion.
A complete git tree is also available at &lt;a href=&#34;https://github.com/gcma-mm/linux&#34;&gt;Github&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&#34;publications-and-presentations&#34;&gt;Publications and Presentations&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;SeongJae Park, Minchan Kim, Heon Y. Yeom, &lt;strong&gt;GCMA: Guaranteed Contiguous
Memory Allocator.&lt;/strong&gt; In &lt;em&gt;Transactions on Computers&lt;/em&gt;, March 2019.
&lt;a href=&#34;https://ieeexplore.ieee.org/document/8456561&#34;&gt;Link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SeongJae Park, &lt;strong&gt;GCMA: Guaranteed Contiguous Memory Allocator.&lt;/strong&gt; In &lt;em&gt;The
Linux Kernel Summit&lt;/em&gt;, November 2018.
&lt;a href=&#34;https://linuxplumbersconf.org/event/2/contributions/247/attachments/74/85/gcma_ksummit2018.pdf&#34;&gt;Slides&lt;/a&gt;,
&lt;a href=&#34;https://www.youtube.com/watch?v=ARrelFfdVkw&#34;&gt;Video&lt;/a&gt;,
&lt;a href=&#34;https://linuxplumbersconf.org/event/2/contributions/247/&#34;&gt;Link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SeongJae Park, Minchan Kim, Heon Y. Yeom, &lt;strong&gt;GCMA: Guaranteed Contiguous
Memory Allocator.&lt;/strong&gt; In &lt;em&gt;45th issue of ACM SIGBED Review&lt;/em&gt;, January 2016.
&lt;a href=&#34;http://sigbed.seas.upenn.edu/archives/2016-01/EWiLi15_4.pdf&#34;&gt;Paper&lt;/a&gt;,
&lt;a href=&#34;http://sigbed.seas.upenn.edu/vol13_num1.html#issue&#34;&gt;Link&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SeongJae Park, Minchan Kim, Heon Y. Yeom, &lt;strong&gt;GCMA: Guaranteed Contiguous
Memory Allocator.&lt;/strong&gt; In &lt;em&gt;Embedded Operating Systems Workshop (EWiLi)&lt;/em&gt;, October
2015.
&lt;a href=&#34;http://ceur-ws.org/Vol-1464/ewili15_12.pdf&#34;&gt;Paper&lt;/a&gt;,
&lt;a href=&#34;https://www.slideshare.net/SeongJaePark1/gcma-guaranteed-contiguous-memory-allocator&#34;&gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;SeongJae Park, Minchan Kim, &lt;strong&gt;GCMA: Guaranteed Contiguous Memory Allocator.&lt;/strong&gt;
In &lt;em&gt;Linux Foundation Korea Linux Forum (LFKLF)&lt;/em&gt;, October 2014.
&lt;a href=&#34;http://events.linuxfoundation.org/sites/events/files/slides/gcma-guaranteed_contiguous_memory_allocator-lfklf2014_0.pdf&#34;&gt;Slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>&#34;Is Parallel Programming Hard, And, If So, What Can You Do About It?&#34; Translation</title>
      <link>/post/perfbook-kokr/</link>
      <pubDate>Tue, 10 Jan 2017 13:46:00 +0900</pubDate>
      <guid>/post/perfbook-kokr/</guid>
      <description>&lt;p&gt;&amp;ldquo;Is Parallel Programming is Hard, And, If So, What Can You Do About It?&amp;quot;[1] 은
parallel programming 분야에서 대가라 불릴만한 분으로, 이쪽 분야에서 매우 중요한
동기화 메커니즘인 RCU[2] 를 개발했으며 리눅스 커널의 RCU 메인테이너로 활동하고
있는 Paul E. McKenney[3] 가 오픈소스 방식으로 저술하고 있는, parallel
programming 에 대한 책입니다.&lt;/p&gt;
&lt;p&gt;개인적으로 이 책의 한국어 번역을 오픈소스[4]로 진행하고 있습니다.  이
프로젝트는 원저작자인 Paul 에게 공식 한국어 번역으로 인증받았습니다[5].&lt;/p&gt;
&lt;p&gt;컨트리뷰션에 대해서도 열려 있으니, 이에 관심 있는 분은 repository 내의 README
문서의 Contribution 섹션[6] 을 참고 바랍니다.&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://www.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html&#34;&gt;https://www.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html&lt;/a&gt;&lt;br&gt;
[2] &lt;a href=&#34;https://en.wikipedia.org/wiki/Read-copy-update&#34;&gt;https://en.wikipedia.org/wiki/Read-copy-update&lt;/a&gt;&lt;br&gt;
[3] &lt;a href=&#34;http://www.rdrop.com/~paulmck/&#34;&gt;http://www.rdrop.com/~paulmck/&lt;/a&gt;&lt;br&gt;
[4] &lt;a href=&#34;https://github.com/sjp38/perfbook-ko_KR&#34;&gt;https://github.com/sjp38/perfbook-ko_KR&lt;/a&gt;&lt;br&gt;
[5] &lt;a href=&#34;https://git.kernel.org/pub/scm/linux/kernel/git/paulmck/perfbook.git/commit/?id=edbfcdee046026d3f98592c411a20219b96c8e50&#34;&gt;https://git.kernel.org/pub/scm/linux/kernel/git/paulmck/perfbook.git/commit/?id=edbfcdee046026d3f98592c411a20219b96c8e50&lt;/a&gt;&lt;br&gt;
[6] &lt;a href=&#34;https://github.com/sjp38/perfbook-ko_KR#contribution&#34;&gt;https://github.com/sjp38/perfbook-ko_KR#contribution&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
