<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>benchmark | hacklog</title>
    <link>/tags/benchmark/</link>
      <atom:link href="/tags/benchmark/index.xml" rel="self" type="application/rss+xml" />
    <description>benchmark</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 02 Aug 2018 17:20:10 +0900</lastBuildDate>
    <image>
      <url>/img/tux.png</url>
      <title>benchmark</title>
      <link>/tags/benchmark/</link>
    </image>
    
    <item>
      <title>Linux Kernel Performance (LKP) Tests</title>
      <link>/post/lkp-tests/</link>
      <pubDate>Thu, 02 Aug 2018 17:20:10 +0900</pubDate>
      <guid>/post/lkp-tests/</guid>
      <description>&lt;p&gt;리눅스 커널의 개발은 커뮤니티 주도입니다.  개발의 한 부분인 테스트 역시
커뮤니티 주도적입니다.  여러 개인 또는 단체가 커널을 각자의 방식으로 테스트
하고 그 결과를 공유합니다.  인텔에서는 0-day 서비스[1] 라는 서비스를 자체적으로
돌리는데, 이 서비스는 최신 리눅스 커널을 가져다가 빌드하고 다양한 기능 / 성능
테스트를 돌리고 그 결과 발견된 regression 을 LKML 에 메일로 보내주는 일을
합니다.  말하자면 Continuous Integration (CI) 이죠.&lt;/p&gt;
&lt;p&gt;Linux Kernel Performance (LKP) Tests[2] 는 0-day 서비스에서 기능 / 성능 테스트를
수행하는데 사용되는 도구입니다.  다양한 테스트를 돌리기 위한 시스템 환경 구성,
테스트 프로그램과 그 종속 프로그램 / 라이브러리의 설치와 환경 구성, 테스트
수행과 결과 정리, 그리고 테스트 진행 사이의 시스템 상태 프로파일링 및
프로파일링 결과 정리를 대신해 줍니다.  0-day 서비스에 연결되어 있지만 lkp-tests
와 0-day 서비스 사이의 종속성이 없으며, 오픈소스 프로젝트로 개발이 진행되고
있어 그 소스코드를 누구나 사용할 수 있으며 개인이 사용하기에도 편리하게 되어
있어서 개인 개발자가 자신의 패치를 테스트할 목적으로 사용하기에도 좋습니다.  이
글에서는 이러한 lkp-tests 의 구조와 사용법을 간단히 설명합니다.  전체적으로
인텔의 관련 블로그 글[3] 을 참고했습니다.&lt;/p&gt;
&lt;h1 id=&#34;heading&#34;&gt;설치&lt;/h1&gt;
&lt;p&gt;먼저 다음 커맨드로 lkp-tests 소스코드를 얻어옵니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/intel/lkp-tests
$ cd lkp-tests
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;그리고 lkp-tests 자체를 설치.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo make install
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;이 커맨드는 단순히 지금 소스코드를 땡겨온 lkp-tests 소스코드 디렉토리의
&lt;code&gt;bin/lkp&lt;/code&gt; 파일을 링크하는 &lt;code&gt;/usr/local/bin/lkp&lt;/code&gt; 심볼릭 링크를 만들 뿐입니다.
따라서 셸에서 &lt;code&gt;lkp&lt;/code&gt; 커맨드를 쓸 수 있게 해주죠.  이 &lt;code&gt;lkp&lt;/code&gt; 파일이 결국 lkp-tests
의 대부분의 일을 해주는 핵심 커맨드입니다.  이 프로그램의 간단한 사용법은
다음과 같이 확인할 수 있습니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ lkp
Usage: lkp &amp;lt;command&amp;gt; [options]

INSTALLATION

        install JOB                     install binary dependencies for JOB

JOB

        split JOB                       split JOB matrix
        compile JOB                     compile JOB into shell script

TESTING

        run JOB                         run test JOB locally
        qemu JOB                        run test JOB in QEMU virtual machine

RESULT

        result|rt|_rt|__rt PATTERNs     show result dirs
        ls|ll PATTERNs                  ls result dirs
        rm-path result                  remove result dirs
        _rm PATTERNs                    remove _result dirs

        stat [options]                  show result stats
        compare [options]               compare result stats

DEBUG

        irb                             run irb with lib/*.rb loaded
        pry                             run pry with lib/*.rb loaded

More commands can be found in /home/sjpark/lkp-tests/{bin,sbin,tools}/
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;여기서 &lt;code&gt;&amp;lt;command&amp;gt;&lt;/code&gt; 는 lkp-tests 소스코드 디렉토리 아래 &lt;code&gt;bin/&lt;/code&gt;, &lt;code&gt;sbin/&lt;/code&gt;,
&lt;code&gt;tools/&lt;/code&gt;, 또는 &lt;code&gt;lkp-exec/&lt;/code&gt; 아래 위치한 실행파일로, &lt;code&gt;lkp&lt;/code&gt; 는 단순히 그
실행파일을 수행하면서 인자를 넘길 뿐입니다.&lt;/p&gt;
&lt;h1 id=&#34;---&#34;&gt;테스트에 필요한 소프트웨어 설치&lt;/h1&gt;
&lt;p&gt;다음 커맨드는 lkp-tests 가 의존하고 있는 기본적 소프트웨어 패키지들을 모두
설치합니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo lkp install
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Ubuntu 16.04 에서는 다음 패키지들을 까는군요:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;bc gawk gzip kmod time automake bison bsdtar build-essential bzip2
ca-certificates cpio fakeroot flex gcc git libc6-dev libc6-dev:i386
libklibc-dev libtool linux-libc-dev linux-libc-dev:i386 linux-tools-generic
make openssl patch rsync ruby ruby-dev wget
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;lkptests---&#34;&gt;lkp-tests 내부 벤치마크 실행&lt;/h1&gt;
&lt;p&gt;이제 lkp-tests 에서 지원하는 벤치마크를 실제로 돌려봅시다.&lt;/p&gt;
&lt;h2 id=&#34;----&#34;&gt;테스트 수행에 필요한 환경 설정&lt;/h2&gt;
&lt;p&gt;실제 테스트를 돌리기 위해선 벤치마크를 깔고, 그 벤치마크가 사용하는 패키지를
깔고, 테스트에 사용될 도구들을 깔고, 여러 설정을 하는등의 작업이 필요합니다.&lt;/p&gt;
&lt;p&gt;다음 명령은 lkp-tests 에서 ebizzy 라는 벤치마크를 사용하는 테스트를 위해
필요한 프로그램들을 설치하고 수행 환경을 준비합니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo lkp install jobs/ebizzy.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;job&#34;&gt;job&lt;/h2&gt;
&lt;p&gt;lkp-tests 에서 테스트 수행의 기본 단위는 &lt;code&gt;job&lt;/code&gt; 이라고 이야기 하는데, &lt;code&gt;jobs/&lt;/code&gt;
디렉토리 아래에 각 job 을 설명한 yaml 파일이 있습니다.  위의 커맨드에서 인자로
넣은 &lt;code&gt;ebizzy.yaml&lt;/code&gt; 은 ebizzy 를 사용한 테스트에 필요한 사항들이 들어있습니다.
이 커맨드는 내부적으로 이 테스트에 필요한 패키지를 설치하고 ebizzy 벤치마크도
소스코드를 인터넷에서 받아다가 컴파일해 설치합니다.&lt;/p&gt;
&lt;p&gt;Job 파일은 또한 해당 테스트가 어떤 시스템 환경들에서 어떤 벤치마크를 어떤
인자를 줘가며 수행해야할지 등에 대한 내용을 담고 있습니다.  예컨대
&lt;code&gt;jobs/aim7-fs-1brd.yaml&lt;/code&gt; job 은 &lt;code&gt;xfs&lt;/code&gt;, &lt;code&gt;ext4&lt;/code&gt;, &lt;code&gt;btrfs&lt;/code&gt;, &lt;code&gt;f2fs&lt;/code&gt; 파일 시스템
각각에 대해 aim7 을 돌려보도록 되어 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;-&#34;&gt;테스트 수행&lt;/h2&gt;
&lt;p&gt;다음 명령은 ebizzy job 으로 기술된 테스트를 실제 수행시킵니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo lkp run jobs/ebizzy.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;job-&#34;&gt;job 쪼개기&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;ebizzy.yaml&lt;/code&gt; 은 시스템 소유 CPU 코어 갯수 2배 갯수의 쓰레드를 사용해 ebizzy 를
10초간 돌리는 실험을 100번 반복하도록 되어 있습니다.  즉, 실험의 경우의 수가
하나입니다.  그러나, 앞서 설명한 &lt;code&gt;aim7-fs-1brd&lt;/code&gt; 와 같이 다양한 구성을 사용하게
되어 있는 경우, 한가지 구성에 대해서만 반복 실험을 하고 싶을 수 있을 겁니다.
이런 경우 다음 명령으로 job 을 쪼갤 수 있습니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo lkp split jobs/ebizzy.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;이 커맨드는 인자로 넣은 job 파일을 쪼개서 현재 디렉토리에 쪼개진 job 파일들을
저장합니다.  어떤 구성이 쪼개졌는지는 파일 이름으로 볼 수 있습니다.
&lt;code&gt;ebizzy.yaml&lt;/code&gt; 을 쪼개면 &lt;code&gt;ebizzy-200%-100x-10s.yaml&lt;/code&gt; 라는 이름의 한개의 job
파일이 생성됩니다.  앞서 이야기한 &lt;code&gt;aim7-fs-1brd.yaml&lt;/code&gt; 을 쪼개면 다음과 같이
많은 수의 job 이 생성됩니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;aim7-fs-1brd-1BRD_48G-btrfs-creat-clo-4.yaml
aim7-fs-1brd-1BRD_48G-f2fs-creat-clo-1500.yaml
aim7-fs-1brd-1BRD_48G-btrfs-disk_cp-1500.yaml
aim7-fs-1brd-1BRD_48G-f2fs-disk_cp-3000.yaml
aim7-fs-1brd-1BRD_48G-btrfs-disk_rd-9000.yaml
aim7-fs-1brd-1BRD_48G-f2fs-disk_rd-9000.yaml
aim7-fs-1brd-1BRD_48G-btrfs-disk_rr-1500.yaml
aim7-fs-1brd-1BRD_48G-f2fs-disk_rr-3000.yaml
aim7-fs-1brd-1BRD_48G-btrfs-disk_rw-1500.yaml
aim7-fs-1brd-1BRD_48G-f2fs-disk_rw-3000.yaml
aim7-fs-1brd-1BRD_48G-btrfs-disk_src-500.yaml
aim7-fs-1brd-1BRD_48G-f2fs-disk_src-3000.yaml
aim7-fs-1brd-1BRD_48G-btrfs-disk_wrt-1500.yaml
aim7-fs-1brd-1BRD_48G-f2fs-disk_wrt-3000.yaml
aim7-fs-1brd-1BRD_48G-btrfs-sync_disk_rw-10.yaml
aim7-fs-1brd-1BRD_48G-f2fs-sync_disk_rw-600.yaml
aim7-fs-1brd-1BRD_48G-ext4-creat-clo-1000.yaml
aim7-fs-1brd-1BRD_48G-xfs-creat-clo-1500.yaml
aim7-fs-1brd-1BRD_48G-ext4-disk_cp-3000.yaml
aim7-fs-1brd-1BRD_48G-xfs-disk_cp-3000.yaml
aim7-fs-1brd-1BRD_48G-ext4-disk_rd-9000.yaml
aim7-fs-1brd-1BRD_48G-xfs-disk_rd-9000.yaml
aim7-fs-1brd-1BRD_48G-ext4-disk_rr-3000.yaml
aim7-fs-1brd-1BRD_48G-xfs-disk_rr-3000.yaml
aim7-fs-1brd-1BRD_48G-ext4-disk_rw-3000.yaml
aim7-fs-1brd-1BRD_48G-xfs-disk_rw-3000.yaml
aim7-fs-1brd-1BRD_48G-ext4-disk_src-3000.yaml
aim7-fs-1brd-1BRD_48G-xfs-disk_src-3000.yaml
aim7-fs-1brd-1BRD_48G-ext4-disk_wrt-3000.yaml
aim7-fs-1brd-1BRD_48G-xfs-disk_wrt-3000.yaml
aim7-fs-1brd-1BRD_48G-ext4-sync_disk_rw-600.yaml
aim7-fs-1brd-1BRD_48G-xfs-sync_disk_rw-600.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;--&#34;&gt;테스트 결과 확인&lt;/h1&gt;
&lt;p&gt;테스트에 사용된 벤치마크 수행의 결과와 테스트 동안의 시스템 프로파일링 결과는
&lt;code&gt;/lkp/result/&lt;/code&gt; 디렉토리 밑에 &lt;code&gt;&amp;lt;job name&amp;gt;/&amp;lt;configuration&amp;gt;/&amp;lt;host name&amp;gt;/&amp;lt;os distribution name&amp;gt;/&amp;lt;kernel config&amp;gt;/&amp;lt;gcc version&amp;gt;/&amp;lt;kernel version&amp;gt;/&amp;lt;unique id&amp;gt;&lt;/code&gt;
의 계층 구조로 저장됩니다.  또한, 이 실험 결과를 parsing 할 수 있는 경우엔
&lt;code&gt;.json&lt;/code&gt; 파일을 만들어 줘서 parsing 된 결과 값도 보여줍니다.&lt;/p&gt;
&lt;p&gt;또한, 최근의 테스트 결과는 테스트 돌린 디렉토리에 &lt;code&gt;result/&lt;/code&gt; 라는 이름의,
&lt;code&gt;/lkp/result/&lt;/code&gt; 아래 해당 디렉토리로의 심볼릭 링크를 만들어 줍니다.&lt;/p&gt;
&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;이렇게 lkp-tests 가 무엇인지, 그리고 어떻게 사용할 수 있는지 알아봤습니다.
이제, 리눅스 커널 개발 커뮤니티에서 사용하는 리그레션 테스트를 여러분의
환경에서도 손쉽게 돌려볼 수 있습니다.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://01.org/lkp/documentation/0-day-test-service&#34;&gt;https://01.org/lkp/documentation/0-day-test-service&lt;/a&gt;&lt;br&gt;
[2] &lt;a href=&#34;https://github.com/intel/lkp-tests&#34;&gt;https://github.com/intel/lkp-tests&lt;/a&gt;&lt;br&gt;
[3] &lt;a href=&#34;https://01.org/blogs/jdu1/2017/lkp-tests-linux-kernel-performance-test-and-analysis-tool&#34;&gt;https://01.org/blogs/jdu1/2017/lkp-tests-linux-kernel-performance-test-and-analysis-tool&lt;/a&gt;&lt;br&gt;
[4] &lt;a href=&#34;https://wiki.archlinux.org/index.php/makepkg&#34;&gt;https://wiki.archlinux.org/index.php/makepkg&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>spec cpu2006 벤치마크 수정하기</title>
      <link>/post/spec_cpu2006_modification/</link>
      <pubDate>Sun, 24 Dec 2017 17:30:12 +0900</pubDate>
      <guid>/post/spec_cpu2006_modification/</guid>
      <description>&lt;p&gt;경우에 따라서 SPEC CPU2006 의 벤치마크 중 일부의 소스코드를 수정하고 싶을 수
있습니다.  예를 들어 특정 벤치마크가 구체적으로 어떻게 동작하는지 알아보기 위해
디버깅 메세지를 추가하고자 할수도 있고, 코드 변경을 통해 성능을 높인다거나 해볼
수도 있겠죠.  그러나, SPEC CPU2006 은 엄정한 벤치마크 수트이기 때문에
소스코드는 물론, 소스코드를 사용하는 도구가 변경된 경우 에러 메세지를 내고
수행을 거부합니다.  수정된 소스코드로 얻어진 결과는 벤치마크 결과로 적합하지
않기 때문이죠.&lt;/p&gt;
&lt;p&gt;때문에, 어쩔 수 없이 수정이 필요하면서도 기존의 수행 방법을 따르려면 이 에러를
내는 곳을 없애는 게 한가지 방법이 될 수 있습니다.  다음의 패치를 적용하면
이 검증 코드가 사라져서 수정된 코드로도 벤치마크를 돌릴 수 있게 됩니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;diff --git a/bin/formatter/setup_common.pl b/bin/formatter/setup_common.pl
index 36170cda1649..b21890972dbd 100755
--- a/bin/formatter/setup_common.pl
+++ b/bin/formatter/setup_common.pl
@@ -278,13 +278,13 @@ sub check_important_files {
     return if (   $::suite_version &amp;gt; 4
                &amp;amp;&amp;amp; !$ENV{&#39;SPEC_CHECK&#39;});
     $::check_integrity = 1;
-    foreach my $important_file (jp(&#39;bin&#39;, basename($0)),
-                                grep { m/$re/ } keys %::file_md5) {
-        if (!check_files(\%::file_md5, $important_file)) {
-            print STDERR &amp;quot;\n\nPart of the tools ($important_file) is corrupt!\nAborting...\n\n&amp;quot;;
-            exit 1;
-        }
-    }
+#    foreach my $important_file (jp(&#39;bin&#39;, basename($0)),
+#                                grep { m/$re/ } keys %::file_md5) {
+#        if (!check_files(\%::file_md5, $important_file)) {
+#            print STDERR &amp;quot;\n\n Part of the tools ($important_file) is corrupt!\nAborting...\n\n&amp;quot;;
+#            exit 1;
+#        }
+#    }
 }
 
 1;
diff --git a/bin/setup_common.pl b/bin/setup_common.pl
index 36170cda1649..d9dbe214d498 100755
--- a/bin/setup_common.pl
+++ b/bin/setup_common.pl
@@ -219,9 +219,9 @@ sub md5filedigest {
 sub load_module {
     my ($module, $quiet) = @_;
 
-    if ($::check_integrity &amp;amp;&amp;amp; !check_files(\%::file_md5, jp(&#39;bin&#39;, $module))) {
-	die &amp;quot;\n\nPart of the tools ($module) is corrupt!  Aborting...\n\n&amp;quot;;
-    }
+#    if ($::check_integrity &amp;amp;&amp;amp; !check_files(\%::file_md5, jp(&#39;bin&#39;, $module))) {
+#	die &amp;quot;\n\nPart of the tools ($module) is corrupt!  Aborting...\n\n&amp;quot;;
+#    }
     eval &amp;quot;require \&amp;quot;$module\&amp;quot;;&amp;quot;;
     print &#39;.&#39; unless ($quiet);
     if ($@) {
@@ -278,13 +278,13 @@ sub check_important_files {
     return if (   $::suite_version &amp;gt; 4
                &amp;amp;&amp;amp; !$ENV{&#39;SPEC_CHECK&#39;});
     $::check_integrity = 1;
-    foreach my $important_file (jp(&#39;bin&#39;, basename($0)),
-                                grep { m/$re/ } keys %::file_md5) {
-        if (!check_files(\%::file_md5, $important_file)) {
-            print STDERR &amp;quot;\n\nPart of the tools ($important_file) is corrupt!\nAborting...\n\n&amp;quot;;
-            exit 1;
-        }
-    }
+#    foreach my $important_file (jp(&#39;bin&#39;, basename($0)),
+#                                grep { m/$re/ } keys %::file_md5) {
+#        if (!check_files(\%::file_md5, $important_file)) {
+#            print STDERR &amp;quot;\n\nPart of the tools ($important_file) is corrupt!\nAborting...\n\n&amp;quot;;
+#            exit 1;
+#        }
+#    }
 }
 
 1;
diff --git a/bin/util.pl b/bin/util.pl
index ccf4a72477c0..c8c0cd786522 100755
--- a/bin/util.pl
+++ b/bin/util.pl
@@ -211,11 +211,11 @@ sub copy_tree {
                     offer_verify_advice();
 		    return 0;
 		}
-		if ($sumhash-&amp;gt;{$sf} ne md5filedigest($sf)) {
-		    Log(0, &amp;quot;\n$sf is corrupt!\n&amp;quot;);
-                    offer_verify_advice();
-		    return 0;
-		}
+#		if ($sumhash-&amp;gt;{$sf} ne md5filedigest($sf)) {
+#		    Log(0, &amp;quot;\n$sf is corrupt!\n&amp;quot;);
+#                    offer_verify_advice();
+#		    return 0;
+#		}
 	    }
             if ($sf =~ /\.bz2$/) {
               copy_bz2_file($sf, $file, [$target], 0);
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>TPC-H on MariaDB (MySQL)</title>
      <link>/post/tpch-on-mariadb/</link>
      <pubDate>Sun, 10 Sep 2017 10:54:24 +0900</pubDate>
      <guid>/post/tpch-on-mariadb/</guid>
      <description>&lt;p&gt;Database 를 위해 사용되는 벤치마크는 크게 OLTP vs OLAP 로 나뉩니다[1].  OLTP
계열의 대표주자는 TPC-C 이고, OLAP 계열의 대표주자 중 하나로 TPC-H[2] 가
있습니다.  이 글에서는 TPC-H 를 MariaDB 에서 돌리는 방법에 대해 설명합니다.&lt;/p&gt;
&lt;h1 id=&#34;environment-setup&#34;&gt;Environment Setup&lt;/h1&gt;
&lt;p&gt;이 글을 작성하면서 사용한 운영체제와 소프트웨어들의 버전은 다음과 같습니다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ubuntu 16.04.2 Server&lt;/li&gt;
&lt;li&gt;MariaDB 10.2.8&lt;/li&gt;
&lt;li&gt;TPC-H toolkit 2.17.2&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;automated-scripts&#34;&gt;Automated Scripts&lt;/h1&gt;
&lt;p&gt;아래 설명할 모든 내용을 자동화 해서 손쉽게 TPC-H 를 돌릴 수 있도록 소스코드
변경부터 빌드, 수행까지 정리한 스크립트들을 github 에 올려 두었습니다:
&lt;a href=&#34;https://github.com/sjp38/tpch-mariadb&#34;&gt;https://github.com/sjp38/tpch-mariadb&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;시간이 없다면 해당 스크립트를 사용하실 것을 권장합니다.&lt;/p&gt;
&lt;h1 id=&#34;tpch-spec&#34;&gt;TPC-H Spec&lt;/h1&gt;
&lt;p&gt;TPC-H 벤치마크 스펙은 TPC 웹사이트에서 얻을 수 있습니다[3].  하지만 여기서는
간단히 설명을 해봅니다.  간단한 설명인 만큼 내용이 엄밀히 말해서 맞다고 할수는
없으므로 엄밀한 내용은 정식 스펙 또는 다른 문서를 확인해 보시기 바랍니다.
TPC-H 는 8개의 테이블에 많은 데이터를 쌓아놓고, 이 데이터의 분석을 위한 22개의
쿼리를 수행하며 그 성능을 측정하는 형태로 구성되어 있습니다.  성능은 테이블에
데이터를 로드하는데 걸리는 시간, 22개의 쿼리 각각의 수행 시간, 그리고 여러
세션을 열어놓고 22개 쿼리를 각 세션에서 수행하면서 파악되는 처리량 (초당 처리된
쿼리의 갯수)으로 측정됩니다.&lt;/p&gt;
&lt;h1 id=&#34;get-tpch-toolkit&#34;&gt;Get TPC-H Toolkit&lt;/h1&gt;
&lt;p&gt;TPC-H 는 8개의 테이블에 데이터가 쌓인 상태에서, 이 데이터의 분석을 위한 22개의
쿼리들을 날리는 형태로 이루어져 있습니다.  테이블을 어떻게 만들고 거기에
데이터는 어떻게 넣어야 하며, 쿼리는 어떤 것들로 이루어져야 하는지에 대한
명세서를 TPC 에서 제공합니다.  이를 바탕으로 각자 TPC-H 를 구성해서 돌릴 수
있습니다.  하지만 이걸 각자 하는건 귀찮고 힘들기 때문에, 테이블과 테이블의
데이터, 그리고 쿼리들을 생성하는 도구를 TPC 에서 TPC-H Toolkit 이라는 이름으로
그 소스코드를 공식적으로 제공하고 있습니다.  TPC 의 해당 사이트[4]를 찾아가
개인정보를 입력하고 license 에 동의를 하면 다운로드 받을 수 있는 링크를 메일로
보내줍니다.&lt;/p&gt;
&lt;p&gt;이렇게 받은 파일은 zip 파일입니다.  압축을 풀어보면 아래와 같이 해당 버전명의
디렉토리가 나오고, 그 아래에 실제 소스 코드와 라이센스 파일이 있습니다.  여기서
우린 dbgen/ 디렉토리를 사용할 겁니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ tree 2.17.2 -L 1
2.17.2
├── dbgen
├── dev-tools
├── EULA.txt
└── ref_data
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;build-source-code&#34;&gt;Build Source Code&lt;/h1&gt;
&lt;p&gt;dbgen 디렉토리 아래 dbgen 과 qgen 이라는, 우리가 사용하게 될 프로그램을 위한
소스코드가 있습니다.  여기 있는 makefile.suite 라는 파일은 &lt;code&gt;make&lt;/code&gt; 를 사용해 이
코드를 빌드하기 위한 규칙의 기본 골조를 담고 있습니다.  이 파일을 `makefile&amp;rsquo;
이라는 이름으로 복사하고 내용을 다음과 같이 수정합니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ diff -u makefile.suite makefile
--- makefile.suite      2017-04-21 06:01:08.000000000 +0900
+++ makefile    2017-09-10 11:10:12.563384756 +0900
@@ -100,15 +100,15 @@
 ################
 ## CHANGE NAME OF ANSI COMPILER HERE
 ################
-CC      =
+CC      = gcc
 # Current values for DATABASE are: INFORMIX, DB2, TDAT (Teradata)
 #                                  SQLSERVER, SYBASE, ORACLE, VECTORWISE
 # Current values for MACHINE are:  ATT, DOS, HP, IBM, ICL, MVS,
 #                                  SGI, SUN, U2200, VMS, LINUX, WIN32
 # Current values for WORKLOAD are:  TPCH
-DATABASE=
-MACHINE =
-WORKLOAD =
+DATABASE= SQLSERVER
+MACHINE = LINUX
+WORKLOAD = TPCH
 #
 CFLAGS = -g -DDBNAME=\&amp;quot;dss\&amp;quot; -D$(MACHINE) -D$(DATABASE) -D$(WORKLOAD) -DRNG_TEST -D_FILE_OFFSET_BITS=64
 LDFLAGS = -O
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;이후, &lt;code&gt;$ make&lt;/code&gt; 명령으로 dbgen 과 qgen 이라는 프로그램이 빌드됩니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ make

...

 bm_utils.o qgen.o rnd.o varsub.o text.o bcd2.o permute.o speed_seed.o rng64.o -lm
$ file dbgen
dbgen: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.32, BuildID[sha1]=d0bca1a18c33947d85f5943c8325837faec7c95d, not stripped
$ file qgen
qgen: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, for GNU/Linux 2.6.32, BuildID[sha1]=79a6216e04c446715b0e55f9c804586887b698c8, not stripped
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;tpch-toolkit-usage&#34;&gt;TPC-H Toolkit Usage&lt;/h1&gt;
&lt;p&gt;MariaDB 에 TPC-H 를 돌리기 위해선 여기서 몇가지 추가 수정을 해야합니다.  하지만
그에 앞서 &lt;code&gt;dbgen/&lt;/code&gt; 디렉토리 내의 파일들을 어떻게 사용해서 TPC-H 를 수행하는지
알아봅시다.&lt;/p&gt;
&lt;h2 id=&#34;data-preparation&#34;&gt;Data Preparation&lt;/h2&gt;
&lt;p&gt;먼저 dss.ddl 파일은 8개의 테이블 생성에 사용되는 sql 문을 담고 있습니다.  DB
에서 이 파일 내에 적힌 sql 문들을 그대로 수행하라고 하면 8개의 테이블이
생성됩니다.&lt;/p&gt;
&lt;p&gt;dbgen 은 테이블에 데이터를 로드하는 sql 문을 생성합니다.  dbgen 에 scale factor
등의 인자를 줘서 수행시키면 8개의 &lt;code&gt;.tbl&lt;/code&gt; suffix 를 갖는 파일이 생성됩니다.  이
파일들은 각각 파일명에 일치하는 이름의 테이블에 데이터를 insert 하는 query
문들로 구성되어 있습니다.  DB 에 이 파일 내의 sql 명령들을 수행하라고 하면
데이터가 로드되는 것입니다.&lt;/p&gt;
&lt;p&gt;dss.ri 는 테이블 인덱스 생성에 필요한 sql 문을 담고 있습니다.  DB 에 이 파일
내의 sql 명령들을 수행하라고 함으로써 테이블 인덱스 생성이 완료되어 TPC-H 의
쿼리들을 수행할 준비가 마쳐집니다.&lt;/p&gt;
&lt;h2 id=&#34;query-creation-and-execution&#34;&gt;Query Creation and Execution&lt;/h2&gt;
&lt;p&gt;qgen 은 TPC-H 의 분석 작업을 대표하는 22개의 쿼리를 생성해 줍니다.  22개의
쿼리라고 표현했지만 22 종류의 쿼리라고 하는게 옳을 겁니다.  동일한 쿼리의 경우
반복 수행되면 DB 에서 앞 쿼리의 결과를 캐시해 뒀다가 곧바로 리턴하기 때문에
인자 등은 달라야 하기 때문입니다.  이를 위해 dbgen/queries/ 디렉토리 아래에는
생성되어야 하는 22 종류 쿼리의 템플릿을 담고 있습니다.  qgen 은 이 템플릿을
참고하고 랜덤하게 인자를 생성해 최종적으로 DB 에서 수행될 수 있는 쿼리문을
생성합니다.  이 때 랜덤 시드는 dists.dss 라는 파일을 참고해 만들어집니다.&lt;/p&gt;
&lt;h1 id=&#34;modify-tpch-toolkit-for-mariadb&#34;&gt;Modify TPC-H Toolkit for MariaDB&lt;/h1&gt;
&lt;p&gt;DBMS 마다 query syntax 가 조금씩 다릅니다.  때문에 TPC-H Toolkit 은 지원하는
DBMS 마다 다르게 테이블 생성, 쿼리 생성을 하도록 짜여져 있습니다만, 지원하는
DBMS 목록에 MariaDB 는 포함되어 있지 않습니다.  따라서 MariaDB 에 TPC-H 를
돌리기 위해선 TPC-H Toolkit 의 일부분을 수정해야 합니다.&lt;/p&gt;
&lt;p&gt;수정해야 하는 파일은 dss.ddl, dss.ri, 그리고 queries/ 디렉토리 아래의 템플릿
등입니다.  하나하나 설명하는 것은 너무 내용이 길어지므로, 수정 내용을 patch
형태로 만들어 github 에 올려두었습니다[5].  이 패치 파일을 가져와서 다음과 같이
적용할 수 있습니다.  명령을 수행하는 디렉토리는 TPC-H Toolkit 소스코드 디렉토리
여야 합니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ wget https://raw.githubusercontent.com/sjp38/tpch-mariadb/07fdcbfa9ba1be26f437ff130338a223d0dbfecd/0001-Modify-for-MariaDB.patch
$ patch -p1 &amp;lt; 0001-Modify-for-MariaDB.patch
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;위 변경 사항은 makefile 의 수정도 포함되어 있습니다.  적용 후 dbgen, qgen 을
빌드해 줍시다.&lt;/p&gt;
&lt;h1 id=&#34;data-creation&#34;&gt;Data Creation&lt;/h1&gt;
&lt;p&gt;dbgen/ 디렉토리로 들어가 dbgen 을 수행해 줍니다.  인자로 scale factor 등을 줄
수 있습니다.  -h 인자를 줘서 dbgen 의 수행 방법을 알 수 있으니 참고합시다.
수행이 마무리 되면 다음과 같이 8개의 .tbl suffix 를 갖는 파일들이 생성됩니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dbgen$ ls -ahl *.tbl
-rw-rw-r-- 1 sjpark sjpark 187M Sep  9 10:48 customer.tbl
-rw-rw-r-- 1 sjpark sjpark 5.8G Sep  9 10:48 lineitem.tbl
-rw-rw-r-- 1 sjpark sjpark 2.2K Sep  9 10:48 nation.tbl
-rw-rw-r-- 1 sjpark sjpark 1.4G Sep  9 10:48 orders.tbl
-rw-rw-r-- 1 sjpark sjpark 919M Sep  9 10:48 partsupp.tbl
-rw-rw-r-- 1 sjpark sjpark 186M Sep  9 10:48 part.tbl
-rw-rw-r-- 1 sjpark sjpark  389 Sep  9 10:48 region.tbl
-rw-rw-r-- 1 sjpark sjpark  11M Sep  9 10:48 supplier.tbl
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;참고로, 위 수행결과는 scale factor 값을 8로 준 결과입니다.&lt;/p&gt;
&lt;h1 id=&#34;load-data&#34;&gt;Load Data&lt;/h1&gt;
&lt;p&gt;이제 MariaDB 를 사용해 tpch 라는 이름의 데이터베이스를 생성하고 (line 1) 그
아래 테이블을 생성하고 (line 2) 각 테이블에 데이터를 로드한 후 (line 3-5) 각
테이블의 인덱스까지 만들어 줍시다 (line 6).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ mysql -u root -p password -e &amp;quot;create database tpch;&amp;quot;
$ mysql -u root -p password &amp;lt; dss.ddl
$ for table in customer lineitem nation orders partsupp part region supplier \
	do mysql -u root -p -e \
		&amp;quot;LOAD DATA LOCAL INFILE &#39;$table.tbl&#39; FIELDS TERMINATED BY &#39;|&#39;;&amp;quot;
	done
$ mysql -u root -p password &amp;lt; ./dss.ri
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;create-queries&#34;&gt;Create Queries&lt;/h1&gt;
&lt;p&gt;이제 쿼리를 만들어 봅시다.  qgen 은 인자로 생성할 쿼리의 타입을 1-22 사이 숫자로 받아서 쿼리문을 생성, 화면에 뿌려줍니다.  다음과 같은 커맨드로 이를 따로 저장합니다.  아래 커맨드는 dbgen/ 디렉토리 아래에서 수행됨을 가정합니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd queries/
$ for i in {1..22}; do ../qgen $i &amp;gt; query-$i.sql; done
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;이제 dbgen/queries/ 디렉토리 아래에 &lt;code&gt;query-&lt;/code&gt; 라는 prefix 의 쿼리문을 담는 파일
22개가 생성되어 있습니다.&lt;/p&gt;
&lt;h1 id=&#34;execute-queries&#34;&gt;Execute Queries&lt;/h1&gt;
&lt;p&gt;앞서 생성한 쿼리문 파일은 MariaDB 에 호환되는 sql 문으로 구성되어 있으므로,
아래와 같이 간단히 실행시키면 됩니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ for i in {1..22}; do mysql -u root -p password &amp;lt; dbgen/queries/query-$i.sql
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;일부 쿼리는 수십초, 일부 쿼리는 1초도 걸리지 않아 수행되는 걸 확인할 수
있습니다.&lt;/p&gt;
&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;TPC-H 가 어떻게 구성되어 있고 어떻게 수행시키며, MariaDB 에서의 수행을 위해서는
어떤 수정이 필요한지 설명했습니다.  github 에 있는 자동화 스크립트[6]를
이용하면 이 과정을 손쉽게 한번에 해결할 수 있습니다.&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;[1] &lt;a href=&#34;http://datawarehouse4u.info/OLTP-vs-OLAP.html&#34;&gt;http://datawarehouse4u.info/OLTP-vs-OLAP.html&lt;/a&gt;&lt;br&gt;
[2] &lt;a href=&#34;http://www.tpc.org/tpch/&#34;&gt;http://www.tpc.org/tpch/&lt;/a&gt;&lt;br&gt;
[3] &lt;a href=&#34;http://www.tpc.org/tpc_documents_current_versions/pdf/tpc-h_v2.17.2.pdf&#34;&gt;http://www.tpc.org/tpc_documents_current_versions/pdf/tpc-h_v2.17.2.pdf&lt;/a&gt;&lt;br&gt;
[4] &lt;a href=&#34;http://www.tpc.org/tpc_documents_current_versions/download_programs/tools-download-request.asp?bm_type=TPC-H&amp;amp;bm_vers=2.17.2&amp;amp;mode=CURRENT-ONLY&#34;&gt;http://www.tpc.org/tpc_documents_current_versions/download_programs/tools-download-request.asp?bm_type=TPC-H&amp;amp;bm_vers=2.17.2&amp;amp;mode=CURRENT-ONLY&lt;/a&gt;&lt;br&gt;
[5] &lt;a href=&#34;https://raw.githubusercontent.com/sjp38/tpch-mariadb/07fdcbfa9ba1be26f437ff130338a223d0dbfecd/0001-Modify-for-MariaDB.patch&#34;&gt;https://raw.githubusercontent.com/sjp38/tpch-mariadb/07fdcbfa9ba1be26f437ff130338a223d0dbfecd/0001-Modify-for-MariaDB.patch&lt;/a&gt;&lt;br&gt;
[6] &lt;a href=&#34;https://github.com/sjp38/tpch-mariadb&#34;&gt;https://github.com/sjp38/tpch-mariadb&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Parsec 3.0 설치 / 사용법</title>
      <link>/post/parsec_3_howto/</link>
      <pubDate>Fri, 19 May 2017 06:23:15 +0900</pubDate>
      <guid>/post/parsec_3_howto/</guid>
      <description>&lt;p&gt;PARSEC 은 멀티쓰레드 프로그램들로 구성된 benchmark suite 입니다.  멀티쓰레드로
구성되어 있기 때문에 멀티코어 시스템에서의 multi core scalability 를 테스트
하기에도 적합합니다.  이 글에선 현재 최신 버전인 3.0 버전의 PARSEC 을 Ubuntu
16.04 server 에 설치하면서 겪는 문제의 해결법과 간단한 사용법을 정리해 봅니다.&lt;/p&gt;
&lt;h1 id=&#34;toolbox-for-parsec-30-on-ubuntu-xenial&#34;&gt;Toolbox for PARSEC 3.0 on Ubuntu Xenial&lt;/h1&gt;
&lt;p&gt;아래의 내용을 하나하나 읽어가면서 따라하는 것도 귀찮은 일입니다.  그래서
아래에서 설명하는, Ubuntu Xenial 에서 PARSEC 3.0 을 돌리기 위해 필요한 작업을
대부분 자동으로 해주는 도구들을 만들어 두었습니다.  오픈소스로 공개되어
있으니[1], 아래의 머리 아픈 내용을 읽기 귀찮다면 해당 도구들을 사용하시기
바랍니다.  해당 도구들의 사용법은 README 에 간략히 설명되어 있습니다.&lt;/p&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://github.com/sjp38/parsec_on_ubuntu_xenial&#34;&gt;https://github.com/sjp38/parsec_on_ubuntu_xenial&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;parsec-30-download&#34;&gt;PARSEC 3.0 Download&lt;/h1&gt;
&lt;p&gt;공식 홈페이지[1] 에 들어가면 PARSEC 3.0 다운로드 링크가 첫페이지부터 있습니다.
해당 링크를 사용하면 &lt;code&gt;tar.gz&lt;/code&gt; 포맷의 tarball 로 정리된 PARSEC 3.0 을 다운받을
수 있습니다.  웹브라우저로 들어가서 다운로드를 받는 방법도 있겠고, &lt;code&gt;curl&lt;/code&gt; 이나
&lt;code&gt;wget&lt;/code&gt; 등의 command line tool 을 사용해 다운받을 수도 있겠습니다.  다음
커맨드는 PARSEC 3.0 을 다운받아 &lt;code&gt;parsec-3.0/&lt;/code&gt; 디렉토리 아래 압축을 풀고 압축을
푼 디렉토리로 이동합니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ wget http://parsec.cs.princeton.edu/download/3.0/parsec-3.0.tar.gz
$ tar zxvf parsec-3.0.tar.gz
$ cd parsec-3.0
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;build&#34;&gt;Build&lt;/h1&gt;
&lt;p&gt;이제 PARSEC 3.0 을 빌드해야 합니다.  PARSEC 은 여러 벤치마크를 포함하고
있으므로 개별적 벤치마크를 하나하나 직접적으로 다루기보다는 suite 내의 각
벤치마크를 통합적으로 관리할 수 있는 &lt;code&gt;parsecmgmt&lt;/code&gt; 라는 관리 프로그램을
사용하도록 되어 있습니다.  빌드 역시 마찬가지입니다.  참고로, &lt;code&gt;parsecmgmt&lt;/code&gt; 는
bash script 입니다.&lt;/p&gt;
&lt;p&gt;기본적인 PARSEC 3.0 빌드 방법은 다음과 같이 간단합니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ source ./env.sh
$ parsecmgmt -a build
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;첫번째 커맨드는 parsecmgmt 의 경로를 PATH 에 추가하는 등, 환경 변수 설정 등의
일을 처리해 주며, 두번째의 간단한 커맨드가 전체 PARSEC 3.0 빌드 프로세스를
수행하게 됩니다.&lt;/p&gt;
&lt;h2 id=&#34;perl-version-problem&#34;&gt;Perl Version Problem&lt;/h2&gt;
&lt;p&gt;하지만 Ubuntu 16.04 server 에서는 다음과 같은 에러 메세지를 내뱉으며 빌드에
실패합니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;smime.pod around line 272: Expected text after =item, not a number
smime.pod around line 276: Expected text after =item, not a number
smime.pod around line 280: Expected text after =item, not a number
smime.pod around line 285: Expected text after =item, not a number
smime.pod around line 289: Expected text after =item, not a number
POD document had syntax errors at /usr/bin/pod2man line 68.
make: *** [install_docs] Error 1
Makefile:680: recipe for target &#39;install_docs&#39; failed
[PARSEC] Error: &#39;env PATH=/usr/local/sbin:...&#39; failed.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;에러 메세지에서 유추할 수 있듯 PARSEC 3.0 의 소스 코드 중 smime.pod 파일이
문법에 맞지 않아 생긴 문제입니다.  참고로 pod 는 perl 프로그램 문서화에
사용되는 간단한 markup language 입니다[2].  Ubuntu 16.04 는 perl 5.22.1 버전을
기본으로 사용하고 있는데, PARSEC 3.0 에 있는 코드는 perl 5.14.2 버전에 맞춰져
있으며 최신 버전으로 오는 사이 문법이 바뀐 것으로 인한 문제로 보입니다.
해결책은 두가지가 있습니다.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;방법 1: perl 5.14.2 설치&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Google groups 의 관련 쓰레드[3] 를 참고한 방법입니다.
5.14.2 버전의 perl 소스코드를 받아와 이를 설치하고 PARSEC 빌드에 이 버전의 perl
을 사용하는 방법입니다.  다음의 커맨드로 &lt;code&gt;~/localperl/&lt;/code&gt; 디렉토리 아래 5.14.2
버전 perl 을 설치하고 사용할 수 있습니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wget http://www.cpan.org/src/5.0/perl-5.14.2.tar.gz
$ tar zxvf perl-5.14.2.tar.gz
$ cd perl-5.14.2/
$ mkdir ~/localperl
$ ./Configure -des -Dprefix=$HOME/localperl
$ time make -j
$ make test
$ make install
$ ~/localperl/bin/perl -v
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;방법 2: pod 파일 문법 오류 수정&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;좀 더 정공법에 가까운 방법으로, 다음 글을 참고한 해결책입니다:
&lt;a href=&#34;https://yulistic.gitlab.io/2016/05/parsec-3.0-installation-issues/&#34;&gt;https://yulistic.gitlab.io/2016/05/parsec-3.0-installation-issues/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;최신 버전의 문법에 맞게 pod 파일의 문제시 되는 부분들을 고쳐주는 것으로,
문제되는 모든 pod 파일의 &lt;code&gt;=item [0-9]&lt;/code&gt; 을 &lt;code&gt;=item C&amp;lt;[0-9]&amp;gt;&lt;/code&gt; 으로 바꿔줍니다.
&lt;code&gt;diff&lt;/code&gt; 로 표현하면 다음과 같은 수정을 가하게 되겠습니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--- a/pkgs/libs/ssl/src/doc/apps/smime.pod
+++ b/pkgs/libs/ssl/src/doc/apps/smime.pod
@@ -265,28 +265,28 @@ encrypted data is used for other purposes.

 =over 4

-=item 0
+=item C&amp;lt;0&amp;gt;

 the operation was completely successfully.

-=item 1
+=item C&amp;lt;1&amp;gt;

 an error occurred parsing the command options.

-=item 2
+=item C&amp;lt;2&amp;gt;

 one of the input files could not be read.

-=item 3
+=item C&amp;lt;3&amp;gt;

 an error occurred creating the PKCS#7 file or when reading the MIME
 message.

-=item 4
+=item C&amp;lt;4&amp;gt;

 an error occurred decrypting or verifying the message.

-=item 5
+=item C&amp;lt;5&amp;gt;

 the message was verified correctly but an error occurred writing out
 the signers certificates.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;이렇게 파일 하나하나 수정하면 이 에러 메세지는 사라집니다.  참고한 링크에서는
하나하나 손으로 수정하기보다는 다음과 같이 간단한 bash shell script 를 짜서
일괄적으로 수정하는 걸 추천합니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#! /bin/bash
for i in 0 1 2 3 4 5 6 7 8 9 
do
    echo &amp;quot;Replacing &#39;=item $i&#39; to &#39;=item C&amp;lt;$i&amp;gt;&#39;&amp;quot;
    grep -rl &amp;quot;=item $i&amp;quot; * | xargs sed -i &amp;quot;s/=item $i/=item C&amp;lt;$i&amp;gt;/g&amp;quot;
done
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;이어서 설명할 문제들과 해결책도 해당 링크를 참고한 것임을 밝혀둡니다.&lt;/p&gt;
&lt;h2 id=&#34;mbstatet-conflict&#34;&gt;&lt;code&gt;__mbstate_t&lt;/code&gt; Conflict&lt;/h2&gt;
&lt;p&gt;앞의 에러 메세지는 사라지지만 이제 다음과 같은 에러 메세지가 나올 겁니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/usr/include/wchar.h:94:3: error: conflicting types for ‘__mbstate_t’
 } __mbstate_t;
   ^
In file included from ../include/machine/bsd_endian.h:37:0,
                 from ../include/sys/bsd_types.h:44,
                 from ../include/sys/bsd_param.h:64,
                 from if_host.c:48:
../include/sys/bsd__types.h:105:3: note: previous declaration of ‘__mbstate_t’ was here
 } __mbstate_t;
   ^
In file included from ../include/net/bsd_if_var.h:82:0,
                 from ../include/net/bsd_if.h:459,
                 from if_host.c:57:
../include/sys/bsd_buf_ring.h: In function ‘buf_ring_dequeue_sc’:
../include/sys/bsd_buf_ring.h:200:33: warning: variable ‘cons_next_next’ set but not used [-Wunused-but-set-variable]
  uint32_t cons_head, cons_next, cons_next_next;
                                 ^
make[1]: *** [if_host.o] Error 1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;basd__types.h&lt;/code&gt; 파일에 &lt;code&gt;__mbstate_t&lt;/code&gt; 타입을 중복 정의했기 때문에 발생한
문제입니다.  해당 파일에서 해당 정의 부분을 다음과 같이 주석 처리하면 이 문제는
사라집니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;diff --git a/pkgs/libs/uptcpip/src/include/sys/bsd__types.h b/pkgs/libs/uptcpip/src/include/sys/bsd__types.h
index fa1b0f0f26d9..bd7e6a97f4c8 100644
--- a/pkgs/libs/uptcpip/src/include/sys/bsd__types.h
+++ b/pkgs/libs/uptcpip/src/include/sys/bsd__types.h
@@ -93,6 +93,7 @@ typedef       __ct_rune_t     __wint_t;       /* wint_t (see above) */

 typedef        __uint32_t      __fixpt_t;      /* fixed point number */

+#if 0  /* Skip conflicting __mbstate_t definition */
 /*
  * mbstate_t is an opaque object to keep conversion state during multibyte
  * stream conversions.
@@ -104,5 +105,6 @@ typedef union {
        __int64_t       _mbstateL;      /* for alignment */
 } __mbstate_t;
 #endif
+#endif /* Skip conflicting __mbstate_t definition */

 #endif /* !_BSD_SYS__TYPES_H_ */
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;pkgconfig-package-not-found&#34;&gt;pkg-config Package Not Found&lt;/h2&gt;
&lt;p&gt;성공적인 빌드를 위해선 당연하지만 PARSEC 3.0 이 의존성을 가진 패키지가 모두
설치되어 있어야 합니다.  이를 주의 깊게 미리 설치해 두지 않았다면 다음과 같은
에러 메세지를 만날 수도 있습니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;configure: error: *** pkg-config not found. See http://www.freedesktop.org/software/pkgconfig/
[PARSEC] Error: ...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;위 메세지는 &lt;code&gt;pkg-config&lt;/code&gt; 프로그램이 설치되어 있지 않아서 발생한 문제임을 알 수
있습니다.  간단히 Ubuntu 의 package 시스템인 apt 를 사용해 다음과 같이 해당
프로그램을 설치해 주면 문제는 사라집니다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo apt install pkg-config
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;build-success&#34;&gt;Build Success&lt;/h2&gt;
&lt;p&gt;이 정도까지가 나타날 수 있는 대부분의 문제입니다.  위 해결책들을 모두
적용했다면 아마 빌드에 성공할 겁니다.  빌드에 성공하면 다음과 같이 성공했다는
메세지를 볼 수 있을 겁니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[PARSEC]
[PARSEC] BIBLIOGRAPHY
[PARSEC]
[PARSEC] [1] Bienia. Benchmarking Modern Multiprocessors. Ph.D. Thesis, 2011.
[PARSEC] [2] Woo et al. The SPLASH-2 Programs: Characterization and Methodological Considerations. ISCA, 1995.
[PARSEC]
[PARSEC] Done.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;참고로 빌드에 꽤 긴 시간이 소모됩니다.  제가 사용한 72 코어 / 144 쓰레드
머신에서도 약 10분이 걸렸습니다.&lt;/p&gt;
&lt;h1 id=&#34;simple-usage&#34;&gt;Simple Usage&lt;/h1&gt;
&lt;p&gt;이제 빌드가 잘 되었는지 돌려봐야 할 차례입니다.  다음 커맨드는 각 벤치마크를
가장 작은 크기의 데이터셋을 가지고 실행해 보기 때문에 각 벤치마크가 돌아가긴
하는지만 보는데 적격입니다:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;parsecmgmt -a run
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;가장 작은 크기의 데이터셋을 사용하기 때문에 모든 벤치마크를 수행하지만 빠르게
종료됩니다.&lt;/p&gt;
&lt;h2 id=&#34;parsecmgmt-options&#34;&gt;&lt;code&gt;parsecmgmt&lt;/code&gt; Options&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;-a&lt;/code&gt; 옵션은 action 을 의미합니다.  앞의 섹션에서는 빌드를 위해 여기에 &lt;code&gt;build&lt;/code&gt;
값을 주었고, 여기선 벤치마크 수행을 위해 &lt;code&gt;run&lt;/code&gt; 값을 준 것입니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;-i&lt;/code&gt; 옵션을 통해 벤치마크들은 워크로드에서 사용할 데이터 크기를 지정할 수
있습니다.  이 인자의 값으로 test, simdev, simsmall, simmedium, simlarge, native
를 줄 수 있습니다.  Test 는 정확성 테스트만을 위한, 빨리 끝나는 데이터로 이
인자를 주지 않으면 default 로 이 값이 취해집니다.  native 는 가장 realworld
workload 에 가까운 벤치마크를 위한 데이터라 볼 수 있습니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;-p&lt;/code&gt; 옵션을 통해 어떤 sub benchmark 를 돌릴지 정할 수 있습니다.  이 옵션을
별도로 주지 않으면 모든 benchmark 를 돌리게 됩니다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;-n&lt;/code&gt; 옵션은 number of threads to use 입니다.&lt;/p&gt;
&lt;p&gt;예를 들어 &lt;code&gt;parsecmgmt -p canneal -a run -i native -n 1&lt;/code&gt; 은 &lt;code&gt;canneal&lt;/code&gt; sub
benchmark 하나만을 쓰레드 한개 써서 &lt;code&gt;native&lt;/code&gt; 데이터셋으로 실행합니다.&lt;/p&gt;
&lt;h1 id=&#34;references&#34;&gt;References&lt;/h1&gt;
&lt;p&gt;[1] &lt;a href=&#34;http://parsec.cs.princeton.edu&#34;&gt;http://parsec.cs.princeton.edu&lt;/a&gt;&lt;br&gt;
[2] &lt;a href=&#34;https://en.wikipedia.org/wiki/Plain_Old_Documentation&#34;&gt;https://en.wikipedia.org/wiki/Plain_Old_Documentation&lt;/a&gt;&lt;br&gt;
[3] &lt;a href=&#34;https://groups.google.com/forum/#&#34;&gt;https://groups.google.com/forum/#&lt;/a&gt;!topic/snipersim/_1qpbmpPRtg&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Install / execute spec cpu2006 benchmark</title>
      <link>/post/spec_cpu2006_install/</link>
      <pubDate>Wed, 29 Mar 2017 05:10:55 +0900</pubDate>
      <guid>/post/spec_cpu2006_install/</guid>
      <description>&lt;p&gt;SPEC, which is a standard corporation for the benchmark[1], makes and shares
various benchmark suites.  SPEC CPU 2006[1] is one of those benchmark suites.
It has made to measure performance of computation intensive workload and widely
being used now.  It has released v1.0 in 2006, 1.1 in 2008, and 1.2 in 2011.
This post briefly describes the way to install and execute the SPEC CPU 2006
v1.1 on Ubuntu 16.04 servers.&lt;/p&gt;
&lt;h1 id=&#34;automated-toolbox&#34;&gt;Automated Toolbox&lt;/h1&gt;
&lt;p&gt;For those who might say &lt;code&gt;TL; DR&lt;/code&gt;, I wrote a script that can install and execute
the SPEC CPU 2006 with one command[1].  If you have no time to read further,
just use it, please.&lt;/p&gt;
&lt;p&gt;[1] &lt;a href=&#34;https://github.com/sjp38/spec_on_ubuntu_xenial&#34;&gt;https://github.com/sjp38/spec_on_ubuntu_xenial&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;test-environment&#34;&gt;Test Environment&lt;/h1&gt;
&lt;p&gt;The test machine I used for this post has:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Intel Xeon E7-8870 v3&lt;/li&gt;
&lt;li&gt;Linux 4.10 kernel&lt;/li&gt;
&lt;li&gt;Ubuntu 16.04.1 Server version&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;get-the-source-code&#34;&gt;Get The Source Code&lt;/h1&gt;
&lt;p&gt;You should get the source code first.  You can buy SPEC CPU 2006 in DVD or
&lt;code&gt;.iso&lt;/code&gt; file format (As of March 2017, the cost of the SPEC CPU 2006 v1.2 is
$800).
There are source code of the benchmarks, source code of tool programs that
helps compile, execution, and verification of the benchmarks, pre-compiled tool
programs, rule files for the execution of the benchmarks, and documents.
This post is written basedon SPEC CPU 2006 v1.1.
If you got the &lt;code&gt;.iso&lt;/code&gt; file, you can access to the files in it by mounting it as
below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ mkdir tmnt
$ sudo mount -o loop SPEC_CPU2006v1.1.iso ./tmnt
$ ls tmnt
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It is ok to directly install and execute the benchmarks, but I prefer to first
copy the files outside of the mounted dir.
The &lt;code&gt;owner&lt;/code&gt; of the files is &lt;code&gt;root&lt;/code&gt;, as the above command mounted the file via
the &lt;code&gt;sudo&lt;/code&gt; command.
Change the owner to you as below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ mkdir SPEC_CPU2006v1.1
$ cp -R ./tmnt/* SPEC_CPU2006v1.1/
$ sudo umount ./tmnt &amp;amp;&amp;amp; rm -fr ./tmnt
$ sudo chown -R &amp;lt;username&amp;gt; SPEC_CPU2006v1.1
$ sudo chmod -R 755 SPEC_CPU2006v1.1
$ cd SPEC_CPU2006v1.1
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;build-the-tools&#34;&gt;Build The Tools&lt;/h1&gt;
&lt;p&gt;The &lt;code&gt;.iso&lt;/code&gt; file has executable binaries for the tools, which is built for
various platforms such as redhat and suse.
But, there is no binary for Ubuntu.
Therefore, you should build the tools from the source code as below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ cd tools/src
$ ./buildtools
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;buildtools&lt;/code&gt; is a shell script which builds tools under &lt;code&gt;tools/src&lt;/code&gt;.
But, you may encounter some errors.  Following sections describe the errors and
how you can solve it.&lt;/p&gt;
&lt;h2 id=&#34;conflicting-types-for-getline&#34;&gt;Conflicting types for &amp;lsquo;getline&amp;rsquo;&lt;/h2&gt;
&lt;p&gt;Build of &lt;code&gt;md5sum&lt;/code&gt; will show you following error message:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gcc -DHAVE_CONFIG_H    -I/home/sjpark/SPEC_CPU2006v1.1/tools/output/include   -I. -Ilib  -c -o md5sum.o md5sum.c
In file included from md5sum.c:38:0:
lib/getline.h:31:1: error: conflicting types for &#39;getline&#39;
 getline PARAMS ((char **_lineptr, size_t *_n, FILE *_stream));
 ^
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Type conflict is occurred because &lt;code&gt;getline()&lt;/code&gt; and &lt;code&gt;getdelim()&lt;/code&gt; functions are
declared in &lt;code&gt;stdio.h&lt;/code&gt;, but those are declared again in &lt;code&gt;getline.h&lt;/code&gt; file.
You can fix this as below, by checking &lt;code&gt;GLIBC&lt;/code&gt; version.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--- a/tools/src/specmd5sum/lib/getline.h
+++ b/tools/src/specmd5sum/lib/getline.h
@@ -27,10 +27,14 @@ Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.  */
 #  endif
 # endif

+# if __GLIBC__ &amp;lt; 2
+
 int
 getline PARAMS ((char **_lineptr, size_t *_n, FILE *_stream));

 int
 getdelim PARAMS ((char **_lineptr, size_t *_n, int _delimiter, FILE *_stream));

+#endif
+
 #endif /* not GETLINE_H_ */
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;undefined-reference-to-pow&#34;&gt;Undefined reference to &lt;code&gt;pow&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;I referenced an internet post[3] to solve this and following two problems.&lt;/p&gt;
&lt;p&gt;Now, you will see below error message while building &lt;code&gt;perl&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cc -L/home/sjpark/SPEC_CPU2006v1.1/tools/output/lib -L/usr/local/lib -o miniperl \
            miniperlmain.o opmini.o libperl.a
libperl.a(pp.o): In function `Perl_pp_pow&#39;:
pp.c:(.text+0x2a76): undefined reference to `pow&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;It failed to find &lt;code&gt;pow&lt;/code&gt; functiona.  You should modify it to link &lt;code&gt;libm&lt;/code&gt;
library.
You can solve this problem by setting &lt;code&gt;PERLFLAGS&lt;/code&gt; env variable and executing
&lt;code&gt;buildtools&lt;/code&gt; again:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$ PERLFLAGS=&amp;quot;-A libs=-lm -A libs=-ldl&amp;quot; ./buildtools&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&#34;you-havent-done-a-make-depend-yet&#34;&gt;You haven&#39;t done a &amp;ldquo;make depend&amp;rdquo; yet!&lt;/h2&gt;
&lt;p&gt;Now, you see below error message.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;You haven&#39;t done a &amp;quot;make depend&amp;quot; yet!
make[1]: *** [hash.o] Error 1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The &lt;code&gt;bin/sh&lt;/code&gt; which is used while building &lt;code&gt;perl&lt;/code&gt; directs to &lt;code&gt;/bin/dash&lt;/code&gt;.
This problem made by &lt;code&gt;dash&lt;/code&gt;.
Simply modify the symbolic link so that it can use &lt;code&gt;bash&lt;/code&gt; instead.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ sudo rm /bin/sh
$ sudo ln -s /bin/bash /bin/sh
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If you want it to revert this change, simply restore the symbolic link again.&lt;/p&gt;
&lt;h2 id=&#34;asmpageh-file-not-found&#34;&gt;&lt;code&gt;asm/page.h&lt;/code&gt; file not found&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;tools/src/perl-5.8.8/ext/IPC/SysV/SysV.xs&lt;/code&gt; is including a kernel header file,
&lt;code&gt;asm/page.h&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cc -c   -I/home/sjpark/SPEC_CPU2006v1.1/tools/output/include -fno-strict-aliasing -pipe -Wdeclaration-after-statement -I/usr/local/include -D_LARGEFILE_SOURCE -D_FILE_OFFSET_BITS=64 -O2   -DVERSION=\&amp;quot;1.04\&amp;quot; -DXS_VERSION=\&amp;quot;1.04\&amp;quot; -fpic &amp;quot;-I../../..&amp;quot;   SysV.c
SysV.xs:7:25: fatal error: asm/page.h: No such file or directory
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Block the &lt;code&gt;include&lt;/code&gt; statement in the &lt;code&gt;SysV.xs&lt;/code&gt; file and define &lt;code&gt;PAGE_SIZE&lt;/code&gt; as
below.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;--- a/tools/src/perl-5.8.8/ext/IPC/SysV/SysV.xs
+++ b/tools/src/perl-5.8.8/ext/IPC/SysV/SysV.xs
@@ -4,7 +4,7 @@

 #include &amp;lt;sys/types.h&amp;gt;
 #ifdef __linux__
-#   include &amp;lt;asm/page.h&amp;gt;
+#define PAGE_SIZE      4096
 #endif
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;perl-test-fail&#34;&gt;&lt;code&gt;perl&lt;/code&gt; test fail&lt;/h2&gt;
&lt;p&gt;If you apply every solution above and run &lt;code&gt;$ PERLFLAGS=&amp;quot;-A libs=-lm -A libs=-ldl&amp;quot; ./buildtools&lt;/code&gt;, about 9 of 900 tests for the perl fails.
Because those tests are ignorable, just answer to ignore (Simply enter &lt;code&gt;y&lt;/code&gt; as
the prompt explains).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Failed 9 test scripts out of 907, 99.01% okay.
### Since not all tests were successful, you may want to run some of
### them individually and examine any diagnostic messages they produce.
### See the INSTALL document&#39;s section on &amp;quot;make test&amp;quot;.
### You have a good chance to get more information by running
###   ./perl harness
### in the &#39;t&#39; directory since most (&amp;gt;=80%) of the tests succeeded.
### You may have to set your dynamic library search path,
### LD_LIBRARY_PATH, to point to the build directory:
###   setenv LD_LIBRARY_PATH `pwd`:$LD_LIBRARY_PATH; cd t; ./perl harness
###   LD_LIBRARY_PATH=`pwd`:$LD_LIBRARY_PATH; export LD_LIBRARY_PATH; cd t; ./perl harness
###   export LD_LIBRARY_PATH=`pwd`:$LD_LIBRARY_PATH; cd t; ./perl harness
### for csh-style shells, like tcsh; or for traditional/modern
### Bourne-style shells, like bash, ksh, and zsh, respectively.
u=0.92  s=0.69  cu=89.23  cs=5.47  scripts=907  tests=112394
make[2]: *** [_test_tty] Error 1
make[2]: Leaving directory `/home/sjpark/SPEC_CPU2006v1.1/tools/src/perl-5.8.8&#39;
make[1]: *** [_test] Error 2
make[1]: Leaving directory `/home/sjpark/SPEC_CPU2006v1.1/tools/src/perl-5.8.8&#39;
make: *** [test] Error 2
+ &#39;[&#39; 2 -ne 0 &#39;]&#39;
+ set +x


Hey!  Some of the Perl tests failed!  If you think this is okay, enter y now:
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;build-success&#34;&gt;Build success&lt;/h2&gt;
&lt;p&gt;Finally, the build step completes.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Tools built successfully.  Go to the top of the tree and
source the shrc file.  Then you should be ready.
$
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id=&#34;execution&#34;&gt;Execution&lt;/h1&gt;
&lt;h2 id=&#34;configuration-file&#34;&gt;Configuration File&lt;/h2&gt;
&lt;p&gt;Now you can execute the benchmarks.
For this, you should configure the execution environemnts of the benchmarks.
There are example configuration files under &lt;code&gt;config/&lt;/code&gt; dir.&lt;br&gt;
&lt;code&gt;Example-linux64-amd64-gcc43.cfg&lt;/code&gt; would be appropriate for the test system I
use for this post.
You can modify this file as you want.
In my test, I just copied the file to &lt;code&gt;config/config.cfg&lt;/code&gt; file.&lt;/p&gt;
&lt;h2 id=&#34;environment-setup&#34;&gt;Environment Setup&lt;/h2&gt;
&lt;p&gt;For execution of SPEC CPU benchmarks, you should set various environemnt
variables.  Below simple one command do that for you.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ source ./shrc
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;running-workload&#34;&gt;Running Workload&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;runspec&lt;/code&gt; program is used for the execution of each benchmark.
This program is located under &lt;code&gt;bin/&lt;/code&gt; dir of the SPEC CPU source code, but you
can use it directly without entering path, as the above envrionment variables
setting has registered it as &lt;code&gt;$PATH&lt;/code&gt;.
For example, if you want to execute &lt;code&gt;mcf&lt;/code&gt; benchmark, you can use below command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ runspec --iterations 1 --size ref --action onlyrun --config config.cfg --noreportable mcf
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This command executes &lt;code&gt;mcf&lt;/code&gt; benchmark and prints the path to the log file
describing the execution results.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;...

Run Complete

The log for this run is in /home/username/spec/spec_src/result/CPU2006.003.log

runspec finished at Sun Sep 24 13:55:14 2017; 290 total seconds elapsed
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To do some experiments for your particular use case, you should understand the
usage of &lt;code&gt;runspec&lt;/code&gt;.
Because it is an out of scope of this post, reference to other documents,
please.&lt;/p&gt;
&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;This post described the way to run SPEC CPU 2006 on an Ubuntu 16.04 system.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;p&gt;[0] &lt;a href=&#34;http://spec.org/&#34;&gt;http://spec.org/&lt;/a&gt;&lt;br&gt;
[1] &lt;a href=&#34;http://spec.org/benchmarks.html#cpu&#34;&gt;http://spec.org/benchmarks.html#cpu&lt;/a&gt;&lt;br&gt;
[2] &lt;a href=&#34;http://spec.org/order.html&#34;&gt;http://spec.org/order.html&lt;/a&gt;&lt;br&gt;
[3] &lt;a href=&#34;https://wiki.linaro.org/MichaelHope/Sandbox/BuildingSPECTools&#34;&gt;https://wiki.linaro.org/MichaelHope/Sandbox/BuildingSPECTools&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
